# Comparing `tmp/mstrio-py-11.3.9.101.tar.gz` & `tmp/mstrio-py-11.3.9.103.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "mstrio-py-11.3.9.101.tar", last modified: Thu Mar  2 13:21:02 2023, max compression
+gzip compressed data, was "mstrio-py-11.3.9.103.tar", last modified: Thu Apr  6 07:42:01 2023, max compression
```

## Comparing `mstrio-py-11.3.9.101.tar` & `mstrio-py-11.3.9.103.tar`

### file list

```diff
@@ -1,329 +1,342 @@
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:02.075390 mstrio-py-11.3.9.101/
--rw-r--r--   0 mgorski  (128402305) staff       (20)    11424 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/LICENSE
--rw-r--r--   0 mgorski  (128402305) staff       (20)      165 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/MANIFEST.in
--rw-r--r--   0 mgorski  (128402305) staff       (20)    24305 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/NEWS.md
--rw-r--r--   0 mgorski  (128402305) staff       (20)    18619 2023-03-02 13:21:02.075780 mstrio-py-11.3.9.101/PKG-INFO
--rw-r--r--   0 mgorski  (128402305) staff       (20)    17172 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/README.md
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.625211 mstrio-py-11.3.9.101/code_snippets/
--rw-r--r--   0 mgorski  (128402305) staff       (20)    14732 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/attributes.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     4461 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/connect.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3876 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/contact_group_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3964 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/contacts.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1756 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/content_cache.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3514 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/create_super_cube.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3216 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/cube_cache.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2953 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/cube_report.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    16106 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/datasource_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6207 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/device_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5872 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/document.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5628 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/dossier.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2199 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/dynamic_recipient_list.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1620 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/events.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5139 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/fact.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5435 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/filter.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2426 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/intelligent_cube.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3929 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/job_monitor.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    14411 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/metrics.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5926 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/migration.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     7741 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/object_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2840 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/code_snippets/project_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5325 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/reports.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5876 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/schedules.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2013 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/schema_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     7488 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/security_filters.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3153 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/security_roles_and_privileges.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3403 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/server_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     7034 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/subscription_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     9296 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/table_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     7745 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/transformation.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     4625 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/transmitter_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5574 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/user_hierarchy_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2525 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/user_library.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6001 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/code_snippets/user_mgmt.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    30297 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/code_snippets/variables.json
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.637183 mstrio-py-11.3.9.101/connector-jupyter/
--rw-r--r--   0 mgorski  (128402305) staff       (20)        8 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/.gitignore
--rw-r--r--   0 mgorski  (128402305) staff       (20)      211 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/connector-jupyter/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)   152349 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/package-lock.json
--rw-r--r--   0 mgorski  (128402305) staff       (20)      169 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/package.json
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.521030 mstrio-py-11.3.9.101/connector-jupyter/production/
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.520477 mstrio-py-11.3.9.101/connector-jupyter/production/jupyter-config/
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.520650 mstrio-py-11.3.9.101/connector-jupyter/production/jupyter-config/nbconfig/
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.642598 mstrio-py-11.3.9.101/connector-jupyter/production/jupyter-config/nbconfig/notebook.d/
--rw-r--r--   0 mgorski  (128402305) staff       (20)       61 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/jupyter-config/nbconfig/notebook.d/mstr_jupyter.json
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.521195 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.712091 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      924 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/.eslintrc.js
--rw-r--r--   0 mgorski  (128402305) staff       (20)      230 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/MicroStrategy.yaml
--rw-r--r--   0 mgorski  (128402305) staff       (20)      752 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/README.md
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6838 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/cell-button.js
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3655 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/global-override.css
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1504 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/globals.js
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.727273 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      349 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/code-copy.png
--rw-r--r--   0 mgorski  (128402305) staff       (20)      314 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/code-edit.png
--rw-r--r--   0 mgorski  (128402305) staff       (20)      615 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/code-hide.png
--rw-r--r--   0 mgorski  (128402305) staff       (20)      238 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/code-run.png
--rw-r--r--   0 mgorski  (128402305) staff       (20)      471 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/code-show.png
--rw-r--r--   0 mgorski  (128402305) staff       (20)    64545 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/nbextensions-issue.png
--rw-r--r--   0 mgorski  (128402305) staff       (20)      622 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/table-hide.png
--rw-r--r--   0 mgorski  (128402305) staff       (20)      500 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/table-show.png
--rw-r--r--   0 mgorski  (128402305) staff       (20)     7176 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/jupyter-cell.js
--rw-r--r--   0 mgorski  (128402305) staff       (20)    16208 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/jupyter-kernel.js
--rw-r--r--   0 mgorski  (128402305) staff       (20)    20775 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/main.js
--rw-r--r--   0 mgorski  (128402305) staff       (20)    12182 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-cell.js
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.522079 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.732379 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      950 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/asset-manifest.json
--rw-r--r--   0 mgorski  (128402305) staff       (20)      433 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/config.json
--rw-r--r--   0 mgorski  (128402305) staff       (20)      977 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/favicon.ico
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1275 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/index.html
--rw-r--r--   0 mgorski  (128402305) staff       (20)      329 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/manifest.json
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.523524 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.733625 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/css/
--rw-r--r--   0 mgorski  (128402305) staff       (20)   611153 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/css/main.533bed2f.css
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.755460 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/js/
--rw-r--r--   0 mgorski  (128402305) staff       (20)  3079329 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/js/main.e1aca29b.js
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2035 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/js/main.e1aca29b.js.LICENSE.txt
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.764483 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1556 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/draggable_icon.66c4c69fd834208f8758.svg
--rw-r--r--   0 mgorski  (128402305) staff       (20)      882 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon-downarrow.2daf0e97b9f1b62b8cf4.svg
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1056 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon-uparrow.5d0f917ebd433f9b1f54.svg
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1217 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon_success.8e1860fe5dd4347e22d1.svg
--rw-r--r--   0 mgorski  (128402305) staff       (20)    13452 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/loading_icon.3b99fd5019e395faa679.gif
--rw-r--r--   0 mgorski  (128402305) staff       (20)      760 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/sort-indicator-desc-icon.e209fd7505e228248d82.svg
--rw-r--r--   0 mgorski  (128402305) staff       (20)      731 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/sort-indicator-none-icon.809a02a624c7e0ead705.svg
--rw-r--r--   0 mgorski  (128402305) staff       (20)      977 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr.ico
--rw-r--r--   0 mgorski  (128402305) staff       (20)    12797 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/python-code.js
--rw-r--r--   0 mgorski  (128402305) staff       (20)      504 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/ui-iframe.css
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5553 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/utilities.js
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.768863 mstrio-py-11.3.9.101/mstrio/
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1831 2023-03-02 13:20:54.000000 mstrio-py-11.3.9.101/mstrio/__init__.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.774261 mstrio-py-11.3.9.101/mstrio/access_and_security/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      166 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/access_and_security/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10359 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/access_and_security/privilege.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)      173 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/access_and_security/privilege_mode.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    20100 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/access_and_security/security_role.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.844226 mstrio-py-11.3.9.101/mstrio/api/
--rw-r--r--   0 mgorski  (128402305) staff       (20)        0 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/api/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    26184 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/administration.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6895 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/attributes.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5213 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/authentication.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     4846 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/bookmarks.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    14585 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/browsing.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1460 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/changesets.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     4496 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/contact_groups.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3474 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/contacts.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10259 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/cubes.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     8192 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/datasets.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    22158 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/datasources.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3874 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/devices.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    25919 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/documents.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3976 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/events.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2151 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/exceptions.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2511 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/facts.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5320 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/filters.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     9299 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/folders.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1610 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/hierarchies.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1785 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/hooks.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    12740 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/incremental_refresh_reports.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3041 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/api/library.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5004 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/metrics.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    11382 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/migration.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)      954 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/misc.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    45295 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/monitors.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    17630 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/objects.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10852 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/projects.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2766 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/registrations.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     9557 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/reports.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     7053 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/schedules.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2731 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/schema.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5212 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/security.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     8490 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/security_filters.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    21114 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/subscriptions.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     9568 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/tables.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3940 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/transformations.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2981 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/transmitters.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6190 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/user_hierarchies.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    14173 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/usergroups.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    17944 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/api/users.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2035 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/config.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    22055 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/connection.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.852947 mstrio-py-11.3.9.101/mstrio/datasources/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      585 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/datasources/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5626 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/datasources/database_connections.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    22199 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/datasources/datasource_connection.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    20079 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/datasources/datasource_instance.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6923 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/datasources/datasource_login.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    21002 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/datasources/datasource_map.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     4423 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/datasources/dbms.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.855767 mstrio-py-11.3.9.101/mstrio/distribution_services/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      154 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/__init__.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.858902 mstrio-py-11.3.9.101/mstrio/distribution_services/device/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      101 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/device/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10701 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/device/device.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    24068 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/device/device_properties.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5269 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/event.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.862808 mstrio-py-11.3.9.101/mstrio/distribution_services/schedule/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      143 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/schedule/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    25743 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/schedule/schedule.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    35144 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/schedule/schedule_time.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.877524 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      667 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    43382 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/base_subscription.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10956 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/cache_update_subscription.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)      200 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/common.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    13973 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/content.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    20035 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/delivery.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    15712 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/dynamic_recipient_list.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6232 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/email_subscription.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10717 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/file_subscription.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10423 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/ftp_subscription.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10200 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/history_list_subscription.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    11513 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/subscription_manager.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.881745 mstrio-py-11.3.9.101/mstrio/distribution_services/transmitter/
--rw-r--r--   0 mgorski  (128402305) staff       (20)       42 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/transmitter/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    11762 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/distribution_services/transmitter/transmitter.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.882432 mstrio-py-11.3.9.101/mstrio/modeling/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      164 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/__init__.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.894659 mstrio-py-11.3.9.101/mstrio/modeling/expression/
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1495 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/modeling/expression/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     9246 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/expression/dynamic_date_time.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     7929 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/expression/enums.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     9710 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/expression/expression.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    46883 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/expression/expression_nodes.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3575 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/expression/fact_expression.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     8469 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/expression/parameters.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.901646 mstrio-py-11.3.9.101/mstrio/modeling/filter/
--rw-r--r--   0 mgorski  (128402305) staff       (20)       37 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/modeling/filter/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    15005 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/filter/filter.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.907609 mstrio-py-11.3.9.101/mstrio/modeling/metric/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      259 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/metric/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     4061 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/metric/dimensionality.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    29476 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/metric/metric.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    13467 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/metric/metric_format.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.912603 mstrio-py-11.3.9.101/mstrio/modeling/schema/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      322 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/__init__.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.918827 mstrio-py-11.3.9.101/mstrio/modeling/schema/attribute/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      146 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/attribute/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    47086 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/attribute/attribute.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    15865 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/attribute/attribute_form.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3140 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/attribute/relationship.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.921586 mstrio-py-11.3.9.101/mstrio/modeling/schema/fact/
--rw-r--r--   0 mgorski  (128402305) staff       (20)       50 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/fact/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    16780 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/fact/fact.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    14235 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/helpers.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    16272 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/schema_management.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.925811 mstrio-py-11.3.9.101/mstrio/modeling/schema/table/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      105 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/table/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    43459 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/table/logical_table.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    13257 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/table/physical_table.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    25027 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/table/warehouse_table.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.928494 mstrio-py-11.3.9.101/mstrio/modeling/schema/transformation/
--rw-r--r--   0 mgorski  (128402305) staff       (20)       45 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/transformation/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    15899 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/transformation/transformation.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.931248 mstrio-py-11.3.9.101/mstrio/modeling/schema/user_hierarchy/
--rw-r--r--   0 mgorski  (128402305) staff       (20)       45 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/user_hierarchy/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    18318 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/schema/user_hierarchy/user_hierarchy.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.934818 mstrio-py-11.3.9.101/mstrio/modeling/security_filter/
--rw-r--r--   0 mgorski  (128402305) staff       (20)       46 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/modeling/security_filter/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    22752 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/modeling/security_filter/security_filter.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.943372 mstrio-py-11.3.9.101/mstrio/object_management/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      706 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/object_management/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    11679 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/object_management/folder.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.948257 mstrio-py-11.3.9.101/mstrio/object_management/migration/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      229 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/object_management/migration/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    15879 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/object_management/migration/migration.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    22654 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/object_management/migration/package.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     7766 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/object_management/object.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2892 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/object_management/predefined_folders.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1065 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/object_management/search_enums.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    25959 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/object_management/search_operations.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     7702 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/object_management/shortcut.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.953764 mstrio-py-11.3.9.101/mstrio/project_objects/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      404 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10245 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/content_cache.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.958441 mstrio-py-11.3.9.101/mstrio/project_objects/datasets/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      251 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/datasets/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    36697 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/datasets/cube.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    12701 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/datasets/cube_cache.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    18785 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/datasets/olap_cube.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    25399 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/datasets/super_cube.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    16357 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/document.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    14256 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/dossier.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.963771 mstrio-py-11.3.9.101/mstrio/project_objects/incremental_refresh_report/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      116 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/project_objects/incremental_refresh_report/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3759 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/incremental_refresh_report/advanced_properties.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    16329 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/incremental_refresh_report/incremental_refresh_report.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2771 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/incremental_refresh_report/template.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3399 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/library.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    31689 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/project_objects/report.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.970768 mstrio-py-11.3.9.101/mstrio/server/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      450 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/server/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    25253 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/server/cluster.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     8228 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/server/environment.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    29615 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/server/job_monitor.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)      823 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/server/node.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    27974 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/server/project.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     4461 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/server/server.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3130 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/types.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:01.977806 mstrio-py-11.3.9.101/mstrio/users_and_groups/
--rw-r--r--   0 mgorski  (128402305) staff       (20)      509 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/users_and_groups/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    12929 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/users_and_groups/contact.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    11816 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/users_and_groups/contact_group.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    36833 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/users_and_groups/user.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    11106 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/users_and_groups/user_connections.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    23286 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/users_and_groups/user_group.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:02.003981 mstrio-py-11.3.9.101/mstrio/utils/
--rw-r--r--   0 mgorski  (128402305) staff       (20)        0 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/utils/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    27528 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/acl.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     5448 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/api_helpers.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    16937 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/cache.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2321 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/certified_info.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2370 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/datasources.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     8325 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/dependence_mixin.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6920 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/dict_filter.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2428 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/encoder.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    55758 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/entity.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1904 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/enum_helper.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3231 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/error_handlers.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)       45 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/utils/exceptions.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6800 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/filter.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2181 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/formjson.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    42249 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/helper.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10510 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/model.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1915 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/monitors.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     4270 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/object_mapping.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6944 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/parser.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3635 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/progress_bar_mixin.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:02.006209 mstrio-py-11.3.9.101/mstrio/utils/resources/
--rw-r--r--   0 mgorski  (128402305) staff       (20)        0 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/utils/resources/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3060 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/resources/locales.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1341 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/sessions.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:02.009734 mstrio-py-11.3.9.101/mstrio/utils/settings/
--rw-r--r--   0 mgorski  (128402305) staff       (20)        0 2023-03-02 11:20:47.000000 mstrio-py-11.3.9.101/mstrio/utils/settings/__init__.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)    10938 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/settings/base_settings.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     6776 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/settings/setting_types.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)      831 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/settings/settings_helper.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     9925 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/settings/settings_io.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     9211 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/time_helper.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     3987 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/version_helper.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     8103 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/mstrio/utils/wip.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:02.042547 mstrio-py-11.3.9.101/mstrio_py.egg-info/
--rw-r--r--   0 mgorski  (128402305) staff       (20)    18619 2023-03-02 13:21:01.000000 mstrio-py-11.3.9.101/mstrio_py.egg-info/PKG-INFO
--rw-r--r--   0 mgorski  (128402305) staff       (20)    11532 2023-03-02 13:21:01.000000 mstrio-py-11.3.9.101/mstrio_py.egg-info/SOURCES.txt
--rw-r--r--   0 mgorski  (128402305) staff       (20)        1 2023-03-02 13:21:01.000000 mstrio-py-11.3.9.101/mstrio_py.egg-info/dependency_links.txt
--rw-r--r--   0 mgorski  (128402305) staff       (20)      468 2023-03-02 13:21:01.000000 mstrio-py-11.3.9.101/mstrio_py.egg-info/requires.txt
--rw-r--r--   0 mgorski  (128402305) staff       (20)       31 2023-03-02 13:21:01.000000 mstrio-py-11.3.9.101/mstrio_py.egg-info/top_level.txt
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2160 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/requirements.txt
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1305 2023-03-02 13:21:02.077359 mstrio-py-11.3.9.101/setup.cfg
--rw-r--r--   0 mgorski  (128402305) staff       (20)     4106 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/setup.py
-drwxr-xr-x   0 mgorski  (128402305) staff       (20)        0 2023-03-02 13:21:02.074765 mstrio-py-11.3.9.101/workflows/
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1800 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/workflows/add_email_to_new_users.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1514 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/workflows/delete_addresses_from_departed_users.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2108 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/workflows/delete_inactive_cube_caches.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2086 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/workflows/delete_subscriptions_of_departed_users.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2429 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/workflows/get_all_columns_in_table.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     1445 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/workflows/list_active_user_privileges.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)      981 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/workflows/list_empty_user_groups.py
--rw-r--r--   0 mgorski  (128402305) staff       (20)     2923 2023-03-02 11:21:53.000000 mstrio-py-11.3.9.101/workflows/list_security_roles_per_user.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.798613 mstrio-py-11.3.9.103/
+-rw-rw-r--   0 root         (0) root         (0)    11424 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/LICENSE
+-rw-rw-r--   0 root         (0) root         (0)      165 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/MANIFEST.in
+-rw-rw-r--   0 root         (0) root         (0)    26053 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/NEWS.md
+-rw-r--r--   0 root         (0) root         (0)    19001 2023-04-06 07:42:01.802613 mstrio-py-11.3.9.103/PKG-INFO
+-rw-rw-r--   0 root         (0) root         (0)    17554 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/README.md
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.734613 mstrio-py-11.3.9.103/code_snippets/
+-rw-rw-r--   0 root         (0) root         (0)    14732 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/attributes.py
+-rw-rw-r--   0 root         (0) root         (0)     4461 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/connect.py
+-rw-rw-r--   0 root         (0) root         (0)     3876 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/contact_group_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     3964 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/contacts.py
+-rw-rw-r--   0 root         (0) root         (0)     1756 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/content_cache.py
+-rw-rw-r--   0 root         (0) root         (0)     4643 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/create_super_cube.py
+-rw-rw-r--   0 root         (0) root         (0)     3216 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/cube_cache.py
+-rw-rw-r--   0 root         (0) root         (0)     2953 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/cube_report.py
+-rw-rw-r--   0 root         (0) root         (0)    18387 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/datasource_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     6207 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/device_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     5872 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/document.py
+-rw-rw-r--   0 root         (0) root         (0)     5628 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/dossier.py
+-rw-rw-r--   0 root         (0) root         (0)     2199 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/dynamic_recipient_list.py
+-rw-rw-r--   0 root         (0) root         (0)     1620 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/events.py
+-rw-rw-r--   0 root         (0) root         (0)     5139 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/fact.py
+-rw-rw-r--   0 root         (0) root         (0)     5435 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/filter.py
+-rw-rw-r--   0 root         (0) root         (0)     2426 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/intelligent_cube.py
+-rw-rw-r--   0 root         (0) root         (0)     3929 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/job_monitor.py
+-rw-rw-r--   0 root         (0) root         (0)    14411 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/metrics.py
+-rw-rw-r--   0 root         (0) root         (0)     5926 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/migration.py
+-rw-rw-r--   0 root         (0) root         (0)     7741 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/object_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     3678 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/project_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     5325 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/reports.py
+-rw-rw-r--   0 root         (0) root         (0)     5876 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/schedules.py
+-rw-rw-r--   0 root         (0) root         (0)     2013 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/schema_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     7488 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/security_filters.py
+-rw-rw-r--   0 root         (0) root         (0)     3153 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/security_roles_and_privileges.py
+-rw-rw-r--   0 root         (0) root         (0)     3403 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/server_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     7161 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/subscription_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     9296 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/table_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     7745 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/transformation.py
+-rw-rw-r--   0 root         (0) root         (0)     4625 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/transmitter_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     5574 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/user_hierarchy_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)     2525 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/user_library.py
+-rw-rw-r--   0 root         (0) root         (0)     6001 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/user_mgmt.py
+-rw-rw-r--   0 root         (0) root         (0)    31764 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/variables.json
+-rw-rw-r--   0 root         (0) root         (0)     5739 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/code_snippets/vldb.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.734613 mstrio-py-11.3.9.103/connector-jupyter/
+-rw-rw-r--   0 root         (0) root         (0)        8 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/.gitignore
+-rw-rw-r--   0 root         (0) root         (0)      233 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)   152349 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/package-lock.json
+-rw-rw-r--   0 root         (0) root         (0)      169 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/package.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.718613 mstrio-py-11.3.9.103/connector-jupyter/production/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.718613 mstrio-py-11.3.9.103/connector-jupyter/production/jupyter-config/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.718613 mstrio-py-11.3.9.103/connector-jupyter/production/jupyter-config/nbconfig/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.734613 mstrio-py-11.3.9.103/connector-jupyter/production/jupyter-config/nbconfig/notebook.d/
+-rw-rw-r--   0 root         (0) root         (0)       61 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/jupyter-config/nbconfig/notebook.d/mstr_jupyter.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.718613 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.738613 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/
+-rw-rw-r--   0 root         (0) root         (0)      924 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/.eslintrc.js
+-rw-rw-r--   0 root         (0) root         (0)      230 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/MicroStrategy.yaml
+-rw-rw-r--   0 root         (0) root         (0)      752 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/README.md
+-rw-rw-r--   0 root         (0) root         (0)     6838 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/cell-button.js
+-rw-rw-r--   0 root         (0) root         (0)     3655 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/global-override.css
+-rw-rw-r--   0 root         (0) root         (0)     1504 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/globals.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.738613 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/
+-rw-rw-r--   0 root         (0) root         (0)      349 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/code-copy.png
+-rw-rw-r--   0 root         (0) root         (0)      314 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/code-edit.png
+-rw-rw-r--   0 root         (0) root         (0)      615 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/code-hide.png
+-rw-rw-r--   0 root         (0) root         (0)      238 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/code-run.png
+-rw-rw-r--   0 root         (0) root         (0)      471 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/code-show.png
+-rw-rw-r--   0 root         (0) root         (0)    64545 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/nbextensions-issue.png
+-rw-rw-r--   0 root         (0) root         (0)      622 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/table-hide.png
+-rw-rw-r--   0 root         (0) root         (0)      500 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/table-show.png
+-rw-rw-r--   0 root         (0) root         (0)     7176 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/jupyter-cell.js
+-rw-rw-r--   0 root         (0) root         (0)    16208 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/jupyter-kernel.js
+-rw-rw-r--   0 root         (0) root         (0)    20775 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/main.js
+-rw-rw-r--   0 root         (0) root         (0)    12182 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-cell.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.722613 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.742613 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/
+-rw-rw-r--   0 root         (0) root         (0)      950 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/asset-manifest.json
+-rw-rw-r--   0 root         (0) root         (0)      433 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/config.json
+-rw-rw-r--   0 root         (0) root         (0)      977 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/favicon.ico
+-rw-rw-r--   0 root         (0) root         (0)     1275 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/index.html
+-rw-rw-r--   0 root         (0) root         (0)      329 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/manifest.json
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.722613 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.742613 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/css/
+-rw-rw-r--   0 root         (0) root         (0)   611153 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/css/main.533bed2f.css
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.746613 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/js/
+-rw-rw-r--   0 root         (0) root         (0)  3079329 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/js/main.e1aca29b.js
+-rw-rw-r--   0 root         (0) root         (0)     2035 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/js/main.e1aca29b.js.LICENSE.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.746613 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/
+-rw-rw-r--   0 root         (0) root         (0)     1556 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/draggable_icon.66c4c69fd834208f8758.svg
+-rw-rw-r--   0 root         (0) root         (0)      882 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon-downarrow.2daf0e97b9f1b62b8cf4.svg
+-rw-rw-r--   0 root         (0) root         (0)     1056 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon-uparrow.5d0f917ebd433f9b1f54.svg
+-rw-rw-r--   0 root         (0) root         (0)     1217 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon_success.8e1860fe5dd4347e22d1.svg
+-rw-rw-r--   0 root         (0) root         (0)    13452 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/loading_icon.3b99fd5019e395faa679.gif
+-rw-rw-r--   0 root         (0) root         (0)      760 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/sort-indicator-desc-icon.e209fd7505e228248d82.svg
+-rw-rw-r--   0 root         (0) root         (0)      731 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/sort-indicator-none-icon.809a02a624c7e0ead705.svg
+-rw-rw-r--   0 root         (0) root         (0)      977 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr.ico
+-rw-rw-r--   0 root         (0) root         (0)    12797 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/python-code.js
+-rw-rw-r--   0 root         (0) root         (0)      504 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/ui-iframe.css
+-rw-rw-r--   0 root         (0) root         (0)     5553 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/utilities.js
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.746613 mstrio-py-11.3.9.103/mstrio/
+-rw-rw-r--   0 root         (0) root         (0)     1831 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.746613 mstrio-py-11.3.9.103/mstrio/access_and_security/
+-rw-rw-r--   0 root         (0) root         (0)      166 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/access_and_security/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    10625 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/access_and_security/privilege.py
+-rw-rw-r--   0 root         (0) root         (0)      173 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/access_and_security/privilege_mode.py
+-rw-rw-r--   0 root         (0) root         (0)    20812 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/access_and_security/security_role.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.758613 mstrio-py-11.3.9.103/mstrio/api/
+-rw-rw-r--   0 root         (0) root         (0)        0 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    26545 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/administration.py
+-rw-rw-r--   0 root         (0) root         (0)     6904 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/attributes.py
+-rw-rw-r--   0 root         (0) root         (0)     5218 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/authentication.py
+-rw-rw-r--   0 root         (0) root         (0)     4852 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/bookmarks.py
+-rw-rw-r--   0 root         (0) root         (0)    14585 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/browsing.py
+-rw-rw-r--   0 root         (0) root         (0)     1521 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/changesets.py
+-rw-rw-r--   0 root         (0) root         (0)     4540 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/contact_groups.py
+-rw-rw-r--   0 root         (0) root         (0)     3481 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/contacts.py
+-rw-rw-r--   0 root         (0) root         (0)    10353 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/cubes.py
+-rw-rw-r--   0 root         (0) root         (0)     8236 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/datasets.py
+-rw-rw-r--   0 root         (0) root         (0)    24567 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/datasources.py
+-rw-rw-r--   0 root         (0) root         (0)     3901 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/devices.py
+-rw-rw-r--   0 root         (0) root         (0)    26299 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/documents.py
+-rw-rw-r--   0 root         (0) root         (0)     1757 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/drivers.py
+-rw-rw-r--   0 root         (0) root         (0)     3990 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/events.py
+-rw-rw-r--   0 root         (0) root         (0)     2173 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/exceptions.py
+-rw-rw-r--   0 root         (0) root         (0)     2610 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/facts.py
+-rw-rw-r--   0 root         (0) root         (0)     5298 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/filters.py
+-rw-rw-r--   0 root         (0) root         (0)     9260 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/folders.py
+-rw-rw-r--   0 root         (0) root         (0)     1157 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/gateways.py
+-rw-rw-r--   0 root         (0) root         (0)     1727 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/hierarchies.py
+-rw-rw-r--   0 root         (0) root         (0)     1796 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/hooks.py
+-rw-rw-r--   0 root         (0) root         (0)    12866 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/incremental_refresh_reports.py
+-rw-rw-r--   0 root         (0) root         (0)     3041 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/library.py
+-rw-rw-r--   0 root         (0) root         (0)     5012 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/metrics.py
+-rw-rw-r--   0 root         (0) root         (0)    11313 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/migration.py
+-rw-rw-r--   0 root         (0) root         (0)      955 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/misc.py
+-rw-rw-r--   0 root         (0) root         (0)    45546 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/monitors.py
+-rw-rw-r--   0 root         (0) root         (0)    17871 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/objects.py
+-rw-rw-r--   0 root         (0) root         (0)    13066 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/projects.py
+-rw-rw-r--   0 root         (0) root         (0)     2788 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/registrations.py
+-rw-rw-r--   0 root         (0) root         (0)     9611 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/reports.py
+-rw-rw-r--   0 root         (0) root         (0)     7104 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/schedules.py
+-rw-rw-r--   0 root         (0) root         (0)     2740 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/schema.py
+-rw-rw-r--   0 root         (0) root         (0)     5286 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/security.py
+-rw-rw-r--   0 root         (0) root         (0)     8483 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/security_filters.py
+-rw-rw-r--   0 root         (0) root         (0)    21140 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/subscriptions.py
+-rw-rw-r--   0 root         (0) root         (0)     9482 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/tables.py
+-rw-rw-r--   0 root         (0) root         (0)     3879 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/transformations.py
+-rw-rw-r--   0 root         (0) root         (0)     2987 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/transmitters.py
+-rw-rw-r--   0 root         (0) root         (0)     6161 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/user_hierarchies.py
+-rw-rw-r--   0 root         (0) root         (0)    14214 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/usergroups.py
+-rw-rw-r--   0 root         (0) root         (0)    17944 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/api/users.py
+-rw-rw-r--   0 root         (0) root         (0)     2057 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/config.py
+-rw-rw-r--   0 root         (0) root         (0)    22452 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/connection.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.758613 mstrio-py-11.3.9.103/mstrio/datasources/
+-rw-rw-r--   0 root         (0) root         (0)      751 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/datasources/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)     5793 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/datasources/database_connections.py
+-rw-rw-r--   0 root         (0) root         (0)    22908 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/datasources/datasource_connection.py
+-rw-rw-r--   0 root         (0) root         (0)    20838 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/datasources/datasource_instance.py
+-rw-rw-r--   0 root         (0) root         (0)     7213 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/datasources/datasource_login.py
+-rw-rw-r--   0 root         (0) root         (0)    21084 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/datasources/datasource_map.py
+-rw-rw-r--   0 root         (0) root         (0)     4572 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/datasources/dbms.py
+-rw-rw-r--   0 root         (0) root         (0)     5663 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/datasources/driver.py
+-rw-rw-r--   0 root         (0) root         (0)     4253 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/datasources/gateway.py
+-rw-rw-r--   0 root         (0) root         (0)     3409 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/datasources/helpers.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.762613 mstrio-py-11.3.9.103/mstrio/distribution_services/
+-rw-rw-r--   0 root         (0) root         (0)      154 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.762613 mstrio-py-11.3.9.103/mstrio/distribution_services/device/
+-rw-rw-r--   0 root         (0) root         (0)      101 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/device/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    11220 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/device/device.py
+-rw-rw-r--   0 root         (0) root         (0)    24699 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/device/device_properties.py
+-rw-rw-r--   0 root         (0) root         (0)     5285 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/event.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.762613 mstrio-py-11.3.9.103/mstrio/distribution_services/schedule/
+-rw-rw-r--   0 root         (0) root         (0)      144 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/schedule/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    26143 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/schedule/schedule.py
+-rw-rw-r--   0 root         (0) root         (0)    36078 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/schedule/schedule_time.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.766613 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/
+-rw-rw-r--   0 root         (0) root         (0)      668 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    45616 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/base_subscription.py
+-rw-rw-r--   0 root         (0) root         (0)    11621 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/cache_update_subscription.py
+-rw-rw-r--   0 root         (0) root         (0)      200 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/common.py
+-rw-rw-r--   0 root         (0) root         (0)    14098 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/content.py
+-rw-rw-r--   0 root         (0) root         (0)    20446 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/delivery.py
+-rw-rw-r--   0 root         (0) root         (0)    16147 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/dynamic_recipient_list.py
+-rw-rw-r--   0 root         (0) root         (0)     6511 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/email_subscription.py
+-rw-rw-r--   0 root         (0) root         (0)    11358 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/file_subscription.py
+-rw-rw-r--   0 root         (0) root         (0)    11061 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/ftp_subscription.py
+-rw-rw-r--   0 root         (0) root         (0)    10838 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/history_list_subscription.py
+-rw-rw-r--   0 root         (0) root         (0)    11830 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/subscription_manager.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.766613 mstrio-py-11.3.9.103/mstrio/distribution_services/transmitter/
+-rw-rw-r--   0 root         (0) root         (0)       42 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/transmitter/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    12186 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/distribution_services/transmitter/transmitter.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.766613 mstrio-py-11.3.9.103/mstrio/modeling/
+-rw-rw-r--   0 root         (0) root         (0)      165 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.770613 mstrio-py-11.3.9.103/mstrio/modeling/expression/
+-rw-rw-r--   0 root         (0) root         (0)     1495 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/expression/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)     9357 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/expression/dynamic_date_time.py
+-rw-rw-r--   0 root         (0) root         (0)     7936 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/expression/enums.py
+-rw-rw-r--   0 root         (0) root         (0)     9790 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/expression/expression.py
+-rw-rw-r--   0 root         (0) root         (0)    47167 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/expression/expression_nodes.py
+-rw-rw-r--   0 root         (0) root         (0)     3600 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/expression/fact_expression.py
+-rw-rw-r--   0 root         (0) root         (0)     8485 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/expression/parameters.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.770613 mstrio-py-11.3.9.103/mstrio/modeling/filter/
+-rw-rw-r--   0 root         (0) root         (0)       37 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/filter/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    15391 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/filter/filter.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.770613 mstrio-py-11.3.9.103/mstrio/modeling/metric/
+-rw-rw-r--   0 root         (0) root         (0)      289 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/metric/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)     4096 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/metric/dimensionality.py
+-rw-rw-r--   0 root         (0) root         (0)    30289 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/metric/metric.py
+-rw-rw-r--   0 root         (0) root         (0)    13585 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/metric/metric_format.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.770613 mstrio-py-11.3.9.103/mstrio/modeling/schema/
+-rw-rw-r--   0 root         (0) root         (0)      323 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.770613 mstrio-py-11.3.9.103/mstrio/modeling/schema/attribute/
+-rw-rw-r--   0 root         (0) root         (0)      164 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/attribute/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    48897 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/attribute/attribute.py
+-rw-rw-r--   0 root         (0) root         (0)    16058 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/attribute/attribute_form.py
+-rw-rw-r--   0 root         (0) root         (0)     3380 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/attribute/relationship.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.774613 mstrio-py-11.3.9.103/mstrio/modeling/schema/fact/
+-rw-rw-r--   0 root         (0) root         (0)       50 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/fact/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    17182 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/fact/fact.py
+-rw-rw-r--   0 root         (0) root         (0)    14297 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/helpers.py
+-rw-rw-r--   0 root         (0) root         (0)    16367 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/schema_management.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.774613 mstrio-py-11.3.9.103/mstrio/modeling/schema/table/
+-rw-rw-r--   0 root         (0) root         (0)      105 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/table/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    44315 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/table/logical_table.py
+-rw-rw-r--   0 root         (0) root         (0)    13185 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/table/physical_table.py
+-rw-rw-r--   0 root         (0) root         (0)    25307 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/table/warehouse_table.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.774613 mstrio-py-11.3.9.103/mstrio/modeling/schema/transformation/
+-rw-rw-r--   0 root         (0) root         (0)       45 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/transformation/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    16548 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/transformation/transformation.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.774613 mstrio-py-11.3.9.103/mstrio/modeling/schema/user_hierarchy/
+-rw-rw-r--   0 root         (0) root         (0)       45 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/user_hierarchy/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    18808 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/schema/user_hierarchy/user_hierarchy.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.774613 mstrio-py-11.3.9.103/mstrio/modeling/security_filter/
+-rw-rw-r--   0 root         (0) root         (0)       46 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/security_filter/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    23356 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/modeling/security_filter/security_filter.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.778613 mstrio-py-11.3.9.103/mstrio/object_management/
+-rw-rw-r--   0 root         (0) root         (0)      741 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/object_management/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    11806 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/object_management/folder.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.778613 mstrio-py-11.3.9.103/mstrio/object_management/migration/
+-rw-rw-r--   0 root         (0) root         (0)      276 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/object_management/migration/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    16280 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/object_management/migration/migration.py
+-rw-rw-r--   0 root         (0) root         (0)    22902 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/object_management/migration/package.py
+-rw-rw-r--   0 root         (0) root         (0)     7939 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/object_management/object.py
+-rw-rw-r--   0 root         (0) root         (0)     2893 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/object_management/predefined_folders.py
+-rw-rw-r--   0 root         (0) root         (0)     1068 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/object_management/search_enums.py
+-rw-rw-r--   0 root         (0) root         (0)    26247 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/object_management/search_operations.py
+-rw-rw-r--   0 root         (0) root         (0)     7807 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/object_management/shortcut.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.778613 mstrio-py-11.3.9.103/mstrio/project_objects/
+-rw-rw-r--   0 root         (0) root         (0)      405 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    10453 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/content_cache.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.782613 mstrio-py-11.3.9.103/mstrio/project_objects/datasets/
+-rw-rw-r--   0 root         (0) root         (0)      366 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/datasets/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    37760 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/datasets/cube.py
+-rw-rw-r--   0 root         (0) root         (0)    12893 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/datasets/cube_cache.py
+-rw-rw-r--   0 root         (0) root         (0)    19048 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/datasets/olap_cube.py
+-rw-rw-r--   0 root         (0) root         (0)    28049 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/datasets/super_cube.py
+-rw-rw-r--   0 root         (0) root         (0)    16598 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/document.py
+-rw-rw-r--   0 root         (0) root         (0)    14374 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/dossier.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.782613 mstrio-py-11.3.9.103/mstrio/project_objects/incremental_refresh_report/
+-rw-rw-r--   0 root         (0) root         (0)      116 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/incremental_refresh_report/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)     3831 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/incremental_refresh_report/advanced_properties.py
+-rw-rw-r--   0 root         (0) root         (0)    16615 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/incremental_refresh_report/incremental_refresh_report.py
+-rw-rw-r--   0 root         (0) root         (0)     2770 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/incremental_refresh_report/template.py
+-rw-rw-r--   0 root         (0) root         (0)     3398 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/library.py
+-rw-rw-r--   0 root         (0) root         (0)    32464 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/project_objects/report.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.786613 mstrio-py-11.3.9.103/mstrio/server/
+-rw-rw-r--   0 root         (0) root         (0)      477 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/server/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    25872 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/server/cluster.py
+-rw-rw-r--   0 root         (0) root         (0)     8293 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/server/environment.py
+-rw-rw-r--   0 root         (0) root         (0)    29837 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/server/job_monitor.py
+-rw-rw-r--   0 root         (0) root         (0)      820 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/server/node.py
+-rw-rw-r--   0 root         (0) root         (0)    29143 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/server/project.py
+-rw-rw-r--   0 root         (0) root         (0)     4461 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/server/server.py
+-rw-rw-r--   0 root         (0) root         (0)     3086 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/types.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.786613 mstrio-py-11.3.9.103/mstrio/users_and_groups/
+-rw-rw-r--   0 root         (0) root         (0)      522 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/users_and_groups/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    13305 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/users_and_groups/contact.py
+-rw-rw-r--   0 root         (0) root         (0)    12213 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/users_and_groups/contact_group.py
+-rw-rw-r--   0 root         (0) root         (0)    37594 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/users_and_groups/user.py
+-rw-rw-r--   0 root         (0) root         (0)    11344 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/users_and_groups/user_connections.py
+-rw-rw-r--   0 root         (0) root         (0)    23890 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/users_and_groups/user_group.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.794613 mstrio-py-11.3.9.103/mstrio/utils/
+-rw-rw-r--   0 root         (0) root         (0)        0 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    28197 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/acl.py
+-rw-rw-r--   0 root         (0) root         (0)     5640 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/api_helpers.py
+-rw-rw-r--   0 root         (0) root         (0)    17276 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/cache.py
+-rw-rw-r--   0 root         (0) root         (0)     2346 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/certified_info.py
+-rw-rw-r--   0 root         (0) root         (0)     2444 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/datasources.py
+-rw-rw-r--   0 root         (0) root         (0)     8344 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/dependence_mixin.py
+-rw-rw-r--   0 root         (0) root         (0)     7082 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/dict_filter.py
+-rw-rw-r--   0 root         (0) root         (0)     2420 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/encoder.py
+-rw-rw-r--   0 root         (0) root         (0)    56753 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/entity.py
+-rw-rw-r--   0 root         (0) root         (0)     1948 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/enum_helper.py
+-rw-rw-r--   0 root         (0) root         (0)     3262 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/error_handlers.py
+-rw-rw-r--   0 root         (0) root         (0)       45 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/exceptions.py
+-rw-rw-r--   0 root         (0) root         (0)     6894 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/filter.py
+-rw-rw-r--   0 root         (0) root         (0)     2139 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/formjson.py
+-rw-rw-r--   0 root         (0) root         (0)    45262 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/helper.py
+-rw-rw-r--   0 root         (0) root         (0)    10865 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/model.py
+-rw-rw-r--   0 root         (0) root         (0)     2084 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/monitors.py
+-rw-rw-r--   0 root         (0) root         (0)     4244 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/object_mapping.py
+-rw-rw-r--   0 root         (0) root         (0)     7485 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/parser.py
+-rw-rw-r--   0 root         (0) root         (0)     3650 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/progress_bar_mixin.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.794613 mstrio-py-11.3.9.103/mstrio/utils/resources/
+-rw-rw-r--   0 root         (0) root         (0)        0 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/resources/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)     3081 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/resources/locales.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.794613 mstrio-py-11.3.9.103/mstrio/utils/response_processors/
+-rw-rw-r--   0 root         (0) root         (0)        0 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/response_processors/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)     1362 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/response_processors/drivers.py
+-rw-rw-r--   0 root         (0) root         (0)      988 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/response_processors/gateways.py
+-rw-rw-r--   0 root         (0) root         (0)      926 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/response_processors/objects.py
+-rw-rw-r--   0 root         (0) root         (0)     1373 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/sessions.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.794613 mstrio-py-11.3.9.103/mstrio/utils/settings/
+-rw-rw-r--   0 root         (0) root         (0)        0 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/settings/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    11023 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/settings/base_settings.py
+-rw-rw-r--   0 root         (0) root         (0)     6884 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/settings/setting_types.py
+-rw-rw-r--   0 root         (0) root         (0)      829 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/settings/settings_helper.py
+-rw-rw-r--   0 root         (0) root         (0)    10093 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/settings/settings_io.py
+-rw-rw-r--   0 root         (0) root         (0)     9426 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/time_helper.py
+-rw-rw-r--   0 root         (0) root         (0)     3967 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/version_helper.py
+-rw-rw-r--   0 root         (0) root         (0)    15825 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/vldb_mixin.py
+-rw-rw-r--   0 root         (0) root         (0)     8127 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/mstrio/utils/wip.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.798613 mstrio-py-11.3.9.103/mstrio_py.egg-info/
+-rw-r--r--   0 root         (0) root         (0)    19001 2023-04-06 07:42:01.000000 mstrio-py-11.3.9.103/mstrio_py.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)    11905 2023-04-06 07:42:01.000000 mstrio-py-11.3.9.103/mstrio_py.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2023-04-06 07:42:01.000000 mstrio-py-11.3.9.103/mstrio_py.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0) root         (0)      509 2023-04-06 07:42:01.000000 mstrio-py-11.3.9.103/mstrio_py.egg-info/requires.txt
+-rw-r--r--   0 root         (0) root         (0)       31 2023-04-06 07:42:01.000000 mstrio-py-11.3.9.103/mstrio_py.egg-info/top_level.txt
+-rw-rw-r--   0 root         (0) root         (0)     2198 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/requirements.txt
+-rw-rw-r--   0 root         (0) root         (0)      661 2023-04-06 07:42:01.802613 mstrio-py-11.3.9.103/setup.cfg
+-rw-rw-r--   0 root         (0) root         (0)     4480 2023-04-06 07:40:38.000000 mstrio-py-11.3.9.103/setup.py
+-rw-rw-r--   0 root         (0) root         (0)       10 2023-04-06 07:41:50.000000 mstrio-py-11.3.9.103/version.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-06 07:42:01.798613 mstrio-py-11.3.9.103/workflows/
+-rw-rw-r--   0 root         (0) root         (0)     1806 2023-04-06 07:40:39.000000 mstrio-py-11.3.9.103/workflows/add_email_to_new_users.py
+-rw-rw-r--   0 root         (0) root         (0)     1563 2023-04-06 07:40:39.000000 mstrio-py-11.3.9.103/workflows/delete_addresses_from_departed_users.py
+-rw-rw-r--   0 root         (0) root         (0)     2126 2023-04-06 07:40:39.000000 mstrio-py-11.3.9.103/workflows/delete_inactive_cube_caches.py
+-rw-rw-r--   0 root         (0) root         (0)     2107 2023-04-06 07:40:39.000000 mstrio-py-11.3.9.103/workflows/delete_subscriptions_of_departed_users.py
+-rw-rw-r--   0 root         (0) root         (0)     2486 2023-04-06 07:40:39.000000 mstrio-py-11.3.9.103/workflows/get_all_columns_in_table.py
+-rw-rw-r--   0 root         (0) root         (0)     1482 2023-04-06 07:40:39.000000 mstrio-py-11.3.9.103/workflows/list_active_user_privileges.py
+-rw-rw-r--   0 root         (0) root         (0)      995 2023-04-06 07:40:39.000000 mstrio-py-11.3.9.103/workflows/list_empty_user_groups.py
+-rw-rw-r--   0 root         (0) root         (0)     2939 2023-04-06 07:40:39.000000 mstrio-py-11.3.9.103/workflows/list_security_roles_per_user.py
```

### Comparing `mstrio-py-11.3.9.101/LICENSE` & `mstrio-py-11.3.9.103/LICENSE`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/NEWS.md` & `mstrio-py-11.3.9.103/NEWS.md`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,41 @@
 # Changelog
 
+## 11.3.9.103 - 2023/05/05
+
+### Major changes
+- added `list_vldb_settings`, `alter_vldb_settings` and `reset_vldb_settings`
+  methods to `DatasourceInstance` class and `Project` class to allow management
+  of VLDB settings
+- added `Driver` class and `list_drivers` function in `mstrio.datasources.driver`
+  module to allow driver management
+- added `Gateway` class and `list_gateways` function in `mstrio.datasources.gateways`
+  module and `GatewayType` and `DBType` enums in `mstrio.datasources.helpers` to
+  allow gateway management
+
+### Minor changes
+- updated `ipython` dependency version to 8.10.0
+- added a `project_id` property for `Metric` instances
+- fixed `is_logical_size_locked` for `LogicalTable` to be working as boolean
+- fixed `list_logical_tables` function to return all tables if called without
+  specifying `project_id` or `project_name`, unless limit argument is provided
+- fixed `Attribute`, `Document`, `Fact`, `Filter`, `Metric`, `Transformation`,
+  `IncrementalRefreshReport` classes to be initialized by name with 
+  `SearchPattern.EXACTLY` instead of `SearchPattern.CONTAINS`
+- fixed `list_objects` function to accept integer as input for `object_type` argument
+- fixed `User.security_filters` property to always return all user's security filters
+  from all loaded projects
+- added `delivery_expiration_timezone` argument for `Subscription` class and its subclasses
+  (supported from Update 10 environments)
+- fixed `Attribute` objects always returning `None` for `hidden` field and fixed
+  `alter` method to allow updating it
+- added `SuperCubeAttribute`, `SupperCubeAttributeForm`, `SuperCubeFormExpression`
+  classes in `mstrio.project_objects.datasets.super_cube` module to support attribute
+  forms for `SuperCube`
+
 ## 11.3.9.101 - 2023/03/03
 
 ### Major changes
 - added `HistoryListSubscription`, `FTPSubscription` and `FileSubscription`
   classes in `mstrio.distribution_services.subscription` package to allow
   management of new subscription types
 - added `DynamicRecipientList` class in `mstrio_distribution_services.subscription`
```

### Comparing `mstrio-py-11.3.9.101/PKG-INFO` & `mstrio-py-11.3.9.103/PKG-INFO`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mstrio-py
-Version: 11.3.9.101
+Version: 11.3.9.103
 Summary: Python interface for the MicroStrategy REST API
 Home-page: https://github.com/MicroStrategy/mstrio-py
 Author: MicroStrategy
 Author-email: pkowal@microstrategy.com
 License: Apache License 2.0
 Project-URL: Bug Tracker, https://github.com/MicroStrategy/mstrio-py/issues
 Project-URL: Documentation, http://www2.microstrategy.com/producthelp/Current/mstrio-py/
@@ -79,25 +79,27 @@
 
 - Import and filter data from a **OlapCube**, **SuperCube** or **Report** into a Pandas DataFrame (see [code_snippets][code_snippet_import])
 - Export data into MicroStrategy by creating or updating **SuperCube** (see [code_snippets][code_snippet_export])
 
 Since version **11.3.0.1**, **mstrio-py** includes also administration modules:
 
 - **Project** management module (see [code_snippets][code_snippet_project])
+with **VLDB settings** management (see [code_snippets][code_snippet_vldb])
 - **Server** management module (see [code_snippets][code_snippet_server])
 - **User** and **User Group** management modules (see [code_snippets][code_snippet_user])
 - **Schedules** management module (see [code_snippets][code_snippet_schedules])
 - **Subscription** management modules including **Email Subscription**,  **Cache Update Subscription**, **File Subscription**, **FTP Subscription** and **History List Subscription** (see [code_snippets][code_snippet_subs])
 - **User Library** module (see [code_snippets][code_snippet_library])
 - **User Connections** management module
 - **Privilege** and **Security Role** management modules (see [code_snippets][code_snippet_privilege])
 - **Cube Cache** management modules (see [code_snippets][code_snippet_cache])
 - **Intelligent Cube** management modules (see [code_snippets][code_snippet_olap])
 - **Security filter** module (see [code_snippets][code_snippet_security_filter])
 - **Datasources and Connection Mapping** subpackage for database management (see [code_snippets][code_snippet_datasource])
+with **VLDB settings** management (see [code_snippets][code_snippet_vldb])
 - **Job Monitor** module for job monitoring (see [code_snippets][code_snippet_job_monitor])
 - **Object management** module (see [code_snippets][code_snippet_object_mgmt])
 - **Contact** module (see [code_snippets][code_snippet_contact])
 - **Contact Group** module (see [code_snippets][code_snippet_contact_group])
 - **Device** module (see [code_snippets][code_snippet_device])
 - **Transmitter** module (see [code_snippets][code_snippet_transmitter])
 - **Event** module (see [code_snippets][code_snippet_events])
@@ -111,14 +113,17 @@
 - **Filter** module (see [code_snippets][code_snippet_filter])
 - **Transformation** module (see [code_snippets][code_snippet_transformation])
 - **Metric** module (see [code_snippets][code_snippet_metrics])
 - **Document** module (see [code_snippets][code_snippet_document])
 - **Dossier** module (see [code_snippets][code_snippet_dossier])
 - **Content Cache** module (see [code_snippets][code_snippet_content_cache])
 - **Dynamic Recipient List** module (see [code_snippets][code_snippet_dynamic_recipient_list])
+- **Driver** module (see [code_snippets][code_snippet_datasource])
+- **Gateway** module (see [code_snippets][code_snippet_datasource])
+
 
 <a id="documentation" name="documentation"></a>
 # Documentation
 
 Detailed information about **mstrio-py** package can be found in [**official documentation**][mstrio_py_doc].
 
 <a id="usage-remarks" name="usage-remarks"></a>
@@ -204,15 +209,15 @@
 jupyter nbextension install connector-jupyter --py --sys-prefix
 jupyter nbextension enable connector-jupyter --py --sys-prefix
 ```
 
 <a id="versioning--changelog" name="versioning--changelog"></a>
 # Versioning & Changelog
 
-Current version: **11.3.9.101** (3 March 2023). Check out [**Changelog**][release_notes] to see what's new.
+Current version: **11.3.9.103** (5 May 2023). Check out [**Changelog**][release_notes] to see what's new.
 
 mstrio-py is constantly developed to support newest MicroStrategy REST APIs. Functionalities may be added to mstrio on monthly basis. It is **recommended** to always install the newest version of mstrio-py, as it will be most stable and still maintain backwards compatibility with various MicroStrategy installations, dating back to 11.1.4.
 
 Features that will be added to the package but require APIs not supported by your environment (I-Server), will raise `VersionException`.
 
 mstrio-py can be used for both, **data-science** related activities and for **administrative tasks**. Former requires at least MicroStrategy 2019 Update 4 (11.1.4), latter works with 11.2.1 and higher.
 
@@ -295,7 +300,8 @@
 [code_snippet_privilege]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/security_roles_and_privileges.py
 [code_snippet_transformation]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/transformation.py
 [code_snippet_metrics]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/metrics.py
 [code_snippet_content_cache]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/content_cache.py
 [code_snippet_document]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/document.py
 [code_snippet_dossier]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/dossier.py
 [code_snippet_dynamic_recipient_list]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/dynamic_recipient_list.py
+[code_snippet_vldb]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/vldb.py
```

### Comparing `mstrio-py-11.3.9.101/README.md` & `mstrio-py-11.3.9.103/README.md`

 * *Files 2% similar despite different names*

```diff
@@ -47,25 +47,27 @@
 
 - Import and filter data from a **OlapCube**, **SuperCube** or **Report** into a Pandas DataFrame (see [code_snippets][code_snippet_import])
 - Export data into MicroStrategy by creating or updating **SuperCube** (see [code_snippets][code_snippet_export])
 
 Since version **11.3.0.1**, **mstrio-py** includes also administration modules:
 
 - **Project** management module (see [code_snippets][code_snippet_project])
+with **VLDB settings** management (see [code_snippets][code_snippet_vldb])
 - **Server** management module (see [code_snippets][code_snippet_server])
 - **User** and **User Group** management modules (see [code_snippets][code_snippet_user])
 - **Schedules** management module (see [code_snippets][code_snippet_schedules])
 - **Subscription** management modules including **Email Subscription**,  **Cache Update Subscription**, **File Subscription**, **FTP Subscription** and **History List Subscription** (see [code_snippets][code_snippet_subs])
 - **User Library** module (see [code_snippets][code_snippet_library])
 - **User Connections** management module
 - **Privilege** and **Security Role** management modules (see [code_snippets][code_snippet_privilege])
 - **Cube Cache** management modules (see [code_snippets][code_snippet_cache])
 - **Intelligent Cube** management modules (see [code_snippets][code_snippet_olap])
 - **Security filter** module (see [code_snippets][code_snippet_security_filter])
 - **Datasources and Connection Mapping** subpackage for database management (see [code_snippets][code_snippet_datasource])
+with **VLDB settings** management (see [code_snippets][code_snippet_vldb])
 - **Job Monitor** module for job monitoring (see [code_snippets][code_snippet_job_monitor])
 - **Object management** module (see [code_snippets][code_snippet_object_mgmt])
 - **Contact** module (see [code_snippets][code_snippet_contact])
 - **Contact Group** module (see [code_snippets][code_snippet_contact_group])
 - **Device** module (see [code_snippets][code_snippet_device])
 - **Transmitter** module (see [code_snippets][code_snippet_transmitter])
 - **Event** module (see [code_snippets][code_snippet_events])
@@ -79,14 +81,17 @@
 - **Filter** module (see [code_snippets][code_snippet_filter])
 - **Transformation** module (see [code_snippets][code_snippet_transformation])
 - **Metric** module (see [code_snippets][code_snippet_metrics])
 - **Document** module (see [code_snippets][code_snippet_document])
 - **Dossier** module (see [code_snippets][code_snippet_dossier])
 - **Content Cache** module (see [code_snippets][code_snippet_content_cache])
 - **Dynamic Recipient List** module (see [code_snippets][code_snippet_dynamic_recipient_list])
+- **Driver** module (see [code_snippets][code_snippet_datasource])
+- **Gateway** module (see [code_snippets][code_snippet_datasource])
+
 
 <a id="documentation" name="documentation"></a>
 # Documentation
 
 Detailed information about **mstrio-py** package can be found in [**official documentation**][mstrio_py_doc].
 
 <a id="usage-remarks" name="usage-remarks"></a>
@@ -172,15 +177,15 @@
 jupyter nbextension install connector-jupyter --py --sys-prefix
 jupyter nbextension enable connector-jupyter --py --sys-prefix
 ```
 
 <a id="versioning--changelog" name="versioning--changelog"></a>
 # Versioning & Changelog
 
-Current version: **11.3.9.101** (3 March 2023). Check out [**Changelog**][release_notes] to see what's new.
+Current version: **11.3.9.103** (5 May 2023). Check out [**Changelog**][release_notes] to see what's new.
 
 mstrio-py is constantly developed to support newest MicroStrategy REST APIs. Functionalities may be added to mstrio on monthly basis. It is **recommended** to always install the newest version of mstrio-py, as it will be most stable and still maintain backwards compatibility with various MicroStrategy installations, dating back to 11.1.4.
 
 Features that will be added to the package but require APIs not supported by your environment (I-Server), will raise `VersionException`.
 
 mstrio-py can be used for both, **data-science** related activities and for **administrative tasks**. Former requires at least MicroStrategy 2019 Update 4 (11.1.4), latter works with 11.2.1 and higher.
 
@@ -263,7 +268,8 @@
 [code_snippet_privilege]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/security_roles_and_privileges.py
 [code_snippet_transformation]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/transformation.py
 [code_snippet_metrics]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/metrics.py
 [code_snippet_content_cache]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/content_cache.py
 [code_snippet_document]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/document.py
 [code_snippet_dossier]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/dossier.py
 [code_snippet_dynamic_recipient_list]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/dynamic_recipient_list.py
+[code_snippet_vldb]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/vldb.py
```

### Comparing `mstrio-py-11.3.9.101/code_snippets/attributes.py` & `mstrio-py-11.3.9.103/code_snippets/attributes.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/connect.py` & `mstrio-py-11.3.9.103/code_snippets/connect.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/contact_group_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/contact_group_mgmt.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/contacts.py` & `mstrio-py-11.3.9.103/code_snippets/contacts.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/content_cache.py` & `mstrio-py-11.3.9.103/code_snippets/content_cache.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/create_super_cube.py` & `mstrio-py-11.3.9.103/code_snippets/create_super_cube.py`

 * *Files 26% similar despite different names*

```diff
@@ -13,14 +13,19 @@
 This script will not work without replacing parameters with real values.
 Its basic goal is to present what can be done with this module and to ease
 its usage.
 """
 
 import pandas as pd
 
+from mstrio.project_objects import (
+    SuperCubeAttribute,
+    SuperCubeAttributeForm,
+    SuperCubeFormExpression
+)
 from mstrio.project_objects.datasets import SuperCube
 from mstrio.connection import get_connection
 
 # Define a variable which can be later used in a script
 PROJECT_NAME = $project_name  # Insert project name here
 
 conn = get_connection(workstationData, project_name=PROJECT_NAME)
@@ -44,14 +49,49 @@
 # additionally upload data to the I-Server and publish it. You can manipulate it
 # by setting parameters `auto_upload` and `auto_publish`
 ds = SuperCube(connection=conn, name=SUPER_CUBE_NAME)
 ds.add_table(name="Stores", data_frame=stores_df, update_policy="add")
 ds.add_table(name="Sales", data_frame=sales_df, update_policy="add")
 ds.create()
 
+# Add tables to super cube and map columns to attribute forms
+ds = SuperCube(connection=conn, name=SUPER_CUBE_NAME)
+ds.add_table(name="Stores", data_frame=stores_df, update_policy="add")
+ds.add_table(name="Sales", data_frame=sales_df, update_policy="add")
+
+attribute_form_mapping = SuperCubeAttribute(
+    name='store',
+    forms=[
+        SuperCubeAttributeForm(
+            category='ID',
+            expressions=[
+                SuperCubeFormExpression(
+                    table='Stores',
+                    column='store_id'
+                ),
+                SuperCubeFormExpression(
+                    table='Sales',
+                    column='store_id'
+                )
+            ]
+        ),
+        SuperCubeAttributeForm(
+            category='DESC',
+            expressions=[
+                SuperCubeFormExpression(
+                    table='Stores',
+                    column='name'
+                )
+            ]
+        )
+    ]
+)
+
+ds.create(attribute_forms=[attribute_form_mapping])
+
 # When using `SuperCube.add_table()`, Pandas data types are mapped to
 # MicroStrategy data types. By default, numeric data is modeled as MSTR metrics
 # and non-numeric as attributes. You can set manually which columns treat as
 # attributes and which as metrics.
 ds.add_table(name="Stores", data_frame=stores_df, update_policy="add", to_attribute=["store_id"])
 
 ds.add_table(
```

### Comparing `mstrio-py-11.3.9.101/code_snippets/cube_cache.py` & `mstrio-py-11.3.9.103/code_snippets/cube_cache.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/cube_report.py` & `mstrio-py-11.3.9.103/code_snippets/cube_report.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/datasource_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/datasource_mgmt.py`

 * *Files 12% similar despite different names*

```diff
@@ -7,23 +7,29 @@
 
 from mstrio.datasources import (
     DatasourceConnection,
     DatasourceInstance,
     DatasourceLogin,
     DatasourceMap,
     DatasourceType,
+    Dbms,
+    DBType,
+    Driver,
     ExecutionMode,
+    Gateway,
+    GatewayType,
     Locale,
     list_available_dbms,
     list_datasource_connections,
     list_datasource_instances,
     list_datasource_logins,
     list_datasource_mappings,
+    list_drivers,
+    list_gateways,
     list_locales,
-    Dbms
 )
 from mstrio.connection import get_connection
 
 
 # Define variables which can be later used in a script
 PROJECT_ID = $project_id  # Project ID to connect to
 PROJECT_NAME = $project_name  # Insert project name to connect to
@@ -32,44 +38,52 @@
 
 # Manage datasource logins
 # Get a list of datasource logins
 datasource_login_list = list_datasource_logins(connection=conn)
 print(datasource_login_list)
 
 # Define variables which can be later used in a script
-DATASOURCE_LOGIN_ID = $datasource_login_id  # Insert ID for login to datasource here
-DATASOURCE_LOGIN_NAME = $datasource_login_name  # Insert name for login to datasource here
+# Insert ID for login to datasource here
+DATASOURCE_LOGIN_ID = $datasource_login_id
+# Insert name for login to datasource here
+DATASOURCE_LOGIN_NAME = $datasource_login_name
 
 # Get datasource login by id
 datasource_login = DatasourceLogin(conn, id=DATASOURCE_LOGIN_ID)
 print(datasource_login)
 
 # Get datasource login by name
 datasource_login = DatasourceLogin(conn, name=DATASOURCE_LOGIN_NAME)
 print(datasource_login)
 
 # Define variables which can be later used in a script
-NEW_DATASOURCE_LOGIN_NAME = $new_datasource_login_name  # Insert name for new login to datasource here
-NEW_DATASOURCE_USERNAME = $new_datasource_username  # Insert name of user in Datasource here
-NEW_DATASOURCE_PASSWORD = $new_datasource_password  # Insert datasource password here
-NEW_DATASOURCE_LOGIN_DESCRIPTION = $new_datasource_login_description  # Insert new datasource login description
+# Insert a new name for new login to datasource here
+NEW_DATASOURCE_LOGIN_NAME = $new_datasource_login_name
+# Insert a new name of user in Datasource here
+NEW_DATASOURCE_USERNAME = $new_datasource_username
+# Insert a new datasource password here
+NEW_DATASOURCE_PASSWORD = $new_datasource_password
+# Insert a new datasource login description
+NEW_DATASOURCE_LOGIN_DESCRIPTION = $new_datasource_login_description
 
 # Create new datasource login
 datasource_login = DatasourceLogin.create(
     connection=conn,
     name=NEW_DATASOURCE_LOGIN_NAME,
     username=NEW_DATASOURCE_USERNAME,
     password=NEW_DATASOURCE_PASSWORD,
     description=NEW_DATASOURCE_LOGIN_DESCRIPTION,
 )
 print(datasource_login)
 
 # Define variables which can be later used in a script
-DATASOURCE_LOGIN_NEW_NAME = $datasource_login_new_name  # Insert new name for login to datasource here
-DATASOURCE_LOGIN_NEW_DESCRIPTION = $datasource_login_new_description  # Insert new datasource login description
+# Insert new name for login to datasource here
+DATASOURCE_LOGIN_NEW_NAME = $datasource_login_new_name
+# Insert new datasource login description
+DATASOURCE_LOGIN_NEW_DESCRIPTION = $datasource_login_new_description
 
 # Update a datasource login
 datasource_login.alter(
     name=DATASOURCE_LOGIN_NEW_NAME,
     description=DATASOURCE_LOGIN_NEW_DESCRIPTION,
 )
 print(datasource_login)
@@ -82,42 +96,48 @@
 
 # Manage datasource connections
 # List all datasource connections
 datasource_conn_list = list_datasource_connections(connection=conn)
 print(datasource_conn_list)
 
 # Define variables which can be later used in a script
-DATASOURCE_CONNECTION_ID = $datasource_connection_id  # Insert ID of datasource connection here
-DATASOURCE_CONNECTION_NAME = $datasource_connection_name  # Insert name of datasource connection here
+# Insert ID of datasource connection here
+DATASOURCE_CONNECTION_ID = $datasource_connection_id
+# Insert name of datasource connection here
+DATASOURCE_CONNECTION_NAME = $datasource_connection_name
 
 # Get datasource connection by id
 datasource_connection = DatasourceConnection(conn, id=DATASOURCE_CONNECTION_ID)
 print(datasource_connection)
 
 # Get datasource connection by name
 datasource_connection = DatasourceConnection(conn, name=DATASOURCE_CONNECTION_NAME)
 print(datasource_connection)
 
 # Define variables which can be later used in a script
-NEW_DATASOURCE_CONNECTION_NAME = $new_datasource_connection_name  # Insert new name of datasource connection here
-NEW_DATASOURCE_CONNECTION_DESCRIPTION = $new_datasource_connection_description  # Insert new description of datasource connection here
+# Insert new name of datasource connection here
+NEW_DATASOURCE_CONNECTION_NAME = $new_datasource_connection_name
+# Insert new description of datasource connection here
+NEW_DATASOURCE_CONNECTION_DESCRIPTION = $new_datasource_connection_description
 
 # Create a new datasource connection
 datasource_connection = DatasourceConnection.create(
     connection=conn,
     name=NEW_DATASOURCE_CONNECTION_NAME,
     description=NEW_DATASOURCE_CONNECTION_DESCRIPTION,
     # the ExecutionMode values can be found in datasources/datasource_connection.py
     execution_mode=ExecutionMode.SYNCHRONOUS,
     datasource_login=DATASOURCE_LOGIN_ID,
 )
 
 # Define variables which can be later used in a script
-DATASOURCE_CONNECTION_NEW_NAME = $datasource_connection_new_name  # Insert new name of datasource connection
-DATASOURCE_CONNECTION_NEW_DESCRIPTION = $datasource_connection_new_description  # Insert new description of datasource connection
+# Insert new name of datasource connection
+DATASOURCE_CONNECTION_NEW_NAME = $datasource_connection_new_name
+# Insert new description of datasource connection
+DATASOURCE_CONNECTION_NEW_DESCRIPTION = $datasource_connection_new_description
 
 # Update a datasource connection
 datasource_connection.alter(
     name=DATASOURCE_CONNECTION_NEW_NAME,
     description=DATASOURCE_CONNECTION_NEW_DESCRIPTION,
 )
 print(datasource_connection)
@@ -132,15 +152,16 @@
 # Note that conversion to DSN-less is supported on certified gateways:
 # Amazon Redshift; Azure Synapse Analytics; ExasolI;
 # BM Db2 for Linux, UNIX and Windows; MySQL; Oracle; PostgreSQL;
 # Salesforce; Cloudera Hive; Cloudera Impala; Google BigQuery; Spark SQL;
 # SAP HANA; Snowflake; SQL Server; Teradata
 
 # Define variables which can be later used in a script
-DATASOURCE_CONNECTION_ID_DSN = $datasource_connection_id_dsn  # Insert id of datasource connection that had DSN connection string
+# Insert ID of datasource connection that had DSN connection string
+DATASOURCE_CONNECTION_ID_DSN = $datasource_connection_id_dsn
 
 # Initialize datasource connection object
 ds_conn = DatasourceConnection(conn, id=DATASOURCE_CONNECTION_ID_DSN)
 
 # List datasource connection properites before conversion
 print(ds_conn.list_properties())
 
@@ -148,15 +169,16 @@
 # Convert datasource connection to DSN-less
 ds_conn.convert_to_dsn_less()
 
 # List datasource connection properites after conversion
 print(ds_conn.list_properties())
 
 # Define variables which can be later used in a script
-DATASOURCE_CONNECTION_ID_DSN_LIST = $datasource_connection_id_dsn_list  # Insert IDs for datasource connections here
+# Insert IDs for datasource connections here
+DATASOURCE_CONNECTION_ID_DSN_LIST = $datasource_connection_id_dsn_list
 
 # Convert datasource connections one by one from list
 for ds_conn_id in DATASOURCE_CONNECTION_ID_DSN_LIST:
     ds_conn = DatasourceConnection(conn, id=ds_conn_id)
     # This method is supported from Update 9 server version
     ds_conn.convert_to_dsn_less()
 
@@ -173,16 +195,18 @@
 # List all datasources by datasource connection
 datasources = list_datasource_instances(
     connection=conn, datasource_connection={'id': DATASOURCE_CONNECTION_ID}
 )
 print(datasources)
 
 # Define variables which can be later used in a script
-DATASOURCE_INSTANCE_ID = $datasource_instance_id  # Insert ID for datasource instance here
-DATASOURCE_INSTANCE_NAME = $datasource_instance_name  # Insert name for datasource instance here
+# Insert ID for datasource instance here
+DATASOURCE_INSTANCE_ID = $datasource_instance_id
+# Insert name for datasource instance here
+DATASOURCE_INSTANCE_NAME = $datasource_instance_name
 
 # Get datasource instance by id
 datasource_instance = DatasourceInstance(conn, id=DATASOURCE_INSTANCE_ID)
 print(datasource_instance)
 
 # Get datasource instance by name
 datasource_instance = DatasourceInstance(conn, name=DATASOURCE_INSTANCE_NAME)
@@ -201,17 +225,20 @@
 print(dbms)
 
 # Get a DBMS by name
 dbms = Dbms(conn, name=DBMS_NAME)
 print(dbms)
 
 # Define variables which can be later used in a script
-NEW_DATASOURCE_INSTANCE_NAME = $new_datasource_instance_name  # Insert name for datasource instance here
-NEW_DATASOURCE_INSTANCE_DESCRIPTION = $new_datasource_instance_description  # Insert description for datasource instance here
-NEW_DATASOURCE_INSTANCE_TABLE_PREFIX = $new_datasource_instance_table_prefix  # Insert table prefix for datasource instance here
+# Insert a new name for datasource instance here
+NEW_DATASOURCE_INSTANCE_NAME = $new_datasource_instance_name
+# Insert a new description for datasource instance here
+NEW_DATASOURCE_INSTANCE_DESCRIPTION = $new_datasource_instance_description
+# Insert a new table prefix for datasource instance here
+NEW_DATASOURCE_INSTANCE_TABLE_PREFIX = $new_datasource_instance_table_prefix
 
 # Create a datasource instance
 datasource_instance = DatasourceInstance.create(
     connection=conn,
     name=NEW_DATASOURCE_INSTANCE_NAME,
     description=NEW_DATASOURCE_INSTANCE_DESCRIPTION,
     dbms=DBMS_ID,
@@ -219,17 +246,20 @@
     table_prefix=NEW_DATASOURCE_INSTANCE_TABLE_PREFIX,
     # The DatasourceType values can be found in datasources/datasource_instance.py
     datasource_type=DatasourceType.RESERVED
 )
 print(datasource_instance)
 
 # Define variables which can be later used in a script
-DATASOURCE_INSTANCE_NEW_NAME = $datasource_instance_new_name  # Insert new name for edited datasource instance here
-DATASOURCE_INSTANCE_NEW_DESCRIPTION = $datasource_instance_new_description  # Insert new description for edited datasource instance here
-DATASOURCE_INSTANCE_TABLE_NEW_PREFIX = $datasource_instance_table_new_prefix  # Insert new table prefix for edited datasource instance here
+# Insert new name for edited datasource instance here
+DATASOURCE_INSTANCE_NEW_NAME = $datasource_instance_new_name
+# Insert new description for edited datasource instance here
+DATASOURCE_INSTANCE_NEW_DESCRIPTION = $datasource_instance_new_description
+# Insert new table prefix for edited datasource instance here
+DATASOURCE_INSTANCE_TABLE_NEW_PREFIX = $datasource_instance_table_new_prefix
 
 # Update a datasource instance
 datasource_instance.alter(
     name=DATASOURCE_INSTANCE_NEW_NAME,
     description=DATASOURCE_INSTANCE_NEW_DESCRIPTION,
     table_prefix=DATASOURCE_INSTANCE_TABLE_NEW_PREFIX
 )
@@ -245,25 +275,27 @@
 # Note that conversion to DSN-less is supported on certified gateways:
 # Amazon Redshift; Azure Synapse Analytics; ExasolI;
 # BM Db2 for Linux, UNIX and Windows; MySQL; Oracle; PostgreSQL;
 # Salesforce; Cloudera Hive; Cloudera Impala; Google BigQuery; Spark SQL;
 # SAP HANA; Snowflake; SQL Server; Teradata
 
 # Define variables which can be later used in a script
-DATASOURCE_INSTANCE_ID_DSN = $datasource_instance_id_dsn  # Insert ID for datasource instance here
+# Insert ID for datasource instance here
+DATASOURCE_INSTANCE_ID_DSN = $datasource_instance_id_dsn
 
 # Get datasource instance by id
 ds_instance = DatasourceInstance(conn, id=DATASOURCE_INSTANCE_ID_DSN)
 
 # This method is supported from Update 9 server version
 # Convert datasource embedded connection from DSN to DSN-less format
 ds_instance.convert_ds_connection_to_dsn_less()
 
 # Define variables which can be later used in a script
-DATASOURCE_INSTANCE_ID_DSN_LIST = $datasource_instance_id_dsn_list  # Insert IDs for datasource instances here
+# Insert IDs for datasource instances here
+DATASOURCE_INSTANCE_ID_DSN_LIST = $datasource_instance_id_dsn_list
 
 # Convert datasource instance embedded connection one by one from list
 for ds_id in DATASOURCE_INSTANCE_ID_DSN_LIST:
     ds_instance = DatasourceInstance(conn, id=ds_id)
     # This method is supported from Update 9 server version
     ds_instance.convert_ds_connection_to_dsn_less()
 
@@ -369,16 +401,16 @@
     connection=conn,
     id=CONNECTION_MAPPING_ID,
     default_connection_map=True,
     project=PROJECT_ID,
 )
 print(connection_mapping)
 
-# Initialise a default connection mapping for a project if only one default connection mapping
-# exists for a project
+# Initialise a default connection mapping for a project if only one default
+# connection mapping exists for a project
 connection_mapping = DatasourceMap(
     connection=conn,
     default_connection_map=True,
     project=PROJECT_ID,
 )
 print(connection_mapping)
 
@@ -400,14 +432,15 @@
     user=USER_OR_USER_GROUP_ID,
     ds_connection=DATASOURCE_CONNECTION_ID,
     datasource=DATASOURCE_INSTANCE_ID,
     login=DATASOURCE_LOGIN_ID,
     locale=LOCALE_ID
 )
 print(connection_mapping)
+
 # Create a connection mapping with locale's name
 connection_mapping = DatasourceMap.create(
     connection=conn,
     project=PROJECT_ID,
     user=USER_OR_USER_GROUP_ID,
     ds_connection=DATASOURCE_CONNECTION_ID,
     datasource=DATASOURCE_INSTANCE_ID,
@@ -425,16 +458,18 @@
     datasource=DATASOURCE_INSTANCE_ID,
     login=DATASOURCE_LOGIN_ID,
     locale=LOCALE_ABBREVIATION
 )
 print(connection_mapping)
 
 # Define variables which can be later used in a script
-CONNECTION_MAPPING_NEW_USER_OR_USER_GROUP = $connection_mapping_new_user_or_user_group  # Insert new user or usergroup ID for connection mapping
-CONNECTION_MAPPING_NEW_LOGIN = $connection_mapping_new_login  # Insert new login ID for connection mapping
+# Insert new user or usergroup ID for connection mapping
+CONNECTION_MAPPING_NEW_USER_OR_USER_GROUP = $connection_mapping_new_user_or_user_group
+# Insert new login ID for connection mapping
+CONNECTION_MAPPING_NEW_LOGIN = $connection_mapping_new_login
 
 # Alter connection mapping
 # NOTE: Altering connection mapping will change its ID
 connection_mapping.alter(
     user=CONNECTION_MAPPING_NEW_USER_OR_USER_GROUP,
     login=CONNECTION_MAPPING_NEW_LOGIN,
 )
@@ -450,7 +485,112 @@
 
 # Alter connection mapping's locale by abbreviation
 connection_mapping.alter(locale=LOCALE_ABBREVIATION)
 print(connection_mapping)
 
 # Delete a connection mapping
 connection_mapping.delete(force=True)
+
+
+# Manage Drivers
+
+# List all drivers
+drivers = list_drivers(conn)
+print(drivers)
+
+# Define variables which can be later used in a script
+DRIVER_ID = $driver_id
+
+# List drivers by id
+drivers = list_drivers(conn, id=DRIVER_ID)
+print(drivers)
+
+# Define variables which can be later used in a script
+DRIVER_NAME = $driver_name
+
+# List drivers by name
+drivers = list_drivers(conn, name=DRIVER_NAME)
+print(drivers)
+
+# List enabled drivers
+drivers = list_drivers(conn, is_enabled=True)
+print(drivers)
+
+# List disabled drivers
+drivers = list_drivers(conn, is_enabled=False)
+print(drivers)
+
+# List ODBC drivers
+drivers = list_drivers(conn, is_odbc=True)
+print(drivers)
+
+# List non-ODBC drivers
+drivers = list_drivers(conn, is_odbc=False)
+print(drivers)
+
+# Initialize driver by id
+driver = Driver(conn, id=DRIVER_ID)
+print(driver)
+
+# Initialize driver by name
+driver = Driver(conn, name=DRIVER_NAME)
+print(driver)
+
+# Enable driver
+driver.enable()
+
+# Disable driver
+driver.disable()
+
+# Alter driver
+driver.alter(is_enabled=True)
+
+
+# Managing Gateways
+
+# List all gateways
+gateways = list_gateways(conn)
+print(gateways)
+
+# Define variables which can be later used in a script
+GATEWAY_ID = $gateway_id
+
+# List gateways by id
+gateways = list_gateways(conn, id=GATEWAY_ID)
+print(gateways)
+
+# Define variables which can be later used in a script
+GATEWAY_NAME = $gateway_name
+
+# List gateways by name
+gateways = list_gateways(conn, name=GATEWAY_NAME)
+print(gateways)
+
+# Define variables which can be later used in a script
+GATEWAY_TYPE = $gateway_type
+
+# List gateways by gateway type
+gateways = list_gateways(conn, gateway_type=GATEWAY_TYPE)
+print(gateways)
+
+# Define variables which can be later used in a script
+DB_TYPE = $db_type
+
+# List gateways by database type
+gateways = list_gateways(conn, db_type=DB_TYPE)
+print(gateways)
+
+# List certified gateways
+gateways = list_gateways(conn, is_certified=True)
+print(gateways)
+
+# List not certified gateways
+gateways = list_gateways(conn, is_certified=False)
+print(gateways)
+
+# Initialize gateway by id
+gateway = Gateway(conn, id=GATEWAY_ID)
+print(gateway)
+
+# Initialize gateway by name
+gateway = Gateway(conn, name=GATEWAY_NAME)
+print(gateway)
```

### Comparing `mstrio-py-11.3.9.101/code_snippets/device_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/device_mgmt.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/document.py` & `mstrio-py-11.3.9.103/code_snippets/document.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/dossier.py` & `mstrio-py-11.3.9.103/code_snippets/dossier.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/dynamic_recipient_list.py` & `mstrio-py-11.3.9.103/code_snippets/dynamic_recipient_list.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/events.py` & `mstrio-py-11.3.9.103/code_snippets/events.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/fact.py` & `mstrio-py-11.3.9.103/code_snippets/fact.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/filter.py` & `mstrio-py-11.3.9.103/code_snippets/filter.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/intelligent_cube.py` & `mstrio-py-11.3.9.103/code_snippets/intelligent_cube.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/job_monitor.py` & `mstrio-py-11.3.9.103/code_snippets/job_monitor.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/metrics.py` & `mstrio-py-11.3.9.103/code_snippets/metrics.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/migration.py` & `mstrio-py-11.3.9.103/code_snippets/migration.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/object_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/object_mgmt.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/reports.py` & `mstrio-py-11.3.9.103/code_snippets/reports.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/schedules.py` & `mstrio-py-11.3.9.103/code_snippets/schedules.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/schema_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/schema_mgmt.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/security_filters.py` & `mstrio-py-11.3.9.103/code_snippets/security_filters.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/security_roles_and_privileges.py` & `mstrio-py-11.3.9.103/code_snippets/security_roles_and_privileges.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/server_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/server_mgmt.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/subscription_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/subscription_mgmt.py`

 * *Files 1% similar despite different names*

```diff
@@ -110,14 +110,15 @@
     zip_password_protect=True,
     zip_filename=ZIP_FILE_NAME,
     zip_password=ZIP_PASSWORD
 )
 
 # Define variables which can be later used in a script
 HISTORY_LIST_SUBSCRIPTION_NAME = $history_list_subscription_name
+DELIVERY_EXPIRATION_DATE = $delivery_expiration_date
 
 # Create a history list subscription
 HL_SUB = HistoryListSubscription.create(
     connection=CONN,
     name=HISTORY_LIST_SUBSCRIPTION_NAME,
     project_name=PROJECT_NAME,
     contents=Content(
@@ -130,28 +131,29 @@
     do_not_create_update_caches=True,
     overwrite_older_version=True,
     re_run_hl=True
 )
 
 # Define variables which can be later used in a script
 CACHE_SUBSCRIPTION_NAME = $cache_subscription_name
-DELIVERY_EXPIRATION_DATE = $delivery_expiration_date
+DELIVERY_EXPIRATION_TIME_ZONE = $delivery_expiration_time_zone
 
 # Create a cache update subscription
 CACHE_UPDATE_SUB = CacheUpdateSubscription.create(
     connection=CONN,
     project_name=PROJECT_NAME,
     name=CACHE_SUBSCRIPTION_NAME,
     contents=Content(
         id=CONTENT_ID,
         type=CONTENT_TYPE,
         personalization=Content.Properties(format_type=Content.Properties.FormatType.PDF),
     ),
     schedules=[SCHEDULE_ID],
     delivery_expiration_date=DELIVERY_EXPIRATION_DATE,
+    delivery_expiration_timezone=DELIVERY_EXPIRATION_TIME_ZONE,
     send_now=True,
     recipients=[RECIPIENT_ID_3],
     cache_cache_type=CacheType.RESERVED
 )  # see distribution_services/subscription/delivery.py for available options
 
 # Define variables which can be later used in a script
 CACHE_SUBSCRIPTION_NEW_NAME = $cache_subscription_new_name
```

### Comparing `mstrio-py-11.3.9.101/code_snippets/table_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/table_mgmt.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/transformation.py` & `mstrio-py-11.3.9.103/code_snippets/transformation.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/transmitter_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/transmitter_mgmt.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/user_hierarchy_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/user_hierarchy_mgmt.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/user_library.py` & `mstrio-py-11.3.9.103/code_snippets/user_library.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/user_mgmt.py` & `mstrio-py-11.3.9.103/code_snippets/user_mgmt.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/code_snippets/variables.json` & `mstrio-py-11.3.9.103/code_snippets/variables.json`

 * *Files 1% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9682266245573738%*

 * *Differences: {"'datasource_mgmt.py'": "{'driver_id': OrderedDict([('type', 'text'), ('multiple', False)]), "*

 * *                         "'driver_name': OrderedDict([('type', 'text'), ('multiple', False)]), "*

 * *                         "'gateway_id': OrderedDict([('type', 'text'), ('multiple', False)]), "*

 * *                         "'gateway_name': OrderedDict([('type', 'text'), ('multiple', False)]), "*

 * *                         "'gateway_type': OrderedDict([('type', 'text'), ('multiple', False)]), "*

 * *                         "' []*

```diff
@@ -340,22 +340,46 @@
             "multiple": false,
             "type": "text"
         },
         "datasource_login_new_name": {
             "multiple": false,
             "type": "text"
         },
+        "db_type": {
+            "multiple": false,
+            "type": "text"
+        },
         "dbms_id": {
             "multiple": false,
             "type": "text"
         },
         "dbms_name": {
             "multiple": false,
             "type": "text"
         },
+        "driver_id": {
+            "multiple": false,
+            "type": "text"
+        },
+        "driver_name": {
+            "multiple": false,
+            "type": "text"
+        },
+        "gateway_id": {
+            "multiple": false,
+            "type": "text"
+        },
+        "gateway_name": {
+            "multiple": false,
+            "type": "text"
+        },
+        "gateway_type": {
+            "multiple": false,
+            "type": "text"
+        },
         "locale_abbreviation": {
             "multiple": false,
             "type": "text"
         },
         "locale_id": {
             "multiple": false,
             "type": "text"
@@ -878,14 +902,18 @@
             "multiple": false,
             "type": "text"
         },
         "csv_file_import": {
             "multiple": false,
             "type": "text"
         },
+        "new_data_engine_version": {
+            "multiple": false,
+            "type": "text"
+        },
         "node_name": {
             "multiple": false,
             "type": "text"
         },
         "project_1_name": {
             "multiple": false,
             "type": "text"
@@ -1164,14 +1192,18 @@
             "multiple": false,
             "type": "text"
         },
         "delivery_expiration_date": {
             "multiple": false,
             "type": "date"
         },
+        "delivery_expiration_time_zone": {
+            "multiple": false,
+            "type": "text"
+        },
         "email_subject": {
             "multiple": false,
             "type": "text"
         },
         "email_subscription_name": {
             "multiple": false,
             "type": "text"
@@ -1560,9 +1592,55 @@
             "multiple": false,
             "type": "text"
         },
         "username_7": {
             "multiple": false,
             "type": "text"
         }
+    },
+    "vldb.py": {
+        "datasource_name": {
+            "multiple": false,
+            "type": "text"
+        },
+        "group_id": {
+            "multiple": false,
+            "type": "text"
+        },
+        "group_name": {
+            "multiple": false,
+            "type": "text"
+        },
+        "project_name": {
+            "multiple": false,
+            "type": "text"
+        },
+        "property_set": {
+            "multiple": false,
+            "type": "text"
+        },
+        "setting_name1": {
+            "multiple": false,
+            "type": "text"
+        },
+        "setting_name2": {
+            "multiple": false,
+            "type": "text"
+        },
+        "setting_name3": {
+            "multiple": false,
+            "type": "text"
+        },
+        "setting_value1": {
+            "multiple": false,
+            "type": "text"
+        },
+        "setting_value2": {
+            "multiple": false,
+            "type": "text"
+        },
+        "setting_value3": {
+            "multiple": false,
+            "type": "text"
+        }
     }
 }
```

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/package-lock.json` & `mstrio-py-11.3.9.103/connector-jupyter/package-lock.json`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/.eslintrc.js` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/.eslintrc.js`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/README.md` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/README.md`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/cell-button.js` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/cell-button.js`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/global-override.css` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/global-override.css`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/globals.js` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/globals.js`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/code-hide.png` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/code-hide.png`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/nbextensions-issue.png` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/nbextensions-issue.png`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/icons/table-hide.png` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/icons/table-hide.png`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/jupyter-cell.js` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/jupyter-cell.js`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/jupyter-kernel.js` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/jupyter-kernel.js`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/main.js` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/main.js`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-cell.js` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-cell.js`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/asset-manifest.json` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/asset-manifest.json`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/favicon.ico` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/favicon.ico`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/index.html` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/index.html`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/css/main.533bed2f.css` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/css/main.533bed2f.css`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/js/main.e1aca29b.js` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/js/main.e1aca29b.js`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/js/main.e1aca29b.js.LICENSE.txt` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/js/main.e1aca29b.js.LICENSE.txt`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/draggable_icon.66c4c69fd834208f8758.svg` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/draggable_icon.66c4c69fd834208f8758.svg`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon-downarrow.2daf0e97b9f1b62b8cf4.svg` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon-downarrow.2daf0e97b9f1b62b8cf4.svg`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon-uparrow.5d0f917ebd433f9b1f54.svg` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon-uparrow.5d0f917ebd433f9b1f54.svg`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon_success.8e1860fe5dd4347e22d1.svg` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/icon_success.8e1860fe5dd4347e22d1.svg`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/loading_icon.3b99fd5019e395faa679.gif` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/loading_icon.3b99fd5019e395faa679.gif`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/sort-indicator-desc-icon.e209fd7505e228248d82.svg` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/sort-indicator-desc-icon.e209fd7505e228248d82.svg`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/sort-indicator-none-icon.809a02a624c7e0ead705.svg` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr-connector/build/static/media/sort-indicator-none-icon.809a02a624c7e0ead705.svg`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/mstr.ico` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/mstr.ico`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/python-code.js` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/python-code.js`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/connector-jupyter/production/mstr_jupyter/static/utilities.js` & `mstrio-py-11.3.9.103/connector-jupyter/production/mstr_jupyter/static/utilities.js`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/mstrio/__init__.py` & `mstrio-py-11.3.9.103/mstrio/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -25,12 +25,12 @@
 a graphical user interface for mstrio-py methods with the help of which user
 can perform all of the import and export actions without writing a single line
 of code manually. MicroStrategy for Jupyter is contained within mstrio-py
 package and is available after installation and enabling as Jupyter extension.
 """
 
 __title__ = "mstrio-py"
-__version__ = "11.3.9.101"  # NOSONAR
+__version__ = "11.3.9.103"  # NOSONAR
 __license__ = "Apache License 2.0"
 __description__ = "Python interface for the MicroStrategy REST API"
 __author__ = "MicroStrategy"
 __author_email__ = "pkowal@microstrategy.com"
```

### Comparing `mstrio-py-11.3.9.101/mstrio/access_and_security/privilege.py` & `mstrio-py-11.3.9.103/mstrio/access_and_security/privilege.py`

 * *Files 5% similar despite different names*

```diff
@@ -24,97 +24,104 @@
         description: privilege description
         categories: privilege category
         is_project_level_privilege: specify if privilege is compatible with
             server configuration level or project level
     """
 
     def __init__(
-        self, connection: Connection, name: Optional[str] = None, id: Optional[str] = None
+        self,
+        connection: Connection,
+        name: Optional[str] = None,
+        id: Optional[str] = None,
     ) -> None:
         """Initialize Privilege object by passing `name` or `id`. When `id` is
         provided (not `None`), `name` is omitted. To explore all available
         privileges use the `list_privileges()` method.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             name: exact name of privilege
             id: ID of privilege
         """
         if name is None and id is None:
             helper.exception_handler(
                 "Please specify either 'name' or 'id' parameter in the constructor.",
-                exception_type=ValueError
+                exception_type=ValueError,
             )
 
         if name is None or (name and id):
             privileges = Privilege.list_privileges(
                 connection=connection, to_dictionary=True, id=str(id)
             )
             if privileges:
                 [privilege] = privileges
                 self._set_object_attributes(**privilege)
             else:
                 helper.exception_handler(
-                    f"There is no Privilege with the given id: '{id}'", exception_type=ValueError
+                    f"There is no Privilege with the given id: '{id}'",
+                    exception_type=ValueError,
                 )
         if id is None:
             privileges = Privilege.list_privileges(
                 connection=connection, to_dictionary=True, name=name
             )
             if privileges:
                 [privilege] = privileges
                 self._set_object_attributes(**privilege)
             else:
                 helper.exception_handler(
                     f"There is no Privilege with the given name: '{name}'",
-                    exception_type=ValueError
+                    exception_type=ValueError,
                 )
         super().__init__(connection, self.id, name=self.name)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self._is_project_level_privilege = kwargs.get("is_project_level_privilege")
         self._categories = kwargs.get("categories")
 
     @classmethod
     def list_privileges(
         cls,
         connection: Connection,
         to_dictionary: bool = False,
         to_dataframe: bool = False,
-        **filters
+        **filters,
     ) -> Union[List["Privilege"], List[dict], DataFrame]:
         """Get list of privilege objects or privilege dicts. Filter the
         privileges by specifying the `filters` keyword arguments.
 
         Optionally use `to_dictionary` or `to_dataframe` to choose output
         format.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             to_dictionary: If `True` returns dict, by default (False) returns
                 User objects.
             to_dataframe: If `True`, returns `DataFrame`.
             **filters: Available filter parameters: ['id', 'name',
-                'description', 'categories', 'is_project_level_privilege']
+                'description', 'is_project_level_privilege']
 
         Examples:
             >>> Privilege.list_privileges(connection, to_dataframe=True,
             >>>                           is_project_level_privilege='True',
             >>>                           id=[1,2,3,4,5])
         """
         if to_dictionary and to_dataframe:
-            helper.exception_handler(
-                "Please select either `to_dictionary=True` or `to_dataframe=True`, but not both.",
-                ValueError
+            raise ValueError(
+                "Please select either `to_dictionary=True` or `to_dataframe=True`,"
+                " but not both.",
             )
         objects = helper.fetch_objects(
-            connection=connection, api=security.get_privileges, limit=None, filters=filters
+            connection=connection,
+            api=security.get_privileges,
+            limit=None,
+            filters=filters,
         )
         if to_dictionary:
             return objects
         elif to_dataframe:
             return DataFrame(objects)
         else:
             return [cls.from_dict(source=obj, connection=connection) for obj in objects]
@@ -122,14 +129,15 @@
     def add_to_user(self, users: List[Union["User", str]]) -> None:
         """Add privilege to user.
 
         Args:
             users: list of `User` objects or names.
         """
         from mstrio.users_and_groups.user import User
+
         if isinstance(users, str):
             users = [User(self.connection, name=users)]
         elif isinstance(users, User):
             users = [users]
         elif hasattr(users, '__iter__') and all(isinstance(el, str) for el in users):
             users = [User(self.connection, name=user) for user in users]
         for user in users:
@@ -138,14 +146,15 @@
     def revoke_from_user(self, users: List[Union["User", str]]) -> None:
         """Revoke privilege from user.
 
         Args:
             users: list of `User` objects or names.
         """
         from mstrio.users_and_groups.user import User
+
         if isinstance(users, str):
             users = [User(self.connection, name=users)]
         elif isinstance(users, User):
             users = [users]
         elif hasattr(users, '__iter__') and all(isinstance(el, str) for el in users):
             users = [User(self.connection, name=user) for user in users]
         for user in users:
@@ -180,53 +189,65 @@
             groups = [UserGroup(self.connection, name=group) for group in groups]
         for group in groups:
             group.revoke_privilege(self.id)
 
     @staticmethod
     def _validate_privileges(
         connection: Connection,
-        privileges: Union[Union["Privilege", int, str], List[Union["Privilege", int, str]]]
+        privileges: Union[
+            Union["Privilege", int, str], List[Union["Privilege", int, str]]
+        ],
     ) -> List[dict]:
         """This function validates if the privilege ID/Name/Object is valid and
         returns the IDs.
 
         If invalid, raise ValueError.
         """
 
-        all_privileges = Privilege.list_privileges(connection=connection, to_dictionary=True)
+        all_privileges = Privilege.list_privileges(
+            connection=connection, to_dictionary=True
+        )
         validated = []
 
         privileges = privileges if isinstance(privileges, list) else [privileges]
 
         for privilege in privileges:
             is_str_name = type(privilege) == str and len(privilege) > 3
-            is_str_id = type(privilege) == str and len(privilege) > 0 and len(privilege) <= 3
-            is_int_id = isinstance(privilege, int) and privilege < 300 and privilege >= 0
+            is_str_id = (
+                type(privilege) == str and len(privilege) > 0 and len(privilege) <= 3
+            )
+            is_int_id = (
+                isinstance(privilege, int) and privilege < 300 and privilege >= 0
+            )
             privilege_ok = False
 
             if is_str_name:
                 temp_priv = helper.filter_list_of_dicts(all_privileges, name=privilege)
                 privilege_ok = bool(temp_priv)
             elif is_str_id or is_int_id:
-                temp_priv = helper.filter_list_of_dicts(all_privileges, id=str(privilege))
+                temp_priv = helper.filter_list_of_dicts(
+                    all_privileges, id=str(privilege)
+                )
                 privilege_ok = bool(temp_priv)
 
             if privilege_ok:
-                validated.append({'id': temp_priv[0]['id'], 'name': temp_priv[0]['name']})
+                validated.append(
+                    {'id': temp_priv[0]['id'], 'name': temp_priv[0]['name']}
+                )
             elif isinstance(privilege, Privilege):
                 validated.append({'id': privilege.id, 'name': privilege.name})
             else:
                 docs_url = (
                     "https://lw.microstrategy.com/msdz/msdl/GARelease_Current/docs/"
                     + "ReferenceFiles/reference/com/microstrategy/webapi/"
                     + "EnumDSSXMLPrivilegeTypes.html"
                 )
                 msg = (
-                    f"'{privilege}' is not a valid privilege. Possible values can be found in "
-                    "EnumDSSXMLPrivilegeTypes: \n" + docs_url
+                    f"'{privilege}' is not a valid privilege. Possible values can be "
+                    f"found in EnumDSSXMLPrivilegeTypes: \n" + docs_url
                 )
                 helper.exception_handler(msg, exception_type=ValueError)
         return validated
 
     @property
     def description(self):
         return self._description
@@ -264,8 +285,10 @@
 
     def to_dict(self):
         """Returns list of privileges dicts."""
         return {int(p.id): p.name for p in self.__privileges}
 
     def to_dataframe(self):
         """Returns DataFrame with privileges."""
-        return DataFrame([[p.id, p.name, p.description, p.categories] for p in self.__privileges])
+        return DataFrame(
+            [[p.id, p.name, p.description, p.categories] for p in self.__privileges]
+        )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/access_and_security/security_role.py` & `mstrio-py-11.3.9.103/mstrio/access_and_security/security_role.py`

 * *Files 9% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 
 @method_version_handler('11.2.0000')
 def list_security_roles(
     connection: Connection,
     to_dictionary: bool = False,
     to_dataframe: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ):
     """Get all Security Roles stored on the server.
 
     Optionally use `to_dictionary` or `to_dataframe` to choose output format.
 
     Args:
         connection(object): MicroStrategy connection object returned
@@ -42,15 +42,19 @@
             'description', 'subtype', 'date_created', 'date_modified',
             'version', 'acg', 'owner', 'ext_type']
 
     Returns:
             List of security roles.
     """
     return SecurityRole._list_security_roles(
-        connection, to_dictionary=to_dictionary, to_dataframe=to_dataframe, limit=limit, **filters
+        connection,
+        to_dictionary=to_dictionary,
+        to_dataframe=to_dataframe,
+        limit=limit,
+        **filters,
     )
 
 
 @class_version_handler('11.2.0000')
 class SecurityRole(Entity, DeleteMixin):
     """A security role is a set of privileges that can be assigned to users and
     reused from project to project. Security roles enable you to assign a
@@ -87,62 +91,71 @@
             'date_created',
             'date_modified',
             'version',
             'owner',
             'privileges',
             'projects',
             'acg',
-            'acl'
+            'acl',
         ): security.get_security_role
     }
     _API_PATCH: dict = {
         ('abbreviation'): (objects.update_object, 'partial_put'),
-        ('name', 'description'): (security.update_security_role, 'patch')
+        ('name', 'description'): (security.update_security_role, 'patch'),
     }
 
     def __init__(
-        self, connection: Connection, name: Optional[str] = None, id: Optional[str] = None
+        self,
+        connection: Connection,
+        name: Optional[str] = None,
+        id: Optional[str] = None,
     ):
         """Initialize Security Role object by passing name or id.
 
         Args:
             connection: MicroStrategy connection object returned
                 by `connection.Connection()`.
             name: name of Security Role
             id: ID of Security Role
         """
         # initialize either by ID or name
         if id is None and name is None:
             helper.exception_handler(
-                "Please specify either 'name' or 'id' parameter in the constructor.", ValueError
+                "Please specify either 'name' or 'id' parameter in the constructor.",
+                ValueError,
             )
 
         if id is None:
-            security_roles = SecurityRole._list_security_role_ids(connection=connection, name=name)
+            security_roles = SecurityRole._list_security_role_ids(
+                connection=connection, name=name
+            )
             if security_roles:
                 id = security_roles[0]
             else:
                 helper.exception_handler(
-                    f"There is no Security Role associated with the given name: '{name}'",
-                    exception_type=ValueError
+                    f"There is no Security Role associated with the given name: '"
+                    f"{name}'",
+                    exception_type=ValueError,
                 )
         super().__init__(connection=connection, object_id=id, name=name)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self._projects = kwargs.get("projects")
         self._privileges = kwargs.get("privileges")
 
     @classmethod
     def create(
         cls,
         connection: Connection,
         name: str,
-        privileges: Union[Union["Privilege", int, str], List[Union["Privilege", int, str]]],
-        description: str = ""
+        privileges: Union[
+            Union["Privilege", int, str], List[Union["Privilege", int, str]]
+        ],
+        description: str = "",
     ):
         """Create a new Security Role.
 
         Args:
             connection(object): MicroStrategy connection object returned
                 by 'connection.Connection()'.
             name(string): Name of the Security Role
@@ -152,53 +165,61 @@
 
         Returns:
             Newly created Security Role if the HTTP server has successfully
                 created the Security Role.
         """
         # get all project level privileges
         from mstrio.access_and_security.privilege import Privilege
+
         project_level = [
-            priv['id'] for priv in Privilege
-            .list_privileges(connection, to_dictionary=True, is_project_level_privilege='True')
+            priv['id']
+            for priv in Privilege.list_privileges(
+                connection, to_dictionary=True, is_project_level_privilege='True'
+            )
         ]
 
         # validate and filter passed privileges
         privileges = Privilege._validate_privileges(connection, privileges)
         server_level = list({priv['id'] for priv in privileges} - set(project_level))
         privileges = helper.filter_list_of_dicts(privileges, id=project_level)
 
         body = {"name": name, "description": description, "privileges": privileges}
 
         response = security.create_security_role(connection, body)
         if response.ok:
             if server_level:
                 msg = (
-                    "Privileges {} are server-level and will be omitted. Only project-level "
-                    "privileges can be granted by this method."
-                ).format(sorted(server_level))
+                    f"Privileges {sorted(server_level)} are server-level and will be "
+                    "omitted. Only project-level privileges can be granted by this "
+                    "method."
+                )
                 helper.exception_handler(msg, exception_type=Warning)
             return cls(connection=connection, id=response.json()['id'])
 
     @classmethod
     def _list_security_roles(
         cls,
         connection: Connection,
         to_dictionary: bool = False,
         to_dataframe: bool = False,
         limit: Optional[int] = None,
-        **filters
+        **filters,
     ) -> Union[List["SecurityRole"], List[Dict[str, Any]], DataFrame]:
         if to_dictionary and to_dataframe:
             helper.exception_handler(
-                "Please select either to_dictionary=True or to_dataframe=True, but not both.",
-                ValueError
+                "Please select either to_dictionary=True or to_dataframe=True, "
+                "but not both.",
+                ValueError,
             )
 
         objects = helper.fetch_objects(
-            connection=connection, api=security.get_security_roles, limit=limit, filters=filters
+            connection=connection,
+            api=security.get_security_roles,
+            limit=limit,
+            filters=filters,
         )
         if to_dictionary:
             return objects
         elif to_dataframe:
             return DataFrame(objects)
         else:
             return [cls.from_dict(source=obj, connection=connection) for obj in objects]
@@ -216,15 +237,15 @@
         Args:
             name: new name of the Security Role
             description: new description of the Security Role
         """
         func = self.alter
         args = helper.get_args_from_func(func)
         defaults = helper.get_default_args_from_func(func)
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
 
         self._alter_properties(**properties)
@@ -233,25 +254,29 @@
         """List all members of the Security Role. Optionally, filter the
         results by Project name.
 
         Args:
             project_name(str, optional): Project name
         """
         if project_name is not None:
-            [filtered_project] = helper.filter_list_of_dicts(self.projects, name=project_name)
+            [filtered_project] = helper.filter_list_of_dicts(
+                self.projects, name=project_name
+            )
             members = filtered_project['members']
         else:
             members = []
             for project in self.projects:
                 for member in project['members']:
                     members.append(member)
         return members
 
     def grant_to(
-        self, members: Union["UserOrGroup", List["UserOrGroup"]], project: Union["Project", str]
+        self,
+        members: Union["UserOrGroup", List["UserOrGroup"]],
+        project: Union["Project", str],
     ) -> None:
         """Assign users/user groups to a Security Role.
 
         Args:
             members(list): List of objects or IDs of Users or User Groups which
                 will be assigned to this Security Role.
             project(Project, str): Project object or name to which
@@ -268,43 +293,52 @@
             project_list = Project._list_projects(
                 connection=self.connection, to_dictionary=True, name=project
             )
             if project_list:
                 project_id = project_list[0]['id']
                 project_name = project_list[0]['name']
             else:
-                helper.exception_handler(f"Project name '{project}' does not exist.", ValueError)
+                helper.exception_handler(
+                    f"Project name '{project}' does not exist.", ValueError
+                )
         else:
             helper.exception_handler(
                 "`project` parameter must be of type str or Project.", TypeError
             )
 
         # create list of objects from strings/objects/lists
         members_list = members if isinstance(members, list) else [members]
         members_list = [
-            obj.id if isinstance(obj, (User, UserGroup)) else str(obj) for obj in members_list
+            obj.id if isinstance(obj, (User, UserGroup)) else str(obj)
+            for obj in members_list
+        ]
+        existing_ids = [
+            obj['id'] for obj in self.list_members(project_name=project_name)
         ]
-        existing_ids = [obj['id'] for obj in self.list_members(project_name=project_name)]
         succeeded = list(set(members_list) - set(existing_ids))
         failed = list(set(existing_ids).intersection(set(members_list)))
 
         value = {"projectId": project_id, "memberIds": members_list}
         self._update_nested_properties(
             objects=value,
             path="members",
             op='add',
         )
         if config.verbose:
             if succeeded:
                 logger.info(f"Granted Security Role '{self.name}' to {succeeded}")
             if failed:
-                logger.warning(f"Security Role '{self.name}' already has member(s) {failed}")
+                logger.warning(
+                    f"Security Role '{self.name}' already has member(s) {failed}"
+                )
 
     def revoke_from(
-        self, members: Union["UserOrGroup", List["UserOrGroup"]], project: Union["Project", str]
+        self,
+        members: Union["UserOrGroup", List["UserOrGroup"]],
+        project: Union["Project", str],
     ) -> None:
         """Remove users/user groups from a Security Role.
 
         Args:
             members(list): List of objects or IDs of Users or User Groups
                 which will be removed from this Security Role.
             project(Project, str): Project object or name
@@ -330,45 +364,55 @@
             helper.exception_handler(
                 "Project parameter must be of type str or Project.", TypeError
             )
 
         # create list of objects from strings/objects/lists
         members_list = members if isinstance(members, list) else [members]
         members_list = [
-            obj.id if isinstance(obj, (User, UserGroup)) else str(obj) for obj in members_list
+            obj.id if isinstance(obj, (User, UserGroup)) else str(obj)
+            for obj in members_list
         ]
 
-        existing_ids = [obj['id'] for obj in self.list_members(project_name=project_name)]
+        existing_ids = [
+            obj['id'] for obj in self.list_members(project_name=project_name)
+        ]
         succeeded = list(set(members_list).intersection(set(existing_ids)))
         failed = list(set(members_list) - set(succeeded))
 
         value = {"projectId": project_id, "memberIds": members_list}
         self._update_nested_properties(
             objects=value,
             path="members",
             op='remove',
         )
 
         if succeeded and config.verbose:
             logger.info(f"Revoked Security Role '{self.name}' from {succeeded}")
         if failed and config.verbose:
-            logger.warning(f"Security Role '{self.name}' does not have member(s) {failed}")
+            logger.warning(
+                f"Security Role '{self.name}' does not have member(s) {failed}"
+            )
 
     def grant_privilege(
-        self, privilege: Union[Union["Privilege", int, str], List[Union["Privilege", int, str]]]
+        self,
+        privilege: Union[
+            Union["Privilege", int, str], List[Union["Privilege", int, str]]
+        ],
     ) -> None:
         """Grant new project-level privileges to the Security Role.
 
         Args:
             privilege: list of privilege objects, ids or names
         """
         # get all project level privileges
         from mstrio.access_and_security.privilege import Privilege
+
         project_level = [
-            priv['id'] for priv in Privilege.list_privileges(
+            priv['id']
+            for priv in Privilege.list_privileges(
                 self.connection, to_dictionary=True, is_project_level_privilege='True'
             )
         ]
 
         # validate and filter passed privileges
         privileges = Privilege._validate_privileges(self.connection, privilege)
         server_level = list({priv['id'] for priv in privileges} - set(project_level))
@@ -378,43 +422,50 @@
         privilege_ids = [priv['id'] for priv in privileges]
         existing_ids = [obj['id'] for obj in self.privileges]
         succeeded = list(set(privilege_ids) - set(existing_ids))
         failed = list(set(existing_ids).intersection(set(privilege_ids)))
 
         if server_level:
             msg = (
-                "Privileges {} are server-level and will be omitted. Only project-level "
-                "privileges can be granted by this method."
-            ).format(sorted(server_level))
+                f"Privileges {sorted(server_level)} are server-level and will be "
+                "omitted. Only project-level privileges can be granted by this method."
+            )
             helper.exception_handler(msg, exception_type=Warning)
 
         self._update_nested_properties(
             objects=privileges,
             path="privileges",
             op="addElement",
         )
         if succeeded:
             self.fetch()  # fetch the object properties and set object attributes
             if config.verbose:
                 logger.info(f"Granted privilege(s) {succeeded} to '{self.name}'")
         if failed and config.verbose:
-            logger.warning(f"Security Role '{self.name}' already has privilege(s) {failed}")
+            logger.warning(
+                f"Security Role '{self.name}' already has privilege(s) {failed}"
+            )
 
     def revoke_privilege(
-        self, privilege: Union[Union["Privilege", int, str], List[Union["Privilege", int, str]]]
+        self,
+        privilege: Union[
+            Union["Privilege", int, str], List[Union["Privilege", int, str]]
+        ],
     ) -> None:
         """Revoke project-level privileges from the Security Role.
 
         Args:
             privilege: list of privilege objects, ids or names
         """
         # get all project level privileges
         from mstrio.access_and_security.privilege import Privilege
+
         project_level = [
-            priv['id'] for priv in Privilege.list_privileges(
+            priv['id']
+            for priv in Privilege.list_privileges(
                 self.connection, to_dictionary=True, is_project_level_privilege='True'
             )
         ]
 
         # validate and filter passed privileges
         privileges = Privilege._validate_privileges(self.connection, privilege)
         server_level = list({priv['id'] for priv in privileges} - set(project_level))
@@ -424,52 +475,62 @@
         privilege_ids = [priv['id'] for priv in privileges]
         existing_ids = [obj['id'] for obj in self.privileges]
         succeeded = list(set(privilege_ids).intersection(set(existing_ids)))
         failed = list(set(privilege_ids) - set(succeeded))
 
         if server_level:
             msg = (
-                "Privilege(s) {} are server-level and will be omitted. Only project-level "
-                "privileges can be granted by this method."
-            ).format(sorted(server_level))
+                f"Privilege(s) {sorted(server_level)} are server-level and will be "
+                "omitted. Only project-level privileges can be granted by this method."
+            )
             helper.exception_handler(msg, exception_type=Warning)
 
-        self._update_nested_properties(objects=privileges, path="privileges", op="removeElement")
+        self._update_nested_properties(
+            objects=privileges, path="privileges", op="removeElement"
+        )
         if succeeded:
             self.fetch()  # fetch the object properties and set object attributes
             if config.verbose:
                 logger.info(f"Revoked privilege(s) {succeeded} from '{self.name}'")
         elif failed and config.verbose:
-            logger.warning(f"Security Role '{self.name}' does not have privilege(s) {failed}")
+            logger.warning(
+                f"Security Role '{self.name}' does not have privilege(s) {failed}"
+            )
 
     def revoke_all_privileges(self, force: bool = False) -> None:
         """Revoke all granted project-level privileges.
 
         Args:
             force(bool, optional): If true, overrides the prompt.
         """
         user_input = 'N'
         if not force:
             user_input = input(
-                "Are you sure you want to revoke all privileges from Security Role '{}'? [Y/N]: "
-                .format(self.name)
+                "Are you sure you want to revoke all privileges from Security Role "
+                f"'{self.name}'? [Y/N]: "
             )
         if force or user_input == 'Y':
             from mstrio.access_and_security.privilege import Privilege
+
             project_level = [
-                priv['id'] for priv in Privilege.list_privileges(
-                    self.connection, to_dictionary=True, is_project_level_privilege='True'
+                priv['id']
+                for priv in Privilege.list_privileges(
+                    self.connection,
+                    to_dictionary=True,
+                    is_project_level_privilege='True',
                 )
             ]
             existing_ids = [obj['id'] for obj in self.privileges]
             to_revoke = list(set(project_level).intersection(set(existing_ids)))
             if to_revoke:
                 self.revoke_privilege(privilege=to_revoke)
             else:
-                logger.warning(f"Security Role '{self.name}' does not have any privilege(s)")
+                logger.warning(
+                    f"Security Role '{self.name}' does not have any privilege(s)"
+                )
 
     def list_privileges(self, to_dataframe: bool = False) -> Union[dict, DataFrame]:
         """List ALL privileges for Security Role. Optionally return a
         `DataFrame` object.
 
         Args:
             to_dataframe: If True, return a `DataFrame` object containing
@@ -483,17 +544,15 @@
             df.index.name = 'ID'
             return df
         else:
             return priv_dict
 
     def _update_nested_properties(self, objects, path: str, op: str) -> None:
         body = {
-            "operationList": [{
-                "op": op, "path": f'/{path}', "value": objects
-            }],
+            "operationList": [{"op": op, "path": f'/{path}', "value": objects}],
         }
 
         response = security.update_security_role(self.connection, self.id, body)
         response = response.json()
         if type(response) == dict:
             self._set_object_attributes(**response)
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/administration.py` & `mstrio-py-11.3.9.103/mstrio/api/administration.py`

 * *Files 3% similar despite different names*

```diff
@@ -9,15 +9,16 @@
         connection: MicroStrategy REST API connection object
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
-        url=f'{connection.base_url}/api/iserver/privileges', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/iserver/privileges',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error getting privilege categories.')
 def get_privilege_categories(connection, error_msg=None):
     """Get the set of available privilege categories for the platform.
 
@@ -45,15 +46,15 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/iserver/ldap/configuration',
-        headers={'X-MSTR-ProjectID': None}
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error creating LDAP configuration.')
 def create_ldap_config(connection, body, error_msg=None):
     """Create a new LDAP configuration and save it to the Intelligence Server.
     There is only one LDAP configuration in Intelligence Server metadata, so
@@ -128,15 +129,15 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/iserver/ldap/attributes',
-        headers={'X-MSTR-ProjectID': None}
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='getting LDAP certificate information.')
 def get_ldap_certificate_info(connection, error_msg=None):
     """Get LDAP server certificate info. The communication between the
     Intelligence Server and LDAP server can be encrypted by SSL (optional).
@@ -147,15 +148,15 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/iserver/ldap/certificate',
-        headers={'X-MSTR-ProjectID': None}
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error updating LDAP certificate.')
 def upload_ldap_certificate(connection, body, error_msg=None):
     """Upload LDAP server certificate for encrypted communication. The
     communication between the Intelligence Server and the LDAP server can be
@@ -188,15 +189,15 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/iserver/ldap/authuserbinds',
-        headers={'X-MSTR-ProjectID': None}
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error getting LDAP batch import status.')
 def get_ldap_batch_import_status(connection, error_msg=None):
     """Get LDAP batch import status. You can get the progress of LDAP batch
     import, including its status (e.g. failed, stopped, undergoing, and
@@ -207,15 +208,16 @@
         connection: MicroStrategy REST API connection object
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
-        url=f'{connection.base_url}/api/iserver/ldap/import', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/iserver/ldap/import',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error stopping LDAP batch import.')
 def stop_ldap_batch_import(connection, error_msg=None):
     """Stop the LDAP batch import if it exists. This operation will be ignored
     if there is no undergoing LDAP batch import.
@@ -226,15 +228,16 @@
             `utils.formjson()`.
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.put(
-        url=f'{connection.base_url}/api/iserver/ldap/import', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/iserver/ldap/import',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error doing LDAP batch import.')
 def do_ldap_batch_import(connection, error_msg=None):
     """Do LDAP batch import now. This API starts the LDAP batch import, which
     will import both groups and users from the LDAP server. No request body is
@@ -244,15 +247,16 @@
         connection: MicroStrategy REST API connection object
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.post(
-        url=f'{connection.base_url}/api/iserver/ldap/import', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/iserver/ldap/import',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error updating authentication configurations.')
 def update_authentication_configs(connection, body, error_msg=None):
     """Update the authentication configuration settings for the current REST
     server. In the body parameter of the request, you specify the default
@@ -268,15 +272,16 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.put(
         url=f'{connection.base_url}/api/admin/restServerSettings/auth',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error updating collaboration server configurations.')
 def update_collaboration_server_configs(connection, body, error_msg=None):
@@ -294,15 +299,16 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.put(
         url=f'{connection.base_url}/api/admin/restServerSettings/collaboration',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error updating web configurations.')
 def update_web_configs(connection, body, error_msg=None):
@@ -318,15 +324,16 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.put(
         url=f'{connection.base_url}/api/admin/restServerSettings/microStrategyWeb',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error testing collaboration server connection.')
 def test_collaboration_connection(connection, body, error_msg=None):
@@ -342,17 +349,19 @@
             `utils.formjson()`.
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.post(
-        url=f'{connection.base_url}/api/admin/restServerSettings/collaboration/connectionTest',
+        url=f'{connection.base_url}/api/admin/restServerSettings/collaboration'
+        f'/connectionTest',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error updating intelligence server configurations.')
 def update_iserver_configs(connection, body, error_msg=None):
@@ -370,15 +379,16 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.put(
         url=f'{connection.base_url}/api/admin/restServerSettings/iServer',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error getting rest configurations.')
 def get_rest_configs(connection, error_msg=None):
@@ -392,40 +402,47 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/admin/restServerSettings',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
     )
 
 
-@ErrorHandler(err_msg='Error checking intelligence server - web server trust relationship.')
+@ErrorHandler(
+    err_msg='Error checking intelligence server - web server trust relationship.'
+)
 def check_iserver_web_trust(connection, error_msg=None):
     """Check to see if there is a trust relationship between the Web Server and
     the Intelligence Server.
 
     Args:
         connection: MicroStrategy REST API connection object
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
-        url=f'{connection.base_url}/api/admin/restServerSettings/iServer/trustRelationship',
+        url=f'{connection.base_url}/api/admin/restServerSettings/iServer'
+        f'/trustRelationship',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
     )
 
 
-@ErrorHandler(err_msg='Error setting intelligence server - web server trust relationship.')
+@ErrorHandler(
+    err_msg='Error setting intelligence server - web server trust relationship.'
+)
 def set_iserver_web_trust(connection, body, error_msg=None):
     """Set up a trust relationship between the Web Server and the Intelligence
     Server. You obtain the authorization token needed to execute the request
     using POST /auth/login; you pass the authorization token in the request
     header. In the body parameter of the request, you specify the URL or other
     unique identifier for the Web Server.
 
@@ -435,40 +452,46 @@
             `utils.formjson()`.
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.post(
-        url=f'{connection.base_url}/api/admin/restServerSettings/iServer/trustRelationship',
+        url=f'{connection.base_url}/api/admin/restServerSettings/iServer'
+        f'/trustRelationship',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
         json=body,
     )
 
 
-@ErrorHandler(err_msg='Error deleting intelligence server - web server trust relationship.')
+@ErrorHandler(
+    err_msg='Error deleting intelligence server - web server trust relationship.'
+)
 def delete_iserver_web_trust(connection, error_msg=None):
     """Delete a trust relationship between the Web Server and the Intelligence
     Server. You obtain the authorization token needed to execute the request
     using POST /auth/login; you pass the authorization token in the request
     header.
 
     Args:
         connection: MicroStrategy REST API connection object
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.delete(
-        url=f'{connection.base_url}/api/admin/restServerSettings/iServer/trustRelationship',
+        url=f'{connection.base_url}/api/admin/restServerSettings/iServer'
+        f'/trustRelationship',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
     )
 
 
 @ErrorHandler(err_msg='Error testing intelligence server connection.')
 def test_iserver_connection(connection, error_msg=None):
     """Test the connection between the Intelligence Server and the REST Server.
@@ -479,17 +502,19 @@
         connection: MicroStrategy REST API connection object
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.post(
-        url=f'{connection.base_url}/api/admin/restServerSettings/iServer/connectionTest',
+        url=f'{connection.base_url}/api/admin/restServerSettings/iServer'
+        f'/connectionTest',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
     )
 
 
 @ErrorHandler(err_msg='Error getting security settings.')
 def get_security_settings(connection, error_msg=None):
     """Get relevant information about security settings, such as whether the
@@ -502,15 +527,16 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/admin/restServerSettings/security',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
     )
 
 
 @ErrorHandler(err_msg='Error updating security settings.')
 def update_security_settings(connection, body, error_msg=None):
     """Update the security settings. In the body of the request you can specify
@@ -526,15 +552,16 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.put(
         url=f'{connection.base_url}/api/admin/restServerSettings/security',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error fetching I-Server settings.')
 def get_iserver_settings_config(connection, error_msg=None):
@@ -546,15 +573,15 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/v2/iserver/settings/config',
-        headers={'X-MSTR-ProjectID': None}
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error fetching I-Server settings.')
 def get_iserver_settings(connection, error_msg=None):
     """This resource will retire resource 'GET iserver/settings' in the future
     version. Current version just cover Governing rule settings.
@@ -563,20 +590,23 @@
         connection: MicroStrategy REST API connection object
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
-        url=f'{connection.base_url}/api/v2/iserver/settings', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/v2/iserver/settings',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error updating I-Server settings.')
-def create_iserver_settings(connection, body, error_msg=None, whitelist=('ERR001', 400)):
+def create_iserver_settings(
+    connection, body, error_msg=None, whitelist=('ERR001', 400)
+):
     """Create some IServer governing settings.
 
     Example:
         body = {
             "maxUsedVirtualByte": {
                 "value": 100
             },
@@ -592,15 +622,17 @@
         url=f'{connection.base_url}/api/v2/iserver/settings',
         headers={'X-MSTR-ProjectID': None},
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error updating I-Server settings.')
-def update_iserver_settings(connection, body, error_msg=None, whitelist=('ERR001', 400)):
+def update_iserver_settings(
+    connection, body, error_msg=None, whitelist=('ERR001', 400)
+):
     """Update some IServer governing settings.
 
     Example:
         body = {
             "maxUsedVirtualByte": {
                 "value": 100
             },
@@ -629,15 +661,16 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/admin/iServer/clusterMembership',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
     )
 
 
 @ErrorHandler(err_msg='Error getting I-Server node {node} settings.')
 def get_iserver_node_settings(connection, node, error_msg=None):
     """Get Intelligence Server configuration settings for a given server node
@@ -650,15 +683,16 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/admin/restServerSettings/iServer/{node}',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
     )
 
 
 @ErrorHandler(err_msg='Error updating Intelligence Server configuration settings.')
 def update_iserver_configuration_settings(connection, body, error_msg=None):
     """Update Intelligence Server configuration settings.
@@ -670,15 +704,16 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.put(
         url=f'{connection.base_url}/api/admin/restServerSettings/iServer',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error updating I-Server node {node} settings.')
 def update_iserver_node_settings(connection, body, node, error_msg=None):
@@ -695,15 +730,16 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.put(
         url=f'{connection.base_url}/api/admin/restServerSettings/iServer/{node}',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error deleting I-Server node {node} settings.')
 def delete_iserver_node_settings(connection, node, error_msg=None):
@@ -715,10 +751,11 @@
         connection: MicroStrategy REST API connection object
         node: Intelligence Server host name
         error_msg (string, optional): Custom Error Message for Error Handling
     """
     return connection.delete(
         url=f'{connection.base_url}/api/admin/restServerSettings/iServer/{node}',
         headers={
-            'X-MSTR-ProjectID': None, 'Authorization': connection._get_authorization()
+            'X-MSTR-ProjectID': None,
+            'Authorization': connection._get_authorization(),
         },
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/attributes.py` & `mstrio-py-11.3.9.103/mstrio/api/attributes.py`

 * *Files 4% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 @ErrorHandler(err_msg='Error creating an attribute')
 def create_attribute(
     connection: Connection,
     body: dict,
     show_expression_as: Optional[List[str]] = None,
     show_potential_tables: Optional[str] = None,
     show_fields: Optional[str] = None,
-    fields: Optional[str] = None
+    fields: Optional[str] = None,
 ):
     """Create a new attribute in the changeset,
     based on the definition provided in request body.
 
     Args:
         connection: MicroStrategy REST API connection object
         body: Attribute creation data
@@ -46,30 +46,30 @@
         return connection.post(
             url=f'{connection.base_url}/api/model/attributes',
             headers={'X-MSTR-MS-Changeset': changeset_id},
             params={
                 'showExpressionAs': show_expression_as,
                 'showPotentialTables': show_potential_tables,
                 'showFields': show_fields,
-                'fields': fields
+                'fields': fields,
             },
-            json=body
+            json=body,
         )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error getting attribute with ID: {id}')
 def get_attribute(
     connection: Connection,
     id: str,
     changeset_id: Optional[str] = None,
     show_expression_as: Optional[List[str]] = None,
     show_potential_tables: Optional[str] = None,
     show_fields: Optional[str] = None,
-    fields: Optional[str] = None
+    fields: Optional[str] = None,
 ):
     """Get definition of a single attribute by id
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of an attribute
         changeset_id: ID of a changeset
@@ -98,30 +98,30 @@
     return connection.get(
         url=f'{connection.base_url}/api/model/attributes/{id}',
         headers={'X-MSTR-MS-Changeset': changeset_id},
         params={
             'showExpressionAs': show_expression_as,
             'showPotentialTables': show_potential_tables,
             'showFields': show_fields,
-            'fields': fields
-        }
+            'fields': fields,
+        },
     )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error updating attribute with ID: {id}')
 def update_attribute(
     connection: Connection,
     id: str,
     body: dict,
     show_expression_as: Optional[List[str]] = None,
     show_potential_tables: Optional[str] = None,
     show_fields: Optional[str] = None,
     fields: Optional[str] = None,
-    remove_invalid_fields: Optional[str] = None
+    remove_invalid_fields: Optional[str] = None,
 ):
     """Update a specific attribute in the changeset
     This endpoint replaces the attribute's top-level fields
     with the new definition provided in the request body.
 
     Args:
         connection: MicroStrategy REST API connection object
@@ -155,11 +155,11 @@
             url=f'{connection.base_url}/api/model/attributes/{id}',
             headers={'X-MSTR-MS-Changeset': changeset_id},
             params={
                 'showExpressionAs': show_expression_as,
                 'showPotentialTables': show_potential_tables,
                 'showFields': show_fields,
                 'fields': fields,
-                'removeInvalidFields': remove_invalid_fields
+                'removeInvalidFields': remove_invalid_fields,
             },
-            json=body
+            json=body,
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/authentication.py` & `mstrio-py-11.3.9.103/mstrio/api/authentication.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 from mstrio.utils.error_handlers import ErrorHandler
 
 
-@ErrorHandler(err_msg='Authentication error. Check user credentials or REST API URL and try again')
+@ErrorHandler(
+    err_msg='Authentication error. Check user credentials or REST API URL and try again'
+)
 def login(connection):
     """Authenticate a user and create an HTTP session on the web server where
     the user's MicroStrategy sessions are stored.
 
     This request returns an authorization token (X-MSTR-AuthToken) which will be
     submitted with subsequent requests. The body of the request contains
     the information needed to create the session. The loginMode parameter in
@@ -60,15 +62,15 @@
     Returns:
         Complete HTTP response object.
     """
     return connection.put(
         skip_expiration_check=True,
         url=f'{connection.base_url}/api/sessions',
         headers={'X-MSTR-ProjectID': None},
-        timeout=2.0
+        timeout=2.0,
     )
 
 
 def session_status(connection):
     """Checks Intelligence Server session status.
 
     Args:
@@ -94,15 +96,17 @@
 
     Args:
         connection: MicroStrategy REST API connection object
 
     Returns:
         Complete HTTP response object.
     """
-    return connection.post(url=f'{connection.base_url}/api/auth/identityToken', )
+    return connection.post(
+        url=f'{connection.base_url}/api/auth/identityToken',
+    )
 
 
 def validate_identity_token(connection, identity_token):
     """Validate an identity token.
 
     Args:
         connection: MicroStrategy REST API connection object
@@ -114,15 +118,16 @@
     return connection.get(
         url=f'{connection.base_url}/api/auth/identityToken',
         headers={'X-MSTR-IdentityToken': identity_token},
     )
 
 
 @ErrorHandler(
-    err_msg='Error creating a new Web server session that shares an existing IServer session.'
+    err_msg='Error creating a new Web server session that shares an existing IServer '
+    'session.'
 )
 def delegate(connection, identity_token, whitelist=None):
     """Returns authentication token and cookies from given X-MSTR-
     IdentityToken.
 
     Args:
         connection: MicroStrategy REST API connection object
@@ -131,17 +136,15 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.post(
         skip_expiration_check=True,
         url=f'{connection.base_url}/api/auth/delegate',
-        json={
-            'loginMode': "-1", 'identityToken': identity_token
-        },
+        json={'loginMode': "-1", 'identityToken': identity_token},
     )
 
 
 @ErrorHandler(err_msg='Error getting privileges list.')
 def user_privileges(connection):
     """Get the list of privileges for the authenticated user.
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/bookmarks.py` & `mstrio-py-11.3.9.103/mstrio/api/bookmarks.py`

 * *Files 0% similar despite different names*

```diff
@@ -65,15 +65,17 @@
     """
     body = {"shortcutId": shortcut_id, "bookmarkIds": bookmark_ids}
     url = f'{connection.base_url}/api/bookmarks'
     return connection.delete(url=url, json=body)
 
 
 @ErrorHandler(err_msg='Error deleting bookmark with ID {bookmark_id}')
-def delete_single_bookmark(connection, shortcut_id: str, bookmark_id: str, error_msg=None):
+def delete_single_bookmark(
+    connection, shortcut_id: str, bookmark_id: str, error_msg=None
+):
     """Delete a bookmark.
 
     Args:
         connection: MicroStrategy REST API connection object
         shortcut_id: Shortcut ID
         bookmark_id (string): Bookmark ID
         error_msg (string, optional): Custom Error Message for Error Handling
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/browsing.py` & `mstrio-py-11.3.9.103/mstrio/api/browsing.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,15 +22,15 @@
     object_types: Optional[List[int]] = None,
     uses_object: Optional[str] = None,
     uses_recursive: bool = False,
     uses_one_of: Optional[bool] = None,
     used_by_object: Optional[str] = None,
     used_by_recursive: Optional[bool] = None,
     used_by_one_of: Optional[bool] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """
     Search the metadata and store an instance of search results.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
@@ -91,27 +91,27 @@
             'root': root,
             'type': object_types,
             'usesObject': uses_object,
             'usesRecursive': uses_recursive,
             'usedByObject': used_by_object,
             'usedByRecursive': used_by_recursive,
             'usesOneOf': uses_one_of,
-            'usedByOneOf': used_by_one_of
-        }
+            'usedByOneOf': used_by_one_of,
+        },
     )
 
 
 @ErrorHandler(err_msg='Error getting search result for search with ID {search_id}')
 def get_search_results(
     connection: "Connection",
     search_id: str,
     project_id: Optional[str] = None,
     offset: int = 0,
     limit: int = -1,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """
     Get search results in a list format.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
@@ -128,27 +128,25 @@
 
     Returns:
         HTTP response returned by the MicroStrategy REST server.
     """
     return connection.get(
         url=f"{connection.base_url}/api/metadataSearches/results",
         headers={'X-MSTR-ProjectID': project_id},
-        params={
-            'searchId': search_id, 'offset': offset, 'limit': limit
-        }
+        params={'searchId': search_id, 'offset': offset, 'limit': limit},
     )
 
 
 def get_search_results_async(
     future_session: "FuturesSession",
     connection: "Connection",
     search_id: str,
     project_id: Optional[str] = None,
     offset: int = 0,
-    limit: int = -1
+    limit: int = -1,
 ):
     """Get search results in a list format asynchronously.
 
     Args:
         future_session(object): Future Session object to call MicroStrategy REST
             Server asynchronously
         connection(object): MicroStrategy connection object returned by
@@ -170,22 +168,24 @@
     url = f'{connection.base_url}/api/objects'
     headers = {'X-MSTR-ProjectID': project_id}
     params = {'searchId': search_id, 'offset': offset, 'limit': limit}
     future = future_session.get(url=url, headers=headers, params=params)
     return future
 
 
-@ErrorHandler(err_msg='Error getting search result in atree format for search with ID {search_id}')
+@ErrorHandler(
+    err_msg='Error getting search result in atree format for search with ID {search_id}'
+)
 def get_search_results_tree_format(
     connection: "Connection",
     search_id: str,
     project_id: Optional[str] = None,
     offset: int = 0,
     limit: int = -1,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """
     Get search results in a tree format.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
@@ -202,17 +202,15 @@
 
     Returns:
         HTTP response returned by the MicroStrategy REST server.
     """
     return connection.get(
         url=f"{connection.base_url}/api/metadataSearches/results/tree",
         headers={'X-MSTR-ProjectID': project_id},
-        params={
-            'searchId': search_id, 'offset': offset, 'limit': limit
-        },
+        params={'searchId': search_id, 'offset': offset, 'limit': limit},
     )
 
 
 @ErrorHandler(err_msg='Error getting quick search result.')
 def get_quick_search_result(
     connection,
     project_id: Optional[str] = None,
@@ -222,67 +220,70 @@
     pattern: Optional[Union["SearchPattern", int]] = None,
     certified_status: Optional["CertifiedStatus"] = None,
     offset: Optional[int] = None,
     limit: Optional[int] = None,
     hidden: Optional[bool] = None,
     get_ancestors: Optional[bool] = None,
     cross_cluster: Optional[bool] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     return connection.get(
         url=f"{connection.base_url}/api/searches/results",
         headers={'X-MSTR-ProjectID': project_id},
         params={
             'name': name,
             'type': object_types,
             'pattern': pattern,
             'root': root,
             'offset': offset,
             'limit': limit,
             'getAncestors': get_ancestors,
             'certifiedStatus': certified_status,
             'result.hidden': hidden,
-            'isCrossCluster': cross_cluster
-        }
+            'isCrossCluster': cross_cluster,
+        },
     )
 
 
 @ErrorHandler(
-    err_msg='Error getting quick search result from search object with ID {search_object_id}'
+    err_msg='Error getting quick search result from search object with ID {'
+    'search_object_id}'
 )
 def get_quick_search_result_from_object(
     connection: "Connection",
     project_id: str,
     search_object_id: str,
-    subtypes: Optional[Union["ObjectSubTypes", List["ObjectSubTypes"], int, List[int]]] = None,
+    subtypes: Optional[
+        Union["ObjectSubTypes", List["ObjectSubTypes"], int, List[int]]
+    ] = None,
     include_ancestors: Optional[bool] = None,
     include_acl: Optional[bool] = None,
     limit: Optional[int] = None,
     offset: Optional[int] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     return connection.get(
         url=f"{connection.base_url}/api/searchObjects/{search_object_id}/results",
         headers={'X-MSTR-ProjectID': project_id},
         params={
             'includeAncestors': include_ancestors,
             'includeAcl': include_acl,
             'result.subtypes': subtypes,
             'offset': offset,
-            'limit': limit
-        }
+            'limit': limit,
+        },
     )
 
 
 @ErrorHandler(err_msg='Error getting specified shortcuts.')
 def get_shortcuts(
     connection: "Connection",
     body: dict,
     shortcut_info_flag: int = 0,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Retrieve information about specific published shortcuts
     in specific projects.
 
     Args:
         connection: MicroStrategy REST API connection object
         body: A dictionary specifying the projects and shortcuts in the form of
@@ -314,15 +315,15 @@
 
 @ErrorHandler(err_msg='Error getting shortcut with id {id}.')
 def get_shortcut(
     connection: "Connection",
     id: str,
     project_id: str,
     shortcut_info_flag: int = 2,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get information about specific published shortcut in specific project.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: id of target shortcut
         project_id: id of project that the shortcut is in
@@ -339,34 +340,34 @@
 
     response = connection.post(
         url=(
             f'{connection.base_url}/api/searches/library/shortcuts'
             f'?shortcutInfoFlag={shortcut_info_flag}'
         ),
         headers={'X-MSTR-ProjectID': None},
-        json=[{
-            "projectId": project_id, "shortcutIds": [id]
-        }],
+        json=[{"projectId": project_id, "shortcutIds": [id]}],
     )
 
     if response.ok:
         response_json = response.json()
         if len(response_json) > 0:
             response_json = response_json[0]
-        response.encoding, response._content = 'utf-8', json.dumps(response_json).encode('utf-8')
+        response.encoding, response._content = 'utf-8', json.dumps(
+            response_json
+        ).encode('utf-8')
     return response
 
 
 @ErrorHandler(err_msg="Error getting search suggestions.")
 def get_search_suggestions(
     connection: "Connection",
     project_id: Optional[str] = None,
     key: Optional[str] = None,
     count: int = -1,
-    is_cross_cluster: bool = None
+    is_cross_cluster: bool = None,
 ):
     """Store results of the Search engine to return search suggestions.
 
     Args:
         connection (object): MicroStrategy REST API connection object
         project_id (string, optional): project ID
         key (string, optional): value the search pattern is set to, which will
@@ -380,9 +381,9 @@
     """
 
     return connection.get(
         url=(
             f'{connection.base_url}/api/searches/suggestions'
             f'?key={key}?count={count}?isCrossCluster={str(is_cross_cluster).lower()}'
         ),
-        headers={'X-MSTR-ProjectID': project_id}
+        headers={'X-MSTR-ProjectID': project_id},
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/changesets.py` & `mstrio-py-11.3.9.103/mstrio/api/changesets.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,42 +1,46 @@
-from mstrio.connection import Connection
+from typing import TYPE_CHECKING
+
 from mstrio.utils.error_handlers import ErrorHandler
 
+if TYPE_CHECKING:
+    from mstrio.connection import Connection
+
 
 @ErrorHandler(err_msg='Error creating a new changeset.')
 def create_changeset(
     connection: "Connection",
     project_id: str = None,
     schema_edit: bool = False,
-    error_msg: str = None
+    error_msg: str = None,
 ):
     """Create a new changeset for modelling manipulations."""
     if project_id is None:
         connection._validate_project_selected()
         project_id = connection.project_id
     return connection.post(
         url=f"{connection.base_url}/api/model/changesets",
         headers={'X-MSTR-ProjectID': project_id},
-        params={'schemaEdit': str(schema_edit).lower()}
+        params={'schemaEdit': str(schema_edit).lower()},
     )
 
 
 @ErrorHandler(err_msg='Error committing changeset {id} changes to the metadata.')
 def commit_changeset_changes(
     connection: "Connection", id: str, error_msg: str = None, throw_error=True
 ):
     """Commit the changeset changes to metadata."""
     return connection.post(
         url=f"{connection.base_url}/api/model/changesets/{id}/commit",
         headers={'X-MSTR-MSChanget': id},
-        params={'changesetId': id}
+        params={'changesetId': id},
     )
 
 
 @ErrorHandler(err_msg='Error deleting the changeset with ID {id}')
 def delete_changeset(connection: "Connection", id: str, error_msg: str = None):
     """Delete the changeset."""
     return connection.delete(
         url=f"{connection.base_url}/api/model/changesets/{id}",
         headers={'X-MSTR-MSChanget': id},
-        params={'changesetId': id}
+        params={'changesetId': id},
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/contact_groups.py` & `mstrio-py-11.3.9.103/mstrio/api/contact_groups.py`

 * *Files 3% similar despite different names*

```diff
@@ -6,15 +6,18 @@
     from requests_futures.sessions import FuturesSession
 
     from mstrio.connection import Connection
 
 
 @ErrorHandler(err_msg='Error listing Contact Groups.')
 def get_contact_groups(
-    connection: "Connection", offset: int = 0, limit: int = 1000, error_msg: Optional[str] = None
+    connection: "Connection",
+    offset: int = 0,
+    limit: int = 1000,
+    error_msg: Optional[str] = None,
 ):
     """Get a list of all contact groups that the authenticated user has access
         to.
 
     Args:
         connection: MicroStrategy REST API connection object
         offset (int, optional): Starting point within the collection of returned
@@ -29,15 +32,18 @@
     """
     url = f"{connection.base_url}/api/contactGroups"
     params = {'offset': offset, 'limit': limit}
     return connection.get(url=url, params=params)
 
 
 def get_contact_groups_async(
-    future_session: "FuturesSession", connection: "Connection", offset: int = 0, limit: int = 1000
+    future_session: "FuturesSession",
+    connection: "Connection",
+    offset: int = 0,
+    limit: int = 1000,
 ):
     """Get a list of all contact groups that the authenticated user has access
         to.
 
     Args:
         future_session(object): Future Session object to call MicroStrategy REST
             Server asynchronously
@@ -54,15 +60,17 @@
     url = f'{connection.base_url}/api/contactGroups'
     params = {'offset': offset, 'limit': limit}
     future = future_session.get(url, params=params)
     return future
 
 
 @ErrorHandler(err_msg='Error creating Contact Group.')
-def create_contact_group(connection: "Connection", body: dict, error_msg: Optional[str] = None):
+def create_contact_group(
+    connection: "Connection", body: dict, error_msg: Optional[str] = None
+):
     """Create a new contact group.
 
     Args:
         connection: MicroStrategy REST API connection object
         body: Contact group creation body
         error_msg (string, optional): Custom Error Message for Error Handling
 
@@ -70,15 +78,17 @@
         Complete HTTP response object. Expected status is 201.
     """
     url = f"{connection.base_url}/api/contactGroups"
     return connection.post(url=url, json=body)
 
 
 @ErrorHandler(err_msg='Error getting Contact Group with ID {id}')
-def get_contact_group(connection: "Connection", id: str, error_msg: Optional[str] = None):
+def get_contact_group(
+    connection: "Connection", id: str, error_msg: Optional[str] = None
+):
     """Get contact group by a specific id.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of the contact group
         error_msg (string, optional): Custom Error Message for Error Handling
 
@@ -105,15 +115,17 @@
         Complete HTTP response object. Expected status is 200.
     """
     url = f"{connection.base_url}/api/contactGroups/{id}"
     return connection.put(url=url, json=body)
 
 
 @ErrorHandler(err_msg='Error deleting Contact Group with ID {id}')
-def delete_contact_group(connection: "Connection", id: str, error_msg: Optional[str] = None):
+def delete_contact_group(
+    connection: "Connection", id: str, error_msg: Optional[str] = None
+):
     """Delete a contact group.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of the contact group
         error_msg (string, optional): Custom Error Message for Error Handling
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/contacts.py` & `mstrio-py-11.3.9.103/mstrio/api/contacts.py`

 * *Files 2% similar despite different names*

```diff
@@ -49,15 +49,17 @@
         Complete HTTP response object. Expected status is 204.
     """
     url = f"{connection.base_url}/api/contacts/{id}"
     return connection.delete(url=url)
 
 
 @ErrorHandler(err_msg='Error updating Contact with ID {id}')
-def update_contact(connection: Connection, id: str, body: dict, error_msg: Optional[str] = None):
+def update_contact(
+    connection: Connection, id: str, body: dict, error_msg: Optional[str] = None
+):
     """Update a contact.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of the contact
         body: Contact update info.
         error_msg (string, optional): Custom Error Message for Error Handling
@@ -71,15 +73,15 @@
 
 @ErrorHandler(err_msg="Error getting Contacts.")
 def get_contacts(
     connection: Connection,
     offset: int = 0,
     limit: int = -1,
     fields: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get information for all contacts.
 
     Args:
         connection: MicroStrategy REST API connection object
         fields(list, optional): Comma separated top-level field whitelist. This
             allows client to selectively retrieve part of the response model.
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/cubes.py` & `mstrio-py-11.3.9.103/mstrio/api/cubes.py`

 * *Files 7% similar despite different names*

```diff
@@ -64,15 +64,19 @@
         Complete HTTP response object.
     """
     return connection.head(url=f'{connection.base_url}/api/cubes/{id}')
 
 
 @ErrorHandler(err_msg='Error creating a new cube instance with ID {cube_id}.')
 def cube_instance(
-    connection: "Connection", cube_id: str, body: dict = {}, offset: int = 0, limit: int = 5000
+    connection: "Connection",
+    cube_id: str,
+    body: dict = {},
+    offset: int = 0,
+    limit: int = 5000,
 ):
     """Create a new instance of a specific cube. This in-memory instance can be
     used by other requests.
 
     Args:
         connection: MicroStrategy REST API connection object.
         cube_id (str): Unique ID of the cube you wish to extract information
@@ -98,15 +102,19 @@
         json=body,
         params=params,
     )
 
 
 @ErrorHandler(err_msg='Error getting cube {cube_id} contents.')
 def cube_instance_id(
-    connection: "Connection", cube_id: str, instance_id: str, offset: int = 0, limit: int = 5000
+    connection: "Connection",
+    cube_id: str,
+    instance_id: str,
+    offset: int = 0,
+    limit: int = 5000,
 ):
     """Get the results of a previously created instance for a specific cube,
     using the in-memory instance created by cube_instance().
 
     Args:
         connection: MicroStrategy REST API connection object.
         cube_id (str): Unique ID of the cube you wish to extract information
@@ -137,15 +145,15 @@
 
 def cube_instance_id_coroutine(
     future_session: "FuturesSession",
     connection: "Connection",
     cube_id: str,
     instance_id: str,
     offset: int = 0,
-    limit: int = 5000
+    limit: int = 5000,
 ):
     """Get the future of a previously created instance for a specific cube
     asynchronously, using the in-memory instance created by cube_instance().
 
     Returns:
         Complete Future object.
     """
@@ -154,56 +162,61 @@
         params['fields'] = CUBE_FIELDS
 
     url = f'{connection.base_url}/api/v2/cubes/{cube_id}/instances/{instance_id}'
     future = future_session.get(url, params=params)
     return future
 
 
-@ErrorHandler(err_msg='Error getting attribute {attribute_id} elements within cube {cube_id}')
+@ErrorHandler(
+    err_msg='Error getting attribute {attribute_id} elements within cube {cube_id}'
+)
 def cube_single_attribute_elements(
     connection: "Connection",
     cube_id: str,
     attribute_id: str,
     offset: int = 0,
-    limit: int = 200000
+    limit: int = 200000,
 ):
     """Get elements of a specific attribute of a specific cube.
 
     Args:
         connection: MicroStrategy REST API connection object.
         cube_id (str): Unique ID of the cube you wish to extract information
             from.
         attribute_id (str): Unique ID of the attribute in the cube.
 
     Returns:
         Complete HTTP response object.
     """
 
     return connection.get(
-        url=f'{connection.base_url}/api/cubes/{cube_id}/attributes/{attribute_id}/elements',
-        params={
-            'offset': offset, 'limit': limit
-        },
+        url=(
+            f'{connection.base_url}/api/cubes/{cube_id}/attributes/'
+            f'{attribute_id}/elements'
+        ),
+        params={'offset': offset, 'limit': limit},
     )
 
 
 def cube_single_attribute_elements_coroutine(
     future_session: "FuturesSession",
     connection: "Connection",
     cube_id: str,
     attribute_id: str,
     offset: int = 0,
-    limit: int = 200000
+    limit: int = 200000,
 ):
     """Get elements of a specific attribute of a specific cube.
 
     Returns:
         Complete Future object.
     """
-    url = f'{connection.base_url}/api/cubes/{cube_id}/attributes/{attribute_id}/elements'
+    url = (
+        f'{connection.base_url}/api/cubes/{cube_id}/attributes/{attribute_id}/elements'
+    )
     return future_session.get(url, params={'offset': offset, 'limit': limit})
 
 
 @ErrorHandler(err_msg='Error sending request to publish cube with ID {cube_id}')
 def publish(connection: "Connection", cube_id: str):
     """Publish a specific cube in a specific project.
 
@@ -241,32 +254,34 @@
 @ErrorHandler(err_msg='Error creating cube {name} definition.')
 def create(
     connection: "Connection",
     name: str,
     folder_id: str,
     overwrite: bool = None,
     description: str = None,
-    definition: dict = None
+    definition: dict = None,
 ):
     """
     Create an intelligent cube.
     POST /api/v2/cubes
     """
     connection._validate_project_selected()
 
     body = {
         'name': name,
         'description': description,
         'folderId': folder_id,
         'overwrite': overwrite,
-        'definition': definition
+        'definition': definition,
     }
     params = {'X-MSTR-ProjectID': connection.project_id}
 
-    return connection.post(url=f'{connection.base_url}/api/v2/cubes', json=body, params=params)
+    return connection.post(
+        url=f'{connection.base_url}/api/v2/cubes', json=body, params=params
+    )
 
 
 @ErrorHandler(err_msg='Error updating cube {cube_id} definition.')
 def update(connection: "Connection", cube_id: str, definition: dict = None):
     """
     Update an intelligent cube.
     PUT /api/v2/cubes/{cube_id}
@@ -289,9 +304,9 @@
     """
     if not project_id:
         connection._validate_project_selected()
         project_id = connection.project_id
 
     return connection.get(
         url=f"{connection.base_url}/api/v2/cubes/{cube_id}/sqlView",
-        params={'X-MSTR-projectID': project_id}
+        params={'X-MSTR-projectID': project_id},
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/datasets.py` & `mstrio-py-11.3.9.103/mstrio/api/datasets.py`

 * *Files 1% similar despite different names*

```diff
@@ -139,20 +139,22 @@
         throw_error (bool): Flag indicates if the error should be thrown
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
     connection._validate_project_selected()
     return connection.put(
-        url=f'{connection.base_url}/api/datasets/{id}/uploadSessions/{session_id}', json=body
+        url=f'{connection.base_url}/api/datasets/{id}/uploadSessions/{session_id}',
+        json=body,
     )
 
 
 @ErrorHandler(
-    err_msg='Error publishing uploaded data for dataset with ID {id} Cancelling publication.'
+    err_msg='Error publishing uploaded data for dataset with ID {id} Cancelling '
+    'publication.'
 )
 def publish(connection, id, session_id, throw_error=False):
     """Publish a multi-table dataset.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
@@ -182,15 +184,18 @@
         session_id (str): Identifier for the server session used for collecting
             uploaded data.
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server
     """
 
-    url = f'{connection.base_url}/api/datasets/{id}/uploadSessions/{session_id}/publishStatus'
+    url = (
+        f'{connection.base_url}/api/datasets/{id}/uploadS'
+        f'essions/{session_id}/publishStatus'
+    )
     return connection.get(url=url)
 
 
 @ErrorHandler(err_msg='Failed to cancel the publication of dataset with ID {id}')
 def publish_cancel(connection, id, session_id, throw_error=False):
     """Delete a multi-table dataset upload session and cancel publication.
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/datasources.py` & `mstrio-py-11.3.9.103/mstrio/api/datasources.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,21 +1,25 @@
 import json
 from typing import Optional
 
 from mstrio.connection import Connection
-from mstrio.utils.api_helpers import FuturesSessionWithRenewal, unpack_information
+from mstrio.utils.api_helpers import (
+    FuturesSessionWithRenewal,
+    changeset_manager,
+    unpack_information,
+)
 from mstrio.utils.datasources import (
     alter_conn_list_resp,
     alter_conn_resp,
     alter_instance_list_resp,
     alter_instance_resp,
-    alter_patch_req_body
+    alter_patch_req_body,
 )
 from mstrio.utils.error_handlers import ErrorHandler
-from mstrio.utils.helper import exception_handler, IServerError, response_handler
+from mstrio.utils.helper import IServerError, exception_handler, response_handler
 
 
 @ErrorHandler(err_msg='Error getting available DBMSs.')
 def get_available_dbms(connection, error_msg=None):
     """Get information for all available database management systems (DBMSs).
 
     Args:
@@ -91,15 +95,17 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object. HTTP STATUS 200/400
     """
     url = f"{connection.base_url}/api/datasources/{id}"
     for op_dict in body["operationList"]:
-        op_dict = alter_patch_req_body(op_dict, "/datasourceConnection", "/databaseConnectionId")
+        op_dict = alter_patch_req_body(
+            op_dict, "/datasourceConnection", "/databaseConnectionId"
+        )
         op_dict = alter_patch_req_body(
             op_dict, "/primaryDatasource", "/databasePrimaryDatasourceId"
         )
         op_dict = alter_patch_req_body(
             op_dict, "/dataMartDatasource", "/databaseDataMartDatasourceId"
         )
         alter_patch_req_body(op_dict, "/dbms", "/dbmsId")
@@ -137,15 +143,15 @@
 @ErrorHandler(err_msg='Error getting the namespaces for datasource with ID: {id}.')
 def get_datasource_namespaces(
     connection: "Connection",
     id: str,
     project_id: Optional[str] = None,
     refresh: Optional[bool] = None,
     fields: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get namespaces for a specific datasource.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (str): Database ID
         project_id (str, optional): Project ID
@@ -176,15 +182,15 @@
 
 def get_datasource_namespaces_async(
     session: FuturesSessionWithRenewal,
     connection: "Connection",
     id: str,
     project_id: Optional[str] = None,
     refresh: Optional[bool] = None,
-    fields: Optional[str] = None
+    fields: Optional[str] = None,
 ):
     return session.get(
         url=f"{connection.base_url}/api/datasources/{id}/catalog/namespaces",
         headers={
             'X-MSTR-ProjectID': project_id,
         },
         params={
@@ -214,33 +220,40 @@
     if project:
         url = f"{connection.base_url}/api/projects/{project}/datasources"
         response = connection.get(url=url)
     else:
         database_type = None if database_type is None else database_type.join(",")
         ids = None if ids is None else ids.join(",")
         url = f"{connection.base_url}/api/datasources"
-        response = connection.get(url=url, params={'id': ids, 'database.type': database_type})
+        response = connection.get(
+            url=url, params={'id': ids, 'database.type': database_type}
+        )
     if not response.ok:
         res = response.json()
         if project and res.get("message") == "HTTP 404 Not Found":
             # aka project based endpoint not supported
             # try without filtering
             warning_msg = (
                 "get_datasource_instances() warning: filtering by Project "
                 "is not yet supported on this version of the I-Server. "
                 "Returning all values."
             )
             exception_handler(warning_msg, Warning)
             return get_datasource_instances(
-                connection=connection, ids=ids, database_type=database_type, error_msg=error_msg
+                connection=connection,
+                ids=ids,
+                database_type=database_type,
+                error_msg=error_msg,
             )
         if not error_msg:
-            if project \
-                    and res.get('code') == "ERR006" \
-                    and "not a valid value for Project ID" in res.get('message'):
+            if (
+                project
+                and res.get('code') == "ERR006"
+                and "not a valid value for Project ID" in res.get('message')
+            ):
                 error_msg = f"{project} is not a valid Project class instance or ID"
                 raise ValueError(error_msg)
             error_msg = "Error getting Datasource Instances"
             if project:
                 error_msg += f" within `{project}` Project"
         response_handler(response, error_msg)
     response = alter_instance_list_resp(response)
@@ -279,16 +292,18 @@
     Returns:
         Complete HTTP response object. HTTP STATUS 200/400
     """
     url = f"{connection.base_url}/api/datasources/connections/{id}"
     response = connection.get(url=url)
     if not response.ok:
         if error_msg is None:
-            error_msg = (f"Error getting Datasource Connection with ID: {id}. "
-                         f"Check if it is not embedded Datasource Connection.")
+            error_msg = (
+                f"Error getting Datasource Connection with ID: {id}. "
+                f"Check if it is not embedded Datasource Connection."
+            )
         response_handler(response, error_msg)
     response = alter_conn_resp(response)
     return response
 
 
 def update_datasource_connection(connection, id, body, error_msg=None):
     """Update a datasource connection based on id.
@@ -369,15 +384,15 @@
 
 
 @ErrorHandler(err_msg='Error fetching connection mappings.')
 def get_datasource_mappings(
     connection: Connection,
     default_connection_map: Optional[bool] = False,
     project_id: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get information for all connection mappings.
 
     Args:
         connection: MicroStrategy REST API connection object
         default_connection_map (bool, optional): If True will get the default
             connection mappings for a project. Requires `project_id`
@@ -390,15 +405,15 @@
         Complete HTTP response object. Expected status is 200.
     """
     response = connection.get(
         url=f"{connection.base_url}/api/datasources/mappings",
         params={
             "defaultConnectionMap": default_connection_map,
             "projectId": project_id,
-        }
+        },
     )
 
     if default_connection_map and not response.ok and response.status_code == 404:
         response.status_code = 200
         response._content = json.dumps({'mappings': []}).encode('utf-8')
 
     return response
@@ -406,15 +421,15 @@
 
 @ErrorHandler(err_msg='Error fetching connection mapping with ID {id}.')
 def get_datasource_mapping(
     connection: Connection,
     id=str,
     default_connection_map: Optional[bool] = False,
     project_id: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get information about specific connection mapping.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of the mapping
         default_connection_map (bool, optional): If True will get the default
@@ -436,27 +451,33 @@
     )
 
     # Faking get single resource endpoint. Only 'list all' available on REST
     if response.ok:
         response_json = response.json()
 
         try:
-            mappings = [mapping for mapping in response_json['mappings'] if mapping["id"] == id]
+            mappings = [
+                mapping for mapping in response_json['mappings'] if mapping["id"] == id
+            ]
 
             mapping_data = mappings[0]
             mapping_data['ds_connection'] = mapping_data.pop('connection')
         except LookupError:
             raise IServerError(message="Connection Mapping not found", http_code=None)
 
-        response.encoding, response._content = 'utf-8', json.dumps(mapping_data).encode('utf-8')
+        response.encoding, response._content = 'utf-8', json.dumps(mapping_data).encode(
+            'utf-8'
+        )
     return response
 
 
 @ErrorHandler(err_msg='Error creating connection mapping.')
-def create_datasource_mapping(connection: Connection, body, error_msg: Optional[str] = None):
+def create_datasource_mapping(
+    connection: Connection, body, error_msg: Optional[str] = None
+):
     """Create a new connection mapping.
 
     Args:
         connection: MicroStrategy REST API connection object
         body: Datasource Connection Map creation info.
         error_msg (string, optional): Custom Error Message for Error Handling
 
@@ -464,15 +485,17 @@
         Complete HTTP response object. Expected status is 201.
     """
     url = f"{connection.base_url}/api/datasources/mappings"
     return connection.post(url=url, json=body)
 
 
 @ErrorHandler(err_msg='Error deleting connection mapping with ID {id}')
-def delete_datasource_mapping(connection: Connection, id: str, error_msg: Optional[str] = None):
+def delete_datasource_mapping(
+    connection: Connection, id: str, error_msg: Optional[str] = None
+):
     """Delete a connection mapping based on id.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): ID of the mapping meant to be deleted.
         error_msg (string, optional): Custom Error Message for Error Handling
 
@@ -495,15 +518,17 @@
         Complete HTTP response object. Expected status is 200.
     """
     url = f"{connection.base_url}/api/datasources/logins"
     return connection.get(url=url)
 
 
 @ErrorHandler(err_msg='Error creating Datasource login.')
-def create_datasource_login(connection: Connection, body, error_msg: Optional[str] = None):
+def create_datasource_login(
+    connection: Connection, body, error_msg: Optional[str] = None
+):
     """Create a new datasource login.
 
     Args:
         connection: MicroStrategy REST API connection object
         body: Datasource login creation info.
         error_msg (string, optional): Custom Error Message for Error Handling
 
@@ -511,15 +536,17 @@
         Complete HTTP response object. Expected status is 201.
     """
     url = f"{connection.base_url}/api/datasources/logins"
     return connection.post(url=url, json=body)
 
 
 @ErrorHandler(err_msg='Error getting Datasource login with ID {id}')
-def get_datasource_login(connection: Connection, id: str, error_msg: Optional[str] = None):
+def get_datasource_login(
+    connection: Connection, id: str, error_msg: Optional[str] = None
+):
     """Get datasource login for a specific id.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of the login
         error_msg (string, optional): Custom Error Message for Error Handling
 
@@ -527,15 +554,17 @@
         Complete HTTP response object. Expected status is 200.
     """
     url = f"{connection.base_url}/api/datasources/logins/{id}"
     return connection.get(url=url)
 
 
 @ErrorHandler(err_msg='Error deleting Datasource login with ID {id}')
-def delete_datasource_login(connection: Connection, id: str, error_msg: Optional[str] = None):
+def delete_datasource_login(
+    connection: Connection, id: str, error_msg: Optional[str] = None
+):
     """Delete a datasource login.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of the login
         error_msg (string, optional): Custom Error Message for Error Handling
 
@@ -567,26 +596,30 @@
 
 @ErrorHandler(err_msg="Error getting table columns for table: {table_id}")
 def get_table_columns(
     connection: Connection,
     datasource_id: str,
     namespace_id: str,
     table_id: str,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     url = (
         f"{connection.base_url}/api/datasources/{datasource_id}/catalog/namespaces/"
         f"{namespace_id}/tables/{table_id}"
     )
     return connection.get(url, headers={"X-MSTR-ProjectID": connection.project_id})
 
 
 @unpack_information
-@ErrorHandler(err_msg='Error converting Datasource embedded connection from DSN to DSN-less')
-def convert_ds_dsn(connection: Connection, datasource_id: str, error_msg: Optional[str] = None):
+@ErrorHandler(
+    err_msg='Error converting Datasource embedded connection from DSN to DSN-less'
+)
+def convert_ds_dsn(
+    connection: Connection, datasource_id: str, error_msg: Optional[str] = None
+):
     """Convert datasource embedded connection from DSN to DSN-less format
     connection string and update the object to metadata.
 
     Args:
         connection: MicroStrategy REST API connection object
         datasource_id (string) : Datasource id
         error_msg (string, optional): Custom Error Message for Error Handling
@@ -596,24 +629,95 @@
         Expected status is 200.
     """
     url = f"{connection.base_url}/api/datasources/{datasource_id}/conversion"
     return connection.post(url=url)
 
 
 @unpack_information
-@ErrorHandler(err_msg='Error converting Datasource connection object from DSN to DSN-less')
+@ErrorHandler(
+    err_msg='Error converting Datasource connection object from DSN to DSN-less'
+)
 def convert_connection_dsn(
     connection: Connection, ds_connection_id: str, error_msg: Optional[str] = None
 ):
     """Convert datasource connection from DSN to DSN-less format connection
     string and update the object to metadata.
 
     Args:
         connection: MicroStrategy REST API connection object
         ds_connection_id (string) : Datasource connection object id
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         HTTP response object with updated object data. Expected status is 200.
     """
-    url = f"{connection.base_url}/api/datasources/connections/{ds_connection_id}/conversion"
+    url = (
+        f"{connection.base_url}/api/datasources/connections/{ds_connection_id}"
+        f"/conversion"
+    )
     return connection.post(url=url)
+
+
+@ErrorHandler(err_msg='Error getting VLDB settings for datasource with ID: {id}')
+def get_vldb_settings(connection: 'Connection', id: str, error_msg: str = None):
+    """Get advanced VLDB settings for a datasource.
+
+    Args:
+        connection (Connection): MicroStrategy REST API connection object
+        id (string): Datasource ID
+        error_msg (string, optional): Custom Error Message for Error Handling
+
+    Returns:
+        Complete HTTP response object.
+    """
+
+    return connection.get(
+        url=f'{connection.base_url}/api/model/datasources/{id}'
+        '?showAdvancedProperties=true'
+    )
+
+
+@ErrorHandler(err_msg='Error updating VLDB settings for datasource with ID {id}')
+def update_vldb_settings(
+    connection: 'Connection', id: str, body: dict, error_msg: str = None
+):
+    """Update metadata of advanced VLDB settings for a datasource.
+
+    Args:
+        connection (Connection): MicroStrategy REST API connection object
+        id (string): Datasource ID
+        body (dict): JSON-formatted data used to update VLDB settings
+        error_msg (string, optional): Custom Error Message for Error Handling
+
+    Returns:
+        Complete HTTP response object.
+    """
+
+    with changeset_manager(connection) as changeset_id:
+        return connection.put(
+            url=f'{connection.base_url}/api/model/datasources/{id}',
+            json=body,
+            headers={'X-MSTR-MS-Changeset': changeset_id},
+        )
+
+
+@ErrorHandler(
+    err_msg='Error getting metadata of VLDB settings for datasource with ID {id}'
+)
+def get_applicable_vldb_settings(
+    connection: 'Connection', id: str, error_msg: str = None
+):
+    """Get metadata of advanced VLDB settings for a datasource.
+
+    Args:
+        connection (Connection): MicroStrategy REST API connection object
+        id (string): Datasource ID
+        error_msg (string, optional): Custom Error Message for Error Handling
+
+    Returns:
+        Complete HTTP response object.
+    """
+
+    return connection.get(
+        url=f'{connection.base_url}/api/model/datasources/{id}'
+        '/applicableAdvancedProperties'
+    )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/devices.py` & `mstrio-py-11.3.9.103/mstrio/api/devices.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,16 @@
 from mstrio.connection import Connection
 from mstrio.utils.error_handlers import ErrorHandler
 from mstrio.utils.time_helper import DatetimeFormats, override_datetime_format
 
 
 @override_datetime_format(
     DatetimeFormats.YMDHMS.value,
-    DatetimeFormats.FULLDATETIME.value, ('dateCreated', 'dateModified')
+    DatetimeFormats.FULLDATETIME.value,
+    ('dateCreated', 'dateModified'),
 )
 @ErrorHandler(err_msg='Error creating Device.')
 def create_device(connection: Connection, body: dict, error_msg: Optional[str] = None):
     """Create a new device.
 
     Args:
         connection: MicroStrategy REST API connection object
@@ -23,15 +24,16 @@
     """
     url = f"{connection.base_url}/api/v2/devices/"
     return connection.post(url=url, json=body)
 
 
 @override_datetime_format(
     DatetimeFormats.YMDHMS.value,
-    DatetimeFormats.FULLDATETIME.value, ('dateCreated', 'dateModified')
+    DatetimeFormats.FULLDATETIME.value,
+    ('dateCreated', 'dateModified'),
 )
 @ErrorHandler(err_msg='Error getting Device with ID {id}')
 def get_device(connection: Connection, id: str, error_msg: Optional[str] = None):
     """Get device by a specific id.
 
     Args:
         connection: MicroStrategy REST API connection object
@@ -59,18 +61,21 @@
     """
     url = f"{connection.base_url}/api/v2/devices/{id}"
     return connection.delete(url=url)
 
 
 @override_datetime_format(
     DatetimeFormats.YMDHMS.value,
-    DatetimeFormats.FULLDATETIME.value, ('dateCreated', 'dateModified')
+    DatetimeFormats.FULLDATETIME.value,
+    ('dateCreated', 'dateModified'),
 )
 @ErrorHandler(err_msg='Error updating Device with ID {id}')
-def update_device(connection: Connection, id: str, body: dict, error_msg: Optional[str] = None):
+def update_device(
+    connection: Connection, id: str, body: dict, error_msg: Optional[str] = None
+):
     """Update a device.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of the device
         body: Device update info.
         error_msg (string, optional): Custom Error Message for Error Handling
@@ -81,22 +86,23 @@
     url = f"{connection.base_url}/api/v2/devices/{id}"
     return connection.put(url=url, json=body)
 
 
 @ErrorHandler(err_msg="Error getting Devices.")
 @override_datetime_format(
     DatetimeFormats.YMDHMS.value,
-    DatetimeFormats.FULLDATETIME.value, ('dateCreated', 'dateModified'),
-    'devices'
+    DatetimeFormats.FULLDATETIME.value,
+    ('dateCreated', 'dateModified'),
+    'devices',
 )
 def get_devices(
     connection: Connection,
     device_type: Optional[str] = None,
     fields: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get information for all devices.
 
     Args:
         connection: MicroStrategy REST API connection object
         fields(list, optional): Comma separated top-level field whitelist. This
             allows client to selectively retrieve part of the response model.
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/documents.py` & `mstrio-py-11.3.9.103/mstrio/api/documents.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,15 +17,15 @@
     offset: int = 0,
     limit: int = -1,
     search_term: Optional[str] = None,
     certified_status: Optional[str] = None,
     search_pattern: Optional[str] = None,
     fields: Optional[str] = None,
     project_id: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> Response:
     """Get the list of available dossiers.
 
     Args:
         connection(object): MicroStrategy REST API connection object
         offset(int): Starting point within the collection of returned search
             results. Used to control paging behavior.
@@ -51,29 +51,29 @@
         headers={'X-MSTR-ProjectID': project_id},
         params={
             'searchTerm': search_term,
             'searchPattern': search_pattern,
             'offset': offset,
             'limit': limit,
             'certifiedStatus': certified_status,
-            'fields': fields
+            'fields': fields,
         },
     )
 
 
 def get_dossiers_async(
     future_session: "FuturesSession",
     connection: "Connection",
     offset: int = 0,
     limit: int = -1,
     search_term: Optional[str] = None,
     certified_status: Optional[str] = None,
     search_pattern: Optional[str] = None,
     fields: Optional[str] = None,
-    project_id: Optional[str] = None
+    project_id: Optional[str] = None,
 ):
     """Get the list of available dossiers asynchronously.
 
     Args:
         future_session: FuturesSession object
         connection: MicroStrategy REST API connection object
         offset(int): Starting point within the collection of returned search
@@ -92,37 +92,37 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     connection._validate_project_selected()
     url = f'{connection.base_url}/api/dossiers'
-    headers = {'X-MSTR-ProjectID': project_id},
+    headers = ({'X-MSTR-ProjectID': project_id},)
     params = {
         'searchTerm': search_term,
         'searchPattern': search_pattern,
         'offset': offset,
         'limit': limit,
         'certifiedStatus': certified_status,
-        'fields': fields
+        'fields': fields,
     }
     return future_session.get(url=url, params=params, headers=headers)
 
 
 @ErrorHandler(err_msg='Error getting available documents.')
 def get_documents(
     connection: "Connection",
     offset: int = 0,
     limit: int = -1,
     search_pattern: str = None,
     search_term: Optional[str] = None,
     certified_status: Optional[str] = None,
     project_id: Optional[str] = None,
     fields: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> Response:
     """Get the list of available documents.
 
     Args:
         connection: MicroStrategy REST API connection object
         offset(int): Starting point within the collection of returned search
             results. Used to control paging behavior.
@@ -149,15 +149,15 @@
         headers={'X-MSTR-ProjectID': project_id},
         params={
             'searchTerm': search_term,
             'searchPattern': search_pattern,
             'offset': offset,
             'limit': limit,
             'certifiedStatus': certified_status,
-            'fields': fields
+            'fields': fields,
         },
     )
 
 
 def get_documents_async(
     future_session: "FuturesSession",
     connection,
@@ -196,15 +196,15 @@
     url = f'{connection.base_url}/api/documents/'
     params = {
         'searchTerm': search_term,
         'searchPattern': search_pattern,
         'offset': offset,
         'limit': limit,
         'certifiedStatus': certified_status,
-        'fields': fields
+        'fields': fields,
     }
     headers = {'X-MSTR-ProjectID': project_id}
     future = future_session.get(url=url, params=params, headers=headers)
     return future
 
 
 @ErrorHandler(err_msg='Error getting document {document_id}')
@@ -216,15 +216,18 @@
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/status"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/instances/"
+        f"{instance_id}/status"
+    )
     return connection.get(url=url, headers={'X-MSTR-ProjectID': None})
 
 
 @ErrorHandler(err_msg='Error getting prompts for document {document_id}')
 def get_prompts_for_instance(connection, document_id, instance_id, error_msg=None):
     """Get the collection of prompts and their respective definitions from a
     document/dossier instance.
@@ -234,15 +237,18 @@
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/prompts"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/"
+        f"instances/{instance_id}/prompts"
+    )
     return connection.get(url=url, headers={'X-MSTR-ProjectID': None})
 
 
 @ErrorHandler(err_msg='Error getting attribute element for prompt {prompt_identifier}')
 def get_attribute_element_for_prompt(
     connection, document_id, instance_id, prompt_identifier, error_msg=None
 ):
@@ -255,39 +261,47 @@
         instance_id (string): Document Instance ID
         prompt_identifier (string): Prompt key or ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/prompts" \
-          f"/{prompt_identifier}/elements"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/"
+        f"instances/{instance_id}/prompts/{prompt_identifier}/elements"
+    )
     return connection.get(url=url, headers={'X-MSTR-ProjectID': None})
 
 
 @ErrorHandler(err_msg='Error getting available object for prompt {prompt_identifier}')
-def get_available_object(connection, document_id, instance_id, prompt_identifier, error_msg=None):
+def get_available_object(
+    connection, document_id, instance_id, prompt_identifier, error_msg=None
+):
     """Get available object for answering all kinds of prompts.
 
     Args:
         connection: MicroStrategy REST API connection object
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         prompt_identifier (string): Prompt key or ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/prompts" \
-          f"/{prompt_identifier}/objects"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/instances/"
+        f"{instance_id}/prompts/{prompt_identifier}/objects"
+    )
     return connection.get(url=url, headers={'X-MSTR-ProjectID': None})
 
 
-@ErrorHandler(err_msg='Error exporting visualization for document {document_id} to PDF file.')
+@ErrorHandler(
+    err_msg='Error exporting visualization for document {document_id} to PDF file.'
+)
 def export_visualization_to_pdf(
     connection, document_id, instance_id, node_key, body, error_msg=None
 ):
     """Export a single visualization from a specific document instance to a PDF
     file.
 
     Args:
@@ -296,20 +310,24 @@
         instance_id (string): Document Instance ID
         body: JSON-formatted information used to format the document
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}" \
-          f"/visualizations/{node_key}/pdf"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}"
+        f"/visualizations/{node_key}/pdf"
+    )
     return connection.post(url=url, headers={'X-MSTR-ProjectID': None}, json=body)
 
 
-@ErrorHandler(err_msg='Error exporting visualization for document {document_id} to CSV file.')
+@ErrorHandler(
+    err_msg='Error exporting visualization for document {document_id} to CSV file.'
+)
 def export_visualization_to_csv(
     connection, document_id, instance_id, node_key, body, error_msg=None
 ):
     """Export a single visualization from a specific document instance to a CSV
     file.
 
     Args:
@@ -319,91 +337,107 @@
         node_key (string): Visualization node key
         body: JSON-formatted information used to format the document
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}" \
-          f"/visualizations/{node_key}/csv"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}"
+        f"/visualizations/{node_key}/csv"
+    )
     return connection.post(url=url, headers={'X-MSTR-ProjectID': None}, json=body)
 
 
 @ErrorHandler(err_msg='Error exporting document {document_id} to PDF file.')
 def export_document_to_pdf(
-        connection: "Connection",
-        document_id: str,
-        instance_id: str,
-        body: dict,
-        error_msg: Optional[str] = None
+    connection: "Connection",
+    document_id: str,
+    instance_id: str,
+    body: dict,
+    error_msg: Optional[str] = None,
 ) -> Response:
     """Export a specific document instance to a PDF file.
 
     Args:
         connection: MicroStrategy REST API connection object
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         body: JSON-formatted information used to format the document
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    project_id = get_valid_project_id(connection=connection, project_id=connection.project_id)
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/pdf"
+    project_id = get_valid_project_id(
+        connection=connection, project_id=connection.project_id
+    )
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/pdf"
+    )
     return connection.post(url=url, headers={'X-MSTR-ProjectID': project_id}, json=body)
 
 
 @ErrorHandler(err_msg='Error exporting document {document_id} to .mstr file')
 def export_document_to_mstr(
-        connection: "Connection",
-        document_id: str,
-        instance_id: str,
-        body: dict,
-        error_msg: Optional[str] = None
+    connection: "Connection",
+    document_id: str,
+    instance_id: str,
+    body: dict,
+    error_msg: Optional[str] = None,
 ) -> Response:
     """Export a specific document in a specific project to an .mstr file.
 
     Args:
         connection: MicroStrategy REST API connection object
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         body: JSON-formatted information used to format the document
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    project_id = get_valid_project_id(connection=connection, project_id=connection.project_id)
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/mstr"
+    project_id = get_valid_project_id(
+        connection=connection, project_id=connection.project_id
+    )
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/instances/"
+        f"{instance_id}/mstr"
+    )
     return connection.post(url=url, headers={'X-MSTR-ProjectID': project_id}, json=body)
 
 
 @ErrorHandler(err_msg='Error exporting document {document_id} to Excel file.')
 def export_document_to_excel(
-        connection: "Connection",
-        document_id: str,
-        instance_id: str,
-        body: dict,
-        error_msg: Optional[str] = None
+    connection: "Connection",
+    document_id: str,
+    instance_id: str,
+    body: dict,
+    error_msg: Optional[str] = None,
 ) -> Response:
     """Export a document from a specific document instance to an Excel file.
 
     Args:
         connection: MicroStrategy REST API connection object
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         body: JSON-formatted information used to format the document
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    project_id = get_valid_project_id(connection=connection, project_id=connection.project_id)
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/excel"
+    project_id = get_valid_project_id(
+        connection=connection, project_id=connection.project_id
+    )
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/"
+        f"instances/{instance_id}/excel"
+    )
     return connection.post(url=url, headers={'X-MSTR-ProjectID': project_id}, json=body)
 
 
 @ErrorHandler(err_msg='Error setting document {document_id} to prompt status.')
 def set_document_to_prompt_status(connection, document_id, instance_id, error_msg=None):
     """Export a document from a specific document instance to an Excel file.
 
@@ -412,15 +446,18 @@
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/rePrompt"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/"
+        f"instances/{instance_id}/rePrompt"
+    )
     return connection.post(url=url, headers={'X-MSTR-ProjectID': None})
 
 
 @ErrorHandler(err_msg='Error getting cubes used by document {document_id}')
 def get_cubes_used_by_document(connection, document_id, error_msg=None):
     """Get the cubes used by a document in a specific project, either directly
     or indirectly.
@@ -446,15 +483,18 @@
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/save"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/"
+        f"instances/{instance_id}/save"
+    )
     return connection.post(url=url, headers={'X-MSTR-ProjectID': None})
 
 
 @ErrorHandler(err_msg='Error saving document {document_id}')
 def save_document_as(connection, document_id, instance_id, error_msg=None):
     """Save a document instance by creating a new document.
 
@@ -463,15 +503,18 @@
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/saveAs"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/"
+        f"instances/{instance_id}/saveAs"
+    )
     return connection.post(url=url, headers={'X-MSTR-ProjectID': None})
 
 
 @ErrorHandler(err_msg='Error creating instance for document {document_id}')
 def create_new_document_instance(connection, document_id, body, error_msg=None):
     """Execute a specific document in a specific project and create an instance
     of the document.
@@ -515,15 +558,18 @@
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/refresh"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/"
+        f"instances/{instance_id}/refresh"
+    )
     return connection.put(url=url, headers={'X-MSTR-ProjectID': None})
 
 
 @ErrorHandler(err_msg='Error getting collection of prompts for document {document_id}')
 def get_prompts(connection, document_id, error_msg=None):
     """Get the collection of prompts and their respective definitions from a
     document/dossier definition.
@@ -552,16 +598,18 @@
         instance_id (string): Document Instance ID
         body: JSON-formatted information used to format the document
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}" \
-          f"/prompts/answers"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}"
+        f"/prompts/answers"
+    )
     return connection.put(url=url, headers={'X-MSTR-ProjectID': None}, json=body)
 
 
 @ErrorHandler(err_msg='Error retrieving document shortcut for document {document_id}')
 def get_document_shortcut(connection, document_id, instance_id, error_msg=None):
     """Retrieve a published shortcut from a specific document instance.
 
@@ -570,15 +618,18 @@
         document_id (string): Document ID
         instance_id (string): Document Instance ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/documents/{document_id}/instances/{instance_id}/shortcut"
+    url = (
+        f"{connection.base_url}/api/documents/{document_id}/"
+        f"instances/{instance_id}/shortcut"
+    )
     return connection.get(url=url)
 
 
 @ErrorHandler(err_msg='Error creating instance for dossier {dossier_id}')
 def create_dossier_instance(connection, dossier_id, body, error_msg=None):
     """Execute a specific dossier and create an instance of the dossier.
 
@@ -592,18 +643,15 @@
         Complete HTTP response object.
     """
     url = f"{connection.base_url}/api/dossiers/{dossier_id}/instances"
     return connection.post(url=url, headers={'X-MSTR-ProjectID': None}, json=body)
 
 
 @ErrorHandler(err_msg='Error getting hierarchy for dossier {id}')
-def get_dossier_hierarchy(
-        connection: "Connection",
-        id: str
-) -> Response:
+def get_dossier_hierarchy(connection: "Connection", id: str) -> Response:
     """Get the hierarchy of a specific dossier in a specific project.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): Dossier ID
 
     Returns:
@@ -626,28 +674,33 @@
         Complete HTTP response object.
     """
     url = f"{connection.base_url}/api/v2/documents/{id}"
     return connection.get(url=url, headers={'X-MSTR-ProjectID': None})
 
 
 @ErrorHandler(err_msg='Error getting dossier hierarchy from instance {instance_id}')
-def get_dossier_hierarchy_from_instance(connection, dossier_id, instance_id, error_msg=None):
+def get_dossier_hierarchy_from_instance(
+    connection, dossier_id, instance_id, error_msg=None
+):
     """Get the hierarchy of a specific dossier in a specific project from
     instance.
 
     Args:
         connection: MicroStrategy REST API connection object
         dossier_id (string): Dossier ID
         instance_id (string): Document Instance ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/v2/dossiers/{dossier_id}/instances/{instance_id}/definition"
+    url = (
+        f"{connection.base_url}/api/v2/dossiers/{dossier_id}/"
+        f"instances/{instance_id}/definition"
+    )
     return connection.get(url=url, headers={'X-MSTR-ProjectID': None})
 
 
 @ErrorHandler(err_msg='Error getting definition and results for dossier {dossier_id}')
 def get_definition_and_results_of_visualization(
     connection, dossier_id, instance_id, chapter_key, visualization_key, error_msg=None
 ):
@@ -659,10 +712,13 @@
         dossier_id (string): Dossier ID
         instance_id (string): Document Instance ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
-    url = f"{connection.base_url}/api/v2/dossiers/{dossier_id}/instances/{instance_id}/chapters" \
-          f"/{chapter_key}/visualizations/{visualization_key}"
+    url = (
+        f"{connection.base_url}/api/v2/dossiers/{dossier_id}"
+        f"/instances/{instance_id}/chapters/{chapter_key}"
+        f"/visualizations/{visualization_key}"
+    )
     return connection.get(url=url, headers={'X-MSTR-ProjectID': None})
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/events.py` & `mstrio-py-11.3.9.103/mstrio/api/events.py`

 * *Files 1% similar despite different names*

```diff
@@ -26,15 +26,17 @@
         connection(object): MicroStrategy connection object returned by
                 `connection.Connection()`.
         error_msg(str, optional): Customized error message.
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
-    return connection.get(url=f'{connection.base_url}/api/events', params={'fields': fields})
+    return connection.get(
+        url=f'{connection.base_url}/api/events', params={'fields': fields}
+    )
 
 
 @ErrorHandler(err_msg='Error getting event {id} information.')
 def get_event(connection, id, fields=None, error_msg=None):
     """Get information of a specific event
 
     Args:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/exceptions.py` & `mstrio-py-11.3.9.103/mstrio/api/exceptions.py`

 * *Files 4% similar despite different names*

```diff
@@ -47,15 +47,17 @@
         succeeded: list of succeeded operations dict elements
     """
 
     def __init__(self, data: List[dict]):
         assert isinstance(data, list)
 
         self.succeeded = data
-        self.full_message = (f"Operation successful:\n{len(self.succeeded)} succeeded requests")
+        self.full_message = (
+            f"Operation successful:\n{len(self.succeeded)} succeeded requests"
+        )
         super().__init__(self.full_message)
 
     def __bool__(self):
         return True
 
 
 class PartialSuccess(Exception):
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/facts.py` & `mstrio-py-11.3.9.103/mstrio/api/facts.py`

 * *Files 4% similar despite different names*

```diff
@@ -10,20 +10,24 @@
 def read_fact(
     connection: "Connection",
     id: str,
     project_id: str = None,
     changeset_id: str = None,
     show_expression_as: Optional[str] = None,
     show_potential_tables: bool = False,
-    show_fields: Optional[str] = None
+    show_fields: Optional[str] = None,
 ):
     if project_id is None:
         connection._validate_project_selected()
         project_id = connection.project_id
-    spt = str(show_potential_tables).lower() if show_potential_tables is not None else None
+    spt = (
+        str(show_potential_tables).lower()
+        if show_potential_tables is not None
+        else None
+    )
     return connection.get(
         url=f"{connection.base_url}/api/model/facts/{id}",
         headers={
             'X-MSTR-ProjectID': project_id,
             'X-MSTR-MS-Changeset': changeset_id,
         },
         params={
@@ -36,17 +40,21 @@
 
 @unpack_information
 @ErrorHandler(err_msg='Error creating a fact.')
 def create_fact(
     connection: "Connection",
     body: dict,
     show_expression_as: Optional[str] = None,
-    show_potential_tables: bool = False
+    show_potential_tables: bool = False,
 ):
-    spt = str(show_potential_tables).lower() if show_potential_tables is not None else None
+    spt = (
+        str(show_potential_tables).lower()
+        if show_potential_tables is not None
+        else None
+    )
     with changeset_manager(connection) as changeset_id:
         return connection.post(
             url=f"{connection.base_url}/api/model/facts",
             headers={'X-MSTR-MS-Changeset': changeset_id},
             params={
                 'showExpressionAs': show_expression_as,
                 'showPotentialTables': spt,
@@ -58,17 +66,21 @@
 @unpack_information
 @ErrorHandler(err_msg='Error updating fact with ID: {id}.')
 def update_fact(
     connection: "Connection",
     id: str,
     body: dict,
     show_expression_as: Optional[str] = None,
-    show_potential_tables: bool = False
+    show_potential_tables: bool = False,
 ):
-    spt = str(show_potential_tables).lower() if show_potential_tables is not None else None
+    spt = (
+        str(show_potential_tables).lower()
+        if show_potential_tables is not None
+        else None
+    )
     with changeset_manager(connection) as changeset_id:
         return connection.put(
             url=f"{connection.base_url}/api/model/facts/{id}",
             headers={'X-MSTR-MS-Changeset': changeset_id},
             params={
                 'showExpressionAs': show_expression_as,
                 'showPotentialTables': spt,
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/filters.py` & `mstrio-py-11.3.9.103/mstrio/api/filters.py`

 * *Files 1% similar despite different names*

```diff
@@ -88,17 +88,15 @@
     """
     if project_id is None:
         connection._validate_project_selected()
         project_id = connection.project_id
 
     return connection.get(
         url=f"{connection.base_url}/api/model/filters/{id}",
-        headers={
-            "X-MSTR-ProjectID": project_id, "X-MSTR-MS-Changeset": changeset_id
-        },
+        headers={"X-MSTR-ProjectID": project_id, "X-MSTR-MS-Changeset": changeset_id},
         params={
             "showExpressionAs": show_expression_as,
             "showFilterTokens": str(show_filter_tokens).lower(),
         },
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/folders.py` & `mstrio-py-11.3.9.103/mstrio/api/folders.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 
 @ErrorHandler(err_msg='Error while creating the folder.')
 def create_folder(
     connection: Connection,
     name: str,
     parent_id: str,
     description: Optional[str] = None,
-    project_id: Optional[str] = None
+    project_id: Optional[str] = None,
 ):
     """Create a folder.
 
     Note:
         When `project_id` is provided then folder will be created in this
         project. Otherwise it will be created in a project selected within
         `connection` object.
@@ -37,15 +37,15 @@
         "name": name,
         "description": description,
         "parent": parent_id,
     }
     return connection.post(
         url=connection.base_url + '/api/folders',
         headers={'X-MSTR-ProjectID': project_id},
-        json=body
+        json=body,
     )
 
 
 @ErrorHandler(err_msg='Error while deleting folder with ID: {id}.')
 def delete_folder(connection: Connection, id: str, project_id: Optional[str] = None):
     """Delete complete folder.
 
@@ -55,25 +55,26 @@
         project_id (string, optional): id of project
 
     Returns:
         Complete Future object.
     """
     project_id = project_id if project_id is not None else connection.project_id
     return connection.delete(
-        url=f"{connection.base_url}/api/folders/{id}", headers={'X-MSTR-ProjectID': project_id}
+        url=f"{connection.base_url}/api/folders/{id}",
+        headers={'X-MSTR-ProjectID': project_id},
     )
 
 
 @ErrorHandler(err_msg='Error while listing folders.')
 def list_folders(
     connection: Connection,
     project_id: Optional[str] = None,
     offset: int = 0,
     limit: int = 5000,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get a list of folders.
 
     Args:
         connection: MicroStrategy REST API connection object
         project_id (string, optional): id of project
         offset (int, optional): Starting point within the collection of returned
@@ -84,26 +85,24 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f"{connection.base_url}/api/folders",
         headers={'X-MSTR-ProjectID': project_id},
-        params={
-            'offset': offset, 'limit': limit
-        }
+        params={'offset': offset, 'limit': limit},
     )
 
 
 def list_folders_async(
     future_session: "FuturesSession",
     connection: Connection,
     project_id: Optional[str] = None,
     offset: int = 0,
-    limit: int = 5000
+    limit: int = 5000,
 ):
     """Get a list of folders asynchronously.
 
     Args:
         future_session(object): `FuturesSession` object to call MicroStrategy
             REST Server asynchronously
         connection: MicroStrategy REST API connection object
@@ -126,15 +125,15 @@
 @ErrorHandler(err_msg='Error while getting contents of a folder with ID: {id}.')
 def get_folder_contents(
     connection: Connection,
     id: str,
     project_id: Optional[str] = None,
     offset: int = 0,
     limit: int = 5000,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get contents of a folder.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): ID of folder
         project_id (string, optional): id of project
@@ -147,27 +146,25 @@
     Returns:
         Complete HTTP response object.
     """
     project_id = project_id if project_id is not None else connection.project_id
     return connection.get(
         url=f"{connection.base_url}/api/folders/{id}",
         headers={'X-MSTR-ProjectID': project_id},
-        params={
-            'offset': offset, 'limit': limit
-        }
+        params={'offset': offset, 'limit': limit},
     )
 
 
 def get_folder_contents_async(
     future_session: "FuturesSession",
     connection: Connection,
     id: str,
     project_id: Optional[str] = None,
     offset: int = 0,
-    limit: int = 5000
+    limit: int = 5000,
 ):
     """Get contents of a folder asynchronously.
 
     Args:
         future_session(object): `FuturesSession` object to call MicroStrategy
             REST Server asynchronously
         connection: MicroStrategy REST API connection object
@@ -192,15 +189,15 @@
 @ErrorHandler(err_msg='Error while getting contents of a pre-defined folder.')
 def get_predefined_folder_contents(
     connection: Connection,
     folder_type: int,
     project_id: Optional[str] = None,
     offset: int = 0,
     limit: int = 5000,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get contents of a pre-defined folder.
 
     Args:
         connection: MicroStrategy REST API connection object
         folder_type (int): predefined folder type, from `EnumDSSXMLFolderNames`
         project_id (string, optional): id of project
@@ -212,27 +209,25 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f"{connection.base_url}/api/folders/preDefined/{folder_type}",
         headers={'X-MSTR-ProjectID': project_id},
-        params={
-            'offset': offset, 'limit': limit
-        }
+        params={'offset': offset, 'limit': limit},
     )
 
 
 def get_predefined_folder_contents_async(
     future_session: "FuturesSession",
     connection: Connection,
     folder_type: int,
     project_id: Optional[str] = None,
     offset: int = 0,
-    limit: int = 5000
+    limit: int = 5000,
 ):
     """Get contents of a pre-defined folder.
 
     Args:
         future_session(object): `FuturesSession` object to call MicroStrategy
             REST Server asynchronously
         connection: MicroStrategy REST API connection object
@@ -250,21 +245,23 @@
     url = f"{connection.base_url}/api/folders/preDefined/{folder_type}"
     headers = {'X-MSTR-ProjectID': project_id}
     params = {'offset': offset, 'limit': limit}
     return future_session.get(url=url, headers=headers, params=params)
 
 
 @ErrorHandler(err_msg='Error while getting contents of My Personal Objects folder.')
-def get_my_personal_objects_contents(connection: Connection, project_id: Optional[str] = None):
+def get_my_personal_objects_contents(
+    connection: Connection, project_id: Optional[str] = None
+):
     """Get contents of My Personal Objects folder.
 
     Args:
         connection: MicroStrategy REST API connection object
         project_id (string, optional): id of project
 
     Returns:
          Complete HTTP response object.
     """
     return connection.get(
         url=f"{connection.base_url}/api/folders/myPersonalObjects",
-        headers={'X-MSTR-ProjectID': project_id}
+        headers={'X-MSTR-ProjectID': project_id},
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/hierarchies.py` & `mstrio-py-11.3.9.103/mstrio/api/hierarchies.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,32 +1,34 @@
 from mstrio.connection import Connection
 from mstrio.utils.api_helpers import changeset_manager
 from mstrio.utils.error_handlers import ErrorHandler
 
 
 @ErrorHandler(err_msg='Error getting attribute {id} relationship.')
-def get_attribute_relationships(
-    connection: Connection, id: str, project_id: str
-):
+def get_attribute_relationships(connection: Connection, id: str, project_id: str):
     """Get relationship(s) of an attribute
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of a attribute
         project_id: Id of a project
 
     Return:
         HTTP response object. Expected status: 200
     """
     with changeset_manager(connection) as changeset_id:
         return connection.get(
-            url=f'{connection.base_url}/api/model/systemHierarchy/attributes/{id}/relationships',
+            url=(
+                f'{connection.base_url}/api/model/systemHierarchy/attributes/'
+                f'{id}/relationships'
+            ),
             headers={
-                'X-MSTR-MS-Changeset': changeset_id, 'X-MSTR-ProjectID': project_id
-            }
+                'X-MSTR-MS-Changeset': changeset_id,
+                'X-MSTR-ProjectID': project_id,
+            },
         )
 
 
 @ErrorHandler(err_msg='Error updating attribute {id} relationship.')
 def update_attribute_relationships(
     connection: Connection,
     id: str,
@@ -40,11 +42,14 @@
         body: JSON-formatted definition of the attribute relationships
 
     Return:
         HTTP response object. Expected status: 200
     """
     with changeset_manager(connection) as changeset_id:
         return connection.put(
-            url=f'{connection.base_url}/api/model/systemHierarchy/attributes/{id}/relationships',
+            url=(
+                f'{connection.base_url}/api/model/systemHierarchy/attributes/'
+                f'{id}/relationships'
+            ),
             headers={'X-MSTR-MS-Changeset': changeset_id},
-            json=body
+            json=body,
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/hooks.py` & `mstrio-py-11.3.9.103/mstrio/api/hooks.py`

 * *Files 6% similar despite different names*

```diff
@@ -3,27 +3,30 @@
 import os
 
 from mstrio.utils.helper import exception_handler
 
 logger = logging.getLogger(__name__)
 
 
-def print_url(response, *args, **kwargs):  # NOSONAR required for hook to session objects
+def print_url(
+    response, *args, **kwargs  # NOSONAR required for hook to session objects
+):
     """Response hook to print url for debugging."""
     logger.debug(response.url)
 
 
-def save_response(response, *args, **kwargs):  # NOSONAR required for hook to session objects
+def save_response(
+    response, *args, **kwargs  # NOSONAR required for hook to session objects
+):
     """Response hook to save REST API responses to files structured by the API
     family."""
     import json
     from pathlib import Path
 
     if response.status_code != 204:
-
         # Generate file name
         base_path = Path(__file__).parents[2] / 'tests/resources/auto-api-responses/'
         url = response.url.rsplit('api/', 1)[1]
         temp_path = url.split('/')
         file_name = '-'.join(temp_path[1:]) if len(temp_path) > 1 else temp_path[0]
         file_name = f'{file_name}-{response.request.method}'
         file_path = base_path if len(temp_path) == 1 else base_path / temp_path[0]
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/incremental_refresh_reports.py` & `mstrio-py-11.3.9.103/mstrio/api/incremental_refresh_reports.py`

 * *Files 1% similar despite different names*

```diff
@@ -189,15 +189,18 @@
         id (str): Incremental Refresh Report's ID
         project_id (str): ID of a project
 
     Return:
         HTTP response object. Expected status: 200
     """
     return connection.get(
-        url=f'{connection.base_url}/api/model/incrementalRefresh/{id}/applicableVldbProperties',
+        url=(
+            f'{connection.base_url}/api/model/incrementalRefresh/'
+            f'{id}/applicableVldbProperties'
+        ),
         headers={'X-MSTR-ProjectID': project_id},
     )
 
 
 @ErrorHandler(err_msg="Error executing an incremental refresh report")
 def execute_incremental_refresh_report(
     connection: Connection, id: str, project_id: str, fields: Optional[str] = None
@@ -239,15 +242,18 @@
         fields: A whitelist of top-level fields separated by commas.
             Allow the client to selectively retrieve fields in the response.
 
     Return:
         HTTP response object. Expected status: 202
     """
     return connection.post(
-        url=f'{connection.base_url}/api/incrementalRefresh/{id}/instances/{instance_id}/data',
+        url=(
+            f'{connection.base_url}/api/incrementalRefresh/{id}/instances'
+            f'/{instance_id}/data'
+        ),
         headers={'X-MSTR-ProjectID': project_id},
         params={'fields': fields},
     )
 
 
 @ErrorHandler(err_msg="Error getting preview data for an incremental refresh report")
 def get_incremental_refresh_report_preview_data(
@@ -271,15 +277,18 @@
         fields: A whitelist of top-level fields separated by commas.
             Allow the client to selectively retrieve fields in the response.
 
     Return:
         HTTP response object. Expected status: 200
     """
     return connection.get(
-        url=f'{connection.base_url}/api/incrementalRefresh/{id}/instances/{instance_id}/data',
+        url=(
+            f'{connection.base_url}/api/incrementalRefresh/{id}/instances'
+            f'/{instance_id}/data'
+        ),
         headers={'X-MSTR-ProjectID': project_id},
         params={
             'offset': offset,
             'limit': limit,
             'fields': fields,
         },
     )
@@ -298,15 +307,17 @@
     """
     return connection.post(
         url=f'{connection.base_url}/api/model/incrementalRefresh/{id}/instances',
     )
 
 
 @ErrorHandler(err_msg="Error deleting instance of the incremental refresh report")
-def delete_incremental_refresh_report_instance(connection: Connection, id: str, instance_id: str):
+def delete_incremental_refresh_report_instance(
+    connection: Connection, id: str, instance_id: str
+):
     """Delete instance of an incremental refresh report.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (str): Incremental Refresh Report's ID
         instance_id (str): Incremental Refresh Report Instance ID
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/library.py` & `mstrio-py-11.3.9.103/mstrio/api/library.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/mstrio/api/metrics.py` & `mstrio-py-11.3.9.103/mstrio/api/metrics.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 
 @unpack_information
 @ErrorHandler(err_msg='Error creating a metric')
 def create_metric(
     connection: Connection,
     body: dict,
     show_expression_as: Optional[list[str]] = None,
-    show_filter_tokens: bool = False
+    show_filter_tokens: bool = False,
 ):
     """Create a new metric in the changeset,
     based on the definition provided in request body.
 
     Args:
         connection: MicroStrategy REST API connection object
         body: Metric creation data
@@ -35,28 +35,28 @@
     """
     with changeset_manager(connection) as changeset_id:
         return connection.post(
             url=f"{connection.base_url}/api/model/metrics",
             headers={"X-MSTR-MS-Changeset": changeset_id},
             params={
                 'showExpressionAs': show_expression_as,
-                'showFilterTokens': str(show_filter_tokens).lower()
+                'showFilterTokens': str(show_filter_tokens).lower(),
             },
             json=body,
         )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error getting metric with ID: {id}')
 def get_metric(
     connection: Connection,
     id: str,
     changeset_id: Optional[str] = None,
     show_expression_as: Optional[list[str]] = None,
-    show_filter_tokens: bool = False
+    show_filter_tokens: bool = False,
 ):
     """Get definition of a single metric by id
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of a metric
         changeset_id: ID of a changeset
@@ -76,27 +76,27 @@
         HTTP response object. Expected status: 200
     """
     return connection.get(
         url=f'{connection.base_url}/api/model/metrics/{id}',
         headers={'X-MSTR-MS-Changeset': changeset_id},
         params={
             'showExpressionAs': show_expression_as,
-            'showFilterTokens': str(show_filter_tokens).lower()
-        }
+            'showFilterTokens': str(show_filter_tokens).lower(),
+        },
     )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error updating metric with ID: {id}')
 def update_metric(
     connection: Connection,
     id: str,
     body: dict,
     show_expression_as: Optional[list[str]] = None,
-    show_filter_tokens: bool = False
+    show_filter_tokens: bool = False,
 ):
     """Update a specific metric in the changeset,
     based on the definition provided in request body.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of a metric
@@ -118,11 +118,11 @@
     """
     with changeset_manager(connection) as changeset_id:
         return connection.put(
             url=f'{connection.base_url}/api/model/metrics/{id}',
             headers={'X-MSTR-MS-Changeset': changeset_id},
             params={
                 'showExpressionAs': show_expression_as,
-                'showFilterTokens': str(show_filter_tokens).lower()
+                'showFilterTokens': str(show_filter_tokens).lower(),
             },
-            json=body
+            json=body,
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/migration.py` & `mstrio-py-11.3.9.103/mstrio/api/migration.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,15 +4,17 @@
 
 from mstrio.connection import Connection
 from mstrio.utils.error_handlers import ErrorHandler
 
 
 @ErrorHandler(err_msg='Error while creating the package holder')
 def create_package_holder(
-    connection: Connection, project_id: Optional[str] = None, error_msg: Optional[str] = None
+    connection: Connection,
+    project_id: Optional[str] = None,
+    error_msg: Optional[str] = None,
 ) -> requests.Response:
     """Create a new in-memory metadata package holder.
 
     Args:
         connection (Connection): Object representation of connection to
             MSTR Server.
         project_id (Optional[str]): Optional ID of a project. Defaults to None.
@@ -20,26 +22,27 @@
 
     Returns:
         requests.Response: Response object containing all of the information
         returned by the server.
     """
     project_id = project_id if project_id is not None else connection.project_id
     return connection.post(
-        url=f'{connection.base_url}/api/packages', headers={'X-MSTR-ProjectID': project_id}
+        url=f'{connection.base_url}/api/packages',
+        headers={'X-MSTR-ProjectID': project_id},
     )
 
 
 @ErrorHandler(err_msg='Error while updating the package holder with id: {id}')
 def update_package_holder(
     connection: Connection,
     body: dict,
     id: str,
     project_id: Optional[str] = None,
     prefer: str = "respond-async",
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> requests.Response:
     """Fill the content of the in-memory metadata package holder per supplied
     specification. Currently, it's only supported when the holder is empty.
 
     Args:
         connection (Connection): Object representation of connection to
             MSTR Server.
@@ -54,27 +57,25 @@
     Returns:
         requests.Response: Response object containing all of the information
         returned by the server.
     """
     project_id = project_id if project_id is not None else connection.project_id
     return connection.put(
         url=f'{connection.base_url}/api/packages/{id}',
-        headers={
-            'X-MSTR-ProjectID': project_id, 'Prefer': prefer
-        },
-        json=body
+        headers={'X-MSTR-ProjectID': project_id, 'Prefer': prefer},
+        json=body,
     )
 
 
 @ErrorHandler(err_msg='Error while downloading the package with id: {id}')
 def download_package(
     connection: Connection,
     id: str,
     project_id: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> requests.Response:
     """Download a package binary.
 
     Args:
         connection (Connection): Object representation of connection to
             MSTR Server.
         id (str): ID of the package to be downloaded.
@@ -84,25 +85,25 @@
     Returns:
         requests.Response: Response object containing all of the information
         returned by the server.
     """
     project_id = project_id if project_id is not None else connection.project_id
     return connection.get(
         url=f'{connection.base_url}/api/packages/{id}/binary',
-        headers={'X-MSTR-ProjectID': project_id}
+        headers={'X-MSTR-ProjectID': project_id},
     )
 
 
 @ErrorHandler(err_msg='Error while uploading the package with id: {id}')
 def upload_package(
     connection: Connection,
     id: str,
     file: bytes,
     project_id: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> requests.Response:
     """Upload package to sandbox directly.
 
     Args:
         connection (Connection): Object representation of connection to
             MSTR Server.
         id (str): ID of the package to be uploaded.
@@ -114,25 +115,25 @@
         requests.Response: Response object containing all of the information
         returned by the server.
     """
     project_id = project_id if project_id is not None else connection.project_id
     return connection.put(
         url=f'{connection.base_url}/api/packages/{id}/binary',
         headers={'X-MSTR-ProjectID': project_id},
-        files={'file': file}
+        files={'file': file},
     )
 
 
 @ErrorHandler(err_msg='Error while getting the package holder with id: {id}')
 def get_package_holder(
     connection: Connection,
     id: str,
     project_id: Optional[str] = None,
     show_content: bool = True,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> requests.Response:
     """Get definition of a package, including package status and its detail
     content.
 
     Args:
         connection (Connection): Object representation of connection to
             MSTR Server.
@@ -147,25 +148,25 @@
         returned by the server.
     """
     project_id = project_id if project_id is not None else connection.project_id
 
     return connection.get(
         url=f'{connection.base_url}/api/packages/{id}',
         headers={'X-MSTR-ProjectID': project_id},
-        params={'showContent': show_content}
+        params={'showContent': show_content},
     )
 
 
 @ErrorHandler(err_msg='Error while deleting the package holder with id: {id}')
 def delete_package_holder(
     connection: Connection,
     id: str,
     project_id: Optional[str] = None,
     prefer: str = 'respond-async',
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> requests.Response:
     """Delete the in-memory metadata package holder, releasing associated
     Intelligence Server resources.
 
     Args:
         connection (Connection): Object representation of connection to
             MSTR Server.
@@ -180,27 +181,27 @@
         requests.Response: Response object containing all of the information
         returned by the server.
     """
 
     project_id = project_id if project_id is not None else connection.project_id
     return connection.delete(
         url=f'{connection.base_url}/api/packages/{id}',
-        headers={
-            'X-MSTR-ProjectID': project_id, 'Prefer': prefer
-        }
+        headers={'X-MSTR-ProjectID': project_id, 'Prefer': prefer},
     )
 
 
-@ErrorHandler(err_msg='Error while creating the import for package holder with id: {id}')
+@ErrorHandler(
+    err_msg='Error while creating the import for package holder with id: {id}'
+)
 def create_import(
     connection: Connection,
     id: str,
     project_id: Optional[str] = None,
     generate_undo: bool = False,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> requests.Response:
     """Create a package import process.
 
     Args:
         connection (Connection): Object representation of connection to
             MSTR Server.
         id (str): ID of the package for which import process will be
@@ -217,29 +218,25 @@
 
     # TODO: Change to a parameter when any other values are supported
     prefer = 'respond-async'
 
     project_id = project_id if project_id is not None else connection.project_id
     return connection.post(
         url=f'{connection.base_url}/api/packages/imports',
-        headers={
-            'X-MSTR-ProjectID': project_id, 'Prefer': prefer
-        },
-        params={
-            'packageId': id, 'generateUndo': generate_undo
-        },
+        headers={'X-MSTR-ProjectID': project_id, 'Prefer': prefer},
+        params={'packageId': id, 'generateUndo': generate_undo},
     )
 
 
 @ErrorHandler(err_msg='Error while getting the import with id: {id}')
 def get_import(
     connection: Connection,
     id: str,
     project_id: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> requests.Response:
     """Get result of a package import process.
 
     Args:
         connection (Connection): Object representation of connection to
             MSTR Server.
         id (str): Import process ID.
@@ -249,24 +246,24 @@
     Returns:
         requests.Response: Response object containing all of the information
         returned by the server.
     """
     project_id = project_id if project_id is not None else connection.project_id
     return connection.get(
         url=f'{connection.base_url}/api/packages/imports/{id}',
-        headers={'X-MSTR-ProjectID': project_id}
+        headers={'X-MSTR-ProjectID': project_id},
     )
 
 
 @ErrorHandler(err_msg='Error while deleting the import with id: {id}')
 def delete_import(
     connection: Connection,
     id: str,
     project_id: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> requests.Response:
     """Closes an existing import process previously created.
 
     Args:
         connection (Connection): Object representation of connection to
             MSTR Server.
         id (str): Import process ID.
@@ -279,26 +276,24 @@
     """
     # TODO: Change to a parameter when any other values are supported
     prefer = 'respond-async'
 
     project_id = project_id if project_id is not None else connection.project_id
     return connection.delete(
         url=f'{connection.base_url}/api/packages/imports/{id}',
-        headers={
-            'X-MSTR-ProjectID': project_id, 'Prefer': prefer
-        }
+        headers={'X-MSTR-ProjectID': project_id, 'Prefer': prefer},
     )
 
 
 @ErrorHandler(err_msg='Error while creating the undo for import with id: {id}')
 def create_undo(
     connection: Connection,
     id: str,
     project_id: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> requests.Response:
     """Download undo package binary for this import process.
 
     Args:
         connection (Connection): Object representation of connection to
             MSTR Server.
         id (str): Import process ID.
@@ -308,9 +303,9 @@
     Returns:
         requests.Response: Response object containing all of the information
         returned by the server.
     """
     project_id = project_id if project_id is not None else connection.project_id
     return connection.get(
         url=f'{connection.base_url}/api/packages/imports/{id}/undoPackage/binary',
-        headers={'X-MSTR-ProjectID': project_id}
+        headers={'X-MSTR-ProjectID': project_id},
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/misc.py` & `mstrio-py-11.3.9.103/mstrio/api/misc.py`

 * *Files 14% similar despite different names*

```diff
@@ -19,13 +19,13 @@
         exception_handler(
             (
                 "SSL certificate error.\nPlease double check that the link you "
                 "are using comes from a trusted source. If you trust the URL "
                 "provided please specify parameter 'ssl_verify' to 'False' in the "
                 "'Connection' class.\n\nCheck readme for more details."
             ),
-            SSLError
+            SSLError,
         )
 
     if not response.ok:
         response_handler(response, "Failed to check server status")
     return response
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/monitors.py` & `mstrio-py-11.3.9.103/mstrio/api/monitors.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,15 +4,19 @@
 from urllib.parse import quote, urlencode
 
 from packaging import version
 from requests.adapters import Response
 
 from mstrio.api.exceptions import MstrException, PartialSuccess, Success
 from mstrio.utils.error_handlers import bulk_operation_response_handler, ErrorHandler
-from mstrio.utils.helper import delete_none_values, filter_list_of_dicts, response_handler
+from mstrio.utils.helper import (
+    delete_none_values,
+    filter_list_of_dicts,
+    response_handler,
+)
 from mstrio.utils.sessions import FuturesSessionWithRenewal
 
 if TYPE_CHECKING:
     from requests_futures.sessions import FuturesSession
 
     from mstrio.connection import Connection
 
@@ -37,17 +41,15 @@
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
 
     return connection.get(
         url=f'{connection.base_url}/api/monitors/projects',
         headers={'X-MSTR-ProjectID': None},
-        params={
-            'offset': offset, 'limit': limit
-        },
+        params={'offset': offset, 'limit': limit},
     )
 
 
 def get_projects_async(
     future_session: "FuturesSession",
     connection: "Connection",
     offset: int = 0,
@@ -71,18 +73,22 @@
     headers = {'X-MSTR-ProjectID': None}
     params = {'offset': offset, 'limit': limit}
     future = future_session.get(url=url, headers=headers, params=params)
     return future
 
 
 @ErrorHandler(
-    err_msg='Error getting information about nodes in the connected Intelligence Server cluster.'
+    err_msg='Error getting information about nodes in the connected Intelligence '
+    'Server cluster.'
 )
 def get_node_info(
-    connection: "Connection", id: str = None, node_name: str = None, error_msg: str = None
+    connection: "Connection",
+    id: str = None,
+    node_name: str = None,
+    error_msg: str = None,
 ):
     """Get information about nodes in the connected Intelligence Server
     cluster.
 
     This includes basic information, runtime state and information of projects
     on each node. This operation requires the "Monitor cluster" privilege.
 
@@ -92,30 +98,29 @@
         id (str, optional): Project ID
         node_name (str, optional): Node Name
         error_msg (string, optional): Custom Error Message for Error Handling
     """
     return connection.get(
         url=f'{connection.base_url}/api/monitors/iServer/nodes',
         headers={'X-MSTR-ProjectID': None},
-        params={
-            'projects.id': id, 'name': node_name
-        },
+        params={'projects.id': id, 'name': node_name},
     )
 
 
 @ErrorHandler(
-    err_msg='Error updating properties for a project {project_id} for cluster node {node_name}.'
+    err_msg='Error updating properties for a project {project_id} for cluster node {'
+    'node_name}.'
 )
 def update_node_properties(
     connection: "Connection",
     node_name: str,
     project_id: str,
     body: dict,
     error_msg: str = None,
-    whitelist: Optional[list[tuple]] = None
+    whitelist: Optional[list[tuple]] = None,
 ):
     """Update properties such as project status for a specific project for
     respective cluster node. You obtain cluster node name and project id from
     GET /monitors/iServer/nodes.
 
     {
         "operationList": [
@@ -139,26 +144,31 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
 
     return connection.patch(
-        url=f'{connection.base_url}/api/monitors/iServer/nodes/{node_name}/projects/{project_id}',
+        url=(
+            f'{connection.base_url}/api/monitors/iServer/nodes/{node_name}/projects'
+            f'/{project_id}'
+        ),
         headers={'X-MSTR-ProjectID': None},
         json=body,
     )
 
 
-@ErrorHandler(err_msg='Error adding node {node_name} to connected Intelligence Server cluster.')
+@ErrorHandler(
+    err_msg='Error adding node {node_name} to connected Intelligence Server cluster.'
+)
 def add_node(
     connection: "Connection",
     node_name: str,
     error_msg: str = None,
-    whitelist: Optional[list[tuple]] = None
+    whitelist: Optional[list[tuple]] = None,
 ):
     """Add a node to the connected Intelligence Server cluster. The node must
     meet I-Server clustering requirements. If the node is part of a multi-node
     cluster, all the nodes in that cluster will be added. If the node is
     already in the cluster, the operation succeeds without making any change.
     This operation requires the "Monitor cluster" and "Administer cluster"
     privilege.
@@ -179,21 +189,22 @@
     return connection.put(
         url=f'{connection.base_url}/api/monitors/iServer/nodes/{node_name}',
         headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(
-    err_msg='Error removing node {node_name} from the connected Intelligence Server cluster.'
+    err_msg='Error removing node {node_name} from the connected Intelligence Server '
+    'cluster.'
 )
 def remove_node(
     connection: "Connection",
     node_name: str,
     error_msg: str = None,
-    whitelist: Optional[list[tuple]] = None
+    whitelist: Optional[list[tuple]] = None,
 ):
     """Remove a node from the connected Intelligence Server cluster. After a
     successful removal, some existing authorization tokens may become
     invalidated and in this case re-login is needed. You cannot remove a node
     if it's the configured default node of Library Server, or there is only one
     node in the cluster. This operation requires the "Monitor cluster" and
     "Administer cluster" privilege.
@@ -219,15 +230,15 @@
 
 @ErrorHandler(err_msg='Error getting user connections for {node_name} cluster node.')
 def get_user_connections(
     connection: "Connection",
     node_name: str,
     offset: int = 0,
     limit: int = 100,
-    error_msg: str = None
+    error_msg: str = None,
 ):
     """Get user connections information on specific intelligence server node.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         offset(int): Starting point within the collection of returned search
@@ -240,26 +251,24 @@
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
     return connection.get(
         url=f'{connection.base_url}/api/monitors/userConnections',
         headers={'X-MSTR-ProjectID': None},
-        params={
-            'clusterNode': node_name, 'offset': offset, 'limit': limit
-        },
+        params={'clusterNode': node_name, 'offset': offset, 'limit': limit},
     )
 
 
 def get_user_connections_async(
     future_session: "FuturesSession",
     connection: "Connection",
     node_name: str,
     offset: int = 0,
-    limit: int = 100
+    limit: int = 100,
 ):
     """Get user connections information on specific intelligence server node.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         node_name (string): Node Name.
@@ -365,24 +374,26 @@
         id (string): cube cache id
         throw_error (bool, optional): Flag indicates if the error should be
             thrown.
 
     Returns:
         Complete HTTP response object.
     """
-    return connection.delete(url=f'{connection.base_url}/api/monitors/caches/cubes/{id}')
+    return connection.delete(
+        url=f'{connection.base_url}/api/monitors/caches/cubes/{id}'
+    )
 
 
 @ErrorHandler(err_msg='Error altering cube cache {id} status.')
 def alter_cube_cache_status(
     connection: "Connection",
     id: str,
     active: bool = None,
     loaded: bool = None,
-    throw_error: bool = True
+    throw_error: bool = True,
 ):
     """Alter an cube cache status. In one request it is possible to set either
     'active' or 'loaded', never both.
 
     Args:
         connection: MicroStrategy connection object returned by
             `connection.Connection()`.
@@ -400,28 +411,28 @@
         loaded = 'loaded' if loaded else 'unloaded'
     body = {'state': {'active': active, 'loadedState': loaded}}
     body = delete_none_values(body, recursion=True)
 
     return connection.patch(
         url=f'{connection.base_url}/api/monitors/caches/cubes/{id}',
         headers={'Prefer': 'respond-async'},
-        json=body
+        json=body,
     )
 
 
 @ErrorHandler(err_msg='Error getting list of cube caches for node {node}.')
 def get_cube_caches(
     connection: "Connection",
     node: str,
     offset: int = 0,
     limit: int = 1000,
     project_ids: str = None,
     loaded: bool = False,
     sort_by: str = None,
-    error_msg: str = None
+    error_msg: str = None,
 ):
     """Get the list of cube caches on a specific cluster node.
 
     Args:
         connection: MicroStrategy connection object returned by
             `connection.Connection()`.
         node (string): Intelligence Server cluster node name
@@ -448,28 +459,28 @@
         url=f'{connection.base_url}/api/monitors/caches/cubes',
         params={
             'clusterNode': node,
             'offset': offset,
             'limit': limit,
             'projectIds': project_ids,
             'state.loadedState': loaded,
-            'sortBy': sort_by
+            'sortBy': sort_by,
         },
     )
 
 
 def get_cube_caches_async(
     future_session: "FuturesSession",
     connection: "Connection",
     node: str,
     offset: int = 0,
     limit: int = 1000,
     project_ids: str = None,
     loaded: bool = False,
-    sort_by: str = None
+    sort_by: str = None,
 ):
     """Get the list of cube caches on a specific cluster node asynchronously.
 
     Args:
         future_session(object): Future Session object to call MicroStrategy REST
             Server asynchronously
         connection: MicroStrategy connection object returned by
@@ -495,15 +506,15 @@
     url = f'{connection.base_url}/api/monitors/caches/cubes'
     params = {
         'clusterNode': node,
         'offset': offset,
         'limit': limit,
         'projectIds': project_ids,
         'state.loadedState': loaded,
-        'sortBy': sort_by
+        'sortBy': sort_by,
     }
     future = future_session.get(url=url, params=params)
     return future
 
 
 @ErrorHandler(err_msg='Error getting cube cache manipulation {manipulation_id} status.')
 def get_cube_cache_manipulation_status(
@@ -517,20 +528,27 @@
         manipulation_id (string): cube cache manipulation ID
         throw_error (bool, optional): In case of True (default) the error will
             be thrown when it occurs.
 
     Returns:
         Complete HTTP response object.
     """
-    url = f'{connection.base_url}/api/monitors/caches/cubes/manipulations/{manipulation_id}/status'
+    url = (
+        f'{connection.base_url}/api/monitors/caches/cubes/'
+        f'manipulations/{manipulation_id}/status'
+    )
     return connection.get(url=url)
 
 
-@ErrorHandler(err_msg='Error getting database connections for {nodes_names} cluster node.')
-def get_database_connections(connection: "Connection", nodes_names: str, error_msg: str = None):
+@ErrorHandler(
+    err_msg='Error getting database connections for {nodes_names} cluster node.'
+)
+def get_database_connections(
+    connection: "Connection", nodes_names: str, error_msg: str = None
+):
     """Get database connections information on specific intelligence
         server node.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         nodes_names (string): Node names split by ",".
@@ -578,15 +596,15 @@
 
 
 def get_job(
     connection: "Connection",
     id: str,
     node_name: str = None,
     fields: list[str] = None,
-    error_msg: str = None
+    error_msg: str = None,
 ):
     """Get job information.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         node_name(str, optional): Node name, if not passed list jobs
@@ -607,16 +625,20 @@
 
     if isinstance(node_name, str):
         node_names = [node_names]
 
     with FuturesSessionWithRenewal(connection=connection, max_workers=8) as session:
         futures = [
             get_jobs_async(
-                future_session=session, connection=connection, node_name=node, fields=fields
-            ) for node in node_names
+                future_session=session,
+                connection=connection,
+                node_name=node,
+                fields=fields,
+            )
+            for node in node_names
         ]
         jobs = []
         for f in futures:
             response = f.result()
             if not response.ok:
                 response_handler(response, error_msg, throw_error=False)
             else:
@@ -636,15 +658,17 @@
         job = json.dumps(job).encode('utf-8')
         response._content = job
         response.status_code = 200
         return response
 
 
 @ErrorHandler(err_msg="Error getting job {id}.")
-def get_job_v2(connection: "Connection", id: str, fields: list[str] = None, error_msg: str = None):
+def get_job_v2(
+    connection: "Connection", id: str, fields: list[str] = None, error_msg: str = None
+):
     """Get job information.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         fields(list, optional): Comma separated top-level field whitelist. This
             allows client to selectively retrieve part of the response model.
@@ -667,15 +691,15 @@
     project_id: str = None,
     status: str = None,
     job_type: str = None,
     user_full_name: str = None,
     object_id: str = None,
     sort_by: str = None,
     fields: list[str] = None,
-    error_msg: str = None
+    error_msg: str = None,
 ) -> Response:
     """Get list of a jobs.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         node_name(str): Node name,
@@ -716,15 +740,15 @@
     node_name: str,
     project_id: str = None,
     status: str = None,
     job_type: str = None,
     user_full_name: str = None,
     object_id: str = None,
     sort_by: str = None,
-    fields: list[str] = None
+    fields: list[str] = None,
 ) -> Response:
     """Get list of a jobs asynchronously.
 
     Args:
         future_session(object): Future Session object to call MicroStrategy REST
             Server asynchronously
         connection(object): MicroStrategy connection object returned by
@@ -775,15 +799,15 @@
     pu_name: Union[list[str], str] = None,
     subscription_type: Union[list[str], str] = None,
     subscription_recipient: Union[list[str], str] = None,
     memory_usage: str = None,
     elapsed_time: str = None,
     sort_by: str = None,
     fields: list[str] = None,
-    error_msg: str = None
+    error_msg: str = None,
 ):
     """Get list of a jobs.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         node_name(str): Node name,
@@ -867,15 +891,15 @@
     project_name: Union[list[str], str] = None,
     pu_name: Union[list[str], str] = None,
     subscription_type: Union[list[str], str] = None,
     subscription_recipient: Union[list[str], str] = None,
     memory_usage: str = None,
     elapsed_time: str = None,
     sort_by: str = None,
-    fields: list[str] = None
+    fields: list[str] = None,
 ) -> Response:
     """Get list of a jobs asynchronously.
 
     Args:
         future_session(object): Future Session object to call MicroStrategy REST
             Server asynchronously
         connection(object): MicroStrategy connection object returned by
@@ -944,29 +968,33 @@
     params_encoded = urlencode(params_delete_none, True, quote_via=quote)
     return future_session.get(
         url=f'{connection.base_url}/api/v2/monitors/jobs', params=params_encoded
     )
 
 
 @ErrorHandler(err_msg="Error killing job {id}")
-def cancel_job(connection: "Connection", id: str, fields: list[str] = None, error_msg: str = None):
+def cancel_job(
+    connection: "Connection", id: str, fields: list[str] = None, error_msg: str = None
+):
     """Cancel a job specified by `id`. Use cancel_job_v1 if I-Server version
     is 11.3.2 or cancel_job_v2 otherwise.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         id(str): ID of the job
         fields(list, optional): Comma separated top-level field whitelist. This
             allows client to selectively retrieve part of the response model.
         error_msg(str, optional): Customized error message.
     Returns:
         HTTP response object returned by the MicroStrategy REST server
     """
-    if version.parse(connection.iserver_version) == version.parse(ISERVER_VERSION_11_3_2):
+    if version.parse(connection.iserver_version) == version.parse(
+        ISERVER_VERSION_11_3_2
+    ):
         return cancel_job_v1(connection, id, fields, error_msg)
     else:
         return cancel_job_v2(connection, id, fields, error_msg)
 
 
 @ErrorHandler(err_msg="Error killing job {id}")
 def cancel_job_v1(
@@ -982,15 +1010,17 @@
             allows client to selectively retrieve part of the response model.
         error_msg(str, optional): Customized error message.
     Returns:
         HTTP response object returned by the MicroStrategy REST server
     """
     params = {'fields': ",".join(fields) if fields else None}
 
-    return connection.delete(url=f'{connection.base_url}/api/monitors/jobs/{id}', params=params)
+    return connection.delete(
+        url=f'{connection.base_url}/api/monitors/jobs/{id}', params=params
+    )
 
 
 @ErrorHandler(err_msg="Error killing job {id}")
 def cancel_job_v2(
     connection: "Connection", id: str, fields: list[str] = None, error_msg: str = None
 ):
     """Cancel a job specified by `id`.
@@ -1003,34 +1033,39 @@
             allows client to selectively retrieve part of the response model.
         error_msg(str, optional): Customized error message.
     Returns:
         HTTP response object returned by the MicroStrategy REST server
     """
     params = {'fields': ",".join(fields) if fields else None}
 
-    return connection.delete(url=f'{connection.base_url}/api/v2/monitors/jobs/{id}', params=params)
+    return connection.delete(
+        url=f'{connection.base_url}/api/v2/monitors/jobs/{id}', params=params
+    )
 
 
-def cancel_jobs(connection: "Connection", ids: list[str],
-                fields: list[str] = None) -> Union[Success, PartialSuccess, MstrException]:
+def cancel_jobs(
+    connection: "Connection", ids: list[str], fields: list[str] = None
+) -> Union[Success, PartialSuccess, MstrException]:
     """Cancel jobs specified by `ids`. Use cancel_jobs_v1 if I-Server version
     is 11.3.2 or cancel_jobs_v2 otherwise.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         ids(List[str]): IDs of the jobs
         fields(list, optional): Comma separated top-level field whitelist. This
             allows client to selectively retrieve part of the response model.
     Returns:
         Success: object if all jobs were killed
         PartialSuccess: if not all jobs were killed
         MstrException: otherwise
     """
-    if version.parse(connection.iserver_version) == version.parse(ISERVER_VERSION_11_3_2):
+    if version.parse(connection.iserver_version) == version.parse(
+        ISERVER_VERSION_11_3_2
+    ):
         response = cancel_jobs_v1(connection, ids, fields)
     else:
         response = cancel_jobs_v2(connection, ids, fields)
 
     return bulk_operation_response_handler(response, "jobCancellationStatus")
 
 
@@ -1047,15 +1082,17 @@
         HTTP response object returned by the MicroStrategy REST server
     """
     params = {'fields': ",".join(fields) if fields else None}
 
     if ids:
         body = {'jobIds': ids}
         return connection.post(
-            url=f'{connection.base_url}/api/monitors/cancelJobs', params=params, json=body
+            url=f'{connection.base_url}/api/monitors/cancelJobs',
+            params=params,
+            json=body,
         )
     else:
         raise ValueError("No ids have been passed.")
 
 
 def cancel_jobs_v2(connection: "Connection", ids: list[str], fields: list[str] = None):
     """Cancel jobs specified by `ids`.
@@ -1070,15 +1107,17 @@
         HTTP response object returned by the MicroStrategy REST server
     """
     params = {'fields': ",".join(fields) if fields else None}
 
     if ids:
         body = {'jobIds': ids}
         return connection.post(
-            url=f'{connection.base_url}/api/v2/monitors/cancelJobs', params=params, json=body
+            url=f'{connection.base_url}/api/v2/monitors/cancelJobs',
+            params=params,
+            json=body,
         )
     else:
         raise ValueError("No ids have been passed.")
 
 
 @ErrorHandler(err_msg="Error getting caches")
 def get_contents_caches(
@@ -1093,15 +1132,15 @@
     size: Optional[str] = None,
     owner: Optional[str] = None,
     expiration: Optional[str] = None,
     last_updated: Optional[str] = None,
     hit_count: Optional[str] = None,
     sort_by: Optional[str] = None,
     fields: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> Response:
     """Get cache objects
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`,
         project_id(str): Field to filter on project id (exact
@@ -1139,15 +1178,15 @@
         'format': content_format,
         'size': size,
         'owner': owner,
         'expiration': expiration,
         'lastUpdated': last_updated,
         'hitCount': hit_count,
         'sortBy': sort_by,
-        'fields': fields
+        'fields': fields,
     }
     params_delete_none = delete_none_values(params, recursion=True)
     params_encoded = urlencode(params_delete_none, True, quote_via=quote)
     return connection.get(
         url=f'{connection.base_url}/api/monitors/caches/contents',
         params=params_encoded,
     )
@@ -1169,12 +1208,10 @@
             allows client to selectively retrieve part of the response model.
 
     Returns:
         HTTP response object. Expected status 200.
     """
     return connection.patch(
         url=f'{connection.base_url}/api/v2/monitors/caches/contents',
-        params={
-            'clusterNode': node, 'fields': fields
-        },
-        json=body
+        params={'clusterNode': node, 'fields': fields},
+        json=body,
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/objects.py` & `mstrio-py-11.3.9.103/mstrio/api/objects.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,20 @@
     from requests_futures.sessions import FuturesSession
 
 logger = logging.getLogger(__name__)
 
 
 @ErrorHandler(err_msg='Error getting information for the object with ID {id}')
 def get_object_info(
-    connection, id, object_type, project_id=None, error_msg=None, whitelist=[('ERR001 ', 500)]
+    connection,
+    id,
+    object_type,
+    project_id=None,
+    error_msg=None,
+    whitelist=[('ERR001 ', 500)],
 ):
     """Get information for a specific object in a specific project; if you do
     not specify a project ID, you get information for the object just in the
     non-project area.
 
     You identify the object with the object ID and object type. You specify
     the object type as a query parameter; possible values for object type are
@@ -39,20 +44,22 @@
         headers = {'X-MSTR-ProjectID': None}
     elif project_id:
         headers = {'X-MSTR-ProjectID': project_id}
     else:
         headers = {'X-MSTR-ProjectID': connection.project_id}
 
     if not project_id and not connection.project_id:
-        logger.info('Project was not selected. Search is performed for the non-project area')
+        logger.info(
+            'Project was not selected. Search is performed for the non-project area'
+        )
 
     return connection.get(
         url=f'{connection.base_url}/api/objects/{id}',
         headers=headers,
-        params={'type': object_type}
+        params={'type': object_type},
     )
 
 
 def get_object_info_async(
     futures_session: "FuturesSession", connection, id, object_type, project_id=None
 ):
     """Get information for a specific object in a specific project; if you do
@@ -82,20 +89,22 @@
         headers = {'X-MSTR-ProjectID': None}
     elif project_id:
         headers = {'X-MSTR-ProjectID': project_id}
     else:
         headers = {'X-MSTR-ProjectID': connection.project_id}
 
     if not project_id and not connection.project_id:
-        logger.info('Project was not selected. Search is performed for the non-project area')
+        logger.info(
+            'Project was not selected. Search is performed for the non-project area'
+        )
 
     return futures_session.get(
         url=f'{connection.base_url}/api/objects/{id}',
         headers=headers,
-        params={'type': object_type}
+        params={'type': object_type},
     )
 
 
 @ErrorHandler(err_msg='Error deleting object with ID {id}')
 def delete_object(connection, id, object_type, project_id=None, error_msg=None):
     """Get information for a specific object in a specific project; if you do
     not specify a project ID, you get information for the object in all
@@ -125,15 +134,15 @@
         headers = {'X-MSTR-ProjectID': project_id}
     else:
         headers = {'X-MSTR-ProjectID': connection.project_id}
 
     return connection.delete(
         url=f'{connection.base_url}/api/objects/{id}',
         headers=headers,
-        params={'type': object_type}
+        params={'type': object_type},
     )
 
 
 @ErrorHandler(err_msg='Error updating object with ID {id}')
 def update_object(
     connection, id, body, object_type, project_id=None, error_msg=None, verbose=True
 ):
@@ -166,20 +175,22 @@
     else:
         headers = {'X-MSTR-ProjectID': connection.project_id}
 
     return connection.put(
         url=f'{connection.base_url}/api/objects/{id}',
         headers=headers,
         params={'type': object_type},
-        json=body
+        json=body,
     )
 
 
 @ErrorHandler(err_msg='Error creating a copy of object with ID {id}')
-def copy_object(connection, id, name, folder_id, object_type, project_id=None, error_msg=None):
+def copy_object(
+    connection, id, name, folder_id, object_type, project_id=None, error_msg=None
+):
     """Create a copy of a specific object.
 
     You identify the object with the object ID and object type. You obtain the
     authorization token needed to execute the request using POST /auth/login;
     you obtain the project ID using GET /projects. You pass the authorization
     token and the project ID in the request header. You specify the object ID in
     the path of the request and object type as a query parameter; possible
@@ -212,15 +223,15 @@
         raise ValueError("Project needs to be specified.")
 
     body = {"name": name, "folderId": folder_id}
     return connection.post(
         url=f'{connection.base_url}/api/objects/{id}/copy',
         headers=headers,
         params={'type': object_type},
-        json=body
+        json=body,
     )
 
 
 @ErrorHandler(err_msg='Error getting VLDB settings for object with ID {id}')
 def get_vldb_settings(connection, id, object_type, project_id=None, error_msg=None):
     """Get vldb settings for an object.
 
@@ -246,15 +257,17 @@
     return connection.get(
         url=f"{connection.base_url}/api/objects/{id}/vldb/propertySets",
         params={'type': object_type},
         headers=headers,
     )
 
 
-@ErrorHandler(err_msg='Error resetting all custom vldb settings for object with ID {id}')
+@ErrorHandler(
+    err_msg='Error resetting all custom vldb settings for object with ID {id}'
+)
 def delete_vldb_settings(connection, id, object_type, project_id=None, error_msg=None):
     """Delete all customized vldb settings in one object, this operation will
     reset all vldb settings to default.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
@@ -277,16 +290,20 @@
     return connection.delete(
         url=f"{connection.base_url}/api/objects/{id}/vldb/propertySets",
         params={'type': object_type},
         headers=headers,
     )
 
 
-@ErrorHandler(err_msg='Error resetting all custom vldb settings for object with ID {id}')
-def set_vldb_settings(connection, id, object_type, name, body, project_id=None, error_msg=None):
+@ErrorHandler(
+    err_msg='Error resetting all custom vldb settings for object with ID {id}'
+)
+def set_vldb_settings(
+    connection, id, object_type, name, body, project_id=None, error_msg=None
+):
     """Set vldb settings for one property set in one object.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         id (str): Object ID
         object_type (int): DssXmlTypeReportDefinition(3) for Dataset and
@@ -313,15 +330,21 @@
         headers=headers,
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error getting objects.')
 def create_search_objects_instance(
-    connection, name=None, pattern=4, domain=2, root=None, object_type=None, error_msg=None
+    connection,
+    name=None,
+    pattern=4,
+    domain=2,
+    root=None,
+    object_type=None,
+    error_msg=None,
 ):
     """Create a search instance.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         name: expression used with the pattern to do the search
@@ -338,21 +361,27 @@
         HTTP response returned by the MicroStrategy REST server
     """
     connection._validate_project_selected()
     return connection.post(
         url=f"{connection.base_url}/api/objects",
         headers={'X-MSTR-ProjectID': connection.project_id},
         params={
-            'name': name, 'pattern': pattern, 'domain': domain, 'root': root, 'type': object_type
+            'name': name,
+            'pattern': pattern,
+            'domain': domain,
+            'root': root,
+            'type': object_type,
         },
     )
 
 
 @ErrorHandler(err_msg='Error getting objects using search with ID {search_id}')
-def get_objects(connection, search_id, offset=0, limit=-1, get_tree=False, error_msg=None):
+def get_objects(
+    connection, search_id, offset=0, limit=-1, get_tree=False, error_msg=None
+):
     """Get list of objects from metadata.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         search_id: ID for the results of a previous search stored in I-Server
             memory
@@ -370,26 +399,29 @@
         HTTP response returned by the MicroStrategy REST server
     """
     connection._validate_project_selected
     return connection.get(
         url=f"{connection.base_url}/api/objects",
         headers={'X-MSTR-ProjectID': connection.project_id},
         params={
-            'searchId': search_id, 'offset': offset, 'limit': limit, 'getTree': get_tree
+            'searchId': search_id,
+            'offset': offset,
+            'limit': limit,
+            'getTree': get_tree,
         },
     )
 
 
 def get_objects_async(
     future_session: "FuturesSession",
     connection,
     search_id,
     offset=0,
     limit=-1,
-    get_tree=False
+    get_tree=False,
 ):
     """Get list of objects from metadata asynchronously.
 
     Args:
         future_session(object): Future Session object to call MicroStrategy REST
             Server asynchronously
         connection(object): MicroStrategy connection object returned by
@@ -407,15 +439,20 @@
 
     Returns:
         HTTP response returned by the MicroStrategy REST server
     """
     connection._validate_project_selected()
     url = connection.base_url + '/api/objects'
     headers = {'X-MSTR-ProjectID': connection.project_id}
-    params = {'searchId': search_id, 'offset': offset, 'limit': limit, 'getTree': get_tree}
+    params = {
+        'searchId': search_id,
+        'offset': offset,
+        'limit': limit,
+        'getTree': get_tree,
+    }
     future = future_session.get(url=url, headers=headers, params=params)
     return future
 
 
 @ErrorHandler(err_msg='Error certifying object with ID {id}')
 def toggle_certification(connection, id, object_type=3, certify=True):
     """Certify/Uncertify a multi-table dataset.
@@ -429,15 +466,15 @@
             defaults to 3 (dataset)
         certify (bool, optional): boolean representing if the instruction is to
             certify (True) or decertify (False); defaults to True.
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
-    url = f'{connection.base_url}/api/objects/{id}/certify/?type={str(object_type)}' \
-          f'&certify={str(certify)}'
+    url = (
+        f'{connection.base_url}/api/objects/{id}/certify/?type={str(object_type)}'
+        f'&certify={str(certify)}'
+    )
     return connection.put(
         url=url,
-        headers={
-            'Content-Type': 'application/json', 'Accept': 'application/json'
-        },
+        headers={'Content-Type': 'application/json', 'Accept': 'application/json'},
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/projects.py` & `mstrio-py-11.3.9.103/mstrio/api/projects.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,22 +1,28 @@
+from typing import TYPE_CHECKING
+
+from mstrio.utils.api_helpers import changeset_manager
 from mstrio.utils.error_handlers import ErrorHandler
 from mstrio.utils.helper import response_handler
 
+if TYPE_CHECKING:
+    from mstrio.connection import Connection
+
 
 @ErrorHandler(
     err_msg='Selected project {name} does not exist or is not loaded.'
     ' Please load the project or select a valid project '
     'or create a new project using `create_new` method'
 )
 def get_project(
     connection,
     name,
     error_msg=None,
     throw_error=True,
-    whitelist=[('ERR001', 500), ('ERR014', 403)]
+    whitelist=[('ERR001', 500), ('ERR014', 403)],
 ):
     """Get a specific project that the authenticated user has access to.
 
     Args:
         connection: MicroStrategy REST API connection object
         name (string): MicroStrategy project name
         error_msg (string, optional): Custom Error Message for Error Handling
@@ -109,15 +115,17 @@
     return connection.put(
         url=f'{connection.base_url}/api/projects/{id}/quotas',
         headers={'X-MSTR-ProjectID': None},
         json=body,
     )
 
 
-@ErrorHandler(err_msg='Error setting user {user_id} import quota for project with ID {id}')
+@ErrorHandler(
+    err_msg='Error setting user {user_id} import quota for project with ID {id}'
+)
 def set_user_import_quota(connection, id, user_id, body, error_msg=None):
     """Set the amount of space, in MB, that can be used for the Data Import
     function for a specific user. The value provided is rounded to an integer.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): Project id string
@@ -266,15 +274,15 @@
             i.e. whitelist = [('ERR001', 500),('ERR004', 404)]
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/projects/settings/onStartup',
-        headers={'X-MSTR-ProjectID': None}
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error updating project startup settings.')
 def update_projects_on_startup(connection, body, error_msg=None, whitelist=None):
     """Update status of projects on iServer nodes at start up. You provide
     the request body as of list of replace operations to be performed on the
@@ -298,7 +306,69 @@
         Complete HTTP response object.
     """
     return connection.patch(
         url=f'{connection.base_url}/api/projects/settings/onStartup',
         headers={'X-MSTR-ProjectID': None},
         json=body,
     )
+
+
+@ErrorHandler(err_msg='Error getting VLDB settings for project with ID {id}')
+def get_vldb_settings(connection: 'Connection', id: str, error_msg: str = None):
+    """Get advanced VLDB settings for a project.
+
+    Args:
+        connection (Connection): MicroStrategy REST API connection object
+        id (string): Project ID
+        error_msg (string, optional): Custom Error Message for Error Handling
+
+    Returns:
+        Complete HTTP response object.
+    """
+    return connection.get(
+        url=f'{connection.base_url}/api/model/projects/{id}?showAdvancedProperties=true'
+    )
+
+
+@ErrorHandler(err_msg='Error updating VLDB settings for project with ID {id}')
+def update_vldb_settings(
+    connection: 'Connection', id: str, body: dict, error_msg: str = None
+):
+    """Update metadata of advanced VLDB settings for a project.
+
+    Args:
+        connection (Connection): MicroStrategy REST API connection object
+        id (string): Project ID
+        body (dict): JSON-formatted data used to update VLDB settings
+        error_msg (string, optional): Custom Error Message for Error Handling
+
+    Returns:
+        Complete HTTP response object.
+    """
+    with changeset_manager(connection) as changeset_id:
+        return connection.put(
+            url=f'{connection.base_url}/api/model/projects/{id}',
+            headers={'X-MSTR-MS-Changeset': changeset_id},
+            json=body,
+        )
+
+
+@ErrorHandler(
+    err_msg='Error getting metadata of VLDB settings for project with ID {id}'
+)
+def get_applicable_vldb_settings(
+    connection: 'Connection', id: str, error_msg: str = None
+):
+    """Get metadata of advanced VLDB settings for a project.
+
+    Args:
+        connection (Connection): MicroStrategy REST API connection object
+        id (string): Project ID
+        error_msg (string, optional): Custom Error Message for Error Handling
+
+    Returns:
+        Complete HTTP response object.
+    """
+    return connection.get(
+        url=f'{connection.base_url}/api/model/projects/{id}'
+        '/applicableAdvancedProperties'
+    )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/registrations.py` & `mstrio-py-11.3.9.103/mstrio/api/registrations.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 from mstrio.utils.error_handlers import ErrorHandler
 
 
 @ErrorHandler(
-    err_msg='Error obtaining the list of registered nodes from the MicroStrategy deployment.'
+    err_msg='Error obtaining the list of registered nodes from the MicroStrategy '
+    'deployment.'
 )
 def get_nodes(connection, error_msg=None):
     """Obtain the list of registered nodes from the MicroStrategy deployment.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             'connection.Connection().
@@ -40,15 +41,17 @@
     from the MicroStrategy deployment.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             'connection.Connection().
         error_msg (string, optional): Custom Error Message for Error Handling
     """
-    return connection.get(url=f'{connection.base_url}/api/registrations/services/metadata')
+    return connection.get(
+        url=f'{connection.base_url}/api/registrations/services/metadata'
+    )
 
 
 @ErrorHandler(err_msg='Error to start/stop service')
 def start_stop_service(
     connection, login, password, name, id, address, action="START", error_msg=None
 ):
     """Start or stop registered service.
@@ -68,12 +71,12 @@
 
     body = {
         "name": name,
         "id": id,
         "action": action,
         "address": address,
         "login": login,
-        "password": password
+        "password": password,
     }
     url = f'{connection.base_url}/api/registrations/services/control'
     response = connection.post(url=url, json=body)
     return response
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/reports.py` & `mstrio-py-11.3.9.103/mstrio/api/reports.py`

 * *Files 5% similar despite different names*

```diff
@@ -96,15 +96,20 @@
     return connection.get(
         url=f'{connection.base_url}/api/v2/reports/{report_id}/instances/{instance_id}',
         params=params,
     )
 
 
 def report_instance_id_coroutine(
-    future_session: "FuturesSession", connection, report_id, instance_id, offset=0, limit=5000
+    future_session: "FuturesSession",
+    connection,
+    report_id,
+    instance_id,
+    offset=0,
+    limit=5000,
 ):
     """Get the future of a previously created instance for a specific report
     asynchronously, using the in-memory instance created by report_instance().
 
     Returns:
         Complete Future object.
     """
@@ -114,15 +119,17 @@
 
     url = f'{connection.base_url}/api/v2/reports/{report_id}/instances/{instance_id}'
     future = future_session.get(url, params=params)
     return future
 
 
 @ErrorHandler(err_msg='Error retrieving attribute {attribute_id} elements.')
-def report_single_attribute_elements(connection, report_id, attribute_id, offset=0, limit=200000):
+def report_single_attribute_elements(
+    connection, report_id, attribute_id, offset=0, limit=200000
+):
     """Get elements of a specific attribute of a specific report.
 
     Args:
         connection: MicroStrategy REST API connection object.
         report_id (str): Unique ID of the report you wish to extract information
             from.
         attribute_id (str): Unique ID of the attribute in the report.
@@ -133,25 +140,31 @@
             an example, if the dataset has 50,000 rows, this function will
             incrementally extract all 50,000 rows in 1,000 row chunks. Depending
             on system resources, using a higher limit setting (e.g. 10,000) may
             reduce the total time required to extract the entire dataset.
     Returns:
         Complete HTTP response object
     """
-    url = f'{connection.base_url}/api/reports/{report_id}/attributes/{attribute_id}/elements'
+    url = (
+        f'{connection.base_url}/api/reports/{report_id}/attributes/'
+        f'{attribute_id}/elements'
+    )
     return connection.get(
         url=url,
-        params={
-            'offset': offset, 'limit': limit
-        },
+        params={'offset': offset, 'limit': limit},
     )
 
 
 def report_single_attribute_elements_coroutine(
-    future_session: "FuturesSession", connection, report_id, attribute_id, offset=0, limit=200000
+    future_session: "FuturesSession",
+    connection,
+    report_id,
+    attribute_id,
+    offset=0,
+    limit=200000,
 ):
     """Get elements of a specific attribute of a specific report.
 
     Args:
         future_session(object): Future Session object to call MicroStrategy REST
             Server asynchronously
         connection: MicroStrategy REST API connection object.
@@ -165,15 +178,18 @@
             an example, if the dataset has 50,000 rows, this function will
             incrementally extract all 50,000 rows in 1,000 row chunks. Depending
             on system resources, using a higher limit setting (e.g. 10,000) may
             reduce the total time required to extract the entire dataset.
     Returns:
         Complete Future object
     """
-    url = f'{connection.base_url}/api/reports/{report_id}/attributes/{attribute_id}/elements'
+    url = (
+        f'{connection.base_url}/api/reports/{report_id}'
+        f'/attributes/{attribute_id}/elements'
+    )
     future = future_session.get(url, params={'offset': offset, 'limit': limit})
     return future
 
 
 @ErrorHandler(err_msg='Error getting collection of prompts for report {report_id}')
 def get_report_prompts(connection, report_id, closed=None, fields=None):
     """Get the collection of prompts and their respective definitions from a
@@ -189,17 +205,15 @@
             that allows the client to selectively retrieve
             part of the response model.
 
     """
     url = f'{connection.base_url}/api/reports/{report_id}/prompts'
     return connection.get(
         url=url,
-        params={
-            'closed': closed, 'fields': fields
-        },
+        params={'closed': closed, 'fields': fields},
     )
 
 
 @ErrorHandler(err_msg='Error getting prompted report {report_id} instance.')
 def get_prompted_instance(connection, report_id, instance_id, closed=None, fields=None):
     """Get the collection of prompts and their respective definitions from a
     report instance. This endpoint will return data only when the report
@@ -214,14 +228,14 @@
         closed(bool): Prompt status, true means get closed prompt,
             false means get open prompt
         fields: Comma-separated, top-level field whitelist
             that allows the client to selectively retrieve
             part of the response model.
 
     """
-    url = f'{connection.base_url}/api/reports/{report_id}/instances/{instance_id}/prompts'
+    url = (
+        f'{connection.base_url}/api/reports/{report_id}/instances/{instance_id}/prompts'
+    )
     return connection.get(
         url=url,
-        params={
-            'closed': closed, 'fields': fields
-        },
+        params={'closed': closed, 'fields': fields},
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/schedules.py` & `mstrio-py-11.3.9.103/mstrio/api/schedules.py`

 * *Files 2% similar despite different names*

```diff
@@ -29,16 +29,17 @@
         event_based_in_list = False
         response_json = response.json()
         for schedule in response_json['schedules']:
             if 'event' in schedule.keys():
                 schedule['event']['id'] = schedule['event'].pop('eventId')
                 event_based_in_list = True
         if event_based_in_list:
-            response.encoding, response._content = 'utf-8', json.dumps(response_json).encode(
-                'utf-8')
+            response.encoding, response._content = 'utf-8', json.dumps(
+                response_json
+            ).encode('utf-8')
 
     return response
 
 
 @ErrorHandler(err_msg='Error getting schedule {id} information.')
 def get_schedule(connection, id, fields=None, error_msg=None):
     """Get information of a specific schedule by `schedule_id`.
@@ -58,16 +59,17 @@
         url=f'{connection.base_url}/api/schedules/{id}', params={'fields': fields}
     )
     if response.ok:
         # Fix for incorrect 'eventId' (expecting 'id')
         response_json = response.json()
         if 'event' in response_json.keys():
             response_json['event']['id'] = response_json['event'].pop('eventId')
-            response.encoding, response._content = 'utf-8', json.dumps(response_json).encode(
-                'utf-8')
+            response.encoding, response._content = 'utf-8', json.dumps(
+                response_json
+            ).encode('utf-8')
 
     return response
 
 
 @ErrorHandler(err_msg='Error getting schedule information.')
 def create_schedule(connection, body, fields=None, error_msg=None):
     """Create a new schedule using data from `body`.
@@ -91,16 +93,17 @@
         url=f'{connection.base_url}/api/schedules', json=body, params={'fields': fields}
     )
     if response.ok:
         # Fix for incorrect 'eventId' (expecting 'id')
         response_json = response.json()
         if 'event' in response_json.keys():
             response_json['event']['id'] = response_json['event'].pop('eventId')
-            response.encoding, response._content = 'utf-8', json.dumps(response_json).encode(
-                'utf-8')
+            response.encoding, response._content = 'utf-8', json.dumps(
+                response_json
+            ).encode('utf-8')
 
     return response
 
 
 @ErrorHandler(err_msg='Error getting schedule {id} information.')
 def update_schedule(connection, id, body, fields=None, error_msg=None):
     """Alter a schedule specified by `schedule_id`, using data from `body`.
@@ -118,22 +121,26 @@
     """
 
     # id to eventId conversion - API Problem
     if 'event' in body.keys():
         body['event']['eventId'] = body['event'].pop('id')
 
     response = connection.put(
-        url=f'{connection.base_url}/api/schedules/{id}', json=body, params={'fields': fields}
+        url=f'{connection.base_url}/api/schedules/{id}',
+        json=body,
+        params={'fields': fields},
     )
     if response.ok:
         # Fix for incorrect 'eventId' (expecting 'id')
         response_json = response.json()
         if 'event' in response_json.keys():
             response_json['event']['id'] = response_json['event'].pop('eventId')
-        response.encoding, response._content = 'utf-8', json.dumps(response_json).encode('utf-8')
+        response.encoding, response._content = 'utf-8', json.dumps(
+            response_json
+        ).encode('utf-8')
 
     return response
 
 
 @ErrorHandler(err_msg='Error getting schedule {id} information.')
 def delete_schedule(connection, id, fields=None, error_msg=None):
     """Delete a schedule specified by `schedule_id`.
@@ -151,18 +158,15 @@
     return connection.delete(
         url=f'{connection.base_url}/api/schedules/{id}', params={'fields': fields}
     )
 
 
 @ErrorHandler(err_msg='Error getting schedule information')
 def get_contents_schedule(
-        connection: "Connection",
-        project_id: str,
-        body: dict,
-        fields: Optional[str] = None
+    connection: "Connection", project_id: str, body: dict, fields: Optional[str] = None
 ) -> Response:
     """Get a list of available schedules for a list of contents within a given
         project.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
@@ -174,9 +178,9 @@
     Return:
         HTTP response object. Expected status: 200
     """
     return connection.post(
         url=f'{connection.base_url}/api/schedules/results',
         headers={'X-MSTR-ProjectID': project_id},
         params={'fields': fields},
-        json=body
+        json=body,
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/schema.py` & `mstrio-py-11.3.9.103/mstrio/api/schema.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
 
 @ErrorHandler(err_msg="Error placing the lock of type `{lock_type}` on the schema.")
 def lock_schema(
     connection: "Connection",
     lock_type: str,
     project_id: Optional[str] = None,
-    throw_error: bool = True
+    throw_error: bool = True,
 ):
     """Places a lock on the schema."""
     project_id = project_id if project_id is not None else connection.project_id
     return connection.post(
         url=f"{connection.base_url}/api/model/schema/lock",
         headers={'X-MSTR-ProjectID': project_id},
         json={'lockType': lock_type},
@@ -31,15 +31,15 @@
 
 
 @ErrorHandler(err_msg='Error unlocking the schema.')
 def unlock_schema(
     connection: "Connection",
     lock_type: Optional[str] = None,
     project_id: Optional[str] = None,
-    throw_error: bool = True
+    throw_error: bool = True,
 ):
     """Unlocks the schema."""
     project_id = project_id if project_id is not None else connection.project_id
     return connection.delete(
         url=f"{connection.base_url}/api/model/schema/lock",
         headers={'X-MSTR-ProjectID': project_id},
         params={'lockType': lock_type},
@@ -47,15 +47,15 @@
 
 
 @ErrorHandler(err_msg='Error reloading the schema.')
 def reload_schema(
     connection: "Connection",
     project_id: Optional[str] = None,
     update_types: Optional[List[str]] = None,
-    prefer_async: bool = False
+    prefer_async: bool = False,
 ):
     """Reloads (updates) the schema."""
     project_id = project_id if project_id is not None else connection.project_id
     update_types = update_types if update_types else []
     prefer_async = 'respond-async' if prefer_async else None
     return connection.post(
         url=f"{connection.base_url}/api/model/schema/reload",
@@ -64,14 +64,16 @@
             'Prefer': prefer_async,
         },
         json={'updateTypes': update_types},
     )
 
 
 @ErrorHandler(err_msg='Error reading status of the task with ID: {task_id}.')
-def read_task_status(connection: "Connection", task_id: str, project_id: Optional[str] = None):
+def read_task_status(
+    connection: "Connection", task_id: str, project_id: Optional[str] = None
+):
     """Read the status of the task."""
     project_id = project_id if project_id is not None else connection.project_id
     return connection.get(
         url=f"{connection.base_url}/api/model/tasks/{task_id}",
         headers={'X-MSTR-ProjectID': project_id},
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/security.py` & `mstrio-py-11.3.9.103/mstrio/api/security.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,15 +9,16 @@
         connection: MicroStrategy REST API connection object
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
-        url=f'{connection.base_url}/api/iserver/privileges', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/iserver/privileges',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error getting privilege categories.')
 def get_privilege_categories(connection, error_msg=None):
     """Get the set of available privilege categories for the platform.
 
@@ -49,15 +50,15 @@
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
         url=f'{connection.base_url}/api/securityRoles',
         headers={'X-MSTR-ProjectID': None},
-        params={'fields': fields}
+        params={'fields': fields},
     )
 
 
 @ErrorHandler(err_msg='Error creating new security role.')
 def create_security_role(connection, body, error_msg=None):
     """Create a new security role.
 
@@ -86,15 +87,16 @@
         id (string): Security role ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
-        url=f'{connection.base_url}/api/securityRoles/{id}', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/securityRoles/{id}',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error deleting security role with ID {id}.')
 def delete_security_role(connection, id, error_msg=None):
     """Delete info for a security role with given Id.
 
@@ -103,15 +105,16 @@
         id (string): Security role ID
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.delete(
-        url=f'{connection.base_url}/api/securityRoles/{id}', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/securityRoles/{id}',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error updating security role with ID {id}')
 def update_security_role(connection, id, body, error_msg=None):
     """Update information for a specific security role.
 
@@ -128,25 +131,30 @@
     return connection.patch(
         url=f'{connection.base_url}/api/securityRoles/{id}',
         headers={'X-MSTR-ProjectID': None},
         json=body,
     )
 
 
-@ErrorHandler(err_msg='Error getting security role with ID {id} for project with ID {project_id}')
+@ErrorHandler(
+    err_msg='Error getting security role with ID {id} for project with ID {project_id}'
+)
 def get_security_role_for_project(connection, id, project_id, error_msg=None):
     """Get all users and user groups that are linked to a specific security
     role.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): Security role ID
         project_id (string, optional): Project id string
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
     return connection.get(
-        url=f'{connection.base_url}/api/securityRoles/{id}/projects/{project_id}/members',
+        url=(
+            f'{connection.base_url}/api/securityRoles/{id}/projects/'
+            f'{project_id}/members'
+        ),
         headers={'X-MSTR-ProjectID': None},
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/security_filters.py` & `mstrio-py-11.3.9.103/mstrio/api/security_filters.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,48 +14,48 @@
     """Get the users and user groups that the specified security filter is
     applied to."""
     if project_id is None:
         connection._validate_project_selected()
         project_id = connection.project_id
     return connection.get(
         url=f"{connection.base_url}/api/securityFilters/{id}/members",
-        headers={'X-MSTR-ProjectID': project_id}
+        headers={'X-MSTR-ProjectID': project_id},
     )
 
 
 @ErrorHandler(err_msg='Error updating members of security filter with ID {id}')
 def update_security_filter_members(
     connection: "Connection",
     id: str,
     body: dict,
     project_id: str = None,
     error_msg: str = None,
-    throw_error: bool = True
+    throw_error: bool = True,
 ):
     """Update members information for a specific security filter."""
     if project_id is None:
         connection._validate_project_selected()
         project_id = connection.project_id
     return connection.patch(
         url=f"{connection.base_url}/api/securityFilters/{id}/members",
         headers={'X-MSTR-ProjectID': project_id},
-        json=body
+        json=body,
     )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error creating new security filter.')
 def create_security_filter(
     connection: "Connection",
     body: dict,
     show_filter_tokens: bool = False,
     show_expression_as: str = None,
     error_msg: str = None,
     throw_error: bool = True,
-    **kwargs
+    **kwargs,
 ):
     """Creates a new security filter in the changeset,
     based on the definition provided in request body.
 
     Args:
         connection: MicroStrategy REST API connection object
         body (dict): Security Filter creation body
@@ -75,30 +75,30 @@
     with changeset_manager(connection) as changeset_id:
         return connection.post(
             url=f"{connection.base_url}/api/model/securityFilters",
             headers={'X-MSTR-MS-Changeset': changeset_id},
             json=body,
             params={
                 'showFilterTokens': str(show_filter_tokens).lower(),
-                'showExpressionAs': show_expression_as
-            }
+                'showExpressionAs': show_expression_as,
+            },
         )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error getting security filter {id} definition.')
 def get_security_filter(
     connection: "Connection",
     id: str,
     project_id: str = None,
     changeset_id: str = None,
     show_expression_as: str = None,
     show_fields: str = None,
     show_filter_tokens: bool = False,
-    error_msg: str = None
+    error_msg: str = None,
 ):
     """Get the definition of a security filter.
     The project ID is required to return a security filter's definition
     in metadata. The changeset ID is required to return a security filter's
     definition within a specific changeset. To execute the request,
     either the project ID or changeset ID needs to be provided.
     If both are provided, only the changeset ID is used.
@@ -128,36 +128,34 @@
     """
     if project_id is None:
         connection._validate_project_selected()
         project_id = connection.project_id
 
     return connection.get(
         url=f"{connection.base_url}/api/model/securityFilters/{id}",
-        headers={
-            'X-MSTR-ProjectID': project_id, 'X-MSTR-MS-Changeset': changeset_id
-        },
+        headers={'X-MSTR-ProjectID': project_id, 'X-MSTR-MS-Changeset': changeset_id},
         params={
             'showExpressionAs': show_expression_as,
             'showFields': show_fields,
-            'showFilterTokens': str(show_filter_tokens).lower()
-        }
+            'showFilterTokens': str(show_filter_tokens).lower(),
+        },
     )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error updating security filter with ID {id}')
 def update_security_filter(
     connection: "Connection",
     id: str,
     body: dict,
     show_expression_as: str = None,
     show_fields: str = None,
     show_filter_tokens: bool = False,
     error_msg: str = None,
-    throw_error: bool = True
+    throw_error: bool = True,
 ):
     """Updates a specific security filter in the changeset,
     based on the definition provided in the request body.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (str): Security Filter ID. The ID can be:
@@ -183,29 +181,29 @@
     with changeset_manager(connection) as changeset_id:
         return connection.put(
             url=f"{connection.base_url}/api/model/securityFilters/{id}",
             headers={'X-MSTR-MS-Changeset': changeset_id},
             params={
                 'showExpressionAs': show_expression_as,
                 'showFields': show_fields,
-                'showFilterTokens': str(show_filter_tokens).lower()
+                'showFilterTokens': str(show_filter_tokens).lower(),
             },
-            json=body
+            json=body,
         )
 
 
 @ErrorHandler(err_msg='Error getting information for set of security filters.')
 def get_security_filters(
     connection: "Connection",
     project_id: str = None,
     name_contains: str = None,
     offset: int = 0,
     limit: int = -1,
     fields: str = None,
-    error_msg: str = None
+    error_msg: str = None,
 ):
     """Get all list of Security Filters for a project.
     You can set the offset and limit for pagination function.
 
     Args:
         connection: MicroStrategy REST API connection object
         project_id (string, optional): id of project
@@ -226,10 +224,10 @@
     return connection.get(
         url=f'{connection.base_url}/api/securityFilters',
         headers={'X-MSTR-ProjectID': project_id},
         params={
             'nameContains': name_contains,
             'offset': offset,
             'limit': limit,
-            'fields': fields
-        }
+            'fields': fields,
+        },
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/subscriptions.py` & `mstrio-py-11.3.9.103/mstrio/api/subscriptions.py`

 * *Files 3% similar despite different names*

```diff
@@ -8,15 +8,17 @@
 if TYPE_CHECKING:
     from requests_futures.sessions import FuturesSession
 
     from mstrio.connection import Connection
 
 
 @ErrorHandler(err_msg='Error getting subscription list.')
-def list_subscriptions(connection, project_id, fields=None, offset=0, limit=-1, error_msg=None):
+def list_subscriptions(
+    connection, project_id, fields=None, offset=0, limit=-1, error_msg=None
+):
     """Get a list of subscriptions.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         project_id (str): ID of the project
         fields (list, optional): Comma separated top-level field whitelist. This
@@ -29,23 +31,26 @@
         error_msg (str, optional): Customized error message.
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
     return connection.get(
         url=f'{connection.base_url}/api/subscriptions',
-        params={
-            'offset': offset, 'limit': limit, 'fields': fields
-        },
+        params={'offset': offset, 'limit': limit, 'fields': fields},
         headers={'X-MSTR-ProjectID': project_id},
     )
 
 
 def list_subscriptions_async(
-    future_session: "FuturesSession", connection, project_id, fields=None, offset=0, limit=-1
+    future_session: "FuturesSession",
+    connection,
+    project_id,
+    fields=None,
+    offset=0,
+    limit=-1,
 ):
     """Get a list of subscriptions asynchronously.
 
     Args:
         future_session: Future Session object to call MicroStrategy REST
             Server asynchronously
         connection (object): MicroStrategy connection object returned by
@@ -72,15 +77,15 @@
 @ErrorHandler(err_msg='Error getting Dynamic Recipient List list.')
 def list_dynamic_recipient_lists(
     connection: "Connection",
     project_id: str,
     offset: int = 0,
     limit: int = -1,
     fields: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> Response:
     """Get a list of Dynamic Recipient Lists.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         project_id (str): ID of the project
@@ -94,28 +99,26 @@
         error_msg (str, optional): Customized error message.
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
     return connection.get(
         url=f'{connection.base_url}/api/dynamicRecipientLists',
-        params={
-            'offset': offset, 'limit': limit, 'fields': fields
-        },
-        headers={'X-MSTR-ProjectID': project_id}
+        params={'offset': offset, 'limit': limit, 'fields': fields},
+        headers={'X-MSTR-ProjectID': project_id},
     )
 
 
 def list_dynamic_recipient_lists_async(
     future_session: "FuturesSession",
     connection: "Connection",
     project_id: str,
     offset: int = 0,
     limit: int = -1,
-    fields: Optional[str] = None
+    fields: Optional[str] = None,
 ) -> Response:
     """Get a list of Dynamic Recipient Lists asynchronously.
 
     Args:
         future_session: Future Session object to call MicroStrategy REST
             Server asynchronously
         connection (object): MicroStrategy connection object returned by
@@ -131,22 +134,22 @@
 
     Returns:
         Complete Future object.
     """
     return future_session.get(
         url=f'{connection.base_url}/api/dynamicRecipientLists',
         headers={'X-MSTR-ProjectID': project_id},
-        params={
-            'offset': offset, 'limit': limit, 'fields': fields
-        }
+        params={'offset': offset, 'limit': limit, 'fields': fields},
     )
 
 
 @ErrorHandler(err_msg='Error getting subscription {subscription_id} information.')
-def get_subscription(connection, subscription_id, project_id, fields=None, error_msg=None):
+def get_subscription(
+    connection, subscription_id, project_id, fields=None, error_msg=None
+):
     """Get information of a specific subscription for a given project.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         subscription_id (str): ID of the subscription
         project_id (str): ID of the project
@@ -166,15 +169,15 @@
 
 @ErrorHandler(err_msg='Error getting Dynamic Recipient List {list_id} information.')
 def get_dynamic_recipient_list(
     connection: "Connection",
     id: str,
     project_id: str,
     fields: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> Response:
     """Get information of a specific Dynamic Recipient List for a given project.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         id (str): ID of the Dynamic Recipient List
@@ -326,15 +329,15 @@
 
 @ErrorHandler(err_msg='Error creating new Dynamic Recipient List.')
 def create_dynamic_recipient_list(
     connection: "Connection",
     project_id: str,
     body: dict,
     fields: Optional[list[str]] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> Response:
     """Create a new subscription.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         project_id (str): ID of the project
@@ -346,15 +349,15 @@
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
     return connection.post(
         url=f'{connection.base_url}/api/dynamicRecipientLists',
         params={'fields': fields},
         headers={'X-MSTR-ProjectID': project_id},
-        json=body
+        json=body,
     )
 
 
 def remove_subscription(
     connection, subscription_id, project_id, error_msg=None, exception_type=None
 ):
     """Remove (Unsubscribe) the subscription using subscription id.
@@ -385,15 +388,15 @@
 
 
 def remove_dynamic_recipient_list(
     connection: "Connection",
     id: str,
     project_id: str,
     error_msg: Optional[str] = None,
-    exception_type: Optional[Exception] = None
+    exception_type: Optional[Exception] = None,
 ) -> Response:
     """Delete a Dynamic Recipient List.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         id (str): ID of the Dynamic Recipient List
@@ -447,15 +450,15 @@
 @ErrorHandler(err_msg='Error updating Dynamic Recipient List {list_id}')
 def update_dynamic_recipient_list(
     connection: "Connection",
     id: str,
     project_id: str,
     body: dict,
     fields: Optional[list[str]] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ) -> Response:
     """Updates a Dynamic Recipient List.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         id (str): ID of the Dynamic Recipient List
@@ -474,15 +477,22 @@
         headers={'X-MSTR-ProjectID': project_id},
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error getting recipients list.')
 def available_recipients(
-    connection, project_id, body, delivery_type, offset=0, limit=-1, fields=None, error_msg=None
+    connection,
+    project_id,
+    body,
+    delivery_type,
+    offset=0,
+    limit=-1,
+    fields=None,
+    error_msg=None,
 ):
     """Get a list of available recipients in shared list, for a given content
     and delivery type, within a given project.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`
@@ -509,15 +519,18 @@
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server
     """
     return connection.post(
         url=f'{connection.base_url}/api/subscriptions/recipients/results',
         params={
-            'fields': fields, 'deliveryType': delivery_type, 'offset': offset, 'limit': limit
+            'fields': fields,
+            'deliveryType': delivery_type,
+            'offset': offset,
+            'limit': limit,
         },
         headers={'X-MSTR-ProjectID': project_id},
         json=body,
     )
 
 
 @ErrorHandler(err_msg='Error getting available bursting attributes list.')
@@ -539,23 +552,23 @@
         error_msg (str, optional): Customized error message.
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server
     """
     return connection.get(
         url=f'{connection.base_url}/api/subscriptions/bursting',
-        params={
-            'fields': fields, 'contentId': content_id, 'contentType': content_type
-        },
+        params={'fields': fields, 'contentId': content_id, 'contentType': content_type},
         headers={'X-MSTR-ProjectID': project_id},
     )
 
 
 @ErrorHandler(err_msg='Error sending subscription {subscription_id}')
-def send_subscription(connection, subscription_id, project_id, body, fields=None, error_msg=None):
+def send_subscription(
+    connection, subscription_id, project_id, body, fields=None, error_msg=None
+):
     """Send the existing subscription immediately.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`
         subscription_id (str): ID of subscription
         project_id (str): ID of the project
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/tables.py` & `mstrio-py-11.3.9.103/mstrio/api/tables.py`

 * *Files 2% similar despite different names*

```diff
@@ -34,41 +34,39 @@
     """
     if project_id is None:
         connection._validate_project_selected(),
         project_id = connection.project_id
 
     return connection.get(
         url=f"{connection.base_url}/api/model/tables/{id}",
-        headers={
-            "X-MSTR-ProjectID": project_id, "X-MSTR-Changeset": changeset_id
-        },
+        headers={"X-MSTR-ProjectID": project_id, "X-MSTR-Changeset": changeset_id},
         params={"fields": fields},
     )
 
 
 @unpack_information
 @ErrorHandler("Error listing tables")
 def get_tables(
     connection: "Connection",
     project_id: Optional[str] = None,
     changeset_id: Optional[str] = None,
-    limit: int = 1000,
+    limit: int = None,
     offset: int = 0,
     fields: Optional[str] = None,
     error_msg: Optional[str] = None,
 ):
     """Get a list of all tables.
 
     Args:
         connection (object): MicroStrategy REST API connection object
         project_id (str, optional): Project ID
         changeset_id (str, optional): Changeset ID
         limit (int, optional): Maximum number of items returned for a single
-            request. Used to control paging behavior. Use -1 for no limit.
-            Default is 1000.
+            request. Used to control paging behavior. Use None for no limit.
+            Default is None.
         offset (int, optional): Starting point within the collection of
             returned results. Used to control paging behavior. Default is 0.
         fields(list, optional): Comma separated top-level field whitelist.
             This allows client to selectively retrieve part of the
             response model.
         error_msg (str, optional): Custom Error Message for Error Handling
     Returns:
@@ -76,20 +74,16 @@
     """
     if project_id is None:
         connection._validate_project_selected(),
         project_id = connection.project_id
 
     return connection.get(
         url=f"{connection.base_url}/api/model/tables",
-        headers={
-            "X-MSTR-ProjectID": project_id, "X-MSTR-Changeset": changeset_id
-        },
-        params={
-            "limit": limit, "offset": offset, "fields": fields
-        },
+        headers={"X-MSTR-ProjectID": project_id, "X-MSTR-Changeset": changeset_id},
+        params={"limit": limit, "offset": offset, "fields": fields},
     )
 
 
 @unpack_information
 @ErrorHandler("Error updating the table with ID: {id}")
 def patch_table(
     connection: "Connection",
@@ -122,17 +116,15 @@
         Complete HTTP response object. Expected status is 200.
     """
     with changeset_manager(connection) as changeset_id:
         return connection.patch(
             url=f"{connection.base_url}/api/model/tables/{id}",
             headers={"X-MSTR-MS-Changeset": changeset_id},
             json=body,
-            params={
-                "columnMergeOption": column_merge_option, "fields": fields
-            },
+            params={"columnMergeOption": column_merge_option, "fields": fields},
         )
 
 
 @unpack_information
 @ErrorHandler("Error creating the table")
 def post_table(
     connection: "Connection",
@@ -180,15 +172,16 @@
     with changeset_manager(connection) as changeset_id:
         return connection.post(
             url=f"{connection.base_url}/api/model/tables",
             headers={"X-MSTR-MS-Changeset": changeset_id},
             json=data,
             params={
                 "checkSecondaryDataSourceTable": "true"
-                if check_secondary_data_source_table else "false",
+                if check_secondary_data_source_table
+                else "false",
                 "columnMergeOption": column_merge_option,
                 "tablePrefixOption": table_prefix_option,
                 "fields": fields,
             },
         )
 
 
@@ -234,27 +227,26 @@
         fields: A whitelist of top-level fields separated by commas.
             Allow the client to selectively retrieve fields in the response.
     Return:
         Complete Future object.
     """
     return session.get(
         url=f"{connection.base_url}/api/model/tables/{id}",
-        headers={
-            "X-MSTR-MS-Changeset": changeset_id, "X-MSTR-ProjectID": project_id
-        },
+        headers={"X-MSTR-MS-Changeset": changeset_id, "X-MSTR-ProjectID": project_id},
         params={"fields": fields},
     )
 
 
 def get_available_warehouse_tables_async(
     session: FuturesSessionWithRenewal,
     connection: "Connection",
     datasource_id: str,
-    namespace_id: str
+    namespace_id: str,
 ):
     return session.get(
-        f"{connection.base_url}/api/datasources/{datasource_id}/catalog/namespaces/{namespace_id}"
+        f"{connection.base_url}/api/datasources/{datasource_id}/catalog/namespaces/"
+        f"{namespace_id}"
         "/tables",
         headers={
             "X-MSTR-ProjectID": connection.project_id,
-        }
+        },
     )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/transformations.py` & `mstrio-py-11.3.9.103/mstrio/api/transformations.py`

 * *Files 5% similar despite different names*

```diff
@@ -3,16 +3,20 @@
 from mstrio.connection import Connection
 from mstrio.utils.api_helpers import changeset_manager, unpack_information
 from mstrio.utils.error_handlers import ErrorHandler
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error getting transformation with ID: {id}')
-def get_transformation(connection: Connection, id: str, changeset_id: Optional[str] = None,
-                       show_expression_as: Optional[list[str]] = None):
+def get_transformation(
+    connection: Connection,
+    id: str,
+    changeset_id: Optional[str] = None,
+    show_expression_as: Optional[list[str]] = None,
+):
     """Get definition of a single transformation by id
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of an transformation
         changeset_id: ID of a changeset
         show_expression_as: Specifies the format in which the expressions
@@ -22,24 +26,26 @@
            If 'tree', the expression is returned in 'text' and 'tree' formats.
            If 'tokens', the expression is returned in 'text' and 'tokens'
            formats.
 
     Return:
         HTTP response object. Expected status: 200
     """
-    return connection.get(url=f'{connection.base_url}/api/model/transformations/{id}',
-                          headers={'X-MSTR-MS-Changeset': changeset_id},
-                          params={'showExpressionAs': show_expression_as})
+    return connection.get(
+        url=f'{connection.base_url}/api/model/transformations/{id}',
+        headers={'X-MSTR-MS-Changeset': changeset_id},
+        params={'showExpressionAs': show_expression_as},
+    )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error creating a transformation')
-def create_transformation(connection: Connection, body: dict,
-                          show_expression_as: Optional[list[str]] = None):
-
+def create_transformation(
+    connection: Connection, body: dict, show_expression_as: Optional[list[str]] = None
+):
     """Create a new transformation in the changeset,
     based on the definition provided in request body.
 
     Args:
         connection: MicroStrategy REST API connection object
         body: Transformation creation data
         show_expression_as: Specifies the format in which the expressions are
@@ -50,23 +56,30 @@
            If 'tokens', the expression is returned in 'text' and 'tokens'
            formats.
 
     Return:
         HTTP response object. Expected status: 200
     """
     with changeset_manager(connection) as changeset_id:
-        return connection.post(url=f'{connection.base_url}/api/model/transformations',
-                               headers={'X-MSTR-MS-Changeset': changeset_id},
-                               params={'showExpressionAs': show_expression_as}, json=body)
+        return connection.post(
+            url=f'{connection.base_url}/api/model/transformations',
+            headers={'X-MSTR-MS-Changeset': changeset_id},
+            params={'showExpressionAs': show_expression_as},
+            json=body,
+        )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error updating transformation with ID: {id}')
-def update_transformation(connection: Connection, id: str, body: dict,
-                          show_expression_as: Optional[list[str]] = None):
+def update_transformation(
+    connection: Connection,
+    id: str,
+    body: dict,
+    show_expression_as: Optional[list[str]] = None,
+):
     """Update a specific transformation in the changeset,
     based on the definition provided in the request body.
     It returns the transformation's updated definition in the changeset.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of a Transformation
@@ -79,10 +92,13 @@
            If 'tokens', the expression is returned in 'text' and 'tokens'
            formats.
 
     Return:
         HTTP response object. Expected status: 200
     """
     with changeset_manager(connection) as changeset_id:
-        return connection.patch(url=f'{connection.base_url}/api/model/transformations/{id}',
-                                headers={'X-MSTR-MS-Changeset': changeset_id},
-                                params={'showExpressionAs': show_expression_as}, json=body)
+        return connection.patch(
+            url=f'{connection.base_url}/api/model/transformations/{id}',
+            headers={'X-MSTR-MS-Changeset': changeset_id},
+            params={'showExpressionAs': show_expression_as},
+            json=body,
+        )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/transmitters.py` & `mstrio-py-11.3.9.103/mstrio/api/transmitters.py`

 * *Files 1% similar despite different names*

```diff
@@ -70,15 +70,17 @@
         Complete HTTP response object. Expected status is 200.
     """
     url = f"{connection.base_url}/api/transmitters/{id}"
     return connection.put(url=url, json=body)
 
 
 @ErrorHandler(err_msg='Error deleting Transmitter with ID {id}')
-def delete_transmitter(connection: "Connection", id: str, error_msg: Optional[str] = None):
+def delete_transmitter(
+    connection: "Connection", id: str, error_msg: Optional[str] = None
+):
     """Delete a transmitter.
 
     Args:
         connection: MicroStrategy REST API connection object
         id: ID of the transmitter
         error_msg (string, optional): Custom Error Message for Error Handling
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/user_hierarchies.py` & `mstrio-py-11.3.9.103/mstrio/api/user_hierarchies.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 @ErrorHandler(err_msg='Error listing Hierarchies.')
 def get_user_hierarchies(
     connection: "Connection",
     project_id: Optional[str] = None,
     changeset_id: Optional[str] = None,
     limit: int = 1000,
     offset: int = 0,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get a list of all user hierarchies.
     The project ID is required to return all user hierarchy definitions
     in metadata. The changeset ID is required to return all user hierarchy
     definitions within a specific changeset. To execute the request,
     provide either the project ID or changeset ID.
     If you provide both, only the changeset ID is used.
@@ -46,15 +46,15 @@
         headers={
             'X-MSTR-ProjectID': project_id,
             'X-MSTR-MS-Changeset': changeset_id,
         },
         params={
             'limit': limit,
             'offset': offset,
-        }
+        },
     )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error creating the user hierarchy.')
 def create_user_hierarchy(
     connection: "Connection", body: dict, error_msg: Optional[str] = None
@@ -70,26 +70,26 @@
     Returns:
         Complete HTTP response object. Expected status is 201.
     """
     with changeset_manager(connection) as changeset_id:
         return connection.post(
             url=f"{connection.base_url}/api/model/hierarchies",
             headers={'X-MSTR-MS-Changeset': changeset_id},
-            json=body
+            json=body,
         )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error getting the user hierarchy with ID: {id}.')
 def get_user_hierarchy(
     connection: "Connection",
     id: str,
     project_id: Optional[str] = None,
     changeset_id: Optional[str] = None,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get the definition of a user hierarchy.
     The project ID is required to return a user hierarchy's definition
     in metadata. The changeset ID is required to return a user hierarchy's
     definition within a specific changeset. To execute the request, provide
     either the project ID or changeset ID.
     If both are provided, only the changeset ID is used.
@@ -109,27 +109,22 @@
     """
     if project_id is None:
         connection._validate_project_selected()
         project_id = connection.project_id
 
     return connection.get(
         url=f"{connection.base_url}/api/model/hierarchies/{id}",
-        headers={
-            'X-MSTR-ProjectID': project_id, 'X-MSTR-MS-Changeset': changeset_id
-        },
+        headers={'X-MSTR-ProjectID': project_id, 'X-MSTR-MS-Changeset': changeset_id},
     )
 
 
 @unpack_information
 @ErrorHandler(err_msg='Error updating the user hierarchy with ID: {id}.')
 def update_user_hierarchy(
-    connection: "Connection",
-    id: str,
-    body: dict,
-    error_msg: Optional[str] = None
+    connection: "Connection", id: str, body: dict, error_msg: Optional[str] = None
 ):
     """Updates a specific user hierarchy in the changeset,
     based on the definition provided in the request body.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (str): Hierarchy ID. The ID can be:
@@ -142,15 +137,15 @@
     Returns:
         Complete HTTP response object. Expected status is 200.
     """
     with changeset_manager(connection) as changeset_id:
         return connection.patch(
             url=f"{connection.base_url}/api/model/hierarchies/{id}",
             headers={'X-MSTR-MS-Changeset': changeset_id},
-            json=body
+            json=body,
         )
 
 
 @ErrorHandler(err_msg='Error deleting the user hierarchy with ID: {id}.')
 def delete_user_hierarchy(
     connection: "Connection", id: str, error_msg: Optional[str] = None
 ):
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/usergroups.py` & `mstrio-py-11.3.9.103/mstrio/api/usergroups.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,15 +5,17 @@
 if TYPE_CHECKING:
     from requests_futures.sessions import FuturesSession
 
     from mstrio.connection import Connection
 
 
 @ErrorHandler(err_msg='Error getting user groups privileges for a group with ID {id}')
-def get_privileges(connection, id, privilege_level=None, project_id=None, error_msg=None):
+def get_privileges(
+    connection, id, privilege_level=None, project_id=None, error_msg=None
+):
     """Get user group's privileges of a project including the source of the
     privileges.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): ID of user group containing your required privileges
         privilege_level (string, optional) [server, project]: String
@@ -24,17 +26,15 @@
     Returns:
         Complete HTTP response object.
     """
 
     return connection.get(
         url=f'{connection.base_url}/api/usergroups/{id}/privileges',
         headers={'X-MSTR-ProjectID': None},
-        params={
-            'privilege.level': privilege_level, 'projectId': project_id
-        },
+        params={'privilege.level': privilege_level, 'projectId': project_id},
     )
 
 
 @ErrorHandler(err_msg='Error getting user groups memberships for a group with ID {id}')
 def get_memberships(connection, id, error_msg=None):
     """Get information for the user group that is the direct parent of a
     specific user group.
@@ -51,15 +51,17 @@
     return connection.get(
         url=f'{connection.base_url}/api/usergroups/{id}/memberships',
         headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error getting user groups members for a group with ID {id}')
-def get_members(connection, id, include_access=False, offset=0, limit=-1, error_msg=None):
+def get_members(
+    connection, id, include_access=False, offset=0, limit=-1, error_msg=None
+):
     """Get member information for a specific user group.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): ID of user group containing your required privileges
         include_access (bool, optional): Specifies whether to return access for
             members
@@ -73,22 +75,22 @@
     Returns:
         Complete HTTP response object.
     """
 
     return connection.get(
         url=f'{connection.base_url}/api/usergroups/{id}/members',
         headers={'X-MSTR-ProjectID': None},
-        params={
-            'includeAccess': include_access, 'offset': offset, 'limit': limit
-        },
+        params={'includeAccess': include_access, 'offset': offset, 'limit': limit},
     )
 
 
 @ErrorHandler(err_msg='Error getting user group settings for a group with ID {id}')
-def get_settings(connection, id, include_access=False, offset=0, limit=-1, error_msg=None):
+def get_settings(
+    connection, id, include_access=False, offset=0, limit=-1, error_msg=None
+):
     """Update the governing setting of the user group id.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): ID of user group containing your required privileges
         include_access (bool, optional): Specifies whether to return access for
             members
@@ -118,15 +120,16 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
 
     return connection.get(
-        url=f'{connection.base_url}/api/usergroups/topLevel', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/usergroups/topLevel',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error updating user group info with ID {id}')
 def update_user_group_info(connection, id, body, error_msg=None):
     """Update specific information for a specific user group.
 
@@ -157,15 +160,16 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object
     """
 
     return connection.delete(
-        url=f'{connection.base_url}/api/usergroups/{id}', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/usergroups/{id}',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error overwriting user group info for a group with ID {id}')
 def replace_user_group_info(connection, id, error_msg=None):
     """Update all of the information for a specific user group.
 
@@ -175,15 +179,16 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object
     """
 
     return connection.put(
-        url=f'{connection.base_url}/api/usergroups/{id}', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/usergroups/{id}',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
 @ErrorHandler(err_msg='Error getting information for a set of user groups.')
 def get_info_all_user_groups(
     connection, name_begins, offset=0, limit=1000, fields=None, error_msg=None
 ):
@@ -219,21 +224,29 @@
         HTTP response object returned by the MicroStrategy REST server
     """
 
     return connection.get(
         f'{connection.base_url}/api/usergroups/',
         headers={'X-MSTR-ProjectID': None},
         params={
-            'nameBegins': name_begins, 'offset': offset, 'limit': limit, 'fields': fields
+            'nameBegins': name_begins,
+            'offset': offset,
+            'limit': limit,
+            'fields': fields,
         },
     )
 
 
 def get_info_all_user_groups_async(
-    future_session: "FuturesSession", connection, name_begins, offset=0, limit=-1, fields=None
+    future_session: "FuturesSession",
+    connection,
+    name_begins,
+    offset=0,
+    limit=-1,
+    fields=None,
 ):
     """Get information for a set of users asynchronously.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`.
         name_begins(string): Characters that the user name must begin with.
@@ -295,19 +308,22 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object.
     """
 
     return connection.get(
-        url=f'{connection.base_url}/api/usergroups/{id}', headers={'X-MSTR-ProjectID': None}
+        url=f'{connection.base_url}/api/usergroups/{id}',
+        headers={'X-MSTR-ProjectID': None},
     )
 
 
-@ErrorHandler(err_msg='Error getting user group security roles for a group with ID {id}')
+@ErrorHandler(
+    err_msg='Error getting user group security roles for a group with ID {id}'
+)
 def get_security_roles(connection, id, project_id=None, error_msg=None):
     """Get security roles for a specific user group in a specific project.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): ID of user group containing your required privileges
         project_id (string, optional): Project id string
@@ -327,15 +343,15 @@
 @ErrorHandler(err_msg='Error getting security filters for user with ID {id}.')
 def get_security_filters(
     connection: "Connection",
     id: str,
     projects: Optional[Union[str, List[str]]] = None,
     offset: int = 0,
     limit: int = -1,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get each project level security filter and its corresponding inherited
     security filters for the user group with given ID.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): User group ID
@@ -348,12 +364,13 @@
             Default is -1.
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object. Expected status is 200.
     """
     url = f"{connection.base_url}/api/usergroups/{id}/securityFilters"
-    projects = (
-        ','.join(projects if isinstance(projects, list) else [projects])
-    ) if projects else projects
+
+    if projects and isinstance(projects, list):
+        projects = ','.join(projects)
+
     params = {'projects.id': projects, 'offset': offset, 'limit': limit}
     return connection.get(url=url, params=params)
```

### Comparing `mstrio-py-11.3.9.101/mstrio/api/users.py` & `mstrio-py-11.3.9.103/mstrio/api/users.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 @ErrorHandler(err_msg='Error getting information for a set of recipients.')
 def get_recipients(
     connection,
     search_term,
     search_pattern="CONTAINS_ANY_WORD",
     offset=0,
     limit=-1,
-    enabled_status='ALL'
+    enabled_status='ALL',
 ):
     """Get information for a set of recipients.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         search_term (string): The value that the search_pattern parameter is set
@@ -46,22 +46,28 @@
     return connection.get(
         url=f'{connection.base_url}/api/collaboration/recipients',
         params={
             'searchTerm': search_term,
             'searchPattern': search_pattern,
             'offset': offset,
             'limit': limit,
-            'enabledStatus': enabled_status
+            'enabledStatus': enabled_status,
         },
     )
 
 
 @ErrorHandler(err_msg='Error getting information for a set of users')
 def get_users_info(
-    connection, name_begins, abbreviation_begins, offset=0, limit=-1, fields=None, error_msg=None
+    connection,
+    name_begins,
+    abbreviation_begins,
+    offset=0,
+    limit=-1,
+    fields=None,
+    error_msg=None,
 ):
     """Get information for a set of users.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         name_begins (string): Characters that the user name must begin with.
@@ -82,28 +88,28 @@
     return connection.get(
         url=f'{connection.base_url}/api/users/',
         params={
             'nameBegins': name_begins,
             'abbreviationBegins': abbreviation_begins,
             'offset': offset,
             'limit': limit,
-            'fields': fields
+            'fields': fields,
         },
         headers={'X-MSTR-ProjectID': None},
     )
 
 
 def get_users_info_async(
     future_session: "FuturesSession",
     connection,
     name_begins,
     abbreviation_begins,
     offset=0,
     limit=-1,
-    fields=None
+    fields=None,
 ):
     """Get information for a set of users asynchronously.
 
     Args:
         future_session: Future Session object to call MicroStrategy REST
             Server asynchronously
         connection (object): MicroStrategy connection object returned by
@@ -123,15 +129,15 @@
         Complete Future object.
     """
     params = {
         'nameBegins': name_begins,
         'abbreviationBegins': abbreviation_begins,
         'offset': offset,
         'limit': limit,
-        'fields': fields
+        'fields': fields,
     }
     url = f'{connection.base_url}/api/users/'
     headers = {'X-MSTR-ProjectID': None}
     future = future_session.get(url=url, headers=headers, params=params)
     return future
 
 
@@ -255,15 +261,17 @@
     return connection.post(
         url=f'{connection.base_url}/api/v2/users/{id}/addresses',
         params={'fields': fields},
         json=body,
     )
 
 
-@ErrorHandler(err_msg='Error updating address with ID {address_id} for user with ID {id}')
+@ErrorHandler(
+    err_msg='Error updating address with ID {address_id} for user with ID {id}'
+)
 def update_address(connection, id, address_id, body, fields=None):
     """Update a specific address for a specific user.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         id (string): User ID.
@@ -278,15 +286,17 @@
     return connection.put(
         url=f'{connection.base_url}/api/users/{id}/addresses/{address_id}',
         params={'fields': fields},
         json=body,
     )
 
 
-@ErrorHandler(err_msg='Error deleting address with ID {address_id} for a user with ID {id}')
+@ErrorHandler(
+    err_msg='Error deleting address with ID {address_id} for a user with ID {id}'
+)
 def delete_address(connection, id, address_id, fields=None):
     """Delete a specific address for a specific user.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`.
         id (string): User ID.
@@ -337,17 +347,15 @@
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
     url = f'{connection.base_url}/api/users/{id}/privileges/'
     return connection.get(
         url=url,
-        params={
-            'privilege.level': privilege_level, 'projectId': project_id
-        },
+        params={'privilege.level': privilege_level, 'projectId': project_id},
     )
 
 
 @ErrorHandler(err_msg='Error getting user data usage limit for project with ID {id}')
 def get_user_data_usage_limit(connection, id, project_id):
     """Get the data usage limit for users, either all users or a specific user,
     in a specific project. A typical use case would be that an administrator
@@ -379,15 +387,17 @@
         fields (list, optional): Comma separated top-level field whitelist. This
             allows client to selectively retrieve part of the response model.
 
     Returns:
         HTTP response object returned by the MicroStrategy REST server.
     """
 
-    return connection.get(url=f'{connection.base_url}/api/users/{id}', params={'fields': fields})
+    return connection.get(
+        url=f'{connection.base_url}/api/users/{id}', params={'fields': fields}
+    )
 
 
 @ErrorHandler(err_msg='Error deleting user with ID {id}')
 def delete_user(connection, id):
     """Delete user for specific user id.
 
     Args:
@@ -462,15 +472,15 @@
 @ErrorHandler(err_msg='Error getting security filters for user with ID {id}.')
 def get_security_filters(
     connection: "Connection",
     id: str,
     projects: Optional[str | list[str]] = None,
     offset: int = 0,
     limit: int = -1,
-    error_msg: Optional[str] = None
+    error_msg: Optional[str] = None,
 ):
     """Get each project level security filter and its corresponding inherited
     security filters for the user with given ID.
 
     Args:
         connection: MicroStrategy REST API connection object
         id (string): User ID
@@ -484,12 +494,12 @@
         error_msg (string, optional): Custom Error Message for Error Handling
 
     Returns:
         Complete HTTP response object. Expected status is 200.
     """
     url = f"{connection.base_url}/api/users/{id}/securityFilters"
 
-    projects = (
-        ','.join(projects if isinstance(projects, list) else [projects])
-    ) if projects else projects
+    if projects and isinstance(projects, list):
+        projects = ','.join(projects)
+
     params = {'projects.id': projects, 'offset': offset, 'limit': limit}
     return connection.get(url=url, params=params)
```

### Comparing `mstrio-py-11.3.9.101/mstrio/config.py` & `mstrio-py-11.3.9.103/mstrio/config.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,34 +2,40 @@
 import sys
 import warnings
 
 from pandas import options
 
 verbose = True  # Controls the amount of feedback from the I-Server
 fetch_on_init = True  # Controls if object will fetch basic data from server on init
-progress_bar = True  # Controls whether progress bar will be shown during long fetch operations
+progress_bar = (
+    True  # Controls whether progress bar will be shown during long fetch operations
+)
 debug = False  # Lets the program run in debugging mode
 # Sets number of rows displayed for pandas DataFrame
 options.display.max_rows = max(250, options.display.max_rows)
 options.display.max_colwidth = max(100, options.display.max_colwidth)
 # Warning settings: "error", "ignore", "always", "default", "module", "once"
 print_warnings = 'always'
 module_path = 'mstrio.*'
 save_responses = False  # Used to save REST API responses for mocking
-wip_warnings_enabled = True  # Controls whether warnings/errors about WIP functionality are emitted
+wip_warnings_enabled = (
+    True  # Controls whether warnings/errors about WIP functionality are emitted
+)
 
 
 def custom_formatwarning(msg, category, *args, **kwargs):
     # ignore everything except the message
     return str(category.__name__) + ': ' + str(msg) + '\n'
 
 
 warnings.formatwarning = custom_formatwarning
 warnings.filterwarnings(action=print_warnings, module=module_path)
-warnings.filterwarnings(action=print_warnings, category=DeprecationWarning, module=module_path)
+warnings.filterwarnings(
+    action=print_warnings, category=DeprecationWarning, module=module_path
+)
 warnings.filterwarnings(action='default', category=UserWarning, module=module_path)
 
 
 def get_logging_level() -> int:
     """Calculate and return logging level
     to configure logger.
     """
```

### Comparing `mstrio-py-11.3.9.101/mstrio/connection.py` & `mstrio-py-11.3.9.103/mstrio/connection.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,15 +19,15 @@
 logger = logging.getLogger(__name__)
 
 
 def get_connection(
     workstation_data: dict,
     project_name: Optional[str] = None,
     project_id: Optional[str] = None,
-    ssl_verify: bool = False
+    ssl_verify: bool = False,
 ) -> Optional["Connection"]:
     """Connect to environment without providing user's credentials.
 
     It is possible to provide `project_id` or `project_name` to select
     project. When both `project_id` and `project_name` are `None`,
     project selection is cleared. When both `project_id` and
     `project_name` are provided, `project_name` is ignored.
@@ -70,32 +70,37 @@
         for c in cookies:
             cookie_values = {'domain': '', 'path': '/'}
             cookie_values.update(c)
             jar.set(
                 cookie_values['name'],
                 cookie_values['value'],
                 domain=cookie_values['domain'],
-                path=cookie_values['path']
+                path=cookie_values['path'],
             )
     except Exception as e:
-        logger.error(f'Some error occurred while preparing data to get identity token: \n{e}')
+        logger.error(
+            f'Some error occurred while preparing data to get identity token: \n{e}'
+        )
         return None
 
     # get identity token
     r = requests.post(
-        base_url + 'api/auth/identityToken', headers=headers, cookies=jar, verify=ssl_verify
+        base_url + 'api/auth/identityToken',
+        headers=headers,
+        cookies=jar,
+        verify=ssl_verify,
     )
     if r.ok:
         # create connection to I-Server
         return Connection(
             base_url,
             identity_token=r.headers['X-MSTR-IdentityToken'],
             project_id=project_id,
             project_name=project_name,
-            ssl_verify=ssl_verify
+            ssl_verify=ssl_verify,
         )
     else:
         logger.error(f'HTTP {r.status_code} - {r.reason}, Message {r.text}')
         return None
 
 
 class Connection:
@@ -145,15 +150,15 @@
         project_name: Optional[str] = None,
         project_id: Optional[str] = None,
         login_mode: int = 1,
         ssl_verify: bool = True,
         certificate_path: Optional[str] = None,
         proxies: Optional[dict] = None,
         identity_token: Optional[str] = None,
-        verbose: bool = True
+        verbose: bool = True,
     ):
         """Establish a connection with MicroStrategy REST API.
 
         You can establish connection by either providing set of values
         (`username`, `password`, `login_mode`) or just `identity_token`.
 
         When both `project_id` and `project_name` are `None`,
@@ -215,22 +220,23 @@
                 self.delegate()
             else:
                 self.connect()
 
             self.select_project(project_id, project_name)
         else:
             msg = (
-                f'This version of mstrio is only supported on MicroStrategy 11.1.0400 or higher.\n'
+                f'This version of mstrio is only supported on MicroStrategy 11.1.0400 '
+                f'or higher.\n'
                 f'Current Intelligence Server version: {self.iserver_version}\n'
                 f'Current MicroStrategy Web version: {self.web_version}'
             )
             logger.warning(msg)
             helper.exception_handler(
                 msg='MicroStrategy Version not supported.',
-                exception_type=exceptions.VersionException
+                exception_type=exceptions.VersionException,
             )
 
     def __enter__(self):
         return self
 
     def __exit__(self, exception_type, exception_value, exception_traceback):
         self.close()
@@ -242,42 +248,50 @@
         If an active connection is detected, the session is renewed.
         """
         response = self._renew() if self.token else None
 
         if response and response.ok:
             self._reset_timeout()
             if config.verbose:
-                logger.info('Connection to MicroStrategy Intelligence Server was renewed.')
+                logger.info(
+                    'Connection to MicroStrategy Intelligence Server was renewed.'
+                )
         else:
             response = self._login()
             self._reset_timeout()
             self.token = response.headers['X-MSTR-AuthToken']
             self.timeout = self._get_session_timeout()
 
             if config.verbose:
                 logger.info(
-                    'Connection to MicroStrategy Intelligence Server has been established.'
+                    'Connection to MicroStrategy Intelligence Server has been '
+                    'established.'
                 )
 
     renew = connect
 
     def delegate(self):
         """Delegates identity token to get authentication token and connect to
         MicroStrategy Intelligence Server."""
-        response = authentication.delegate(self, self.identity_token, whitelist=[('ERR003', 401)])
+        response = authentication.delegate(
+            self, self.identity_token, whitelist=[('ERR003', 401)]
+        )
         if response.ok:
             self._reset_timeout()
             self.token = response.headers['X-MSTR-AuthToken']
             self.timeout = self._get_session_timeout()
             if config.verbose:
                 logger.info(
-                    'Connection with MicroStrategy Intelligence Server has been delegated.'
+                    'Connection with MicroStrategy Intelligence Server has been '
+                    'delegated.'
                 )
         else:
-            print("Could not share existing connection session, please input credentials:")
+            print(
+                "Could not share existing connection session, please input credentials:"
+            )
             self.__prompt_credentials()
             self.connect()
 
     def get_identity_token(self) -> str:
         """Create new identity token using existing authentication token."""
         response = authentication.identity_token(self)
         return response.headers['X-MSTR-IdentityToken']
@@ -292,29 +306,33 @@
         authentication.logout(connection=self, whitelist=[('ERR009', 401)])
 
         self._session.close()
 
         self.token = None
 
         if config.verbose:
-            logger.info('Connection to MicroStrategy Intelligence Server has been closed.')
+            logger.info(
+                'Connection to MicroStrategy Intelligence Server has been closed.'
+            )
 
     def status(self) -> bool:
         """Checks if the session is still alive.
 
         Raises:
             HTTPError if I-Server behaves unexpectedly
         """
         status = self._status()
 
         if status.status_code == 200:
             logger.info('Connection to MicroStrategy Intelligence Server is active.')
             return True
         else:
-            logger.info('Connection to MicroStrategy Intelligence Server is not active.')
+            logger.info(
+                'Connection to MicroStrategy Intelligence Server is not active.'
+            )
             return False
 
     def select_project(
         self, project_id: Optional[str] = None, project_name: Optional[str] = None
     ) -> None:
         """Select project for the given connection based on project_id or
         project_name.
@@ -441,27 +459,30 @@
             raise AttributeError(
                 "Project not selected. Select project using `select_project` method."
             )
 
     def __prompt_credentials(self) -> None:
         self.username = self.username or input("Username: ")
         self.__password = self.__password or getpass("Password: ")
-        self.login_mode = self.login_mode or input("Login mode (1 - Standard, 16 - LDAP): ")
+        self.login_mode = self.login_mode or input(
+            "Login mode (1 - Standard, 16 - LDAP): "
+        )
 
     def __check_version(self) -> bool:
         """Checks version of I-Server and MicroStrategy Web and store these
         variables."""
 
         def get_server_status():
             json_response = misc.server_status(self).json()
             try:
                 iserver_version = json_response["iServerVersion"][:9]
             except KeyError:
                 raise exceptions.IServerException(
-                    "I-Server is currently unavailable. Please contact your administrator."
+                    "I-Server is currently unavailable. Please contact your "
+                    "administrator."
                 )
             web_version = json_response.get("webVersion")
             web_version = web_version[:9] if web_version else None
             return iserver_version, web_version
 
         self._iserver_version, self._web_version = get_server_status()
         return version.parse(self.iserver_version) >= version.parse("11.1.0400")
@@ -469,15 +490,15 @@
     def __configure_session(
         self,
         verify,
         certificate_path,
         proxies,
         existing_session=None,
         retries=2,
-        backoff_factor=0.3
+        backoff_factor=0.3,
     ):
         """Creates a shared requests.Session() object with configuration from
         the initialization. Additional parameters change how the HTTPAdapter is
         configured.
 
         Args:
             existing_session (requests.Session() object, optional): Optional
@@ -519,32 +540,37 @@
         session.mount('http://', adapter)
         session.mount('https://', adapter)
 
         return session
 
     @staticmethod
     def _configure_ssl(ssl_verify, certificate_path):
-
         def get_certs_from_cwd():
             cert_extensions = ['crt', 'pem', 'p12']
-            return [file for file in os.listdir('.') if file.split('.')[-1] in cert_extensions]
+            return [
+                file
+                for file in os.listdir('.')
+                if file.split('.')[-1] in cert_extensions
+            ]
 
         def find_cert_in_cwd(ssl_verify):
             certs = get_certs_from_cwd()
             if certs and ssl_verify:
                 return certs[0]
             else:
                 return ssl_verify
 
         if certificate_path:
             return certificate_path
         return find_cert_in_cwd(ssl_verify)
 
     def __get_user_info(self) -> None:
-        response = authentication.get_info_for_authenticated_user(connection=self).json()
+        response = authentication.get_info_for_authenticated_user(
+            connection=self
+        ).json()
         self._user_id = response.get("id")
         self._user_full_name = response.get("fullName")
         self._user_initials = response.get("initials")
 
     @property
     def user_id(self) -> str:
         if not self._user_id:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/datasources/database_connections.py` & `mstrio-py-11.3.9.103/mstrio/datasources/database_connections.py`

 * *Files 4% similar despite different names*

```diff
@@ -26,15 +26,18 @@
         Args:
             connection: MicroStrategy connection object returned
                 by `connection.Connection()`
         """
         self.connection = connection
 
     def list_connections(
-        self, nodes: Union[str, List[str]] = None, limit: Optional[int] = None, **filters
+        self,
+        nodes: Union[str, List[str]] = None,
+        limit: Optional[int] = None,
+        **filters,
     ) -> List[Dict[str, Any]]:
         """Get all active database connections. Optionally filter the
          connections by specifying the `filters` keyword arguments.
 
         Args:
             nodes: Node (server) names on which databases will be disconnected.
             limit: limit the number of elements returned. If `None`, all objects
@@ -50,15 +53,15 @@
         nodes_names = ",".join(nodes) if isinstance(nodes, list) else nodes
         all_databases = helper.fetch_objects(
             connection=self.connection,
             api=monitors.get_database_connections,
             nodes_names=nodes_names,
             dict_unpack_value="dbConnectionInstances",
             limit=limit,
-            filters=filters
+            filters=filters,
         )
         return all_databases
 
     def disconnect_database(self, connection_id: str, force: bool = False) -> bool:
         """Disconnect database connections by passing in connection_id.
 
         Args:
@@ -71,18 +74,21 @@
         user_input = 'N'
         if not force:
             user_input = input(
                 f"Are you sure you want to disconnect database connection "
                 f"'with ID:{connection_id}? [Y/N]: "
             )
         if force or user_input == 'Y':
-            response = monitors.delete_database_connection(self.connection, connection_id)
+            response = monitors.delete_database_connection(
+                self.connection, connection_id
+            )
             if response.status_code == 204 and config.verbose:
                 logger.info(
-                    f'Successfully disconnected database connection instance {connection_id}.'
+                    f'Successfully disconnected database connection instance '
+                    f'{connection_id}.'
                 )
             return response.ok
         else:
             return False
 
     def disconnect_all_databases(self, force: bool = False) -> Union[List[dict], None]:
         """Disconnect all database connections.
@@ -103,26 +109,30 @@
             if user_input != "Y":
                 return None
             else:
                 force = True
 
         connections = self.list_connections()
         threads = helper.get_parallel_number(len(connections))
-        with FuturesSessionWithRenewal(connection=self.connection, max_workers=threads) as session:
-
+        with FuturesSessionWithRenewal(
+            connection=self.connection, max_workers=threads
+        ) as session:
             futures = [
-                monitors.delete_database_connection_async(session, self.connection, conn["id"])
+                monitors.delete_database_connection_async(
+                    session, self.connection, conn["id"]
+                )
                 for conn in connections
             ]
             statuses: List[Dict[str, Union[str, int]]] = []
             for f in futures:
                 response = f.result()
                 statuses.append(
                     {
-                        'id': response.url.rsplit("/").pop(-1), 'status': response.status_code
+                        'id': response.url.rsplit("/").pop(-1),
+                        'status': response.status_code,
                     }
                 )
         return self._prepare_disconnect_by_id_message(statuses=statuses)
 
     @staticmethod
     def _prepare_disconnect_by_id_message(statuses: List[dict]) -> List[dict]:
         succeeded = []
@@ -140,11 +150,11 @@
             if succeeded:
                 logger.info(
                     'Database connections with ids listed below were successfully '
                     'disconnected:\n\t' + ',\n\t'.join(succeeded)
                 )
             if failed:
                 logger.warning(
-                    'Database connections with ids listed below were not disconnected:\n\t'
-                    + ',\n\t'.join(failed)
+                    'Database connections with ids listed below were not '
+                    'disconnected:\n\t' + ',\n\t'.join(failed)
                 )
         return statuses
```

### Comparing `mstrio-py-11.3.9.101/mstrio/datasources/datasource_connection.py` & `mstrio-py-11.3.9.103/mstrio/datasources/datasource_connection.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,39 +5,53 @@
 from mstrio import config
 from mstrio.api import datasources, objects
 from mstrio.datasources.datasource_login import DatasourceLogin
 from mstrio.users_and_groups.user import User
 from mstrio.utils import helper
 from mstrio.utils.entity import CopyMixin, DeleteMixin, Entity, ObjectTypes
 from mstrio.utils.enum_helper import AutoName, get_enum_val
-from mstrio.utils.helper import get_args_from_func, get_default_args_from_func, get_objects_id
+from mstrio.utils.helper import (
+    get_args_from_func,
+    get_default_args_from_func,
+    get_objects_id,
+)
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
 logger = logging.getLogger(__name__)
 
 
 @method_version_handler('11.3.0000')
 def list_datasource_connections(
-    connection: "Connection", to_dictionary: bool = False, limit: Optional[int] = None, **filters
+    connection: "Connection",
+    to_dictionary: bool = False,
+    limit: Optional[int] = None,
+    **filters,
 ) -> Union[List["DatasourceConnection"], List[dict]]:
     """Get list of DatasourceConnection objects or dicts. Optionally filter the
     connections by specifying filters.
 
     Args:
         connection: MicroStrategy connection object returned by
             `connection.Connection()`
         to_dictionary: If True returns dict, by default (False) returns
             User objects.
         limit: limit the number of elements returned. If `None` (default), all
             objects are returned.
-        **filters: Available filter parameters: ['id', 'name', 'description',
-            'acg']
+        **filters: Available filter parameters: ['name', 'id', 'description',
+            'acg', 'execution_mode', 'max_cancel_attempt_time',
+            'max_query_exe_time', 'max_connection_attempt_time',
+            'connection_lifetime', 'connection_idle_timeout',
+            'char_encoding_windows', 'char_encoding_unix',
+            'table_prefix', 'connection_string', 'parameterized_queries',
+            'extended_fetch', 'driver_type', 'oauth_parameter', 'iam',
+            'resource', 'scope', 'enable_sso', 'datasource_login',
+            'database_type', 'database_version']
 
     Examples:
         >>> list_datasource_connections(connection, name='db_conn_name')
     """
     return DatasourceConnection._list_datasource_connections(
         connection=connection,
         to_dictionary=to_dictionary,
@@ -137,15 +151,15 @@
             'date_modified',
             'version',
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
-            'acl'
+            'acl',
         ): objects.get_object_info,
         (
             'id',
             'name',
             'description',
             'execution_mode',
             'max_cancel_attempt_time',
@@ -164,16 +178,16 @@
             'database_type',
             'database_version',
             'oauth_parameter',
             'acg',
             'iam',
             'resource',
             'scope',
-            'enable_sso'
-        ): datasources.get_datasource_connection
+            'enable_sso',
+        ): datasources.get_datasource_connection,
     }
     _API_PATCH: dict = {
         ('abbreviation'): (objects.update_object, 'partial_put'),
         (
             "name",
             "description",
             "execution_mode",
@@ -191,19 +205,19 @@
             "driver_type",
             "database_type",
             "database_version",
             "datasource_login",
             'iam',
             'resource',
             'scope',
-            'enable_sso'
+            'enable_sso',
         ): (
             datasources.update_datasource_connection,
             'patch',
-        )
+        ),
     }
     _PATCH_PATH_TYPES = {
         "name": str,
         "description": str,
         "execution_mode": str,
         "max_cancel_attempt_time": int,
         "max_query_exe_time": int,
@@ -219,31 +233,36 @@
         "driver_type": str,
         "database_type": str,
         "database_version": str,
         "datasource_login": dict,
         "iam": dict,
         "resource": str,
         "scope": str,
-        "enable_sso": bool
+        "enable_sso": bool,
     }
 
     def __init__(
-        self, connection: "Connection", name: Optional[str] = None, id: Optional[str] = None
+        self,
+        connection: "Connection",
+        name: Optional[str] = None,
+        id: Optional[str] = None,
     ) -> None:
         """Initialize DatasourceConnection object and synchronize with server.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             name: exact name of Datasource Connection
             id: ID of Datasource Connection
         """
 
         if id is None and name is None:
-            raise ValueError("Please specify either 'id' or 'name' parameter in the constructor.")
+            raise ValueError(
+                "Please specify either 'id' or 'name' parameter in the constructor."
+            )
 
         if id is None:
             objects_info = DatasourceConnection._list_datasource_connections(
                 connection=connection, name=name, to_dictionary=True
             )
             if objects_info:
                 object_info, object_info["connection"] = objects_info[0], connection
@@ -251,34 +270,46 @@
             else:
                 raise ValueError(f"There is no Datasource Connection: '{name}'")
         else:
             super().__init__(connection=connection, object_id=id)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
-        self.execution_mode = ExecutionMode(kwargs["execution_mode"]
-                                            ) if kwargs.get("execution_mode") else None
+        self.execution_mode = (
+            ExecutionMode(kwargs["execution_mode"])
+            if kwargs.get("execution_mode")
+            else None
+        )
         self.max_cancel_attempt_time = kwargs.get("max_cancel_attempt_time")
         self.max_query_exe_time = kwargs.get("max_query_exe_time")
         self.max_connection_attempt_time = kwargs.get("max_connection_attempt_time")
         self.connection_lifetime = kwargs.get("connection_lifetime")
         self.connection_idle_timeout = kwargs.get("connection_idle_timeout")
-        self.char_encoding_windows = CharEncoding(
-            kwargs["char_encoding_windows"]
-        ) if kwargs.get("char_encoding_windows") else None
-        self.char_encoding_unix = CharEncoding(kwargs["char_encoding_unix"]
-                                               ) if kwargs.get("char_encoding_unix") else None
+        self.char_encoding_windows = (
+            CharEncoding(kwargs["char_encoding_windows"])
+            if kwargs.get("char_encoding_windows")
+            else None
+        )
+        self.char_encoding_unix = (
+            CharEncoding(kwargs["char_encoding_unix"])
+            if kwargs.get("char_encoding_unix")
+            else None
+        )
         self.table_prefix = kwargs.get("table_prefix")
         self.connection_string = kwargs.get("connection_string")
         self.parameterized_queries = kwargs.get("parameterized_queries")
         self.extended_fetch = kwargs.get("extended_fetch")
-        self.driver_type = DriverType(kwargs["driver_type"]) if kwargs.get("driver_type") else None
-        self.datasource_login = DatasourceLogin.from_dict(
-            kwargs.get("datasource_login"), self.connection
-        ) if kwargs.get("datasource_login") else None
+        self.driver_type = (
+            DriverType(kwargs["driver_type"]) if kwargs.get("driver_type") else None
+        )
+        self.datasource_login = (
+            DatasourceLogin.from_dict(kwargs.get("datasource_login"), self.connection)
+            if kwargs.get("datasource_login")
+            else None
+        )
         self.database_type = kwargs.get("database_type")
         self.database_version = kwargs.get("database_version")
         self._oauth_parameter = kwargs.get("oauth_parameter")
         self.iam = kwargs.get("iam")
         self.resource = kwargs.get("resource")
         self.scope = kwargs.get("scope")
         self.enable_sso = kwargs.get("enable_sso")
@@ -302,15 +333,15 @@
         driver_type: Union[str, DriverType] = None,
         database_type: Optional[str] = None,
         database_version: Optional[str] = None,
         datasource_login: Union[str, DatasourceLogin, None] = None,
         iam: Optional[dict] = None,
         resource: Optional[str] = None,
         scope: Optional[str] = None,
-        enable_sso: Optional[bool] = None
+        enable_sso: Optional[bool] = None,
     ) -> None:
         """Alter the datasource connection properties.
 
         Args:
             name: Unique datasource connection name.
             description: Datasource connection description.
             execution_mode: ExecutionMode Enum specifying how SQL statements
@@ -344,21 +375,23 @@
             database_version: Database version
             iam: List of projects to which the fence is applied.
             resource: The url of configured Web API for OAuth authentication
                 usage.
             scope: List of delegated permissions that the app is requesting.
             enable_sso: Specifies whether to use Single Sign-On.
         """
-        datasource_login = {
-            'id': get_objects_id(datasource_login, DatasourceLogin)
-        } if datasource_login else None
+        datasource_login = (
+            {'id': get_objects_id(datasource_login, DatasourceLogin)}
+            if datasource_login
+            else None
+        )
         func = self.alter
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
         self._alter_properties(**properties)
 
@@ -385,15 +418,15 @@
         database_type: Optional[str] = None,
         database_version: Optional[str] = None,
         driver_type: Union[str, DriverType] = None,
         oauth_parameter: Optional[str] = None,
         iam: Optional[dict] = None,
         resource: Optional[str] = None,
         scope: Optional[str] = None,
-        enable_sso: bool = False
+        enable_sso: bool = False,
     ) -> "DatasourceConnection":
         """Create a new datasource connection on the I-Server.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             name: Unique datasource connection name.
@@ -453,30 +486,31 @@
             "charEncodingWindows": get_enum_val(char_encoding_windows, CharEncoding),
             "charEncodingUnix": get_enum_val(char_encoding_unix, CharEncoding),
             "tablePrefix": table_prefix,
             "connectionString": connection_string,
             "parameterizedQueries": parameterized_queries,
             "extendedFetch": extended_fetch,
             "database": {
-                "login": {
-                    "id": login_id
-                }, "type": database_type, "version": database_version
+                "login": {"id": login_id},
+                "type": database_type,
+                "version": database_version,
             },
             "driverType": get_enum_val(driver_type, DriverType),
             "oauthParameter": oauth_parameter,
             "iam": iam,
             "resource": resource,
             "scope": scope,
-            "enable_sso": enable_sso
+            "enable_sso": enable_sso,
         }
         body = helper.delete_none_values(body, recursion=True)
         response = datasources.create_datasource_connection(connection, body).json()
         if config.verbose:
             logger.info(
-                f"Successfully created datasource connection named: '{response.get('name')}' "
+                f"Successfully created datasource connection named: '"
+                f"{response.get('name')}' "
                 f"with ID: '{response.get('id')}'"
             )
         return cls.from_dict(source=response, connection=connection)
 
     @method_version_handler('11.3.0100')
     def test_connection(self) -> bool:
         """Test datasource connection object.
@@ -501,22 +535,22 @@
 
     @classmethod
     def _list_datasource_connections(
         cls,
         connection: "Connection",
         to_dictionary: bool = False,
         limit: Optional[int] = None,
-        **filters
+        **filters,
     ) -> Union[List["DatasourceConnection"], List[dict]]:
         objects = helper.fetch_objects(
             connection=connection,
             api=datasources.get_datasource_connections,
             dict_unpack_value="connections",
             limit=limit,
-            filters=filters
+            filters=filters,
         )
         if to_dictionary:
             return objects
         else:
             return [cls.from_dict(source=obj, connection=connection) for obj in objects]
 
     @property
```

### Comparing `mstrio-py-11.3.9.101/mstrio/datasources/datasource_instance.py` & `mstrio-py-11.3.9.103/mstrio/datasources/datasource_instance.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,37 +1,42 @@
-from enum import auto
 import logging
-from typing import Optional, TYPE_CHECKING
+from enum import auto
+from typing import TYPE_CHECKING, Optional
 
 from mstrio import config
 from mstrio.api import datasources, objects
 from mstrio.datasources import DatasourceConnection, Dbms, list_datasource_connections
 from mstrio.server.project import Project
 from mstrio.users_and_groups.user import User
 from mstrio.utils import helper
 from mstrio.utils.entity import CopyMixin, DeleteMixin, Entity, ObjectTypes
 from mstrio.utils.enum_helper import AutoName, get_enum_val
-from mstrio.utils.helper import get_args_from_func, get_default_args_from_func, get_objects_id
+from mstrio.utils.helper import (
+    get_args_from_func,
+    get_default_args_from_func,
+    get_objects_id,
+)
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
+from mstrio.utils.vldb_mixin import ModelVldbMixin
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
 logger = logging.getLogger(__name__)
 
 
 @method_version_handler('11.3.0000')
 def list_datasource_instances(
     connection: "Connection",
     to_dictionary: bool = False,
     limit: Optional[int] = None,
     ids: Optional[list[str]] = None,
     database_types: Optional[list[str]] = None,
-    project: Optional[Project | str] = None,
-    **filters
+    project: Optional['Project | str'] = None,
+    **filters,
 ) -> list["DatasourceInstance"] | list[dict]:
     """Get list of DatasourceInstance objects or dicts. Optionally filter the
     datasource instances by specifying filters.
 
     Args:
         connection: MicroStrategy connection object returned by
             `connection.Connection()`
@@ -62,17 +67,19 @@
             'splunk', 'sql_server', 'square', 'sybase', 'sybase_iq',
             'sybase_sql_any', 'tandem', 'teradata', 'tm1', 'twitter', 'unknown',
             'url_auth', 'vectorwise', 'vertica', 'xquery']
         project: id (str) of a project or instance of an Project class
             to search for the datasource instances in. When provided, both
             `ids` and `database_types` are ignored. By default `None`.
         **filters: Available filter parameters: ['id', 'name', 'description',
-            'date_created', 'date_modified', 'datasource_type', table_prefix,
-            'odbc_version', 'intermediate_store_db_name',
-            'intermediate_store_table_space_name', 'dbms', 'owner', 'acg']
+            'date_created', 'date_modified', 'acg', 'datasource_type',
+            'table_prefix', 'odbc_version', 'intermediate_store_db_name',
+            'intermediate_store_table_space_name', 'dbms', 'owner', 'hidden',
+            'datasource_connection', 'database_type', 'database_version',
+            'primary_datasource', 'data_mart_datasource']
 
     Examples:
         >>> list_datasource_instances(connection, name='ds_instance_name')
     """
     return DatasourceInstance._list_datasource_instances(
         connection=connection,
         ids=ids,
@@ -93,25 +100,27 @@
     Args:
         connection (Connection): MicroStrategy connection object returned by
             `connection.Connection()`
         to_dictionary (bool, optional): If True returns a list of dictionaries
             representing datasource instances
 
     Returns:
-        Union[list["DatasourceInstance"], list[dict]]: A list of connected
+        list["DatasourceInstance"] | list[dict]: A list of connected
             datasource instances.
     """
     all_datasource_instances = list_datasource_instances(connection, to_dictionary=True)
     datasource_connections_ids = [
         ds_connection.get('id')
         for ds_connection in list_datasource_connections(connection, to_dictionary=True)
     ]
     connected_datasource_instances = [
-        ds_instance for ds_instance in all_datasource_instances
-        if ds_instance.get('datasource_connection').get('id') in datasource_connections_ids
+        ds_instance
+        for ds_instance in all_datasource_instances
+        if ds_instance.get('datasource_connection').get('id')
+        in datasource_connections_ids
         # remove xquery datasources because they are not available
         # in Workstation and listing namespaces for them can cause
         # IServer to become unresponsive.
         and ds_instance.get('database_type') != 'xquery'
     ]
 
     if to_dictionary:
@@ -126,15 +135,15 @@
     RESERVED = auto()
     NORMAL = auto()
     DATA_IMPORT = auto()
     DATA_IMPORT_PRIMARY = auto()
 
 
 @class_version_handler('11.3.0000')
-class DatasourceInstance(Entity, CopyMixin, DeleteMixin):
+class DatasourceInstance(Entity, CopyMixin, DeleteMixin, ModelVldbMixin):
     """Object representation of MicroStrategy DataSource Instance object.
 
     Attributes:
         connection: A MicroStrategy connection object
         id: Datasource Instance ID
         name: Datasource Instance name
         description: Datasource Instance description
@@ -158,29 +167,29 @@
 
     _OBJECT_TYPE = ObjectTypes.DBROLE
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'dbms': Dbms.from_dict,
         'owner': User.from_dict,
         'datasource_type': DatasourceType,
-        'datasource_connection': DatasourceConnection.from_dict
+        'datasource_connection': DatasourceConnection.from_dict,
     }
     _API_GETTERS = {
         (
             'abbreviation',
             'type',
             'subtype',
             'ext_type',
             'version',
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
-            'acl'
+            'acl',
         ): objects.get_object_info,
         (
             'id',
             'name',
             'description',
             'date_created',
             'date_modified',
@@ -191,52 +200,60 @@
             'datasource_connection',
             'database_type',
             'database_version',
             'primary_datasource',
             'data_mart_datasource',
             'intermediate_store_table_space_name',
             'dbms',
-            'acg'
-        ): datasources.get_datasource_instance
+            'acg',
+        ): datasources.get_datasource_instance,
     }
     _API_PATCH: dict = {
         ('abbreviation'): (objects.update_object, 'partial_put'),
         (
             "name",
             "description",
             "datasource_type",
             "table_prefix",
             "intermediate_store_db_name",
             "intermediate_store_table_space_name",
             "odbc_version",
             "datasource_connection",
             "primary_datasource",
             "data_mart_datasource",
-            "dbms"
+            "dbms",
         ): (
             datasources.update_datasource_instance,
             'patch',
-        )
+        ),
     }
     _PATCH_PATH_TYPES = {
         "name": str,
         "description": str,
         "datasource_type": str,
         "table_prefix": str,
         "intermediate_store_db_name": str,
         "intermediate_store_table_space_name": str,
         "odbc_version": str,
         "datasource_connection": dict,
         "primary_datasource": dict,
         "data_mart_datasource": dict,
         "dbms": dict,
     }
+    _MODEL_VLDB_API = {
+        'GET_ADVANCED': datasources.get_vldb_settings,
+        'PUT_ADVANCED': datasources.update_vldb_settings,
+        'GET_APPLICABLE': datasources.get_applicable_vldb_settings,
+    }
 
     def __init__(
-        self, connection: "Connection", name: Optional[str] = None, id: Optional[str] = None
+        self,
+        connection: "Connection",
+        name: Optional[str] = None,
+        id: Optional[str] = None,
     ) -> None:
         """Initialize DatasourceInstance object by passing name or id.
 
         To explore all available DatasourceInstance objects use the
         `list_datasource_instance()` method.
 
         Args:
@@ -255,42 +272,61 @@
                 connection=connection, name=name, to_dictionary=True
             )
             if objects_info:
                 object_info, object_info["connection"] = objects_info[0], connection
                 self._init_variables(**object_info)
             else:
                 helper.exception_handler(
-                    f"There is no Datasource Instance: '{name}'", exception_type=ValueError
+                    f"There is no Datasource Instance: '{name}'",
+                    exception_type=ValueError,
                 )
         else:
             super().__init__(connection=connection, object_id=id)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
-        self.datasource_type = DatasourceType(kwargs["datasource_type"]
-                                              ) if kwargs.get("datasource_type") else None
+        self.datasource_type = (
+            DatasourceType(kwargs["datasource_type"])
+            if kwargs.get("datasource_type")
+            else None
+        )
         self.table_prefix = kwargs.get("table_prefix")
         self.intermediate_store_db_name = kwargs.get("intermediate_store_db_name")
         self.intermediate_store_table_space_name = kwargs.get(
             "intermediate_store_table_space_name"
         )
         self.odbc_version = kwargs.get("odbc_version")
-        self.datasource_connection = DatasourceConnection.from_dict(
-            kwargs.get("datasource_connection"), self.connection
-        ) if kwargs.get("datasource_connection") else None
+        self.datasource_connection = (
+            DatasourceConnection.from_dict(
+                kwargs.get("datasource_connection"), self.connection
+            )
+            if kwargs.get("datasource_connection")
+            else None
+        )
         self.database_type = kwargs.get("database_type")
         self.database_version = kwargs.get("database_version")
-        self.primary_datasource = DatasourceInstance.from_dict(
-            kwargs.get("primary_datasource"), self.connection
-        ) if kwargs.get("primary_datasource") else None
-        self.data_mart_datasource = DatasourceInstance.from_dict(
-            kwargs.get("data_mart_datasource"), self.connection
-        ) if kwargs.get("data_mart_datasource") else None
-        self.dbms = Dbms.from_dict(kwargs.get("dbms"), self.connection)\
-            if kwargs.get("dbms") else None
+        self.primary_datasource = (
+            DatasourceInstance.from_dict(
+                kwargs.get("primary_datasource"), self.connection
+            )
+            if kwargs.get("primary_datasource")
+            else None
+        )
+        self.data_mart_datasource = (
+            DatasourceInstance.from_dict(
+                kwargs.get("data_mart_datasource"), self.connection
+            )
+            if kwargs.get("data_mart_datasource")
+            else None
+        )
+        self.dbms = (
+            Dbms.from_dict(kwargs.get("dbms"), self.connection)
+            if kwargs.get("dbms")
+            else None
+        )
 
     @classmethod
     def create(
         cls,
         connection: "Connection",
         name: str,
         dbms: Dbms | str,
@@ -300,15 +336,15 @@
         odbc_version: Optional[str] = None,
         intermediate_store_db_name: Optional[str] = None,
         intermediate_store_table_space_name: Optional[str] = None,
         datasource_connection: Optional[str | DatasourceConnection] = None,
         database_type: str = None,
         database_version: str = None,
         primary_datasource: Optional["str | DatasourceInstance"] = None,
-        data_mart_datasource: Optional["str | DatasourceInstance"] = None
+        data_mart_datasource: Optional["str | DatasourceInstance"] = None,
     ) -> Optional["DatasourceInstance"]:
         """Create a new DatasourceInstance object on I-Server.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             name: Datasource name
@@ -333,17 +369,15 @@
         dbms_id = get_objects_id(dbms, Dbms)
         connection_id = get_objects_id(datasource_connection, DatasourceConnection)
         primary_datasource_id = get_objects_id(primary_datasource, cls)
         data_mart_datasource_id = get_objects_id(data_mart_datasource, cls)
         database = {
             "type": database_type,
             "version": database_version,
-            "connection": {
-                "id": connection_id
-            }
+            "connection": {"id": connection_id},
         }
         if primary_datasource_id:
             database["primaryDatasource"] = {"id": primary_datasource_id}
         if data_mart_datasource_id:
             database["dataMartDatasource"] = {"id": data_mart_datasource_id}
 
         body = {
@@ -351,24 +385,22 @@
             "database": database,
             "description": description,
             "datasourceType": get_enum_val(datasource_type, DatasourceType),
             "tablePrefix": table_prefix,
             "odbcVersion": odbc_version,
             "intermediateStoreDbName": intermediate_store_db_name,
             "intermediateStoreTableSpaceName": intermediate_store_table_space_name,
-            "dbms": {
-                "id": dbms_id
-            }
+            "dbms": {"id": dbms_id},
         }
         body = helper.delete_none_values(body, recursion=True)
         response = datasources.create_datasource_instance(connection, body).json()
         if config.verbose:
             logger.info(
-                f"Successfully created datasource instance named: '{response.get('name')}' "
-                f"with ID: '{response.get('id')}'"
+                f"Successfully created datasource instance named: "
+                f"'{response.get('name')}' with ID: '{response.get('id')}'"
             )
         return cls.from_dict(source=response, connection=connection)
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
@@ -376,15 +408,15 @@
         table_prefix: Optional[str] = None,
         odbc_version: Optional[str] = None,
         intermediate_store_db_name: Optional[str] = None,
         intermediate_store_table_space_name: Optional[str] = None,
         dbms: Optional[str | Dbms] = None,
         datasource_connection: Optional[str | DatasourceConnection] = None,
         primary_datasource: Optional["str | DatasourceInstance"] = None,
-        data_mart_datasource: Optional["str | DatasourceInstance"] = None
+        data_mart_datasource: Optional["str | DatasourceInstance"] = None,
     ) -> None:
         """Alter DatasourceInstance properties.
 
         Args:
             name: Datasource name
             description: Datasource description
             datasource_type: DatasourceType Enum (reserved, normal, data_import,
@@ -397,27 +429,33 @@
             dbms: The database management system (DBMS) object or ID
             datasource_connection: `DatasourceConnection` object or ID
             primary_datasource: `DatasourceInstance` object or ID
             data_mart_datasource: `DatasourceInstance` object or ID
 
         """
         dbms = {'id': get_objects_id(dbms, Dbms)} if dbms else None
-        datasource_connection = {
-            'id': get_objects_id(datasource_connection, DatasourceConnection)
-        } if datasource_connection else None
-        primary_datasource = {
-            'id': get_objects_id(primary_datasource, self)
-        } if primary_datasource else None
-        data_mart_datasource = {
-            'id': get_objects_id(data_mart_datasource, self)
-        } if data_mart_datasource else None
+        datasource_connection = (
+            {'id': get_objects_id(datasource_connection, DatasourceConnection)}
+            if datasource_connection
+            else None
+        )
+        primary_datasource = (
+            {'id': get_objects_id(primary_datasource, self)}
+            if primary_datasource
+            else None
+        )
+        data_mart_datasource = (
+            {'id': get_objects_id(data_mart_datasource, self)}
+            if data_mart_datasource
+            else None
+        )
         func = self.alter
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
         self._alter_properties(**properties)
 
@@ -426,26 +464,26 @@
         cls,
         connection: "Connection",
         to_dictionary: Optional[bool] = False,
         limit: Optional[int] = None,
         ids: Optional[list] = None,
         database_types: Optional[list] = None,
         project: Optional[Project | str] = None,
-        **filters
+        **filters,
     ) -> list["DatasourceInstance"] | list[dict]:
         project_id = project.id if isinstance(project, Project) else project
         objects = helper.fetch_objects(
             connection=connection,
             api=datasources.get_datasource_instances,
             dict_unpack_value="datasources",
             limit=limit,
             filters=filters,
             ids=ids,
             database_types=database_types,
-            project=project_id
+            project=project_id,
         )
         if project_id:
             for obj in objects:
                 obj['project_id'] = project_id
 
         if to_dictionary:
             return objects
@@ -457,29 +495,31 @@
         if kwargs.get("primary_datasource"):
             setattr(
                 self,
                 'primary_datasource',
                 DatasourceInstance(
                     id=kwargs.get("primary_datasource").get("id"),
                     name=kwargs.get("primary_datasource").get("name"),
-                    connection=self.connection
-                )
+                    connection=self.connection,
+                ),
             )
         if kwargs.get("data_mart_datasource"):
             setattr(
                 self,
                 'data_mart_datasource',
                 DatasourceInstance(
                     id=kwargs.get("data_mart_datasource").get("id"),
                     name=kwargs.get("data_mart_datasource").get("name"),
-                    connection=self.connection
-                )
+                    connection=self.connection,
+                ),
             )
 
     @method_version_handler('11.3.0900')
     def convert_ds_connection_to_dsn_less(self):
         """Convert datasource embedded connection from DSN to DSN-less format
         connection string and update the object to metadata.
         """
-        response = datasources.convert_ds_dsn(connection=self.connection, datasource_id=self.id)
+        response = datasources.convert_ds_dsn(
+            connection=self.connection, datasource_id=self.id
+        )
         if response.ok:
             self.fetch()
```

### Comparing `mstrio-py-11.3.9.101/mstrio/datasources/datasource_login.py` & `mstrio-py-11.3.9.103/mstrio/datasources/datasource_login.py`

 * *Files 9% similar despite different names*

```diff
@@ -26,15 +26,15 @@
         connection: MicroStrategy connection object returned by
             `connection.Connection()`
         to_dictionary: If True returns dict, by default (False) returns
             User objects.
         limit: limit the number of elements returned. If `None` (default), all
             objects are returned.
         **filters: Available filter parameters: ['id', 'name', 'description',
-            'date_created', 'date_modified', 'acg']
+            'date_created', 'date_modified', 'acg', 'username']
 
     Examples:
         >>> list_db_logins(connection, name='db_login_name')
     """
     return DatasourceLogin._list_datasource_logins(
         connection=connection,
         to_dictionary=to_dictionary,
@@ -75,31 +75,47 @@
             'ext_type',
             'version',
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
-            'acl'
+            'acl',
         ): objects.get_object_info,
-        ('id', 'name', 'description', 'username', 'date_created', 'date_modified',
-         'acg'): datasources.get_datasource_login
+        (
+            'id',
+            'name',
+            'description',
+            'username',
+            'date_created',
+            'date_modified',
+            'acg',
+        ): datasources.get_datasource_login,
     }
     _API_PATCH: dict = {
         ("abbreviation"): (objects.update_object, "partial_put"),
-        ("name", "username", "description",
-         "password"): (datasources.update_datasource_login, "patch")
+        ("name", "username", "description", "password"): (
+            datasources.update_datasource_login,
+            "patch",
+        ),
+    }
+    _PATCH_PATH_TYPES = {
+        "name": str,
+        "username": str,
+        "description": str,
+        "password": str,
     }
-    _PATCH_PATH_TYPES = {"name": str, "username": str, "description": str, "password": str}
 
     def __init__(self, connection: "Connection", name: str = None, id: str = None):
         """Initialize DatasourceLogin object."""
 
         if id is None and name is None:
-            raise ValueError("Please specify either 'id' or 'name' parameter in the constructor.")
+            raise ValueError(
+                "Please specify either 'id' or 'name' parameter in the constructor."
+            )
 
         if id is None:
             objects_info = DatasourceLogin._list_datasource_logins(
                 connection=connection, name=name, to_dictionary=True
             )
             if objects_info:
                 object_info, object_info["connection"] = objects_info[0], connection
@@ -114,76 +130,84 @@
         self.username = kwargs.get("username")
 
     def alter(
         self,
         name: str = None,
         username: str = None,
         description: str = None,
-        password: str = None
+        password: str = None,
     ) -> None:
         """Alter the datasource login properties.
 
         Args:
             name: login object name
             username: username
             description: login object description
             password: database password to be used by the database login
         """
         func = self.alter
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
         self._alter_properties(**properties)
 
     @classmethod
     def create(
         cls,
         connection: "Connection",
         name: str,
         username: str,
         password: str,
-        description: str = None
+        description: str = None,
     ) -> "DatasourceLogin":
         """Create a new datasource login.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`
             name: login object name
             username: username
             description: login object description
             password: database password to be used by the database login
         Returns:
             DatasourceConnection object.
         """
         body = {
-            "name": name, "description": description, "username": username, "password": password
+            "name": name,
+            "description": description,
+            "username": username,
+            "password": password,
         }
         body = helper.delete_none_values(body, recursion=True)
         response = datasources.create_datasource_login(connection, body).json()
         if config.verbose:
             logger.info(
-                f"Successfully created datasource login named: '{response.get('name')}' "
+                f"Successfully created datasource login named: '"
+                f"{response.get('name')}' "
                 f"with ID: '{response.get('id')}'"
             )
         return cls.from_dict(source=response, connection=connection)
 
     @classmethod
     def _list_datasource_logins(
-        cls, connection: "Connection", to_dictionary: bool = False, limit: int = None, **filters
+        cls,
+        connection: "Connection",
+        to_dictionary: bool = False,
+        limit: int = None,
+        **filters,
     ) -> Union[List["DatasourceLogin"], List[dict]]:
         objects = helper.fetch_objects(
             connection=connection,
             api=datasources.get_datasource_logins,
             dict_unpack_value="logins",
             limit=limit,
-            filters=filters
+            filters=filters,
         )
         if to_dictionary:
             return objects
         else:
             return [cls.from_dict(source=obj, connection=connection) for obj in objects]
```

### Comparing `mstrio-py-11.3.9.101/mstrio/datasources/datasource_map.py` & `mstrio-py-11.3.9.103/mstrio/datasources/datasource_map.py`

 * *Files 1% similar despite different names*

```diff
@@ -84,15 +84,16 @@
                 by `connection.Connection()`.
             id: Locale's ID
             name: Locale's name
             abbreviation: Locale's abbreviation
         """
         if not (id or name or abbreviation):
             raise ValueError(
-                "Please specify 'id' or 'name' or 'abbreviation' parameter in the constructor."
+                "Please specify 'id' or 'name' or 'abbreviation' parameter in the "
+                "constructor."
             )
         elif not (locale_id := id):
             if name:
                 locale_id = self._get_by_name(name, connection).id
             elif abbreviation:
                 locale_id = self._get_by_abbreviation(abbreviation, connection).id
 
@@ -163,15 +164,16 @@
         except LookupError:
             raise ValueError(
                 f"Locale with abbreviation: {abbreviation} does not exists."
             )
 
     def __repr__(self):
         return (
-            f"Locale(connection, name='{self.name}', abbreviation='{self.abbreviation}',"
+            f"Locale(connection, name='{self.name}', abbreviation='"
+            f"{self.abbreviation}',"
             f" id='{self.id}')"
         )
 
     def to_dict(self, camel_case: bool = True) -> dict:
         return {'id': self.id, 'name': self.name}
 
 
@@ -351,15 +353,16 @@
                 raise ValueError(
                     f"The project: {project_id} has no default datasource mapping."
                 )
             elif len(mappings) > 1:
                 project_id = get_objects_id(project, Project)
 
                 raise ValueError(
-                    f"The project: {project_id} has more than one default connection mapping."
+                    f"The project: {project_id} has more than one default connection "
+                    f"mapping."
                 )
             else:
                 data = mappings[0]
                 data.update({'ds_connection': data.pop('connection')})
                 self._init_variables(connection=connection, **mappings[0])
 
         else:
@@ -411,15 +414,14 @@
         user: Optional[User | UserGroup | str] = None,
         ds_connection: Optional[DatasourceConnection | str] = None,
         datasource: Optional[DatasourceInstance | str] = None,
         login: Optional[DatasourceLogin | str] = None,
         locale: Optional[Locale | str] = None,
         default_connection_map: bool = False,
     ) -> list['DatasourceMap'] | list[dict]:
-
         project_id = get_objects_id(project, Project)
 
         if isinstance(locale, Locale):
             locale = locale.to_dict()
         elif isinstance(locale, str):
             locale = Locale._get(locale).to_dict()
 
@@ -572,15 +574,16 @@
             and ds_connection is None
             and datasource is None
             and login is None
             and locale is None
         ):
             if config.verbose:
                 logger.info(
-                    f"No changes specified for {type(self).__name__} with ID:'{self.id}'."
+                    f"No changes specified for {type(self).__name__} with ID:'"
+                    f"{self.id}'."
                 )
             return
 
         self.delete(force=True)
 
         new_conn_map = self.create(
             connection=self.connection,
```

### Comparing `mstrio-py-11.3.9.101/mstrio/datasources/dbms.py` & `mstrio-py-11.3.9.103/mstrio/datasources/dbms.py`

 * *Files 9% similar despite different names*

```diff
@@ -54,66 +54,76 @@
 
     def __init__(
         self,
         connection: "Connection",
         name: str = None,
         id: str = None,
         type: str = None,
-        version: str = None
+        version: str = None,
     ):
         """Initialize Dbms object."""
         if name is None and id is None:
             helper.exception_handler(
                 "Please specify either 'name' or 'id' parameter in the constructor.",
-                exception_type=ValueError
+                exception_type=ValueError,
             )
         temp_dbms = None
 
         for dbms in self._DBMS_CACHE:
             if name == dbms.name or id == dbms.id:
                 temp_dbms = dbms
                 super().__init__(
                     connection=connection,
                     object_id=temp_dbms.id,
                     name=temp_dbms.name,
                     type=temp_dbms.type,
-                    version=temp_dbms.version
+                    version=temp_dbms.version,
                 )
 
         if not temp_dbms:
             if id:
-                temp_dbms = Dbms._list_available_dbms(connection, id=id, to_dictionary=True)
+                temp_dbms = Dbms._list_available_dbms(
+                    connection, id=id, to_dictionary=True
+                )
             elif name:
-                temp_dbms = Dbms._list_available_dbms(connection, name=name, to_dictionary=True)
+                temp_dbms = Dbms._list_available_dbms(
+                    connection, name=name, to_dictionary=True
+                )
 
             if temp_dbms:
                 [temp_dbms] = temp_dbms
                 super().__init__(
                     connection=connection,
                     object_id=temp_dbms["id"],
                     name=temp_dbms["name"],
                     type=temp_dbms["type"],
-                    version=temp_dbms["version"]
+                    version=temp_dbms["version"],
                 )
             else:
                 identifier = name if name else id
                 raise ValueError(f"There is no Dbms: '{identifier}'")
 
     def _init_variables(self, **kwargs) -> None:
         """Set object attributes by providing keyword args."""
         super()._init_variables(**kwargs)
         self._version = kwargs.get("version")
 
     @classmethod
     def _list_available_dbms(
-        cls, connection: "Connection", to_dictionary: bool = False, limit: int = None, **filters
+        cls,
+        connection: "Connection",
+        to_dictionary: bool = False,
+        limit: int = None,
+        **filters,
     ) -> Union[List["Dbms"], List[dict]]:
-
         objects = helper.fetch_objects(
-            connection=connection, api=datasources.get_available_dbms, limit=None, filters=None
+            connection=connection,
+            api=datasources.get_available_dbms,
+            limit=None,
+            filters=None,
         )
         cls._DBMS_CACHE.update(
             [cls.from_dict(source=obj, connection=connection) for obj in objects]
         )
 
         if limit:
             objects = objects[:limit]
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/device/device.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/device/device.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,28 +7,28 @@
 from mstrio.api import devices, objects
 from mstrio.distribution_services.device.device_properties import (
     AndroidDeviceProperties,
     EmailDeviceProperties,
     FileDeviceProperties,
     FtpDeviceProperties,
     IOSDeviceProperties,
-    PrinterDeviceProperties
+    PrinterDeviceProperties,
 )
 from mstrio.distribution_services.transmitter import Transmitter
 from mstrio.types import ObjectTypes
 from mstrio.users_and_groups import User
 from mstrio.utils.entity import DeleteMixin, Entity
 from mstrio.utils.enum_helper import AutoName, get_enum_val
 from mstrio.utils.helper import (
     delete_none_values,
     Dictable,
     fetch_objects,
     get_args_from_func,
     get_default_args_from_func,
-    get_objects_id
+    get_objects_id,
 )
 from mstrio.utils.version_helper import class_version_handler
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
 logger = logging.getLogger(__name__)
@@ -56,15 +56,16 @@
         connection: MicroStrategy connection object returned by
             `connection.Connection()`
         to_dictionary: If True returns dict, by default (False) returns
             Device objects.
         limit: limit the number of elements returned. If `None` (default), all
             objects are returned.
         **filters: Available filter parameters: ['id', 'name', 'description',
-            'date_created', 'date_modified', 'acg']
+            'date_created', 'date_modified', 'device_type', 'transmitter',
+            'device_properties']
 
     Examples:
         >>> list_devices(connection, name='device_name')
     """
     return Device._list_devices(
         connection=connection,
         to_dictionary=to_dictionary,
@@ -104,25 +105,32 @@
     _DEVICE_TYPE_MAP = {
         "android": AndroidDeviceProperties,
         "email": EmailDeviceProperties,
         "file": FileDeviceProperties,
         "ftp": FtpDeviceProperties,
         "ipad": IOSDeviceProperties,
         "iphone": IOSDeviceProperties,
-        "printer": PrinterDeviceProperties
+        "printer": PrinterDeviceProperties,
     }
+
+    @staticmethod
+    def _map_device_properties(source, connection):
+        device_type = next(iter(source))
+        device_properties = source[device_type]
+
+        return Device._DEVICE_TYPE_MAP[device_type].from_dict(
+            device_properties, connection
+        )
+
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'device_type': DeviceType,
         'owner': User.from_dict,
         'transmitter': Transmitter.from_dict,
-        'device_properties': lambda source,
-        connection,
-        device_type_map=_DEVICE_TYPE_MAP: device_type_map[next(iter(source))].
-        from_dict(source[next(iter(source))], connection)
+        'device_properties': _map_device_properties,
     }
     _API_GETTERS = {
         (
             'abbreviation',
             'type',
             'subtype',
             'ext_type',
@@ -131,30 +139,38 @@
             'version',
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
             'acg',
-            'acl'
+            'acl',
         ): objects.get_object_info,
-        ('id', 'name', 'description', 'device_type', 'transmitter',
-         'device_properties'): devices.get_device
+        (
+            'id',
+            'name',
+            'description',
+            'device_type',
+            'transmitter',
+            'device_properties',
+        ): devices.get_device,
     }
     _API_DELETE = staticmethod(devices.delete_device)
     _API_PATCH: dict = {
         ("name", "description", "device_properties"): (devices.update_device, "put")
     }
     _PATCH_PATH_TYPES = {"name": str, "description": str, "device_properties": dict}
 
     def __init__(self, connection: "Connection", name: str = None, id: str = None):
         """Initialize Device object."""
 
         if id is None and name is None:
-            raise ValueError("Please specify either 'id' or 'name' parameter in the constructor.")
+            raise ValueError(
+                "Please specify either 'id' or 'name' parameter in the constructor."
+            )
 
         if id is None:
             objects_info = Device._list_devices(
                 connection=connection,
                 name=name,
                 to_dictionary=True,
             )
@@ -166,31 +182,38 @@
         else:
             super().__init__(connection=connection, object_id=id)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         device_type = kwargs.get("device_type")
         self._device_type = DeviceType(device_type) if device_type else None
-        self._transmitter = Transmitter.from_dict(kwargs.get("transmitter"), self.connection
-                                                  ) if kwargs.get("transmitter") else None
+        self._transmitter = (
+            Transmitter.from_dict(kwargs.get("transmitter"), self.connection)
+            if kwargs.get("transmitter")
+            else None
+        )
         device_properties = kwargs.get("device_properties")
-        self.device_properties = self._DEVICE_TYPE_MAP[device_type].from_dict(
-            device_properties[device_type],
-            self.connection,
-        ) if device_properties and device_type else None
+        self.device_properties = (
+            self._DEVICE_TYPE_MAP[device_type].from_dict(
+                device_properties[device_type],
+                self.connection,
+            )
+            if device_properties and device_type
+            else None
+        )
 
     @classmethod
     def create(
         cls,
         connection: "Connection",
         name: str,
         device_type: Union[DeviceType, str],
         transmitter: Union[Transmitter, str],
         device_properties: Union[dict, Dictable],
-        description: str = None
+        description: str = None,
     ) -> "Device":
         """Create a new device.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`
             name: device object name
@@ -198,57 +221,64 @@
             transmitter: Transmitter object
             description: device object description
             device_properties: properties of the device
         Returns:
             Device object.
         """
         device_type = get_enum_val(device_type, DeviceType)
-        device_properties = device_properties.to_dict(
-        ) if isinstance(device_properties, Dictable) else device_properties
+        device_properties = (
+            device_properties.to_dict()
+            if isinstance(device_properties, Dictable)
+            else device_properties
+        )
         transmitter_id = get_objects_id(transmitter, Transmitter)
         body = {
             "name": name,
             "description": description,
             "deviceType": device_type,
             "transmitter": {
                 "id": transmitter_id,
             },
-            "deviceProperties": {
-                device_type: device_properties
-            }
+            "deviceProperties": {device_type: device_properties},
         }
         body = delete_none_values(body, recursion=True)
         response = devices.create_device(connection, body).json()
         if config.verbose:
             logger.info(
-                f"Successfully created device named: '{name}' with ID: '{response['id']}'."
+                f"Successfully created device named: '{name}' with ID: '"
+                f"{response['id']}'."
             )
         return cls.from_dict(source=response, connection=connection)
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
-        device_properties: Optional[Union[Dictable, dict]] = None
+        device_properties: Optional[Union[Dictable, dict]] = None,
     ):
         """Alter the device object properties.
 
         Args:
             name: device object name
             description: device object description
             device_properties: properties of the device, specific for each
                 device type
         """
-        device_properties = self.device_properties if not device_properties else device_properties
-        device_properties = device_properties.to_dict(
-        ) if isinstance(device_properties, Dictable) else device_properties
+        device_properties = (
+            self.device_properties if not device_properties else device_properties
+        )
+        device_properties = (
+            device_properties.to_dict()
+            if isinstance(device_properties, Dictable)
+            else device_properties
+        )
         func = self.alter
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        defaults_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        defaults_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = defaultdict(dict)
         for property_key in defaults_dict.keys():
             if property_key == 'device_properties':
                 properties[property_key][self.device_type.value] = device_properties
             elif local[property_key] is not None:
                 properties[property_key] = local[property_key]
@@ -264,22 +294,29 @@
         changes = {k: v[1] for k, v in self._altered_properties.items()}
         if "device_properties" in changes:
             device_properties = changes["device_properties"]
             del changes["device_properties"]
         else:
             device_properties = self.device_properties
         changes["device_properties"] = {}
-        changes["device_properties"][self.device_type.value] = device_properties.to_dict(
-        ) if not isinstance(device_properties, dict) else device_properties
+        changes["device_properties"][self.device_type.value] = (
+            device_properties.to_dict()
+            if not isinstance(device_properties, dict)
+            else device_properties
+        )
         self._alter_properties(**changes)
         self._altered_properties.clear()
 
     @classmethod
     def _list_devices(
-        cls, connection: "Connection", to_dictionary: bool = False, limit: int = None, **filters
+        cls,
+        connection: "Connection",
+        to_dictionary: bool = False,
+        limit: int = None,
+        **filters,
     ) -> Union[List["Device"], List[dict]]:
         objects = fetch_objects(
             connection=connection,
             api=devices.get_devices,
             dict_unpack_value="devices",
             limit=limit,
             filters=filters,
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/device/device_properties.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/device/device_properties.py`

 * *Files 4% similar despite different names*

```diff
@@ -96,15 +96,15 @@
     """
 
     def __init__(
         self,
         create_folder: bool = True,
         filename_append_time_stamp: bool = True,
         override_filename: bool = False,
-        append_to_file: bool = False
+        append_to_file: bool = False,
     ):
         self.create_folder = create_folder
         self.filename_append_time_stamp = filename_append_time_stamp
         self.override_filename = override_filename
         self.append_to_file = append_to_file
 
 
@@ -117,15 +117,15 @@
         delivery_timeout_seconds: Delivery Timeout (Seconds), default: 10
     """
 
     def __init__(
         self,
         retries_count: int = 5,
         seconds_between_retries: int = 3,
-        delivery_timeout_seconds: int = 10
+        delivery_timeout_seconds: int = 10,
     ):
         self.retries_count = retries_count
         self.seconds_between_retries = seconds_between_retries
         self.delivery_timeout_seconds = delivery_timeout_seconds
 
 
 class EmailMimeSettings(Dictable):
@@ -156,43 +156,51 @@
         css_inline_style: Whether to use inline style CSS, default: False
     """
 
     _FROM_DICT_MAP = {
         "plain_text_html_body_encoding": EmailEncoding,
         "text_attachment_encoding": EmailEncoding,
         "binary_attachment_encoding": EmailEncoding,
-        "message_sensitivity": EmailMessageSensitivity
+        "message_sensitivity": EmailMessageSensitivity,
     }
 
     def __init__(
         self,
         plain_text_html_body_encoding: Union[EmailEncoding, str],
         text_attachment_encoding: Union[EmailEncoding, str],
         binary_attachment_encoding: Union[EmailEncoding, str],
         message_sensitivity: Union[EmailMessageSensitivity, str],
         us_ascii_encoding: bool = False,
         non_us_ascii_quotes: bool = False,
         embed_html_attachments: bool = False,
         embed_all_attachments: bool = False,
         embed_adobe_flash_content: bool = False,
         html_table_position_only: bool = False,
-        css_inline_style: bool = False
+        css_inline_style: bool = False,
     ):
-        self.plain_text_html_body_encoding = EmailEncoding(
-            plain_text_html_body_encoding
-        ) if isinstance(plain_text_html_body_encoding, str) else plain_text_html_body_encoding
-        self.text_attachment_encoding = EmailEncoding(text_attachment_encoding) if isinstance(
-            text_attachment_encoding, str
-        ) else text_attachment_encoding
-        self.binary_attachment_encoding = EmailEncoding(binary_attachment_encoding) if isinstance(
-            binary_attachment_encoding, str
-        ) else binary_attachment_encoding
-        self.message_sensitivity = EmailMessageSensitivity(message_sensitivity) if isinstance(
-            message_sensitivity, str
-        ) else message_sensitivity
+        self.plain_text_html_body_encoding = (
+            EmailEncoding(plain_text_html_body_encoding)
+            if isinstance(plain_text_html_body_encoding, str)
+            else plain_text_html_body_encoding
+        )
+        self.text_attachment_encoding = (
+            EmailEncoding(text_attachment_encoding)
+            if isinstance(text_attachment_encoding, str)
+            else text_attachment_encoding
+        )
+        self.binary_attachment_encoding = (
+            EmailEncoding(binary_attachment_encoding)
+            if isinstance(binary_attachment_encoding, str)
+            else binary_attachment_encoding
+        )
+        self.message_sensitivity = (
+            EmailMessageSensitivity(message_sensitivity)
+            if isinstance(message_sensitivity, str)
+            else message_sensitivity
+        )
         self.us_ascii_encoding = us_ascii_encoding
         self.non_us_ascii_quotes = non_us_ascii_quotes
         self.embed_html_attachments = embed_html_attachments
         self.embed_all_attachments = embed_all_attachments
         self.embed_adobe_flash_content = embed_adobe_flash_content
         self.html_table_position_only = html_table_position_only
         self.css_inline_style = css_inline_style
@@ -211,15 +219,15 @@
 
     def __init__(
         self,
         server: Optional[str] = None,
         port: Optional[int] = None,
         always_use_smart_host: bool = False,
         smart_host_username: Optional[str] = None,
-        smart_host_password: bool = False
+        smart_host_password: bool = False,
     ):
         self.server = server
         self.port = port
         self.always_use_smart_host = always_use_smart_host
         self.smart_host_username = smart_host_username
         self.smart_host_password = smart_host_password
 
@@ -232,30 +240,34 @@
         mime_settings: MIME settings for MIME email format
         smart_host_settings: smart host settings
     """
 
     _FROM_DICT_MAP = {
         "format": EmailFormat,
         "mime_settings": EmailMimeSettings.from_dict,
-        "smart_host_settings": EmailSmartHostSettings.from_dict
+        "smart_host_settings": EmailSmartHostSettings.from_dict,
     }
 
     def __init__(
         self,
         format: Union[str, EmailFormat],
         mime_settings: Optional[Union[dict, EmailMimeSettings]] = None,
-        smart_host_settings: Optional[Union[dict, EmailSmartHostSettings]] = None
+        smart_host_settings: Optional[Union[dict, EmailSmartHostSettings]] = None,
     ):
         self.format = EmailFormat(format) if isinstance(format, str) else format
-        self.mime_settings = EmailMimeSettings.from_dict(mime_settings) if isinstance(
-            mime_settings, dict
-        ) else mime_settings
-        self.smart_host_settings = EmailSmartHostSettings.from_dict(
-            smart_host_settings
-        ) if isinstance(smart_host_settings, dict) else smart_host_settings
+        self.mime_settings = (
+            EmailMimeSettings.from_dict(mime_settings)
+            if isinstance(mime_settings, dict)
+            else mime_settings
+        )
+        self.smart_host_settings = (
+            EmailSmartHostSettings.from_dict(smart_host_settings)
+            if isinstance(smart_host_settings, dict)
+            else smart_host_settings
+        )
 
 
 class FtpServerSettings(Dictable):
     """FTP Server Settings
 
     Attributes:
         protocol: FTP Protocol, FtpProtocol enum
@@ -280,15 +292,15 @@
         port: int,
         path: str,
         host: Optional[str] = None,
         passive_mode: bool = True,
         max_connections: int = -1,
         ascii_mode: bool = True,
         user_name: Optional[str] = None,
-        password: Optional[str] = None
+        password: Optional[str] = None,
     ):
         self.protocol = FtpProtocol(protocol) if isinstance(protocol, str) else protocol
         self.host = host
         self.port = port
         self.path = path
         self.passive_mode = passive_mode
         self.max_connections = max_connections
@@ -309,22 +321,26 @@
         "server_settings": FtpServerSettings.from_dict,
         "file_system": FileSystem.from_dict,
     }
 
     def __init__(
         self,
         server_settings: Union[FtpServerSettings, dict],
-        file_system: Union[FileSystem, dict]
+        file_system: Union[FileSystem, dict],
     ):
-        self.server_settings = FtpServerSettings.from_dict(server_settings) if isinstance(
-            server_settings, dict
-        ) else server_settings
-        self.file_system = FileSystem.from_dict(file_system) if isinstance(
-            file_system, dict
-        ) else file_system
+        self.server_settings = (
+            FtpServerSettings.from_dict(server_settings)
+            if isinstance(server_settings, dict)
+            else server_settings
+        )
+        self.file_system = (
+            FileSystem.from_dict(file_system)
+            if isinstance(file_system, dict)
+            else file_system
+        )
 
 
 class IOSDeviceProperties(Dictable):
     """Device properties for ipad and iphone device types.
 
     Attributes:
         app_id: Application ID
@@ -339,15 +355,15 @@
     def __init__(
         self,
         app_id: str = '',
         server: Optional[str] = None,
         port: Optional[int] = None,
         provider_certificate: Optional[str] = None,
         feedback_service_server: Optional[str] = None,
-        feedback_service_port: Optional[int] = None
+        feedback_service_port: Optional[int] = None,
     ):
         self.app_id = app_id
         self.server = server
         self.port = port
         self.provider_certificate = provider_certificate
         self.feedback_service_server = feedback_service_server
         self.feedback_service_port = feedback_service_port
@@ -377,15 +393,15 @@
         port: Optional[int] = None,
         auth_key: Optional[str] = None,
         collapse_key: Optional[str] = None,
         delay_with_idle: bool = False,
         notification_active_hours: Optional[int] = None,
         use_proxy: bool = False,
         proxy_server: Optional[str] = None,
-        proxy_port: Optional[int] = None
+        proxy_port: Optional[int] = None,
     ):
         self.package_name = package_name
         self.server = server
         self.port = port
         self.auth_key = auth_key
         self.collapse_key = collapse_key
         self.delay_with_idle = delay_with_idle
@@ -407,15 +423,15 @@
     """
 
     def __init__(
         self,
         file_path: str,
         append_user_path: bool = False,
         use_backup_location: bool = False,
-        backup_file_path: Optional[str] = None
+        backup_file_path: Optional[str] = None,
     ):
         self.file_path = file_path
         self.append_user_path = append_user_path
         self.use_backup_location = use_backup_location
         self.backup_file_path = backup_file_path
 
 
@@ -436,21 +452,24 @@
 
     def __init__(
         self,
         read_only: bool = True,
         archive: bool = False,
         index: bool = False,
         file_encoding: Optional[Union[FileEncoding, str]] = None,
-        unix_access_rights: Optional[str] = None
+        unix_access_rights: Optional[str] = None,
     ):
         self.read_only = read_only
         self.archive = archive
         self.index = index
-        self.file_encoding = FileEncoding(file_encoding
-                                          ) if isinstance(file_encoding, str) else file_encoding
+        self.file_encoding = (
+            FileEncoding(file_encoding)
+            if isinstance(file_encoding, str)
+            else file_encoding
+        )
         self.unix_access_rights = unix_access_rights
 
 
 class UnixWindowsSharity(Dictable):
     """Unix to Windows Sharity settings
 
     Attributes:
@@ -462,15 +481,15 @@
     """
 
     def __init__(
         self,
         sharity_enabled: bool = False,
         server_username: Optional[str] = None,
         server_password: Optional[str] = None,
-        server_mount_root: Optional[str] = None
+        server_mount_root: Optional[str] = None,
     ):
         self.sharity_enabled = sharity_enabled
         self.server_username = server_username
         self.server_password = server_password
         self.server_mount_root = server_mount_root
 
 
@@ -497,43 +516,55 @@
 
     def __init__(
         self,
         file_location: Union[FileLocation, dict],
         file_system: Union[FileSystem, dict],
         connection_parameters: Union[ConnectionParameters, dict],
         file_properties: Union[FileProperties, dict],
-        unix_windows_sharity: Union[UnixWindowsSharity, dict]
+        unix_windows_sharity: Union[UnixWindowsSharity, dict],
     ):
-        self.file_location = FileLocation.from_dict(file_location) if isinstance(
-            file_location, dict
-        ) else file_location
-        self.file_system = FileSystem.from_dict(file_system) if isinstance(
-            file_system, dict
-        ) else file_system
-        self.connection_parameters = ConnectionParameters.from_dict(
-            connection_parameters
-        ) if isinstance(connection_parameters, dict) else connection_parameters
-        self.file_properties = FileProperties.from_dict(file_properties) if isinstance(
-            file_properties, dict
-        ) else file_properties
-        self.unix_windows_sharity = UnixWindowsSharity.from_dict(
-            unix_windows_sharity
-        ) if isinstance(unix_windows_sharity, dict) else unix_windows_sharity
+        self.file_location = (
+            FileLocation.from_dict(file_location)
+            if isinstance(file_location, dict)
+            else file_location
+        )
+        self.file_system = (
+            FileSystem.from_dict(file_system)
+            if isinstance(file_system, dict)
+            else file_system
+        )
+        self.connection_parameters = (
+            ConnectionParameters.from_dict(connection_parameters)
+            if isinstance(connection_parameters, dict)
+            else connection_parameters
+        )
+        self.file_properties = (
+            FileProperties.from_dict(file_properties)
+            if isinstance(file_properties, dict)
+            else file_properties
+        )
+        self.unix_windows_sharity = (
+            UnixWindowsSharity.from_dict(unix_windows_sharity)
+            if isinstance(unix_windows_sharity, dict)
+            else unix_windows_sharity
+        )
 
 
 class PrinterLocation(Dictable):
     """Printer Location.
 
     Attributes:
         location: Printer Location
         user_defined_location: Whether to allow user defined location,
             default: False
     """
 
-    def __init__(self, location: Optional[str] = None, user_defined_location: bool = False):
+    def __init__(
+        self, location: Optional[str] = None, user_defined_location: bool = False
+    ):
         self.location = location
         self.user_defined_location = user_defined_location
 
 
 class PrinterPdfSettings(Dictable):
     """PDF printing settings.
 
@@ -553,28 +584,35 @@
     }
 
     def __init__(
         self,
         post_script_level: int = 2,
         reverse_pages: bool = False,
         odd_even_pages: Optional[Union[PdfOddEvenPages, str]] = None,
-        application_priority: Optional[Union[PdfApplicationPriority, str]] = None
+        application_priority: Optional[Union[PdfApplicationPriority, str]] = None,
     ):
         self.post_script_level = (
-            post_script_level if 0 <= post_script_level <= 9 else exception_handler(
-                'Please provide appropriate value for post_script_level (from 0 to 9)', ValueError
+            post_script_level
+            if 0 <= post_script_level <= 9
+            else exception_handler(
+                'Please provide appropriate value for post_script_level (from 0 to 9)',
+                ValueError,
             )
         )
-        self.odd_even_pages = PdfOddEvenPages(odd_even_pages) if isinstance(
-            odd_even_pages, str
-        ) else odd_even_pages
+        self.odd_even_pages = (
+            PdfOddEvenPages(odd_even_pages)
+            if isinstance(odd_even_pages, str)
+            else odd_even_pages
+        )
         self.reverse_pages = reverse_pages
-        self.application_priority = PdfApplicationPriority(application_priority) if isinstance(
-            application_priority, str
-        ) else application_priority
+        self.application_priority = (
+            PdfApplicationPriority(application_priority)
+            if isinstance(application_priority, str)
+            else application_priority
+        )
 
 
 class PrinterProperties(Dictable):
     """Printer Properties.
 
     Attributes:
         pdf_setting: PDF printing settings, PrinterPdfSettings class
@@ -592,26 +630,31 @@
 
     def __init__(
         self,
         pdf_setting: Union[PrinterPdfSettings, dict],
         quality: Optional[str] = None,
         scale: int = 100,
         paper_source: Optional[Union[PrinterPaperSource, str]] = None,
-        paper_size: Optional[Union[PrinterPaperSize, str]] = None
+        paper_size: Optional[Union[PrinterPaperSize, str]] = None,
     ):
-        self.pdf_setting = PrinterPdfSettings.from_dict(pdf_setting) if isinstance(
-            pdf_setting, dict
-        ) else pdf_setting
+        self.pdf_setting = (
+            PrinterPdfSettings.from_dict(pdf_setting)
+            if isinstance(pdf_setting, dict)
+            else pdf_setting
+        )
         self.quality = quality
         self.scale = scale
-        self.paper_source = PrinterPaperSource(paper_source) if isinstance(
-            paper_source, str
-        ) else paper_source
-        self.paper_size = PrinterPaperSize(paper_size
-                                           ) if isinstance(paper_size, str) else paper_size
+        self.paper_source = (
+            PrinterPaperSource(paper_source)
+            if isinstance(paper_source, str)
+            else paper_source
+        )
+        self.paper_size = (
+            PrinterPaperSize(paper_size) if isinstance(paper_size, str) else paper_size
+        )
 
 
 class BackupPrinterProperties(Dictable):
     """Printer Backup Setting.
 
     Attributes:
         print_on_backup: Whether to print on Backup printer if
@@ -627,20 +670,22 @@
     }
 
     def __init__(
         self,
         print_on_backup: bool = False,
         backup_location_type: Optional[Union[PrinterBackupLocationType, str]] = None,
         backup_printer_location: Optional[str] = None,
-        backup_file_location: Optional[str] = None
+        backup_file_location: Optional[str] = None,
     ):
         self.print_on_backup = print_on_backup
-        self.backup_location_type = PrinterBackupLocationType(backup_location_type) if isinstance(
-            backup_file_location, str
-        ) else backup_location_type
+        self.backup_location_type = (
+            PrinterBackupLocationType(backup_location_type)
+            if isinstance(backup_file_location, str)
+            else backup_location_type
+        )
         self.backup_printer_location = backup_printer_location
         self.backup_file_location = backup_file_location
 
 
 class PrinterDeviceProperties(Dictable):
     """Device properties for printer device type.
 
@@ -662,22 +707,30 @@
 
     def __init__(
         self,
         printer_location: Union[PrinterLocation, dict],
         printer_properties: Union[PrinterProperties, dict],
         connection_parameters: Union[ConnectionParameters, dict],
         backup_printer_properties: Union[BackupPrinterProperties, dict],
-        temp_file_location: Optional[str] = None
+        temp_file_location: Optional[str] = None,
     ):
-        self.printer_location = PrinterLocation.from_dict(printer_location) if isinstance(
-            printer_location, dict
-        ) else printer_location
-        self.printer_properties = PrinterProperties.from_dict(printer_properties) if isinstance(
-            printer_properties, dict
-        ) else printer_properties
-        self.connection_parameters = ConnectionParameters.from_dict(
-            connection_parameters
-        ) if isinstance(connection_parameters, dict) else connection_parameters
-        self.backup_printer_properties = BackupPrinterProperties.from_dict(
-            backup_printer_properties
-        ) if isinstance(backup_printer_properties, dict) else backup_printer_properties
+        self.printer_location = (
+            PrinterLocation.from_dict(printer_location)
+            if isinstance(printer_location, dict)
+            else printer_location
+        )
+        self.printer_properties = (
+            PrinterProperties.from_dict(printer_properties)
+            if isinstance(printer_properties, dict)
+            else printer_properties
+        )
+        self.connection_parameters = (
+            ConnectionParameters.from_dict(connection_parameters)
+            if isinstance(connection_parameters, dict)
+            else connection_parameters
+        )
+        self.backup_printer_properties = (
+            BackupPrinterProperties.from_dict(backup_printer_properties)
+            if isinstance(backup_printer_properties, dict)
+            else backup_printer_properties
+        )
         self.temp_file_location = temp_file_location
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/event.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/event.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,34 +10,34 @@
 from mstrio.utils.entity import DeleteMixin, Entity, ObjectTypes
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 logger = logging.getLogger(__name__)
 
 
 @method_version_handler('11.3.0100')
-def list_events(connection: Connection, to_dictionary: bool = False, limit: int = None,
-                **filters) -> Union[List["Event"], List[dict]]:
+def list_events(
+    connection: Connection, to_dictionary: bool = False, limit: int = None, **filters
+) -> Union[List["Event"], List[dict]]:
     """List event objects or event dictionaries. Optionally filter list.
 
     Args:
         connection(object): MicroStrategy connection object returned
             by 'connection.Connection()'
         to_dictionary(bool, optional): if True, return event as
             list of dicts
         limit(int, optional): maximum number of Events returned.
-        **filters: Available filter parameters:['name':,
-                                                'id',
-                                                'description']
+        **filters: Available filter parameters:
+            ['name', 'id', 'description', 'acg']
     """
     _objects = helper.fetch_objects(
         connection=connection,
         api=events.list_events,
         limit=limit,
         filters=filters,
-        dict_unpack_value='events'
+        dict_unpack_value='events',
     )
 
     if to_dictionary:
         return _objects
     else:
         return [Event.from_dict(source=obj, connection=connection) for obj in _objects]
 
@@ -66,36 +66,41 @@
             'version',
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
             'acg',
-            'acl'
+            'acl',
         ): objects.get_object_info,
     }
     _API_DELETE = staticmethod(events.delete_event)
     _API_PATCH = {('name', 'description'): (events.update_event, 'put')}
 
     def __init__(
-        self, connection: Connection, id: Optional[str] = None, name: Optional[str] = None
+        self,
+        connection: Connection,
+        id: Optional[str] = None,
+        name: Optional[str] = None,
     ) -> None:
         """Initialize the Event object, populates it with I-Server data.
         Specify either `id` or `name`. When `id` is provided (not `None`),
         `name` is omitted.
 
         Args:
             connection: MicroStrategy connection object returned
                 by `connection.Connection()`.
             id: Event ID
             name: Event name
         """
-        self._API_GETTERS[('id', 'name', 'description')] = \
-            events.get_event if version.parse(connection.web_version) >= \
-            version.parse('11.3.0200') else objects.get_object_info
+        self._API_GETTERS[('id', 'name', 'description')] = (
+            events.get_event
+            if version.parse(connection.web_version) >= version.parse('11.3.0200')
+            else objects.get_object_info
+        )
 
         if id is None and name is None:
             raise AttributeError(
                 "Please specify either 'name' or 'id' parameter in the constructor."
             )
         if id is None:
             objects_info = list_events(connection, name=name, to_dictionary=True)
@@ -107,15 +112,17 @@
         else:
             super().__init__(connection=connection, object_id=id, name=name)
 
     def trigger(self):
         """Trigger the Event"""
         response = events.trigger_event(self.connection, self.id)
         if response.ok and config.verbose:
-            logger.info(f"Event '{self.name}' with ID : '{self.id}' has been triggered.")
+            logger.info(
+                f"Event '{self.name}' with ID : '{self.id}' has been triggered."
+            )
         return response.ok
 
     @classmethod
     def create(
         cls, connection: Connection, name: str, description: Optional[str] = None
     ) -> "Event":
         """Create an Event
@@ -126,15 +133,16 @@
             name: Name of the new Event
             description: Description of the new Event
         """
         body = helper.delete_none_values(
             {
                 "name": name,
                 "description": description,
-            }, recursion=True
+            },
+            recursion=True,
         )
         response = events.create_event(connection, body)
         return cls.from_dict(response.json(), connection)
 
     def alter(self, name: Optional[str] = None, description: Optional[str] = None):
         """Alter the Event's properties
 
@@ -142,12 +150,13 @@
             name: New name for the Event
             description: New description for the Event
         """
         args = helper.delete_none_values(
             {
                 "name": name,
                 "description": description,
-            }, recursion=True
+            },
+            recursion=True,
         )
         self._alter_properties(**args)
         if config.verbose:
             logger.info(f"Updated subscription '{self.name}' with ID: {self.id}.")
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/schedule/schedule.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/schedule/schedule.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,19 @@
 from mstrio.connection import Connection
 from mstrio.distribution_services.event import Event
 from mstrio.distribution_services.schedule import ScheduleEnums, ScheduleTime
 from mstrio.users_and_groups.user import User
 from mstrio.utils import helper
 from mstrio.utils.entity import DeleteMixin, Entity, ObjectTypes
 from mstrio.utils.enum_helper import AutoName, get_enum_val
-from mstrio.utils.time_helper import DatetimeFormats, map_datetime_to_str, map_str_to_datetime
+from mstrio.utils.time_helper import (
+    DatetimeFormats,
+    map_datetime_to_str,
+    map_str_to_datetime,
+)
 from mstrio.utils.version_helper import method_version_handler
 
 logger = logging.getLogger(__name__)
 
 
 @method_version_handler('11.3.0000')
 def list_schedules(
@@ -26,36 +30,35 @@
 
     Args:
         connection(object): MicroStrategy connection object returned by
             'connection.Connection()'
         to_dictionary(bool, optional): if True, return Schedules as
             list of dicts
         limit(int, optional): maximum number of schedules returned.
-        **filters: Available filter parameters:['name':,
-                                                'id',
-                                                'description',
-                                                'schedule_type',
-                                                'start_date',
-                                                'expired']
+        **filters: Available filter parameters: ['name', 'id', 'description',
+            'schedule_type', 'schedule_next_delivery', 'start_date', 'time',
+             'expired', 'acg']
     Returns:
         list["Schedule"] | list[dict]: [description]
     """
 
     objects = helper.fetch_objects(
         connection=connection,
         api=schedules.list_schedules,
         limit=limit,
         filters=filters,
-        dict_unpack_value='schedules'
+        dict_unpack_value='schedules',
     )
 
     if to_dictionary:
         return objects
     else:
-        return [Schedule.from_dict(source=obj, connection=connection) for obj in objects]
+        return [
+            Schedule.from_dict(source=obj, connection=connection) for obj in objects
+        ]
 
 
 class Schedule(Entity, DeleteMixin):
     """Class representation of MicroStrategy Schedule object.
 
     Attributes:
         connection: A MicroStrategy connection object
@@ -66,14 +69,15 @@
         schedule_next_delivery: Schedule next delivery date
         time(ScheduleTime): Details of time-based schedule
         event(Event): Details of event-based schedule
     """
 
     class ScheduleType(AutoName):
         """Class representation of a type of a Microstrategy Schedule."""
+
         EVENT_BASED = auto()
         TIME_BASED = auto()
         NONE = None
 
     _OBJECT_TYPE = ObjectTypes.SCHEDULE_TRIGGER
 
     _API_GETTERS: dict = {
@@ -83,15 +87,15 @@
             'description',
             'expired',
             'schedule_type',
             'schedule_next_delivery',
             'start_date',
             'stop_date',
             'time',
-            'event'
+            'event',
         ): schedules.get_schedule,
         (
             'abbreviation',
             'type',
             'subtype',
             'ext_type',
             'date_created',
@@ -99,47 +103,56 @@
             'version',
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
             'acg',
-            'acl'
-        ): objects.get_object_info
+            'acl',
+        ): objects.get_object_info,
     }
 
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'owner': User.from_dict,
         'schedule_type': ScheduleType,
         'time': ScheduleTime.from_dict,
         'event': Event.from_dict,
         'schedule_next_delivery': DatetimeFormats.YMDHMS,
         'start_date': DatetimeFormats.DATE,
         'stop_date': DatetimeFormats.DATE,
     }
     _API_PATCH: dict = {
         ('abbreviation'): (objects.update_object, 'partial_put'),
-        ('name', 'description', 'schedule_type', 'start_date', 'stop_date', 'time',
-         'event'): (schedules.update_schedule, 'put')
+        (
+            'name',
+            'description',
+            'schedule_type',
+            'start_date',
+            'stop_date',
+            'time',
+            'event',
+        ): (schedules.update_schedule, 'put'),
     }
 
     _PATCH_PATH_TYPES = {
         'name': str,
         'description': str,
         'abbreviation': str,
         'schedule_type': str,
         'start_date': str,
         'stop_date': str,
         'time': dict,
         'event': dict,
     }
 
     @method_version_handler('11.3.0000')
-    def __init__(self, connection: Connection, id: str = None, name: str = None) -> None:
+    def __init__(
+        self, connection: Connection, id: str = None, name: str = None
+    ) -> None:
         """Initialize the Schedule object, populates it with I-Server data.
         Specify either `id` or `name`. When `id` is provided (not `None`),
         `name` is omitted.
 
         Args:
             connection: MicroStrategy connection object returned
                 by `connection.Connection()`.
@@ -152,15 +165,17 @@
         """
 
         if id is None and name is None:
             raise AttributeError(
                 "Please specify either 'name' or 'id' parameter in the constructor."
             )
         if id is None:
-            objects_info = list_schedules(connection=connection, name=name, to_dictionary=True)
+            objects_info = list_schedules(
+                connection=connection, name=name, to_dictionary=True
+            )
             if objects_info:
                 object_info, object_info["connection"] = objects_info[0], connection
                 self._init_variables(**object_info)
             else:
                 raise ValueError(f"There is no schedule with the given name: '{name}'")
         else:
             super().__init__(connection, id, name=name)
@@ -175,23 +190,35 @@
         Args:
             **kwargs: dict with information about schedule attributes.
         Returns:
             None
         """
         super()._init_variables(**kwargs)
         self.schedule_type = self.ScheduleType(kwargs.get('schedule_type'))
-        self.time = ScheduleTime.from_dict(
-            kwargs.get('time')
-        ) if (self.schedule_type == self.ScheduleType.TIME_BASED and kwargs.get('time')) else None
-        self.event = Event.from_dict(kwargs.get('event'), connection=self._connection) if (
-            self.schedule_type == self.ScheduleType.EVENT_BASED and kwargs.get('event')
-        ) else None
+        self.time = (
+            ScheduleTime.from_dict(kwargs.get('time'))
+            if (
+                self.schedule_type == self.ScheduleType.TIME_BASED
+                and kwargs.get('time')
+            )
+            else None
+        )
+        self.event = (
+            Event.from_dict(kwargs.get('event'), connection=self._connection)
+            if (
+                self.schedule_type == self.ScheduleType.EVENT_BASED
+                and kwargs.get('event')
+            )
+            else None
+        )
         self._expired = kwargs.get('expired')
         self._schedule_next_delivery = map_str_to_datetime(
-            "schedule_next_delivery", kwargs.get("schedule_next_delivery"), self._FROM_DICT_MAP
+            "schedule_next_delivery",
+            kwargs.get("schedule_next_delivery"),
+            self._FROM_DICT_MAP,
         )
         self.start_date = map_str_to_datetime(
             "start_date", kwargs.get("start_date"), self._FROM_DICT_MAP
         )
 
     @method_version_handler('11.3.0000')
     def enable(self, stop_date: str | datetime) -> bool:
@@ -210,54 +237,64 @@
         if config.verbose and not self.expired:
             logger.info(
                 f'Schedule \'{self.name}\' with ID {self.id} has been enabled, '
                 f'until {self.stop_date}.'
             )
             return True
         elif config.verbose:
-            logger.info(f'Schedule \'{self.name}\' with ID {self.id} has NOT been enabled.')
+            logger.info(
+                f'Schedule \'{self.name}\' with ID {self.id} has NOT been enabled.'
+            )
             return False
 
     @method_version_handler('11.3.0000')
     def disable(self, stop_date: Optional[str | datetime] = None) -> bool:
-        """ Disable the schedule. Optional `stop_date` sets the date when
+        """Disable the schedule. Optional `stop_date` sets the date when
             the schedule should be disabled.
 
         Args:
             stop_date: stop date provided either as a datetime or
             as a string in yyyy-MM-dd format
         Returns:
             Returns `True` if disabled properly. It does not mean that schedule
             is already expired, as it can take up to one day.
             If operation failed, return `False`.
         """
         stop_date = (
-            datetime.now(timezone.utc) if stop_date is None else
-            map_str_to_datetime('stop_date', stop_date, self._FROM_DICT_MAP)
+            datetime.now(timezone.utc)
+            if stop_date is None
+            else map_str_to_datetime('stop_date', stop_date, self._FROM_DICT_MAP)
         )
         self._alter_properties(stop_date=stop_date)
 
         if config.verbose and self.expired:
-            logger.info(f'Schedule \'{self.name}\' with ID {self.id} has been disabled.')
+            logger.info(
+                f'Schedule \'{self.name}\' with ID {self.id} has been disabled.'
+            )
             return True
         elif config.verbose and self.stop_date.date() == stop_date.date():
             logger.info(
-                f"Schedule '{self.name}' with ID '{self.id}' has been set for disabling. "
-                f"Depending on the schedule configuration (`event`, `time` and `stop_date`),"
-                f" it will be disabled by day after '{self.stop_date.date()}'."
+                f"Schedule '{self.name}' with ID '{self.id}' has been set for "
+                f"disabling. Depending on the schedule configuration (`event`, `time` "
+                f"and `stop_date`), it will be disabled by day after "
+                f"'{self.stop_date.date()}'."
             )
             return True
         else:
-            logger.info(f"Schedule '{self.name}' with ID '{self.id}' has NOT been disabled.")
+            logger.info(
+                f"Schedule '{self.name}' with ID '{self.id}' has NOT been disabled."
+            )
             return False
 
     @method_version_handler('11.3.0000')
     def list_properties(self):
         """List all properties of the object."""
-        attributes = {key: self.__dict__[key] for key in self.__dict__ if not key.startswith('_')}
+        attributes = {
+            key: self.__dict__[key] for key in self.__dict__ if not key.startswith('_')
+        }
         attributes = {
             **attributes,
             'expired': self._expired,
             'schedule_next_delivery': self._schedule_next_delivery,
             'id': self.id,
             'type': self.type,
             'subtype': self.subtype,
@@ -303,15 +340,15 @@
         day: Optional[int] = None,
         month: Optional[int] = None,
         week_offset: Optional[ScheduleEnums.WeekOffset | str] = None,
         day_of_week: Optional[ScheduleEnums.DaysOfWeek | str] = None,
         weekday_off_set: Optional[str] = None,
         days_of_month: Optional[list[str]] = None,
         monthly_pattern: Optional[ScheduleEnums.MonthlyPattern | str] = None,
-        yearly_pattern: Optional[ScheduleEnums.YearlyPattern | str] = None
+        yearly_pattern: Optional[ScheduleEnums.YearlyPattern | str] = None,
     ):
         """Create a Schedule using provided parameters as data.
 
         Args:
             recurrence_pattern (ScheduleEnums.RecurrencePattern, optional):
                 The recurrence pattern of the schedule. Possible values are
                 DAILY, WEEKLY, MONTHLY, YEARLY. Defaults to None.
@@ -368,27 +405,28 @@
                 The yearly recurrence pattern of the schedule. Possible values
                 are DAY, DAY_OF_WEEK. Defaults to None.
         Returns:
             Schedule object with provided parameters.
         """
         time_kwargs = {
             key: val
-            for key,
-            val in locals().items()
-            if val is not None and key not in [
+            for key, val in locals().items()
+            if val is not None
+            and key
+            not in [
                 'event_id',
                 'connection',
                 'description',
                 'name',
                 'schedule_type',
                 'start_date',
                 'stop_date',
                 'time',
                 'self',
-                'cls'
+                'cls',
             ]
         }
         # Event based or Time based logic
         if schedule_type == cls.ScheduleType.EVENT_BASED:
             execution_details = {'type': 'event', 'content': {'id': event_id}}
         elif schedule_type == cls.ScheduleType.TIME_BASED:
             if time is None:
@@ -406,15 +444,15 @@
         # Create body and send request
         body = {
             'name': name,
             'description': description,
             'schedule_type': get_enum_val(schedule_type, cls.ScheduleType),
             'start_date': start_date,
             'stop_date': stop_date,
-            execution_details['type']: execution_details['content']
+            execution_details['type']: execution_details['content'],
         }
         body = helper.delete_none_values(body, recursion=True)
         body = helper.snake_to_camel(body)
         # Response is already unpacked in wrapper
         response = schedules.create_schedule(connection, body)
         response = response.json()
         if config.verbose:
@@ -443,15 +481,15 @@
         day: Optional[int] = None,
         month: Optional[int] = None,
         week_offset: Optional[ScheduleEnums.WeekOffset] = None,
         day_of_week: Optional[ScheduleEnums.DaysOfWeek] = None,
         weekday_offset: Optional[str] = None,
         days_of_month: Optional[list[str]] = None,
         monthly_pattern: Optional[ScheduleEnums.MonthlyPattern] = None,
-        yearly_pattern: Optional[ScheduleEnums.YearlyPattern] = None
+        yearly_pattern: Optional[ScheduleEnums.YearlyPattern] = None,
     ) -> None:
         """Alter Schedule properties.
 
         Args:
             recurrence_pattern (ScheduleEnums.RecurrencePattern, optional):
                 The recurrence pattern of the schedule. Possible values are
                 DAILY, WEEKLY, MONTHLY, YEARLY. Defaults to None.
@@ -539,15 +577,15 @@
                 day,
                 month,
                 week_offset,
                 day_of_week,
                 weekday_offset,
                 days_of_month,
                 monthly_pattern,
-                yearly_pattern
+                yearly_pattern,
             )
             properties['time'] = self.time
 
         if name:
             properties['name'] = name
         if description:
             properties['description'] = description
@@ -558,17 +596,23 @@
         if stop_date:
             properties['stop_date'] = map_str_to_datetime(
                 'stop_date', stop_date, self._FROM_DICT_MAP
             )
 
         self._alter_properties(**properties)
 
-        if self.schedule_type == self.ScheduleType.EVENT_BASED and 'time' in self.__dir__():
+        if (
+            self.schedule_type == self.ScheduleType.EVENT_BASED
+            and 'time' in self.__dir__()
+        ):
             delattr(self, 'time')
-        elif self.schedule_type == self.ScheduleType.TIME_BASED and 'event' in self.__dir__():
+        elif (
+            self.schedule_type == self.ScheduleType.TIME_BASED
+            and 'event' in self.__dir__()
+        ):
             delattr(self, 'event')
 
     @method_version_handler('11.3.0000')
     def delete(self) -> bool:
         """Delete the schedule.
 
         Returns:
@@ -581,15 +625,15 @@
         self._delete_confirm_msg = (
             "This schedule may be part of a subscription. "
             "Deleting such a schedule will remove the subscription as well. "
             "This action cannot be undone. "
             f"Are you sure you want to delete the schedule '{self.name}'"
             f" with ID: {self.id}?[Y/N]: "
         )
-        self._delete_success_msg = (f"Deleted schedule '{self.name}' with ID: {self.id}.")
+        self._delete_success_msg = f"Deleted schedule '{self.name}' with ID: {self.id}."
 
         return super().delete(force=force)
 
     @property
     def expired(self):
         """Whether or not the schedule is expired"""
         return self._expired
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/schedule/schedule_time.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/schedule/schedule_time.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,16 @@
 
 from mstrio.utils import helper
 from mstrio.utils.enum_helper import AutoName
 from mstrio.utils.helper import Dictable
 
 
 class ScheduleEnums:
-    """Object representations of recurrence information of a time-based schedule
+    """
+    Object representations of recurrence information of a time-based schedule
     """
 
     class DaysOfWeek(AutoName):
         MONDAY = auto()
         TUESDAY = auto()
         WEDNESDAY = auto()
         THURSDAY = auto()
@@ -70,20 +71,21 @@
 
         _FROM_DICT_MAP = {
             'execution_pattern': ScheduleEnums.ExecutionPattern,
         }
 
         def __init__(
             self,
-            execution_pattern: Union[ScheduleEnums.ExecutionPattern,
-                                     str] = ScheduleEnums.ExecutionPattern.ONCE,
+            execution_pattern: Union[
+                ScheduleEnums.ExecutionPattern, str
+            ] = ScheduleEnums.ExecutionPattern.ONCE,
             execution_time: Optional[str] = None,
             start_time: Optional[str] = None,
             stop_time: Optional[str] = None,
-            repeat_interval: Optional[int] = 1
+            repeat_interval: Optional[int] = 1,
         ):
             """Set attributes representing execution information of the schedule
 
             Args:
                 execution_pattern (ScheduleEnums.ExecutionPattern, optional):
                     The execution pattern of the schedule.
                     Possible values are ONCE or REPEAT.
@@ -101,72 +103,83 @@
                 repeat_interval (int, optional):
                     The repeat interval of minutes of the execution day, if
                     executionPattern is repeat. Defaults to 1.
             Raises:
                 ValueError: when execution_repeat_interval = None if
                 execution_pattern == REPEAT
             """
-            if (execution_pattern == ScheduleEnums.ExecutionPattern.REPEAT
-                    and repeat_interval is None):
+            if (
+                execution_pattern == ScheduleEnums.ExecutionPattern.REPEAT
+                and repeat_interval is None
+            ):
                 helper.exception_handler(
                     msg=(
                         'Value error: execution_repeat_interval '
                         'cannot be None, '
                         'for execution_pattern == ExecutionPattern.Repeat'
                     ),
-                    exception_type=ValueError
+                    exception_type=ValueError,
                 )
             if execution_pattern == ScheduleEnums.ExecutionPattern.REPEAT:
                 self.start_time = start_time
                 self.stop_time = stop_time
                 self.repeat_interval = repeat_interval
             else:
                 self.execution_time = execution_time
-            self.execution_pattern = execution_pattern if isinstance(
-                execution_pattern, ScheduleEnums.ExecutionPattern
-            ) else ScheduleEnums.ExecutionPattern(execution_pattern)
+            self.execution_pattern = (
+                execution_pattern
+                if isinstance(execution_pattern, ScheduleEnums.ExecutionPattern)
+                else ScheduleEnums.ExecutionPattern(execution_pattern)
+            )
 
     class Daily(Dictable):
-        """Object representation of daily recurrence information of the schedule
+        """
+        Object representation of daily recurrence information of the schedule
         """
 
         _FROM_DICT_MAP = {'daily_pattern': ScheduleEnums.DailyPattern}
 
         def __init__(
             self,
-            daily_pattern: Union[ScheduleEnums.DailyPattern, str] = ScheduleEnums.DailyPattern.DAY,
-            repeat_interval: int = 1
+            daily_pattern: Union[
+                ScheduleEnums.DailyPattern, str
+            ] = ScheduleEnums.DailyPattern.DAY,
+            repeat_interval: int = 1,
         ):
             """Set attributes representing daily recurrence information of the
             schedule
 
             Args:
                 daily_pattern (ScheduleEnums.DailyPattern, optional):
                     The daily recurrence pattern of the schedule.Possible values
                     are DAY, WEEKDAY.Defaults to ScheduleEnums.DailyPattern.DAY.
                 repeat_interval (int, optional):
                     The repeat interval of days of daily schedule,
                     if daily_pattern is DAY. Defaults to 1.
             """
-            self.daily_pattern = daily_pattern if isinstance(
-                daily_pattern, ScheduleEnums.DailyPattern
-            ) else ScheduleEnums.DailyPattern(daily_pattern)
+            self.daily_pattern = (
+                daily_pattern
+                if isinstance(daily_pattern, ScheduleEnums.DailyPattern)
+                else ScheduleEnums.DailyPattern(daily_pattern)
+            )
             if daily_pattern == ScheduleEnums.DailyPattern.DAY:
                 self.repeat_interval = repeat_interval
 
     class Weekly(Dictable):
         """Object representation of weekly recurrence information of the
         schedule"""
 
         _FROM_DICT_MAP = {'days_of_week': [ScheduleEnums.DaysOfWeek]}
 
         def __init__(
             self,
-            days_of_week: Optional[Union[List[ScheduleEnums.DaysOfWeek], List[str]]] = None,
-            repeat_interval: int = 1
+            days_of_week: Optional[
+                Union[List[ScheduleEnums.DaysOfWeek], List[str]]
+            ] = None,
+            repeat_interval: int = 1,
         ):
             """Set attributes representing weekly recurrence information of the
             schedule.
 
             Args:
                 days_of_week (List[ScheduleEnums.DaysOfWeek], optional):
                     The days of week of weekly schedule. Possible values are:
@@ -177,41 +190,42 @@
                     Defaults to 1.
             """
             if days_of_week is None:
                 self.days_of_week = []
             else:
                 days_of_week = [
                     ScheduleEnums.DaysOfWeek(item)
-                    if not isinstance(item, ScheduleEnums.DaysOfWeek) else item
+                    if not isinstance(item, ScheduleEnums.DaysOfWeek)
+                    else item
                     for item in days_of_week
                 ]
                 self.days_of_week = days_of_week
 
             self.repeat_interval = repeat_interval
 
     class Monthly(Dictable):
         """Object representation of monthly recurrence information of the
         schedule"""
 
         _FROM_DICT_MAP = {
             'monthly_pattern': ScheduleEnums.MonthlyPattern,
             'week_offset': ScheduleEnums.WeekOffset,
             'day_of_week': ScheduleEnums.DaysOfWeek,
-            'weekday_offset': ScheduleEnums.WeekdayOffset
+            'weekday_offset': ScheduleEnums.WeekdayOffset,
         }
 
         def __init__(
             self,
             monthly_pattern: Union[ScheduleEnums.MonthlyPattern, str],
             repeat_interval: int,
             day: Optional[int] = None,
             week_offset: Optional[Union[ScheduleEnums.WeekOffset, str]] = None,
             day_of_week: Optional[Union[ScheduleEnums.DaysOfWeek, str]] = None,
             weekday_offset: Optional[Union[ScheduleEnums.WeekdayOffset, str]] = None,
-            days_of_month: Optional[str] = None
+            days_of_month: Optional[str] = None,
         ):
             """Set attributes representing monthly recurrence information of the
             schedule.
 
             Args:
                 monthly_pattern (ScheduleEnums.MonthlyPattern):
                     The monthly recurrence pattern of the schedule. Possible
@@ -237,53 +251,62 @@
                     LAST. Defaults to None.
                 days_of_month (Optional[str], optional):
                     The days of month of monthly schedule, if monthly_pattern
                     is DAYS_OF_MONTH. Must be provided as a list of one or more
                     stringified digits (from '1' to '31'). Defaults to None.
             """
 
-            self.monthly_pattern = monthly_pattern if isinstance(
-                monthly_pattern, ScheduleEnums.MonthlyPattern
-            ) else ScheduleEnums.MonthlyPattern(monthly_pattern)
+            self.monthly_pattern = (
+                monthly_pattern
+                if isinstance(monthly_pattern, ScheduleEnums.MonthlyPattern)
+                else ScheduleEnums.MonthlyPattern(monthly_pattern)
+            )
             self.repeat_interval = repeat_interval
 
             if monthly_pattern == ScheduleEnums.MonthlyPattern.DAY:
                 self.day = day
             elif monthly_pattern == ScheduleEnums.MonthlyPattern.DAY_OF_WEEK:
-                self.week_offset = week_offset if isinstance(
-                    week_offset, ScheduleEnums.WeekOffset
-                ) else ScheduleEnums.WeekOffset(week_offset)
-                self.day_of_week = day_of_week if isinstance(
-                    day_of_week, ScheduleEnums.DaysOfWeek
-                ) else ScheduleEnums.DaysOfWeek(day_of_week)
+                self.week_offset = (
+                    week_offset
+                    if isinstance(week_offset, ScheduleEnums.WeekOffset)
+                    else ScheduleEnums.WeekOffset(week_offset)
+                )
+                self.day_of_week = (
+                    day_of_week
+                    if isinstance(day_of_week, ScheduleEnums.DaysOfWeek)
+                    else ScheduleEnums.DaysOfWeek(day_of_week)
+                )
             elif monthly_pattern == ScheduleEnums.MonthlyPattern.WEEKDAY:
-                self.weekday_offset = weekday_offset if isinstance(
-                    weekday_offset, ScheduleEnums.WeekdayOffset
-                ) else ScheduleEnums.WeekdayOffset(weekday_offset)
+                self.weekday_offset = (
+                    weekday_offset
+                    if isinstance(weekday_offset, ScheduleEnums.WeekdayOffset)
+                    else ScheduleEnums.WeekdayOffset(weekday_offset)
+                )
             elif monthly_pattern == ScheduleEnums.MonthlyPattern.DAYS_OF_MONTH:
                 self.days_of_month = days_of_month
 
     class Yearly(Dictable):
         """Object representation of yearly recurrence information of the
         schedule"""
 
         _FROM_DICT_MAP = {
             'yearly_pattern': ScheduleEnums.YearlyPattern,
             'week_offset': ScheduleEnums.WeekOffset,
-            'day_of_week': ScheduleEnums.DaysOfWeek
+            'day_of_week': ScheduleEnums.DaysOfWeek,
         }
 
         def __init__(
             self,
-            yearly_pattern: Union[ScheduleEnums.YearlyPattern,
-                                  str] = ScheduleEnums.YearlyPattern.DAY,
+            yearly_pattern: Union[
+                ScheduleEnums.YearlyPattern, str
+            ] = ScheduleEnums.YearlyPattern.DAY,
             month: int = 1,
             day: int = 1,
             week_offset: Optional[Union[ScheduleEnums.WeekOffset, str]] = None,
-            day_of_week: Optional[Union[ScheduleEnums.DaysOfWeek, str]] = None
+            day_of_week: Optional[Union[ScheduleEnums.DaysOfWeek, str]] = None,
         ):
             """Set attributes representing yearly recurrence information of the
             schedule
 
             Args:
                 yearly_pattern (ScheduleEnums.YearlyPattern, optional):
                     The yearly recurrence pattern of the schedule. Possible
@@ -300,46 +323,54 @@
                     SECOND, THIRD, FOURTH, LAST. Defaults to None.
                 day_of_week (ScheduleEnums.DaysOfWeek, optional):
                     The day of week in year of yearly schedule,
                     if yearly_pattern is DAY_OF_WEEK. Possible values are:
                     MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY,
                     SUNDAY. Defaults to None.
             """
-            self.yearly_pattern = yearly_pattern if isinstance(
-                yearly_pattern, ScheduleEnums.YearlyPattern
-            ) else ScheduleEnums.YearlyPattern(yearly_pattern)
+            self.yearly_pattern = (
+                yearly_pattern
+                if isinstance(yearly_pattern, ScheduleEnums.YearlyPattern)
+                else ScheduleEnums.YearlyPattern(yearly_pattern)
+            )
             self.month = month
             if yearly_pattern == ScheduleEnums.YearlyPattern.DAY:
                 self.day = day
             if yearly_pattern == ScheduleEnums.YearlyPattern.DAYOFWEEK:
-                self.week_offset = week_offset if isinstance(
-                    week_offset, ScheduleEnums.WeekOffset
-                ) else ScheduleEnums.WeekOffset(week_offset)
-                self.day_of_week = day_of_week if isinstance(
-                    day_of_week, ScheduleEnums.DaysOfWeek
-                ) else ScheduleEnums.DaysOfWeek(day_of_week)
+                self.week_offset = (
+                    week_offset
+                    if isinstance(week_offset, ScheduleEnums.WeekOffset)
+                    else ScheduleEnums.WeekOffset(week_offset)
+                )
+                self.day_of_week = (
+                    day_of_week
+                    if isinstance(day_of_week, ScheduleEnums.DaysOfWeek)
+                    else ScheduleEnums.DaysOfWeek(day_of_week)
+                )
 
     _FROM_DICT_MAP = {
         'recurrence_pattern': ScheduleEnums.RecurrencePattern,
         'days_of_week': ScheduleEnums.DaysOfWeek,
         'execution': Execution.from_dict,
         'daily': Daily.from_dict,
         'weekly': Weekly.from_dict,
         'monthly': Monthly.from_dict,
-        'yearly': Yearly.from_dict
+        'yearly': Yearly.from_dict,
     }
 
     def __init__(
         self,
-        recurrence_pattern: Optional[Union[ScheduleEnums.RecurrencePattern, str]] = None,
+        recurrence_pattern: Optional[
+            Union[ScheduleEnums.RecurrencePattern, str]
+        ] = None,
         execution: Optional[Execution] = None,
         daily: Optional[Daily] = None,
         weekly: Optional[Weekly] = None,
         monthly: Optional[Monthly] = None,
-        yearly: Optional[Yearly] = None
+        yearly: Optional[Yearly] = None,
     ):
         """Set attributes representing details of the time-based schedule.
 
         Args:
             recurrence_pattern (ScheduleEnums.RecurrencePattern, optional):
                 The recurrence pattern of the schedule. Possible values are
                 DAILY, WEEKLY, MONTHLY, YEARLY. Defaults to None.
@@ -356,17 +387,19 @@
                 Object representing monthly recurrence information of the
                 schedule. Defaults to None.
             yearly (Yearly, optional):
                 Object representing yearly recurrence information of the
                 schedule. Defaults to None.
         """
 
-        self.recurrence_pattern = recurrence_pattern if isinstance(
-            recurrence_pattern, ScheduleEnums.RecurrencePattern
-        ) else ScheduleEnums.RecurrencePattern(recurrence_pattern)
+        self.recurrence_pattern = (
+            recurrence_pattern
+            if isinstance(recurrence_pattern, ScheduleEnums.RecurrencePattern)
+            else ScheduleEnums.RecurrencePattern(recurrence_pattern)
+        )
         self.execution = execution
         if daily:
             self.daily = daily
         elif weekly:
             self.weekly = weekly
         elif monthly:
             self.monthly = monthly
@@ -378,30 +411,35 @@
         cls,
         recurrence_pattern: Union[ScheduleEnums.RecurrencePattern, str],
         execution_pattern: Union[ScheduleEnums.ExecutionPattern, str],
         execution_time: Optional[str] = None,
         start_time: Optional[str] = None,
         stop_time: Optional[str] = None,
         execution_repeat_interval: Optional[int] = None,
-        daily_pattern: Optional[Union[ScheduleEnums.DailyPattern,
-                                      str]] = ScheduleEnums.DailyPattern.NONE,
+        daily_pattern: Optional[
+            Union[ScheduleEnums.DailyPattern, str]
+        ] = ScheduleEnums.DailyPattern.NONE,
         repeat_interval: Optional[int] = None,
         days_of_week: Optional[Union[List[ScheduleEnums.DaysOfWeek], List[str]]] = None,
         day: Optional[int] = None,
         month: Optional[int] = None,
-        week_offset: Optional[Union[ScheduleEnums.WeekOffset,
-                                    str]] = ScheduleEnums.WeekOffset.NONE,
-        day_of_week: Optional[Union[ScheduleEnums.DaysOfWeek,
-                                    str]] = ScheduleEnums.DaysOfWeek.NONE,
+        week_offset: Optional[
+            Union[ScheduleEnums.WeekOffset, str]
+        ] = ScheduleEnums.WeekOffset.NONE,
+        day_of_week: Optional[
+            Union[ScheduleEnums.DaysOfWeek, str]
+        ] = ScheduleEnums.DaysOfWeek.NONE,
         weekday_offset: Optional[str] = None,
         days_of_month: Optional[List[str]] = None,
-        monthly_pattern: Optional[Union[ScheduleEnums.MonthlyPattern,
-                                        str]] = ScheduleEnums.MonthlyPattern.NONE,
-        yearly_pattern: Optional[Union[ScheduleEnums.YearlyPattern,
-                                       str]] = ScheduleEnums.YearlyPattern.NONE
+        monthly_pattern: Optional[
+            Union[ScheduleEnums.MonthlyPattern, str]
+        ] = ScheduleEnums.MonthlyPattern.NONE,
+        yearly_pattern: Optional[
+            Union[ScheduleEnums.YearlyPattern, str]
+        ] = ScheduleEnums.YearlyPattern.NONE,
     ):
         """
         Uses provided properties to create object representation of details of a
         time-based schedule.
 
         This object is used as 'time' part of request body and is needed for
         creating and updating schedule.
@@ -473,82 +511,96 @@
             ScheduleTime: Object representation of details of time-based
             schedule.
         """
 
         if execution_pattern == ScheduleEnums.ExecutionPattern.ONCE:
             execution = cls.Execution.from_dict(
                 {
-                    'execution_pattern': execution_pattern, 'execution_time': execution_time
+                    'execution_pattern': execution_pattern,
+                    'execution_time': execution_time,
                 }
             )
         elif execution_pattern == ScheduleEnums.ExecutionPattern.REPEAT:
             execution = cls.Execution.from_dict(
                 {
                     'execution_pattern': execution_pattern,
                     'start_time': start_time,
                     'stop_time': stop_time,
-                    'repeat_interval': execution_repeat_interval
+                    'repeat_interval': execution_repeat_interval,
                 }
             )
         else:
             helper.exception_handler(
                 msg='Error: Wrong value of execution_pattern', exception_type=ValueError
             )
 
         if recurrence_pattern == ScheduleEnums.RecurrencePattern.DAILY:
             daily = cls.Daily.from_dict(
-                {
-                    'daily_pattern': daily_pattern, 'repeat_interval': repeat_interval
-                }
+                {'daily_pattern': daily_pattern, 'repeat_interval': repeat_interval}
+            )
+            return cls(
+                recurrence_pattern=recurrence_pattern, execution=execution, daily=daily
             )
-            return cls(recurrence_pattern=recurrence_pattern, execution=execution, daily=daily)
         elif recurrence_pattern == ScheduleEnums.RecurrencePattern.WEEKLY:
             if days_of_week and type(days_of_week) is not list:
                 helper.exception_handler(
                     msg='Error: days_of_week must be provided as a list',
-                    exception_type=ValueError
+                    exception_type=ValueError,
                 )
             weekly = cls.Weekly.from_dict(
-                {
-                    'repeat_interval': repeat_interval, 'days_of_week': days_of_week
-                }
+                {'repeat_interval': repeat_interval, 'days_of_week': days_of_week}
+            )
+            return cls(
+                recurrence_pattern=recurrence_pattern,
+                execution=execution,
+                weekly=weekly,
             )
-            return cls(recurrence_pattern=recurrence_pattern, execution=execution, weekly=weekly)
         elif recurrence_pattern == ScheduleEnums.RecurrencePattern.MONTHLY:
             monthly = cls.Monthly.from_dict(
                 {
                     "monthly_pattern": monthly_pattern,
                     "repeatInterval": repeat_interval,
                     "day": day,
                     "week_offset": week_offset,
                     "day_of_week": day_of_week,
                     "WeekdayOffset": weekday_offset,
-                    "days_of_month": days_of_month
+                    "days_of_month": days_of_month,
                 }
             )
-            return cls(recurrence_pattern=recurrence_pattern, execution=execution, monthly=monthly)
+            return cls(
+                recurrence_pattern=recurrence_pattern,
+                execution=execution,
+                monthly=monthly,
+            )
         elif recurrence_pattern == ScheduleEnums.RecurrencePattern.YEARLY:
             yearly = cls.Yearly.from_dict(
                 {
                     'yearly_pattern': yearly_pattern,
                     'month': month,
                     'day': day,
                     'week_offset': week_offset,
-                    'day_of_week': day_of_week
+                    'day_of_week': day_of_week,
                 }
             )
-            return cls(recurrence_pattern=recurrence_pattern, execution=execution, yearly=yearly)
+            return cls(
+                recurrence_pattern=recurrence_pattern,
+                execution=execution,
+                yearly=yearly,
+            )
         else:
             helper.exception_handler(
-                msg='Error: Wrong value of recurrence_pattern', exception_type=ValueError
+                msg='Error: Wrong value of recurrence_pattern',
+                exception_type=ValueError,
             )
 
     def update_properties(
         self,
-        recurrence_pattern: Optional[Union[ScheduleEnums.RecurrencePattern, str]] = None,
+        recurrence_pattern: Optional[
+            Union[ScheduleEnums.RecurrencePattern, str]
+        ] = None,
         execution_pattern: Optional[Union[ScheduleEnums.ExecutionPattern, str]] = None,
         execution_time: Optional[str] = None,
         start_time: Optional[str] = None,
         stop_time: Optional[str] = None,
         execution_repeat_interval: Optional[int] = None,
         daily_pattern: Optional[Union[ScheduleEnums.DailyPattern, str]] = None,
         repeat_interval: Optional[int] = None,
@@ -556,15 +608,15 @@
         day: Optional[int] = None,
         month: Optional[int] = None,
         week_offset: Optional[Union[ScheduleEnums.WeekOffset, str]] = None,
         day_of_week: Optional[Union[ScheduleEnums.DaysOfWeek, str]] = None,
         weekday_offset: Optional[Union[ScheduleEnums.WeekdayOffset, str]] = None,
         days_of_month: Optional[List[str]] = None,
         monthly_pattern: Optional[Union[ScheduleEnums.MonthlyPattern, str]] = None,
-        yearly_pattern: Optional[Union[ScheduleEnums.YearlyPattern, str]] = None
+        yearly_pattern: Optional[Union[ScheduleEnums.YearlyPattern, str]] = None,
     ):
         """
         Updates ScheduleTime object according to provided parameters. If a
         provided parameter is not None then update it, else use its current
         value.
 
         Args:
@@ -626,116 +678,130 @@
                 Defaults to None.
             yearly_pattern (ScheduleEnums.YearlyPattern, optional):
                 The yearly recurrence pattern of the schedule. Possible values
                 are DAY, DAY_OF_WEEK. Defaults to None.
         """
 
         if execution_pattern:
-            execution_pattern = execution_pattern if isinstance(
-                execution_pattern, ScheduleEnums.ExecutionPattern
-            ) else ScheduleEnums.ExecutionPattern(execution_pattern)
-        self.execution.execution_pattern = execution_pattern or self.execution.execution_pattern
+            execution_pattern = (
+                execution_pattern
+                if isinstance(execution_pattern, ScheduleEnums.ExecutionPattern)
+                else ScheduleEnums.ExecutionPattern(execution_pattern)
+            )
+        self.execution.execution_pattern = (
+            execution_pattern or self.execution.execution_pattern
+        )
         if recurrence_pattern:
-            recurrence_pattern = recurrence_pattern if isinstance(
-                recurrence_pattern, ScheduleEnums.RecurrencePattern
-            ) else ScheduleEnums.RecurrencePattern(recurrence_pattern)
+            recurrence_pattern = (
+                recurrence_pattern
+                if isinstance(recurrence_pattern, ScheduleEnums.RecurrencePattern)
+                else ScheduleEnums.RecurrencePattern(recurrence_pattern)
+            )
         self.recurrence_pattern = recurrence_pattern or self.recurrence_pattern
 
         if self.execution.execution_pattern == ScheduleEnums.ExecutionPattern.ONCE:
             self.execution = self.Execution.from_dict(
                 {
-                    'execution_pattern': execution_pattern or self.execution.execution_pattern,
-                    'execution_time': execution_time or self.execution.execution_time
+                    'execution_pattern': execution_pattern
+                    or self.execution.execution_pattern,
+                    'execution_time': execution_time or self.execution.execution_time,
                 }
             )
         elif self.execution.execution_pattern == ScheduleEnums.ExecutionPattern.REPEAT:
             self.execution = self.Execution.from_dict(
                 {
-                    'execution_pattern': execution_pattern or self.execution.execution_pattern,
+                    'execution_pattern': execution_pattern
+                    or self.execution.execution_pattern,
                     'start_time': start_time or self.execution.start_time,
                     'stop_time': stop_time or self.execution.stop_time,
-                    'repeat_interval': execution_repeat_interval or self.execution.repeat_interval
+                    'repeat_interval': execution_repeat_interval
+                    or self.execution.repeat_interval,
                 }
             )
 
         if self.recurrence_pattern == ScheduleEnums.RecurrencePattern.DAILY:
             if hasattr(self, 'daily') and self.daily:
                 self.daily = self.Daily.from_dict(
                     {
                         'daily_pattern': daily_pattern or self.daily.daily_pattern,
                         'repeat_interval': (
-                            repeat_interval or getattr(self.daily, 'repeat_interval', None)
-                        )
+                            repeat_interval
+                            or getattr(self.daily, 'repeat_interval', None)
+                        ),
                     }
                 )
             else:
                 self.daily = self.Daily.from_dict(
-                    {
-                        'daily_pattern': daily_pattern, 'repeat_interval': repeat_interval
-                    }
+                    {'daily_pattern': daily_pattern, 'repeat_interval': repeat_interval}
                 )
 
         if self.recurrence_pattern == ScheduleEnums.RecurrencePattern.WEEKLY:
             if hasattr(self, 'weekly') and self.weekly:
                 self.weekly = self.Weekly.from_dict(
                     {
-                        'repeat_interval': repeat_interval or self.weekly.repeat_interval,
-                        'days_of_week': days_of_week or self.weekly.days_of_week
+                        'repeat_interval': repeat_interval
+                        or self.weekly.repeat_interval,
+                        'days_of_week': days_of_week or self.weekly.days_of_week,
                     }
                 )
             else:
                 self.weekly = self.Weekly.from_dict(
-                    {
-                        'repeat_interval': repeat_interval, 'days_of_week': days_of_week
-                    }
+                    {'repeat_interval': repeat_interval, 'days_of_week': days_of_week}
                 )
 
         if self.recurrence_pattern == ScheduleEnums.RecurrencePattern.MONTHLY:
             if hasattr(self, 'monthly') and self.monthly:
                 self.monthly = self.Monthly.from_dict(
                     {
-                        "monthly_pattern": monthly_pattern or self.monthly.monthly_pattern,
-                        "repeat_interval": repeat_interval or self.monthly.repeat_interval,
+                        "monthly_pattern": monthly_pattern
+                        or self.monthly.monthly_pattern,
+                        "repeat_interval": repeat_interval
+                        or self.monthly.repeat_interval,
                         "day": day or getattr(self.monthly, 'day', None),
-                        "week_offset": week_offset or getattr(self.monthly, 'week_offset', None),
-                        "day_of_week": day_of_week or getattr(self.monthly, 'day_of_week', None),
+                        "week_offset": week_offset
+                        or getattr(self.monthly, 'week_offset', None),
+                        "day_of_week": day_of_week
+                        or getattr(self.monthly, 'day_of_week', None),
                         "weekday_offset": (
-                            weekday_offset or getattr(self.monthly, 'weekday_offset', None)
+                            weekday_offset
+                            or getattr(self.monthly, 'weekday_offset', None)
                         ),
                         "days_of_month": days_of_month
-                        or getattr(self.monthly, 'days_of_month', None)
+                        or getattr(self.monthly, 'days_of_month', None),
                     }
                 )
             else:
                 self.monthly = self.Monthly.from_dict(
                     {
                         "monthly_pattern": monthly_pattern,
                         "repeat_interval": repeat_interval,
                         "day": day,
                         "week_offset": week_offset,
                         "day_of_week": day_of_week,
                         "weekday_offset": weekday_offset,
-                        "days_of_month": days_of_month
+                        "days_of_month": days_of_month,
                     }
                 )
 
         if self.recurrence_pattern == ScheduleEnums.RecurrencePattern.YEARLY:
             if hasattr(self, 'yearly') and self.yearly:
                 self.yearly = self.Yearly.from_dict(
                     {
                         'yearly_pattern': yearly_pattern or self.yearly.yearly_pattern,
                         'month': month or getattr(self.yearly, 'month', None),
                         'day': day or getattr(self.yearly, 'day', None),
-                        'week_offset': week_offset or getattr(self.yearly, 'week_offset', None),
-                        'day_of_week': day_of_week or getattr(self.yearly, 'day_of_week', None),
+                        'week_offset': week_offset
+                        or getattr(self.yearly, 'week_offset', None),
+                        'day_of_week': day_of_week
+                        or getattr(self.yearly, 'day_of_week', None),
                     }
                 )
             else:
                 self.yearly = self.Yearly.from_dict(
                     {
                         'yearly_pattern': yearly_pattern,
                         'month': month,
                         'day': day,
                         'week_offset': week_offset,
-                        'day_of_week': day_of_week
+                        'day_of_week': day_of_week,
                     }
                 )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/__init__.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 from .delivery import (
     CacheType,
     ClientType,
     Delivery,
     Orientation,
     SendContentAs,
     ShortcutCacheFormat,
-    ZipSettings
+    ZipSettings,
 )
 from .dynamic_recipient_list import DynamicRecipientList, list_dynamic_recipient_lists
 from .email_subscription import EmailSubscription
 from .file_subscription import FileSubscription
 from .ftp_subscription import FTPSubscription
 from .history_list_subscription import HistoryListSubscription
 from .subscription_manager import list_subscriptions, SubscriptionManager
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/base_subscription.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/base_subscription.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-from enum import auto
 import logging
+from enum import auto
 from pprint import pformat
 from typing import Any, Optional
 
 from mstrio import config
 from mstrio.api import subscriptions
 from mstrio.connection import Connection
 from mstrio.distribution_services.schedule import Schedule
@@ -13,23 +13,25 @@
     ClientType,
     Delivery,
     LegacyCacheType,
     LibraryCacheTypes,
     Orientation,
     SendContentAs,
     ShortcutCacheFormat,
-    ZipSettings
+    ZipSettings,
 )
 from mstrio.users_and_groups import User
 from mstrio.utils import helper, time_helper
 from mstrio.utils.entity import EntityBase
-from mstrio.utils.exceptions import NotSupportedError
 from mstrio.utils.enum_helper import AutoUpperName
+from mstrio.utils.exceptions import NotSupportedError
 from mstrio.utils.helper import (
-    get_args_from_func, get_default_args_from_func, get_valid_project_id
+    get_args_from_func,
+    get_default_args_from_func,
+    get_valid_project_id,
 )
 from mstrio.utils.version_helper import method_version_handler
 
 logger = logging.getLogger(__name__)
 
 
 class RecipientsTypes(AutoUpperName):
@@ -58,42 +60,44 @@
             "editable",
             "date_created",
             "date_modified",
             "owner",
             "schedules",
             "contents",
             "recipients",
-            "delivery"
+            "delivery",
         ): subscriptions.get_subscription
     }
     _FROM_DICT_MAP = {
         "owner": User.from_dict,
         "contents": (
-            lambda source,
-            connection: [Content.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                Content.from_dict(content, connection) for content in source
+            ]
         ),
         "delivery": Delivery.from_dict,
         "schedules": (
-            lambda source,
-            connection: [Schedule.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                Schedule.from_dict(content, connection) for content in source
+            ]
         ),
         "date_created": time_helper.DatetimeFormats.YMDHMS,
         "date_modified": time_helper.DatetimeFormats.YMDHMS,
     }
     _API_PATCH = [subscriptions.update_subscription]
     _RECIPIENTS_TYPES = RecipientsTypes
     _RECIPIENTS_INCLUDE = ['TO', 'CC', 'BCC', None]
 
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         subscription_id: Optional[str] = None,
         project_id: Optional[str] = None,
-        project_name: Optional[str] = None
+        project_name: Optional[str] = None,
     ):
         """Initialize Subscription object, populates it with I-Server data.
         Specify either `project_id` or `project_name`.
         When `project_id` is provided (not `None`), `project_name` is omitted.
 
         Args:
             connection (Connection): MicroStrategy connection object returned
@@ -112,15 +116,16 @@
             project_name=project_name,
             with_fallback=False if project_name else True,
         )
         if id or subscription_id:
             subscription_id = id if id else subscription_id
         else:
             helper.exception_handler(
-                msg='Must specify valid id or subscription_id', exception_type=ValueError
+                msg='Must specify valid id or subscription_id',
+                exception_type=ValueError,
             )
 
         super().__init__(connection, subscription_id, project_id=project_id)
 
     def _init_variables(self, project_id, **kwargs):
         super()._init_variables(**kwargs)
         self.subscription_id = kwargs.get('id')
@@ -131,25 +136,41 @@
         self.allow_unsubscribe = kwargs.get('allow_unsubscribe')
         self.date_created = time_helper.map_str_to_datetime(
             "date_created", kwargs.get("date_created"), self._FROM_DICT_MAP
         )
         self.date_modified = time_helper.map_str_to_datetime(
             "date_modified", kwargs.get("date_modified"), self._FROM_DICT_MAP
         )
-        self.owner = User.from_dict(kwargs.get('owner'),
-                                    self.connection) if kwargs.get('owner') else None
-        self.schedules = [
-            Schedule.from_dict(schedule, self._connection) for schedule in kwargs.get('schedules')
-        ] if kwargs.get('schedules') else None
-        self.contents = [
-            Content.from_dict(content, self._connection) for content in kwargs.get('contents')
-        ] if kwargs.get('contents') else None
+        self.owner = (
+            User.from_dict(kwargs.get('owner'), self.connection)
+            if kwargs.get('owner')
+            else None
+        )
+        self.schedules = (
+            [
+                Schedule.from_dict(schedule, self._connection)
+                for schedule in kwargs.get('schedules')
+            ]
+            if kwargs.get('schedules')
+            else None
+        )
+        self.contents = (
+            [
+                Content.from_dict(content, self._connection)
+                for content in kwargs.get('contents')
+            ]
+            if kwargs.get('contents')
+            else None
+        )
         self.recipients = kwargs.get('recipients', None)
-        self.delivery = Delivery.from_dict(kwargs.get('delivery')
-                                           ) if kwargs.get('delivery') else None
+        self.delivery = (
+            Delivery.from_dict(kwargs.get('delivery'))
+            if kwargs.get('delivery')
+            else None
+        )
         self.project_id = project_id
 
     @method_version_handler('11.3.0000')
     def alter(
         self,  # NOSONAR
         name: Optional[str] = None,
         multiple_contents: Optional[bool] = None,
@@ -161,14 +182,15 @@
         schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
         contents: Optional[Content] = None,
         recipients: Optional[list[str] | list[dict]] = None,
         delivery: Optional[Delivery | dict] = None,
         delivery_mode: Optional[str] = None,
         custom_msg: Optional[str] = None,
         delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
         contact_security: Optional[bool] = None,
         filename: Optional[str] = None,
         compress: Optional[bool] = None,
         space_delimiter: Optional[str] = None,
         email_subject: Optional[str] = None,
         email_message: Optional[str] = None,
         email_send_content_as: Optional[str] = None,
@@ -185,19 +207,21 @@
         printer_use_print_range: Optional[bool] = None,
         cache_cache_type: Optional[str] = None,
         cache_shortcut_cache_format: Optional[str] = None,
         mobile_client_type: Optional[str] = None,
         device_id: Optional[str] = None,
         do_not_create_update_caches: Optional[bool] = None,
         re_run_hl: Optional[bool] = None,
-        cache_library_cache_types: list[LibraryCacheTypes | str] = [LibraryCacheTypes.WEB],
+        cache_library_cache_types: list[LibraryCacheTypes | str] = [
+            LibraryCacheTypes.WEB
+        ],
         cache_reuse_dataset_cache: bool = False,
         cache_is_all_library_users: bool = False,
         delivery_notification_enabled: bool = False,
-        delivery_personal_notification_address_id: Optional[str] = None
+        delivery_personal_notification_address_id: Optional[str] = None,
     ):
         """
         Alter subscription.
 
         Args:
             name (str): name of the subscription,
             multiple_contents (bool, optional): whether multiple contents are
@@ -221,14 +245,16 @@
             delivery_mode (str, enum): the subscription delivery mode [EMAIL,
                 FILE, PRINTER, HISTORY_LIST, CACHE, MOBILE, FTP, SNAPSHOT,
                 PERSONAL_VIEW, SHARED_LINK, UNSUPPORTED],
             custom_msg (str, optional): customized message displayed when
                 Subscription has been successfully altered
             delivery_expiration_date (str): expiration date of the subscription,
                 format should be yyyy-MM-dd,
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription
             contact_security (bool): whether to use contact security for each
                 contact group member,
             filename (str): the filename that will be delivered when
                 the subscription is executed,
             compress (bool): whether to compress the file
             space_delimiter (str): space delimiter,
             email_subject (str): email subject associated with the subscription,
@@ -268,36 +294,47 @@
             cache_is_all_library_users (bool): Whether for all library users
             delivery_notification_enabled (bool): Whether notification is
                 enabled, notification applies to cache
             delivery_personal_notification_address_id (str, optional):
                 Notification details
         """
         # TODO Potentially remove if new subscription types are supported
-        if self.delivery.mode in ['SNAPSHOT', 'PERSONAL_VIEW', 'SHARED_LINK', 'UNSUPPORTED']:
+        if self.delivery.mode in [
+            'SNAPSHOT',
+            'PERSONAL_VIEW',
+            'SHARED_LINK',
+            'UNSUPPORTED',
+        ]:
             helper.exception_handler(
                 msg=f'{self.delivery.mode} subscription altering is not supported.',
-                exception_type=NotSupportedError
+                exception_type=NotSupportedError,
             )
         # Schedules logic
         schedules = self.__validate_schedules(schedules=schedules)
         if not schedules:
             schedules = [{'id': sch.id} for sch in self.schedules]
 
         # Content logic
         if contents:
             contents = self.__validate_contents(contents)
         else:
             contents = [cont.to_dict() for cont in self.contents]
 
         # Delivery logic
+        delivery_expiration_timezone = self.__validate_expiration_time_zone(
+            self.connection,
+            delivery_expiration_timezone,
+        )
         if delivery:
             temp_delivery = (
                 Delivery.from_dict(delivery) if isinstance(delivery, dict) else delivery
             )
         else:
+            personal_notification_address_id = delivery_personal_notification_address_id
+
             temp_delivery = self.__change_delivery_properties(
                 delivery_mode,
                 delivery_expiration_date,
                 contact_security,
                 email_subject,
                 email_message,
                 filename,
@@ -312,49 +349,54 @@
                 file_burst_sub_folder,
                 printer_copies,
                 printer_range_start,
                 printer_range_end,
                 printer_collated,
                 printer_orientation,
                 printer_use_print_range,
+                expiration_time_zone=delivery_expiration_timezone,
                 client_type=mobile_client_type,
                 device_id=device_id,
                 do_not_create_update_caches=do_not_create_update_caches,
                 re_run_hl=re_run_hl,
                 cache_type=cache_cache_type,
                 shortcut_cache_format=cache_shortcut_cache_format,
                 library_cache_types=cache_library_cache_types,
                 reuse_dataset_cache=cache_reuse_dataset_cache,
                 is_all_library_users=cache_is_all_library_users,
                 notification_enabled=delivery_notification_enabled,
-                personal_notification_address_id=delivery_personal_notification_address_id
+                personal_notification_address_id=personal_notification_address_id,
             )
         delivery = temp_delivery.to_dict(camel_case=True)
 
         # Recipients logic
         recipients = self.__is_val_changed(recipients=recipients)
         recipients = Subscription._validate_recipients(
             self.connection,
             contents,
             recipients,
             self.project_id,
             delivery['mode'],
-            self.recipients
+            self.recipients,
         )
 
         body = {
             "name": self.__is_val_changed(name=name),
             "allowDeliveryChanges": self.__is_val_changed(
                 allow_delivery_changes=allow_delivery_changes
             ),
-            "multipleContents": self.__is_val_changed(multiple_contents=multiple_contents),
+            "multipleContents": self.__is_val_changed(
+                multiple_contents=multiple_contents
+            ),
             "allowPersonalizationChanges": self.__is_val_changed(
                 allow_personalization_changes=allow_personalization_changes
             ),
-            "allowUnsubscribe": self.__is_val_changed(allow_unsubscribe=allow_unsubscribe),
+            "allowUnsubscribe": self.__is_val_changed(
+                allow_unsubscribe=allow_unsubscribe
+            ),
             "sendNow": send_now,
             'owner': {
                 'id': self.__is_val_changed(nested=self.owner.id, owner_id=owner_id)
             },
             "schedules": schedules,
             "contents": contents,
             "recipients": recipients,
@@ -379,63 +421,73 @@
     def __is_val_changed(self, nested=None, **kwargs):
         for key, value in kwargs.items():
             if nested:
                 return value if value != nested and value is not None else nested
             else:
                 current_val = self.__dict__.get(key)
                 # if not current_val: we need to get
-                return value if value != current_val and value is not None else current_val
+                return (
+                    value if value != current_val and value is not None else current_val
+                )
 
     @staticmethod
-    def __validate_schedules(schedules: str | list[str] | Schedule | list[Schedule] = None):
+    def __validate_schedules(
+        schedules: str | list[str] | Schedule | list[Schedule] = None,
+    ):
         tmp_schedules = []
         schedules = schedules if isinstance(schedules, list) else [schedules]
         schedules = [s for s in schedules if s is not None]
         for schedule in schedules:
             if isinstance(schedule, Schedule):
                 sch_id = schedule.id
             elif isinstance(schedule, str):
                 sch_id = schedule
             tmp_schedules.append({'id': sch_id})
 
         return tmp_schedules
 
     @staticmethod
-    def __validate_contents(contents: list[Content | dict] | Content | dict) -> list[dict]:
+    def __validate_contents(
+        contents: list[Content | dict] | Content | dict,
+    ) -> list[dict]:
         contents = contents if isinstance(contents, list) else [contents]
         content_type_msg = "Contents must be dictionaries or Content objects."
         return [
-            content.to_dict(camel_case=True) if isinstance(content, Content) else content if
-            isinstance(content, dict) else helper.exception_handler(content_type_msg, TypeError)
+            content.to_dict(camel_case=True)
+            if isinstance(content, Content)
+            else content
+            if isinstance(content, dict)
+            else helper.exception_handler(content_type_msg, TypeError)
             for content in contents
         ]
 
     def execute(self):
-        """Executes a subscription with given name or GUID for given project.
-        """
+        """Executes a subscription with given name or GUID for given project."""
         self.alter(
-            send_now=True, custom_msg=f"Executed subscription '{self.name}' with ID '{self.id}'."
+            send_now=True,
+            custom_msg=f"Executed subscription '{self.name}' with ID '{self.id}'.",
         )
 
     @method_version_handler('11.2.0203')
     def delete(self, force: bool = False) -> bool:
         """Delete a subscription. Returns True if deletion was successful.
 
         Args:
             force: If True, no additional prompt will be shown before deleting
         """
         user_input = 'N'
         if not force:
             user_input = input(
-                "Are you sure you want to delete subscription '{}' with ID: {}? [Y/N]: ".format(
-                    self.name, self.id
-                )
+                f"Are you sure you want to delete subscription '{self.name}' with ID: "
+                f"{self.id}? [Y/N]: "
             )
         if force or user_input == 'Y':
-            response = subscriptions.remove_subscription(self.connection, self.id, self.project_id)
+            response = subscriptions.remove_subscription(
+                self.connection, self.id, self.project_id
+            )
             if response.ok and config.verbose:
                 logger.info(f"Deleted subscription '{self.name}' with ID: {self.id}.")
             return response.ok
         else:
             return False
 
     @method_version_handler('11.3.0000')
@@ -468,15 +520,15 @@
 
     @method_version_handler('11.3.0000')
     def add_recipient(
         self,
         recipients: list[dict] | dict | list[str] | str = None,
         recipient_id: Optional[str] = None,
         recipient_type: Optional[str] = None,
-        recipient_include_type: str = 'TO'
+        recipient_include_type: str = 'TO',
     ):
         """Adds recipient to subscription. You can either specify id, type and
         include_type of single recipient, or just pass recipients list as a
         list of dictionaries.
 
         Args:
             recipients: list of ids or dicts containing recipients, dict format:
@@ -494,35 +546,36 @@
         else:
             recipients = []
         if recipient_id and recipient_type:
             recipients.append(
                 {
                     "id": recipient_id,
                     "type": recipient_type,
-                    "includeType": recipient_include_type
+                    "includeType": recipient_include_type,
                 }
             )
-        elif (recipients == [] and recipient_id is None) or (len(recipients) >= 1
-                                                             and recipient_id):
+        elif (recipients == [] and recipient_id is None) or (
+            len(recipients) >= 1 and recipient_id
+        ):
             msg = (
-                "Specify either a recipient ID, type and include type or pass recipients "
-                "dictionaries"
+                "Specify either a recipient ID, type and include type or pass "
+                "recipients dictionaries"
             )
             helper.exception_handler(msg, ValueError)
 
         all_recipients = self.recipients.copy()
         ready_recipients = self.__prepare_recipients(recipients)
 
         ready_recipients = self._validate_recipients(
             connection=self.connection,
             contents=self.contents,
             recipients=ready_recipients,
             project_id=self.project_id,
             delivery_mode=self.delivery.mode,
-            current_recipients=self.recipients
+            current_recipients=self.recipients,
         )
 
         if ready_recipients:
             all_recipients.extend(ready_recipients)
             self.alter(recipients=all_recipients)
         elif config.verbose:
             logger.info('No recipients were added to the subscription.')
@@ -540,35 +593,36 @@
         """
         all_recipients = self.recipients
         recipients = recipients if isinstance(recipients, list) else [recipients]
         existing_recipients = [rec['id'] for rec in self.recipients]
 
         if len(self.recipients) == 1:
             helper.exception_handler(
-                "Subscription must have at last one recipient. Add new recipient before removing."
+                "Subscription must have at last one recipient. Add new recipient "
+                "before removing."
             )
         for recipient in recipients:
             rec_id = recipient['id'] if isinstance(recipient, dict) else recipient
             if rec_id not in existing_recipients:
                 helper.exception_handler(
                     f"{rec_id} is not a recipient of subscription", UserWarning
                 )
             else:
                 all_recipients = [rec for rec in all_recipients if rec['id'] != rec_id]
         if len(all_recipients) == 0:
             helper.exception_handler(
-                "You cannot remove all existing recipients. Add new recipient before removing."
+                "You cannot remove all existing recipients. Add new recipient before "
+                "removing."
             )
         elif len(self.recipients) - len(all_recipients) > 0:
             self.alter(recipients=all_recipients)
         elif len(self.recipients) == len(all_recipients) and config.verbose:
             logger.info('No recipients were removed from the subscription.')
 
     def __prepare_recipients(self, recipients):
-
         existing_recipients = [rec['id'] for rec in self.recipients]
         ready_recipients = []
 
         def __already_recipient(recipient):
             if recipient in existing_recipients:
                 helper.exception_handler(
                     f"{recipient} is already a recipient of subscription", UserWarning
@@ -580,15 +634,18 @@
             not_dict_msg = """Wrong recipient format, expected format is
                               {"id": recipient_id,
                                "type": "CONTACT_GROUP" / "USER_GROUP" / "CONTACT" /
                                        "USER" / "PERSONAL_ADDRESS" / "UNSUPPORTED"
                                "includeType": "TO" / "CC" / "BCC" (optional)
                               }"""
             if isinstance(recipient, dict):
-                if list(recipient.keys()) in [['id', 'type', 'includeType'], ['id', 'type']]:
+                if list(recipient.keys()) in [
+                    ['id', 'type', 'includeType'],
+                    ['id', 'type'],
+                ]:
                     __already_recipient(recipient['id'])
                 else:
                     helper.exception_handler(not_dict_msg, TypeError)
             if isinstance(recipient, str):
                 __already_recipient(recipient)
         return ready_recipients
 
@@ -611,77 +668,88 @@
         burst_sub_folder: Optional[str] = None,
         copies: Optional[int] = None,
         range_start: Optional[int] = None,
         range_end: Optional[int] = None,
         collated: Optional[bool] = None,
         orientation: Optional[Orientation] = None,
         use_print_range: Optional[bool] = None,
+        expiration_time_zone: Optional[str] = None,
         cache_type: Optional[CacheType] = None,
         shortcut_cache_format: Optional[ShortcutCacheFormat] = None,
         client_type: Optional[ClientType] = None,
         device_id: Optional[str] = None,
         do_not_create_update_caches: Optional[bool] = None,
         re_run_hl: Optional[bool] = None,
         library_cache_types: list[LibraryCacheTypes | str] = [LibraryCacheTypes.WEB],
         reuse_dataset_cache: bool = False,
         is_all_library_users: bool = False,
         notification_enabled: bool = False,
         personal_notification_address_id: Optional[str] = None,
     ):
-
         func = self.__change_delivery_properties
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         # create dict of properties to be changed
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
 
         # 'zip_settings' is 'zip' in object
         if 'zip_settings' in properties.keys():
             properties['zip'] = properties.pop('zip_settings')
 
         obj_dict = self.delivery.VALIDATION_DICT
-        obj_mode_dict = self.delivery.__dict__[self.delivery.mode.lower()].VALIDATION_DICT
+        obj_mode_dict = self.delivery.__dict__[
+            self.delivery.mode.lower()
+        ].VALIDATION_DICT
         obj_mode_zip_dict = {
             "zip_filename": str,
             "zip_password": str,
             "zip_password_protect": bool,
         }
 
         if properties:  # at this point only not None values in properties
             for key, value in properties.items():
-                if key in obj_dict.keys():  # Highest level parameters. Mainly mode type and object
+                if (
+                    key in obj_dict.keys()
+                ):  # Highest level parameters. Mainly mode type and object
                     # Change mode or set attr if it's not mode param
                     if not self.delivery.change_mode(key, value):
                         self.delivery.__setattr__(key, value)
-                elif key in obj_mode_dict.keys():  # parameters of a particular mode e.g. of email
-                    helper.rsetattr(self.delivery, f'{self.delivery.mode.lower()}.{key}', value)
+                elif (
+                    key in obj_mode_dict.keys()
+                ):  # parameters of a particular mode e.g. of email
+                    helper.rsetattr(
+                        self.delivery, f'{self.delivery.mode.lower()}.{key}', value
+                    )
                 elif key in obj_mode_zip_dict.keys():  # zip settings
                     key = key[4:]
                     if not helper.rgetattr(
-                            self.delivery, f'{self.delivery.mode.lower()}.zip', None):
+                        self.delivery, f'{self.delivery.mode.lower()}.zip', None
+                    ):
                         helper.rsetattr(
-                            self.delivery, f'{self.delivery.mode.lower()}.zip', ZipSettings()
+                            self.delivery,
+                            f'{self.delivery.mode.lower()}.zip',
+                            ZipSettings(),
                         )
                     helper.rsetattr(
                         self.delivery, f'{self.delivery.mode.lower()}.zip.{key}', value
                     )
         return self.delivery
 
     @classmethod
     def from_dict(
         cls,
         source: dict[str, Any],
         connection: "Connection" = None,
         project_id: Optional[str] = None,
-        project_name: Optional[str] = None
+        project_name: Optional[str] = None,
     ) -> "Subscription":
         """Initialize Subscription object from dictionary.
         Specify either `project_id` or `project_name`.
         When `project_id` is provided (not `None`), `project_name` is omitted"""
         if source.get('project_id') and not project_id:
             project_id = source['project_id']
         project_id = get_valid_project_id(
@@ -696,60 +764,65 @@
         obj: Subscription = super().from_dict(_source, connection)
 
         return obj
 
     @classmethod
     @method_version_handler('11.3.0000')
     def __create(  # NOSONAR
-            cls,  # NOSONAR
-            connection: Connection,
-            name: str,
-            contents: Content | dict,
-            project_id: Optional[str] = None,
-            project_name: Optional[str] = None,
-            multiple_contents: Optional[bool] = None,
-            allow_delivery_changes: Optional[bool] = None,
-            allow_personalization_changes: Optional[bool] = None,
-            allow_unsubscribe: Optional[bool] = None,
-            send_now: Optional[bool] = None,
-            owner_id: Optional[str] = None,
-            schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
-            recipients: Optional[list[dict] | list[str]] = None,
-            delivery: Optional[Delivery | dict] = None,
-            delivery_mode: str = Delivery.DeliveryMode.EMAIL,
-            delivery_expiration_date: Optional[str] = None,
-            contact_security: bool = True,
-            filename: Optional[str] = None,
-            compress: bool = False,
-            space_delimiter: Optional[str] = None,
-            email_subject: Optional[str] = None,
-            email_message: Optional[str] = None,
-            email_send_content_as: str = SendContentAs.DATA,
-            overwrite_older_version: bool = False,
-            zip_filename: Optional[str] = None,
-            zip_password_protect: Optional[bool] = None,
-            zip_password: Optional[str] = None,
-            file_burst_sub_folder: Optional[str] = None,
-            printer_copies: int = 1,
-            printer_range_start: int = 0,
-            printer_range_end: int = 0,
-            printer_collated: bool = True,
-            printer_orientation: str = Orientation.PORTRAIT,
-            printer_use_print_range: bool = False,
-            cache_cache_type: CacheType | str = CacheType.RESERVED,
-            cache_shortcut_cache_format: ShortcutCacheFormat | str = ShortcutCacheFormat.RESERVED,
-            mobile_client_type: str = ClientType.RESERVED,
-            device_id: Optional[str] = None,
-            do_not_create_update_caches: bool = True,
-            re_run_hl: bool = True,
-            cache_library_cache_types: list[LibraryCacheTypes | str] = [LibraryCacheTypes.WEB],
-            cache_reuse_dataset_cache: bool = False,
-            cache_is_all_library_users: bool = False,
-            delivery_notification_enabled: bool = False,
-            delivery_personal_notification_address_id: Optional[str] = None):
+        cls,  # NOSONAR
+        connection: Connection,
+        name: str,
+        contents: Content | dict,
+        project_id: Optional[str] = None,
+        project_name: Optional[str] = None,
+        multiple_contents: Optional[bool] = None,
+        allow_delivery_changes: Optional[bool] = None,
+        allow_personalization_changes: Optional[bool] = None,
+        allow_unsubscribe: Optional[bool] = None,
+        send_now: Optional[bool] = None,
+        owner_id: Optional[str] = None,
+        schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
+        recipients: Optional[list[dict] | list[str]] = None,
+        delivery: Optional[Delivery | dict] = None,
+        delivery_mode: str = Delivery.DeliveryMode.EMAIL,
+        delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
+        contact_security: bool = True,
+        filename: Optional[str] = None,
+        compress: bool = False,
+        space_delimiter: Optional[str] = None,
+        email_subject: Optional[str] = None,
+        email_message: Optional[str] = None,
+        email_send_content_as: str = SendContentAs.DATA,
+        overwrite_older_version: bool = False,
+        zip_filename: Optional[str] = None,
+        zip_password_protect: Optional[bool] = None,
+        zip_password: Optional[str] = None,
+        file_burst_sub_folder: Optional[str] = None,
+        printer_copies: int = 1,
+        printer_range_start: int = 0,
+        printer_range_end: int = 0,
+        printer_collated: bool = True,
+        printer_orientation: str = Orientation.PORTRAIT,
+        printer_use_print_range: bool = False,
+        cache_cache_type: CacheType | str = CacheType.RESERVED,
+        cache_shortcut_cache_format: ShortcutCacheFormat
+        | str = ShortcutCacheFormat.RESERVED,
+        mobile_client_type: str = ClientType.RESERVED,
+        device_id: Optional[str] = None,
+        do_not_create_update_caches: bool = True,
+        re_run_hl: bool = True,
+        cache_library_cache_types: list[LibraryCacheTypes | str] = [
+            LibraryCacheTypes.WEB
+        ],
+        cache_reuse_dataset_cache: bool = False,
+        cache_is_all_library_users: bool = False,
+        delivery_notification_enabled: bool = False,
+        delivery_personal_notification_address_id: Optional[str] = None,
+    ):
         """Creates a subscription Create_Subscription_Outline.
 
         Args:
             connection (Connection): a MicroStrategy connection object
             name (str): name of the subscription,
             contents (Content): The content settings.
             project_id (str): project ID,
@@ -769,16 +842,18 @@
             schedules (str | list[str] | Schedule | List[Schedule]):
                 Schedules IDs or Schedule objects,
             recipients (list[dict], list[str]): list of recipients IDs or dicts,
             delivery (Delivery | dict): delivery object or dict
             delivery_mode (str, enum): the subscription delivery mode [EMAIL,
                 FILE, PRINTER, HISTORY_LIST, CACHE, MOBILE, FTP, SNAPSHOT,
                 PERSONAL_VIEW, SHARED_LINK, UNSUPPORTED],
-            delivery_expiration_date (str): expiration date of the subscription,
-                format should be yyyy-MM-dd,
+            delivery_expiration_date (str, optional): expiration date of the
+                subscription, format should be yyyy-MM-dd,
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription, example value 'Europe/London'
             contact_security (bool): whether to use contact security for each
                 contact group member,
             filename (str): the filename that will be delivered when
                 the subscription is executed,
             compress (bool): whether to compress the file,
             space_delimiter (str): space delimiter,
             email_subject (str): email subject associated with the subscription,
@@ -821,44 +896,58 @@
             delivery_personal_notification_address_id (str, optional):
                 Notification details
         """
         if connection._iserver_version <= '11.3.0100':
             cache_cache_type = LegacyCacheType[cache_cache_type.name]
         else:
             cache_cache_type = CacheType[cache_cache_type.name]
-        name = name if len(name) <= 255 else helper.exception_handler(
-            "Name too long. Max name length is 255 characters."
+        name = (
+            name
+            if len(name) <= 255
+            else helper.exception_handler(
+                "Name too long. Max name length is 255 characters."
+            )
         )
         project_id = get_valid_project_id(
             connection=connection,
             project_id=project_id,
             project_name=project_name,
-            with_fallback=False if project_name else True
+            with_fallback=False if project_name else True,
         )
 
         if not schedules:
             msg = "Please specify 'schedules' parameter."
             helper.exception_handler(msg)
 
         schedules = cls.__validate_schedules(schedules=schedules)
 
         # Content logic
         contents = contents if isinstance(contents, list) else [contents]
         content_type_msg = "Contents must be dictionaries or Content objects."
         contents = [
-            content.to_dict(camel_case=True) if isinstance(content, Content) else content if
-            isinstance(content, dict) else helper.exception_handler(content_type_msg, TypeError)
+            content.to_dict(camel_case=True)
+            if isinstance(content, Content)
+            else content
+            if isinstance(content, dict)
+            else helper.exception_handler(content_type_msg, TypeError)
             for content in contents
         ]
 
         # Delivery logic
+        delivery_expiration_timezone = cls.__validate_expiration_time_zone(
+            connection,
+            delivery_expiration_timezone,
+        )
         if delivery:
-            temp_delivery = Delivery.from_dict(delivery
-                                               ) if isinstance(delivery, dict) else delivery
+            temp_delivery = (
+                Delivery.from_dict(delivery) if isinstance(delivery, dict) else delivery
+            )
         else:
+            personal_notification_address_id = delivery_personal_notification_address_id
+
             temp_delivery = Delivery(
                 delivery_mode,
                 delivery_expiration_date,
                 contact_security,
                 email_subject,
                 email_message,
                 filename,
@@ -882,15 +971,16 @@
                 re_run_hl,
                 cache_type=cache_cache_type,
                 shortcut_cache_format=cache_shortcut_cache_format,
                 library_cache_types=cache_library_cache_types,
                 reuse_dataset_cache=cache_reuse_dataset_cache,
                 is_all_library_users=cache_is_all_library_users,
                 notification_enabled=delivery_notification_enabled,
-                personal_notification_address_id=delivery_personal_notification_address_id
+                personal_notification_address_id=personal_notification_address_id,
+                expiration_time_zone=delivery_expiration_timezone,
             )
         delivery = temp_delivery.to_dict(camel_case=True)
 
         # Recipients logic
         recipients = cls._validate_recipients(
             connection, contents, recipients, project_id, delivery['mode']
         )
@@ -898,40 +988,39 @@
         # Create body
         body = {
             "name": name,
             "allowDeliveryChanges": allow_delivery_changes,
             "allowPersonalizationChanges": allow_personalization_changes,
             "allowUnsubscribe": allow_unsubscribe,
             "sendNow": send_now,
-            "owner": {
-                "id": owner_id
-            },
+            "owner": {"id": owner_id},
             "schedules": schedules,
             "contents": contents,
             "recipients": recipients,
-            "delivery": delivery
+            "delivery": delivery,
         }
 
         body = helper.delete_none_values(body, recursion=True)
         response = subscriptions.create_subscription(connection, project_id, body)
         if config.verbose:
             unpacked_response = response.json()
-            logger.info(f"Created subscription '{name}' with ID: '{unpacked_response['id']}'.")
+            logger.info(
+                f"Created subscription '{name}' with ID: '{unpacked_response['id']}'."
+            )
         return cls.from_dict(response.json(), connection, project_id)
 
     @staticmethod
     def _validate_recipients(
         connection: "Connection",
         contents: list[Content | dict],
         recipients: list[str] | list[dict] | str,
         project_id: str,
         delivery_mode: str,
-        current_recipients: Optional[list[dict]] = None
+        current_recipients: Optional[list[dict]] = None,
     ):
-
         def __not_available(recipient):
             if recipient in available_recipients_ids:
                 rec = helper.filter_list_of_dicts(available_recipients, id=recipient)
                 formatted_recipients.append(rec[0])
             else:
                 msg = (
                     f"'{recipient}' is not a valid recipient ID for selected content "
@@ -939,33 +1028,48 @@
                     f"{pformat(available_recipients,indent=2)}"
                 )
                 helper.exception_handler(msg, ValueError)
 
         recipients = recipients if isinstance(recipients, list) else [recipients]
         body = {
             "contents": [
-                cont.to_dict() if isinstance(cont, Content) else cont for cont in contents
+                cont.to_dict() if isinstance(cont, Content) else cont
+                for cont in contents
             ]
         }
         available_recipients = subscriptions.available_recipients(
             connection, project_id, body, delivery_mode
         )
         if not current_recipients:
             current_recipients = []
-        available_recipients = available_recipients.json()['recipients'] + current_recipients
+        available_recipients = (
+            available_recipients.json()['recipients'] + current_recipients
+        )
         available_recipients_ids = [rec['id'] for rec in available_recipients]
         # Format recipients list if needed
         formatted_recipients = []
         if recipients:
             for recipient in recipients:
                 if isinstance(recipient, dict):
                     __not_available(recipient['id'])
                 elif isinstance(recipient, str):
                     __not_available(recipient)
                 else:
+                    recipient_type = type(recipient)
+
                     helper.exception_handler(
-                        "Recipients must be a dictionaries or a strings, not a {}".format(
-                            type(recipient)
-                        ),
-                        exception_type=TypeError
+                        "Recipients must be a dictionaries or a strings, "
+                        f"not a {recipient_type}",
+                        exception_type=TypeError,
                     )
         return formatted_recipients
+
+    @staticmethod
+    def __validate_expiration_time_zone(connection, expiration_time_zone):
+        if connection._iserver_version < '11.3.1000' and expiration_time_zone:
+            if config.verbose:
+                logger.info(
+                    'delivery_expiration_timezone argument is available from '
+                    'iServer Version 11.3.1000'
+                )
+        else:
+            return expiration_time_zone
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/cache_update_subscription.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/cache_update_subscription.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         subscription_id: Optional[str] = None,
         project_id: Optional[str] = None,
-        project_name: Optional[str] = None
+        project_name: Optional[str] = None,
     ):
         """Initialize CacheUpdateSubscription object, populates it with
         I-Server data if id or subscription_id is passed.
         Specify either `project_id` or `project_name`.
         When `project_id` is provided (not `None`), `project_name` is omitted.
 
         Args:
@@ -51,14 +51,15 @@
         send_now: Optional[bool] = None,
         owner_id: Optional[str] = None,
         schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
         contents: Optional[Content] = None,
         recipients: Optional[list[dict] | list[str]] = None,
         delivery: Optional[Delivery | dict] = None,
         delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
         contact_security: bool = True,
         cache_cache_type: Optional[CacheType | str] = None,
         cache_shortcut_cache_format: Optional[ShortcutCacheFormat | str] = None,
         cache_library_cache_types: Optional[list[LibraryCacheTypes | str]] = None,
         cache_reuse_dataset_cache: bool = False,
         cache_is_all_library_users: bool = False,
         delivery_notification_enabled: bool = False,
@@ -85,14 +86,16 @@
                 Schedules IDs or Schedule objects,
             contents (Content, optional): The content settings.
             recipients (list[str] | list[dict], optional): list of recipients
                 IDs or dicts,
             delivery (Delivery | dict, optional): delivery object or dict
             delivery_expiration_date (str, optional): expiration date of the
                 subscription, format should be yyyy - MM - dd,
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription, example value 'Europe/London'
             contact_security (bool): whether to use contact security for each
                 contact group member
             cache_cache_type (CacheType | str, optional):
                 [RESERVED, SHORTCUT, SHORTCUTWITHBOOKMARK]
             cache_shortcut_cache_format (ShortcutCacheFormat | str, optional):
                 [RESERVED, JSON, BINARY, BOTH]
             cache_library_cache_types (list[LibraryCacheTypes | str], optional):
@@ -101,14 +104,16 @@
             cache_reuse_dataset_cache (bool): Whether to reuse dataset cache
             cache_is_all_library_users (bool): Whether for all library users
             delivery_notification_enabled (bool): Whether notification is
                 enabled, notification applies to cache
             delivery_personal_notification_address_id (str, optional):
                 Notification details
         """
+        notification_address_id = delivery_personal_notification_address_id
+
         return super()._Subscription__create(
             connection=connection,
             name=name,
             project_id=project_id,
             project_name=project_name,
             allow_delivery_changes=allow_delivery_changes,
             allow_personalization_changes=allow_personalization_changes,
@@ -117,23 +122,25 @@
             owner_id=owner_id,
             schedules=schedules,
             contents=contents,
             recipients=recipients,
             delivery=delivery,
             delivery_mode=Delivery.DeliveryMode.CACHE,
             delivery_expiration_date=delivery_expiration_date,
+            delivery_expiration_timezone=delivery_expiration_timezone,
             contact_security=contact_security,
             cache_cache_type=cache_cache_type or CacheType.RESERVED,
             cache_shortcut_cache_format=cache_shortcut_cache_format
             or ShortcutCacheFormat.RESERVED,
-            cache_library_cache_types=cache_library_cache_types or [LibraryCacheTypes.WEB],
+            cache_library_cache_types=cache_library_cache_types
+            or [LibraryCacheTypes.WEB],
             cache_reuse_dataset_cache=cache_reuse_dataset_cache,
             cache_is_all_library_users=cache_is_all_library_users,
             delivery_notification_enabled=delivery_notification_enabled,
-            delivery_personal_notification_address_id=delivery_personal_notification_address_id,
+            delivery_personal_notification_address_id=notification_address_id,
         )
 
     def alter(
         cls,
         name: Optional[str] = None,
         allow_delivery_changes: Optional[bool] = None,
         allow_personalization_changes: Optional[bool] = None,
@@ -142,14 +149,15 @@
         owner_id: Optional[str] = None,
         schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
         contents: Optional[Content] = None,
         recipients: Optional[list[dict] | list[str]] = None,
         delivery: Optional[Delivery | dict] = None,
         custom_msg: Optional[str] = None,
         delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
         contact_security: bool = True,
         cache_cache_type: Optional[CacheType | str] = None,
         cache_shortcut_cache_format: Optional[ShortcutCacheFormat | str] = None,
         cache_library_cache_types: Optional[list[LibraryCacheTypes | str]] = None,
         cache_reuse_dataset_cache: bool = False,
         cache_is_all_library_users: bool = False,
         delivery_notification_enabled: bool = False,
@@ -173,14 +181,16 @@
                 Schedules IDs or Schedule objects,
             contents (Content, optional): The content settings.
             recipients (list[str] | list[dict], optional): list of recipients
                 IDs or dicts,
             delivery (Delivery | dict, optional): delivery object or dict
             delivery_expiration_date (str, optional): expiration date of the
                 subscription, format should be yyyy - MM - dd,
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription
             contact_security (bool): whether to use contact security for each
                 contact group member
             cache_cache_type (CacheType | str, optional):
                 [RESERVED, SHORTCUT, SHORTCUTWITHBOOKMARK]
             cache_shortcut_cache_format (ShortcutCacheFormat | str, optional):
                 [RESERVED, JSON, BINARY, BOTH]
             cache_library_cache_types (list[LibraryCacheTypes | str], optional):
@@ -189,30 +199,34 @@
             cache_reuse_dataset_cache (bool): Whether to reuse dataset cache
             cache_is_all_library_users (bool): Whether for all library users
             delivery_notification_enabled (bool): Whether notification is
                 enabled, notification applies to cache
             delivery_personal_notification_address_id (str, optional):
                 Notification details
         """
+        notification_address_id = delivery_personal_notification_address_id
+
         return super().alter(
             name=name,
             allow_delivery_changes=allow_delivery_changes,
             allow_personalization_changes=allow_personalization_changes,
             allow_unsubscribe=allow_unsubscribe,
             send_now=send_now,
             owner_id=owner_id,
             schedules=schedules,
             contents=contents,
             recipients=recipients,
             delivery=delivery,
             custom_msg=custom_msg,
             delivery_expiration_date=delivery_expiration_date,
+            delivery_expiration_timezone=delivery_expiration_timezone,
             contact_security=contact_security,
             cache_cache_type=cache_cache_type or CacheType.RESERVED,
             cache_shortcut_cache_format=cache_shortcut_cache_format
             or ShortcutCacheFormat.RESERVED,
-            cache_library_cache_types=cache_library_cache_types or [LibraryCacheTypes.WEB],
+            cache_library_cache_types=cache_library_cache_types
+            or [LibraryCacheTypes.WEB],
             cache_reuse_dataset_cache=cache_reuse_dataset_cache,
             cache_is_all_library_users=cache_is_all_library_users,
             delivery_notification_enabled=delivery_notification_enabled,
-            delivery_personal_notification_address_id=delivery_personal_notification_address_id
+            delivery_personal_notification_address_id=notification_address_id,
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/content.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/content.py`

 * *Files 3% similar despite different names*

```diff
@@ -23,15 +23,15 @@
         REPORT = auto()
         DOCUMENT = auto()
         CUBE = auto()
         DOSSIER = auto()
         UNSUPPORTED = auto()
 
     class Properties(Dictable):
-        """ Class representation of personalization properties
+        """Class representation of personalization properties
 
         Attributes:
             format_mode: Type that defines how much of the Report Services
                 document, which has group by units, should be delivered
             view_mode: Indicates the view mode that is supported by this format
             format_type: Content format mode
             export_to_pdf_settings: ExportToPdfSettings object which specifies
@@ -152,17 +152,16 @@
                 page_detail_level=PageDetailLevel.OVERVIEW,
                 include_header: bool = True,
                 include_footer: bool = True,
                 include_toc: bool = False,
                 filter_summary: FilterSummary = FilterSummary.BAR,
                 fit_to_page: bool = False,
                 repeat_column_header: bool = False,
-                grid_paging_mode: GridPagingMode = GridPagingMode.NONE
+                grid_paging_mode: GridPagingMode = GridPagingMode.NONE,
             ):
-
                 self.page_option = page_option
                 self.page_size = page_size
                 self.page_detail_level = page_detail_level
                 self.orientation = orientation
                 self.include_header = include_header
                 self.include_footer = include_footer
                 self.include_toc = include_toc
@@ -171,15 +170,15 @@
                 self.repeat_column_header = repeat_column_header
                 self.grid_paging_mode = grid_paging_mode
 
             _FROM_DICT_MAP = {
                 "page_option": PageOption,
                 "page_size": PageSize,
                 "orientation": Orientation,
-                "filter_summary": FilterSummary
+                "filter_summary": FilterSummary,
             }
 
         class Bursting(Dictable):
             """Bursting settings
 
             Attributes:
                 slicing_attributes: The list of attributes to slice on
@@ -189,25 +188,24 @@
             """
 
             def __init__(
                 self,
                 slicing_attributes: Optional[list[str]] = None,
                 address_attribute_id: Optional[str] = None,
                 device_id: Optional[str] = None,
-                form_id: Optional[str] = None
+                form_id: Optional[str] = None,
             ):
-                self.slicing_attributes = slicing_attributes if isinstance(
-                    slicing_attributes, list
-                ) else []
+                self.slicing_attributes = (
+                    slicing_attributes if isinstance(slicing_attributes, list) else []
+                )
                 self.address_attribute_id = address_attribute_id
                 self.device_id = device_id
                 self.form_id = form_id
 
         class Prompt(Dictable):
-
             def __init__(self, enabled: bool, instance_id: str = None):
                 self.enabled = enabled
                 self.instance_id = instance_id
 
         # Properties
         def __init__(
             self,
@@ -216,17 +214,16 @@
             format_type: FormatType = FormatType.PDF,
             export_to_pdf_settings: Optional[ExportToPdfSettings] = None,
             delimiter: Optional[str] = None,
             bursting: Optional[Bursting] = None,
             prompt: Optional[Prompt] = None,
             file_name: Optional[str] = None,
             content_modes: Optional[list[str]] = None,
-            bookmark_ids: Optional[list[str]] = None
+            bookmark_ids: Optional[list[str]] = None,
         ):
-
             self.format_mode = format_mode
             self.view_mode = view_mode
             self.format_type = format_type
             pdf_format = format_type in [self.FormatType.PDF, self.FormatType.PDF.value]
             self.export_to_pdf_settings = export_to_pdf_settings if pdf_format else None
             self.delimiter = delimiter
             self.bursting = bursting
@@ -237,15 +234,15 @@
 
         _FROM_DICT_MAP = {
             "format_mode": FormatMode,
             "view_mode": ViewMode,
             "format_type": FormatType,
             "export_to_pdf_settings": ExportToPdfSettings.from_dict,
             "bursting": Bursting.from_dict,
-            "prompt": Prompt.from_dict
+            "prompt": Prompt.from_dict,
         }
 
     class RefreshCondition(Dictable):
         """Dataset refresh condition settings
 
         Attributes:
             tables: List of TableRefreshInfo objects
@@ -254,16 +251,19 @@
                 setting value is not provided or empty.
             filters: list of SubscriptionFilter objects
         """
 
         class SubscriptionFilter(Dictable):
             """Subscription filter. The format of the subscription filters are
                 exactly the same as the view filters. Please refer to
-                https://lw.microstrategy.com/msdz/MSDL/GARelease_Current/docs/projects/RESTSDK/Content/topics/REST_API/REST_API_Filtering_RptsCubes_ViewFilter_CodeSamples.htm#multiple_filters_on_attribute_forms
-                for detailed information. But itshould be noted that
+                https://lw.microstrategy.com/msdz/MSDL/GARelease_Current/docs
+                /projects/RESTSDK/Content/topics/REST_API
+                /REST_API_Filtering_RptsCubes_ViewFilter_CodeSamples.htm
+                #multiple_filters_on_attribute_forms
+                for detailed information. But it should be noted that
                 subscription filters only support Filter on attribute forms
                 and Multiple filters on attribute forms.
 
             Attributes:
                 type: Filter type
                 expression: Metric limits
             """
@@ -297,72 +297,75 @@
 
                 # XXX: Should all of those be optional or all required or what?
                 def __init__(
                     self,
                     db_role_id: Optional[str] = None,
                     namespace: Optional[str] = None,
                     table_name: Optional[str] = None,
-                    url: Optional[str] = None
+                    url: Optional[str] = None,
                 ):
                     self.db_role_id = db_role_id
                     self.namespace = namespace
                     self.table_name = table_name
                     self.url = url
 
             # TableRefreshInfo
             def __init__(
                 self,
                 id: str,
                 refresh_policy: RefreshPolicy,
-                alternate_source: Optional[AlternateSource] = None
+                alternate_source: Optional[AlternateSource] = None,
             ):
                 self.id = id
                 self.refresh_policy = refresh_policy
                 self.alternate_source = alternate_source
 
             _FROM_DICT_MAP = {
-                "refresh_policy": RefreshPolicy, "alternate_source": AlternateSource.from_dict
+                "refresh_policy": RefreshPolicy,
+                "alternate_source": AlternateSource.from_dict,
             }
 
         # RefreshCondition
         def __init__(
             self,
             tables: list[TableRefreshInfo],
             dataset_refresh_policy: Optional[RefreshPolicy] = None,
-            filters: Optional[list[SubscriptionFilter]] = None
+            filters: Optional[list[SubscriptionFilter]] = None,
         ):
             self.tables = tables
             self.dataset_refresh_policy = dataset_refresh_policy
             self.filters = filters
 
         _FROM_DICT_MAP = {
             "dataset_refresh_policy": RefreshPolicy,
-            "tables": lambda tables,
-            connection:
-            [Content.RefreshCondition.TableRefreshInfo.from_dict(t, connection) for t in tables],
-            "filters": lambda filters,
-            connection: [
-                Content.RefreshCondition.SubscriptionFilter.from_dict(f, connection)  # noqa
+            "tables": lambda tables, connection: [
+                Content.RefreshCondition.TableRefreshInfo.from_dict(t, connection)
+                for t in tables
+            ],
+            "filters": lambda filters, connection: [
+                Content.RefreshCondition.SubscriptionFilter.from_dict(
+                    f, connection
+                )  # noqa
                 for f in filters
             ],
         }
 
     # Content
     def __init__(
         self,
         id: str,
         type: Type,
         name: Optional[str] = None,
         personalization: Optional[Properties] = None,
-        refresh_condition: Optional[RefreshCondition] = None
+        refresh_condition: Optional[RefreshCondition] = None,
     ):
         self.id = id
         self.type = type
         self.name = name
         self.personalization = personalization
         self.refresh_condition = refresh_condition
 
     _FROM_DICT_MAP = {
         "type": Type,
         "personalization": Properties.from_dict,
-        "refresh_condition": RefreshCondition.from_dict
+        "refresh_condition": RefreshCondition.from_dict,
     }
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/delivery.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/delivery.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from datetime import datetime
 from enum import auto
 from typing import Optional, Union
 
 from mstrio.utils.enum_helper import AutoName, AutoUpperName
-from mstrio.utils.helper import camel_to_snake, Dictable, exception_handler
+from mstrio.utils.helper import Dictable, camel_to_snake, exception_handler
 
 
 class SendContentAs(AutoName):
     DATA = auto()
     DATA_AND_HISTORY_LIST = auto()
     DATA_AND_LINK_AND_HISTORY_LIST = auto()
     LINK_AND_HISTORY_LIST = auto()
@@ -24,14 +24,15 @@
     SHORTCUTWITHBOOKMARK = 'shortcut_and_bookmark'
 
 
 class LegacyCacheType(AutoUpperName):
     """
     Available values when using environment with version 11.3.0100 or lower
     """
+
     RESERVED = auto()
     SHORTCUT = auto()
     SHORTCUTWITHBOOKMARK = auto()
     BOOKMARK = auto()
 
 
 class ShortcutCacheFormat(AutoUpperName):
@@ -53,15 +54,14 @@
     ANDROID = auto()
     ANDROID_AND_IOS = auto()
     IOS = auto()
     WEB = auto()
 
 
 class DeliveryDictable(Dictable):
-
     VALIDATION_DICT = {}
 
     @classmethod
     def from_dict(cls, source, **kwargs):
         """Initialize Delivery object from dictionary."""
         obj = cls.__new__(cls)
         super(DeliveryDictable, obj).__init__()
@@ -71,48 +71,52 @@
                 setattr(obj, key, ZipSettings.from_dict(value))
             else:
                 setattr(obj, key, value)
         return obj
 
     def validate(self):
         """Validate whether all obligatory properties of the Delivery object
-            are present and whether all the properties present are of
-            correct types."""
+        are present and whether all the properties present are of
+        correct types."""
         for key, value in self.__dict__.items():
             vtype = self.VALIDATION_DICT[key][0]
             obligatory = self.VALIDATION_DICT[key][1]
             if value and not isinstance(value, vtype):
                 exception_handler(
                     "{} has incorrect type {}. Correct type is {}.".format(
                         key, type(value), vtype
                     ),
-                    TypeError
+                    TypeError,
                 )
             elif value is None and obligatory:
-                exception_handler(f"{key} is obligatory and cannot be empty.", ValueError)
+                exception_handler(
+                    f"{key} is obligatory and cannot be empty.", ValueError
+                )
 
 
 class ZipSettings(DeliveryDictable):
     """Optional compression settings
 
     Attributes:
         filename: Filename of the compressed content
         password: Optional password for the compressed file
         password_protect: Whether to password protect file or not
     """
 
     VALIDATION_DICT = {
-        "filename": [str, False], "password": [str, False], "password_protect": [bool, False]
+        "filename": [str, False],
+        "password": [str, False],
+        "password_protect": [bool, False],
     }
 
     def __init__(
         self,
         filename: Optional[str] = None,
         password: Optional[str] = None,
-        password_protect: bool = False
+        password_protect: bool = False,
     ):
         self.filename = filename
         self.password = password if password_protect else None
         self.password_protect = password_protect
         self.validate()
 
 
@@ -168,45 +172,49 @@
         VALIDATION_DICT = {
             "subject": [str, True],
             "message": [str, False],
             "filename": [str, False],
             "space_delimiter": [str, False],
             "send_content_as": [str, False],
             "overwrite_older_version": [bool, False],
-            "zip": [ZipSettings, False]
+            "zip": [ZipSettings, False],
         }
 
         def __init__(
             self,
             subject: Optional[str] = None,
             message: Optional[str] = None,
             filename: Optional[str] = None,
             space_delimiter: Optional[str] = None,
             send_content_as: Optional[SendContentAs] = None,
             overwrite_older_version: bool = False,
-            zip: Optional[ZipSettings] = None
+            zip: Optional[ZipSettings] = None,
         ):
             self.subject = subject
             self.message = message
             self.filename = filename
             self.space_delimiter = space_delimiter
             self.send_content_as = send_content_as
             self.overwrite_older_version = overwrite_older_version
             self.zip = zip
             self.validate()
 
         def validate(self):
             """Validate whether all obligatory properties of the Delivery
-                object are present, whether all the properties present are
-                of correct types and whether the message and subject do
-                not exceed the charater limits."""
+            object are present, whether all the properties present are
+            of correct types and whether the message and subject do
+            not exceed the character limits."""
             if self.message and len(self.message) > 1000:
-                exception_handler("Message too long. Max message length is 1000 characters.")
+                exception_handler(
+                    "Message too long. Max message length is 1000 characters."
+                )
             if self.subject and len(self.subject) > 265:
-                exception_handler("Subject too long. Max subject length is 265 characters.")
+                exception_handler(
+                    "Subject too long. Max subject length is 265 characters."
+                )
             super().validate()
 
     class File(DeliveryDictable):
         """Delivery properties for File subscriptions
 
         Attributes:
             filename: The filename that will be delivered when the subscription
@@ -216,23 +224,23 @@
             zip: Optional compression settings object
         """
 
         VALIDATION_DICT = {
             "filename": [str, False],
             "space_delimiter": [str, False],
             "burst_sub_folder": [str, False],
-            "zip": [ZipSettings, False]
+            "zip": [ZipSettings, False],
         }
 
         def __init__(
             self,
             filename: Optional[str] = None,
             space_delimiter: Optional[str] = None,
             burst_sub_folder: Optional[str] = None,
-            zip: Optional[ZipSettings] = None
+            zip: Optional[ZipSettings] = None,
         ):
             self.filename = filename
             self.space_delimiter = space_delimiter
             self.burst_sub_folder = burst_sub_folder
             self.zip = zip
 
     class Printer(DeliveryDictable):
@@ -251,25 +259,25 @@
 
         VALIDATION_DICT = {
             "copies": [int, False],
             "range_start": [int, False],
             "range_end": [int, False],
             "collated": [bool, False],
             "orientation": [str, False],
-            "use_print_range": [bool, False]
+            "use_print_range": [bool, False],
         }
 
         def __init__(
             self,
             copies: Optional[int] = None,
             range_start: Optional[int] = None,
             range_end: Optional[int] = None,
             collated: bool = False,
             orientation: Orientation = Orientation.PORTRAIT.name,
-            use_print_range: bool = False
+            use_print_range: bool = False,
         ):
             self.copies = copies
             self.range_start = range_start
             self.range_end = range_end
             self.collated = collated
             self.orientation = orientation
             self.use_print_range = use_print_range
@@ -281,22 +289,24 @@
             filename: The filename that will be delivered when the subscription
                 is executed
             space_delimiter: The space delimiter
             zip: Optional compression settings object
         """
 
         VALIDATION_DICT = {
-            "filename": [str, False], "space_delimiter": [str, False], "zip": [ZipSettings, False]
+            "filename": [str, False],
+            "space_delimiter": [str, False],
+            "zip": [ZipSettings, False],
         }
 
         def __init__(
             self,
             space_delimiter: Optional[str] = None,
             filename: Optional[str] = None,
-            zip: Optional[ZipSettings] = None
+            zip: Optional[ZipSettings] = None,
         ):
             self.space_delimiter = space_delimiter
             self.filename = filename
             self.zip = zip
 
     class Cache(DeliveryDictable):
         """Delivery properties for Cache subscriptions
@@ -318,15 +328,15 @@
 
         def __init__(
             self,
             cache_type: CacheType = CacheType.RESERVED,
             shortcut_cache_format: ShortcutCacheFormat = ShortcutCacheFormat.RESERVED,
             library_cache_types: Optional[list[LibraryCacheTypes]] = None,
             reuse_dataset_cache: bool = False,
-            is_all_library_users: bool = False
+            is_all_library_users: bool = False,
         ):
             self.cache_type = cache_type
             self.shortcut_cache_format = shortcut_cache_format
             self.library_cache_types = library_cache_types
             self.reuse_dataset_cache = reuse_dataset_cache
             self.is_all_library_users = is_all_library_users
 
@@ -345,24 +355,24 @@
         """
 
         VALIDATION_DICT = {
             "client_type": [str, False],
             "device_id": [str, False],
             "do_not_create_update_caches": [bool, False],
             "overwrite_older_version": [bool, False],
-            "re_run_hl": [bool, False]
+            "re_run_hl": [bool, False],
         }
 
         def __init__(
             self,
             client_type: ClientType = ClientType.RESERVED.name,
             device_id: Optional[str] = None,
             do_not_create_update_caches: bool = False,
             overwrite_older_version: bool = False,
-            re_run_hl: bool = False
+            re_run_hl: bool = False,
         ):
             self.client_type = client_type
             self.device_id = device_id
             self.do_not_create_update_caches = do_not_create_update_caches
             self.overwrite_older_version = overwrite_older_version
             self.re_run_hl = re_run_hl
 
@@ -379,40 +389,41 @@
             re_run_hl: Whether the subscription will re-run against warehouse
         """
 
         VALIDATION_DICT = {
             "device_id": [str, False],
             "do_not_create_update_caches": [bool, False],
             "overwrite_older_version": [bool, False],
-            "re_run_hl": [bool, False]
+            "re_run_hl": [bool, False],
         }
 
         def __init__(
             self,
             device_id: Optional[str] = None,
             do_not_create_update_caches: bool = False,
             overwrite_older_version: bool = False,
-            re_run_hl: bool = False
+            re_run_hl: bool = False,
         ):
             self.device_id = device_id
             self.do_not_create_update_caches = do_not_create_update_caches
             self.overwrite_older_version = overwrite_older_version
             self.re_run_hl = re_run_hl
 
     VALIDATION_DICT = {
         "mode": [str, True],
         "expiration": [str, False],
+        "expiration_time_zone": [str, False],
         "contact_security": [bool, False],
         "email": [Email, False],
         "file": [File, False],
         "printer": [Printer, False],
         "ftp": [Ftp, False],
         "cache": [Cache, False],
         "mobile": [Mobile, False],
-        "history_list": [HistoryList, False]
+        "history_list": [HistoryList, False],
     }
 
     def __init__(
         self,
         mode=DeliveryMode.EMAIL.value,
         expiration: str = None,
         contact_security: Optional[bool] = None,
@@ -433,37 +444,42 @@
         collated: bool = False,
         orientation: Orientation = Orientation.PORTRAIT.name,
         use_print_range: bool = False,
         client_type: ClientType = ClientType.RESERVED.name,
         device_id: Optional[str] = None,
         do_not_create_update_caches: bool = False,
         re_run_hl: bool = False,
+        expiration_time_zone: Optional[str] = None,
         email: Optional[Email] = None,
         file: Optional[File] = None,
         cache_type: Union[CacheType, str] = CacheType.RESERVED,
-        shortcut_cache_format: Union[ShortcutCacheFormat, str] = ShortcutCacheFormat.RESERVED,
-        library_cache_types: list[Union[LibraryCacheTypes,
-                                        str]] = [LibraryCacheTypes.WEB],  # noqa: E501
+        shortcut_cache_format: Union[
+            ShortcutCacheFormat, str
+        ] = ShortcutCacheFormat.RESERVED,
+        library_cache_types: list[Union[LibraryCacheTypes, str]] = [
+            LibraryCacheTypes.WEB
+        ],
         reuse_dataset_cache: bool = False,
         is_all_library_users: bool = False,
         notification_enabled: bool = False,
-        personal_notification_address_id: Optional[str] = None
+        personal_notification_address_id: Optional[str] = None,
     ):
         self.mode = mode
         if expiration:
             if not self._expiration_check(expiration):
                 exception_handler(
                     "Expiration date must be later or equal to {}".format(
                         datetime.now().strftime("%Y-%m-%d")
                     ),
-                    ValueError
+                    ValueError,
                 )
             else:
                 self.expiration = expiration
         self.contact_security = contact_security
+        self.expiration_time_zone = expiration_time_zone
 
         if zip is None and compress:
             temp_zip = ZipSettings(filename, password, password_protect)
         elif zip is not None and compress:
             temp_zip = zip
         else:
             temp_zip = None
@@ -472,15 +488,15 @@
             self.email = self.Email(
                 subject,
                 message,
                 filename,
                 space_delimiter,
                 send_content_as,
                 overwrite_older_version,
-                temp_zip
+                temp_zip,
             )
         elif self.DeliveryMode(mode) == self.DeliveryMode.FILE:
             self.file = self.File(filename, space_delimiter, burst_sub_folder, temp_zip)
         elif self.DeliveryMode(mode) == self.DeliveryMode.PRINTER:
             self.printer = self.Printer(
                 copies, range_start, range_end, collated, orientation, use_print_range
             )
@@ -488,40 +504,47 @@
             self.ftp = self.Ftp(space_delimiter, filename, temp_zip)
         elif self.DeliveryMode(mode) == self.DeliveryMode.CACHE:
             self.cache = self.Cache(
                 cache_type,
                 shortcut_cache_format,
                 library_cache_types,
                 reuse_dataset_cache,
-                is_all_library_users
+                is_all_library_users,
             )
         elif self.DeliveryMode(mode) == self.DeliveryMode.MOBILE:
             self.mobile = self.Mobile(
                 client_type,
                 device_id,
                 do_not_create_update_caches,
                 overwrite_older_version,
-                re_run_hl
+                re_run_hl,
             )
         elif self.DeliveryMode(mode) == self.DeliveryMode.HISTORY_LIST:
             self.history_list = self.HistoryList(
-                device_id, do_not_create_update_caches, overwrite_older_version, re_run_hl
+                device_id,
+                do_not_create_update_caches,
+                overwrite_older_version,
+                re_run_hl,
             )
         if notification_enabled:
             self.notification_enabled = notification_enabled
-            self.personal_notification = {"address_id": personal_notification_address_id}
+            self.personal_notification = {
+                "address_id": personal_notification_address_id
+            }
 
     @classmethod
     def from_dict(cls, source, **kwargs):
         """Initialize Delivery object from dictionary."""
         obj = cls.__new__(cls)
         super(Delivery, obj).__init__()
         source = camel_to_snake(source)
         for key, value in source.items():
-            if not obj.change_mode(key, value):  # Change mode or set attr if its not mode param
+            if not obj.change_mode(
+                key, value
+            ):  # Change mode or set attr if its not mode param
                 setattr(obj, key, value)
         return obj
 
     def change_mode(self, mode_name: str, mode_value) -> bool:
         """Change mode of the Delivery object.
         Return True on success, False if `mode_name` was invalid.
         """
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/dynamic_recipient_list.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/dynamic_recipient_list.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,28 +10,28 @@
 from mstrio.utils.entity import EntityBase, DeleteMixin
 from mstrio.utils.helper import (
     delete_none_values,
     Dictable,
     exception_handler,
     fetch_objects_async,
     filter_params_for_func,
-    get_valid_project_id
+    get_valid_project_id,
 )
 from mstrio.utils.version_helper import class_version_handler
 
 logger = logging.getLogger(__name__)
 
 
 def list_dynamic_recipient_lists(
     connection: Connection,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> list["DynamicRecipientList"] | list[dict]:
     """Get list of Dynamic Recipient List objects or dicts with them.
 
     Note:
         When `project_id` is specified, `project_name` is omitted.
         If neither is specified then `project_id` from `connection` object
         is taken.
@@ -41,47 +41,52 @@
             `connection.Connection()`
         project_id (str, optional): ID of the project to list the metrics from
         project_name (str, optional): name of the project
         to_dictionary (bool, optional): If True returns list of dictionaries,
             by default (False) returns DynamicRecipientList objects
         limit (integer, optional): limit the number of elements returned. If
             None all object are returned
-        **filters: parameters to filter the search on, for example `name`
+        **filters: Available filter parameters: ['name', 'id', 'description',
+            'source_report_id', 'physical_address', 'linked_user', 'device']
 
     Returns:
         list with DynamicRecipientList objects or list of dictionaries
     """
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
         project_name=project_name,
-        with_fallback=False if project_name else True
+        with_fallback=False if project_name else True,
     )
 
     msg = "Error getting Dynamic Recipient List list."
-    chunk_size = 1000 if version.parse(connection.iserver_version
-                                       ) >= version.parse('11.3.0300') else 1000000
+    chunk_size = (
+        1000
+        if version.parse(connection.iserver_version) >= version.parse('11.3.0300')
+        else 1000000
+    )
 
     objects = fetch_objects_async(
         connection=connection,
         api=subscriptions.list_dynamic_recipient_lists,
         async_api=subscriptions.list_dynamic_recipient_lists_async,
         limit=limit,
         chunk_size=chunk_size,
         filters=filters,
         error_msg=msg,
         dict_unpack_value='listOfDynamicRecipientLists',
-        project_id=project_id
+        project_id=project_id,
     )
 
     if to_dictionary:
         return objects
     else:
         return [
-            DynamicRecipientList.from_dict(connection=connection, source=obj) for obj in objects
+            DynamicRecipientList.from_dict(connection=connection, source=obj)
+            for obj in objects
         ]
 
 
 @class_version_handler('11.3.0600')
 class DynamicRecipientList(EntityBase, DeleteMixin):
     """Python representation of MicroStrategy DynamicRecipientList object.
 
@@ -94,24 +99,25 @@
         physical_address: Physical Address for the DynamicRecipientList
         linked_user: Linked User for the DynamicRecipientList
         device: Device for the DynamicRecipientList
         recipient_name: Recipient Name for the DynamicRecipientList
         notification_address: Notification Address for the DynamicRecipientList
         notification_device: Notification Device for the DynamicRecipientList
         personalization: Personalization for the DynamicRecipientList
-        """
+    """
 
     @dataclass
     class MappingField(Dictable):
         """Python representation of a Mapping Field.
 
         Attributes:
             attribute_id: ID of the mapped attribute
             attribute_form_id: ID of the mapped attribute's form
-            """
+        """
+
         attribute_id: str
         attribute_form_id: str
 
     _API_GETTERS = {
         (
             'id',
             'name',
@@ -119,51 +125,51 @@
             'source_report_id',
             'physical_address',
             'linked_user',
             'device',
             'recipient_name',
             'notification_address',
             'notification_device',
-            'personalization'
+            'personalization',
         ): subscriptions.get_dynamic_recipient_list
     }
     _API_PATCH = {
         (
             'id',
             'name',
             'description',
             'source_report_id',
             'physical_address',
             'linked_user',
             'device',
             'recipient_name',
             'notification_address',
             'notification_device',
-            'personalization'
+            'personalization',
         ): (subscriptions.update_dynamic_recipient_list, 'partial_put')
     }
     _API_DELETE = staticmethod(subscriptions.remove_dynamic_recipient_list)
     _FROM_DICT_MAP = {
         **EntityBase._FROM_DICT_MAP,
         'physical_address': MappingField.from_dict,
         'linked_user': MappingField.from_dict,
         'device': MappingField.from_dict,
         'recipient_name': MappingField.from_dict,
         'notification_address': MappingField.from_dict,
         'notification_device': MappingField.from_dict,
-        'personalization': MappingField.from_dict
+        'personalization': MappingField.from_dict,
     }
 
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         name: Optional[str] = None,
         project_id: Optional[str] = None,
-        project_name: Optional[str] = None
+        project_name: Optional[str] = None,
     ) -> None:
         """Initializes a new instance of a DynamicRecipientList class
 
         Args:
             connection (Connection): MicroStrategy connection object returned
                 by `connection.Connection()`
             id (str, optional): DynamicRecipientList's ID. Defaults to None
@@ -180,50 +186,68 @@
         if not id:
             if name:
                 dynamic_recipient_list = self.__find_dynamic_recipient_list_by_name(
                     connection=connection, name=name
                 )
                 id = dynamic_recipient_list['id']
             else:
-                exception_handler(msg='Must provide valid id or name', exception_type=ValueError)
+                exception_handler(
+                    msg='Must provide valid id or name', exception_type=ValueError
+                )
         project_id = get_valid_project_id(
             connection=connection,
             project_id=project_id,
             project_name=project_name,
-            with_fallback=False if project_name else True
+            with_fallback=False if project_name else True,
+        )
+        super().__init__(
+            connection=connection, object_id=id, name=name, project_id=project_id
         )
-        super().__init__(connection=connection, object_id=id, name=name, project_id=project_id)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self.name = kwargs.get('name')
         self.project_id = kwargs.get('project_id')
         self.description = kwargs.get('description')
         self.source_report_id = kwargs.get('source_report_id')
-        self.physical_address = DynamicRecipientList.MappingField.from_dict(paddress) if (
-            paddress := kwargs.get('physical_address')
-        ) else None
-        self.linked_user = DynamicRecipientList.MappingField.from_dict(luser) if (
-            luser := kwargs.get('linked_user')
-        ) else None
-        self.device = DynamicRecipientList.MappingField.from_dict(dvc) if (
-            dvc := kwargs.get('device')
-        ) else None
-        self.recipient_name = DynamicRecipientList.MappingField.from_dict(rname) if (
-            rname := kwargs.get('recipient_name')
-        ) else None
-        self.notification_address = DynamicRecipientList.MappingField.from_dict(naddress) if (
-            naddress := kwargs.get('notification_address')
-        ) else None
-        self.notification_device = DynamicRecipientList.MappingField.from_dict(ndevice) if (
-            ndevice := kwargs.get('notification_device')
-        ) else None
-        self.personalization = DynamicRecipientList.MappingField.from_dict(prsnlz) if (
-            prsnlz := kwargs.get('personalization')
-        ) else None
+        self.physical_address = (
+            DynamicRecipientList.MappingField.from_dict(paddress)
+            if (paddress := kwargs.get('physical_address'))
+            else None
+        )
+        self.linked_user = (
+            DynamicRecipientList.MappingField.from_dict(luser)
+            if (luser := kwargs.get('linked_user'))
+            else None
+        )
+        self.device = (
+            DynamicRecipientList.MappingField.from_dict(dvc)
+            if (dvc := kwargs.get('device'))
+            else None
+        )
+        self.recipient_name = (
+            DynamicRecipientList.MappingField.from_dict(rname)
+            if (rname := kwargs.get('recipient_name'))
+            else None
+        )
+        self.notification_address = (
+            DynamicRecipientList.MappingField.from_dict(naddress)
+            if (naddress := kwargs.get('notification_address'))
+            else None
+        )
+        self.notification_device = (
+            DynamicRecipientList.MappingField.from_dict(ndevice)
+            if (ndevice := kwargs.get('notification_device'))
+            else None
+        )
+        self.personalization = (
+            DynamicRecipientList.MappingField.from_dict(prsnlz)
+            if (prsnlz := kwargs.get('personalization'))
+            else None
+        )
 
     @classmethod
     def create(
         cls,
         connection: Connection,
         name: str,
         source_report_id: str,
@@ -232,15 +256,15 @@
         device: MappingField,
         project_id: Optional[str] = None,
         project_name: Optional[str] = None,
         description: Optional[str] = None,
         recipient_name: Optional[MappingField] = None,
         notification_address: Optional[MappingField] = None,
         notification_device: Optional[MappingField] = None,
-        personalization: Optional[MappingField] = None
+        personalization: Optional[MappingField] = None,
     ) -> "DynamicRecipientList":
         """Create a new DynamicRecipientList with specified properties.
 
         Args:
             name (string): DynamicRecipientList's name
             source_report_id (string): ID of the Report that is the source of
                 the DynamicRecipientList
@@ -278,31 +302,34 @@
             'physicalAddress': physical_address.to_dict(),
             'linkedUser': linked_user.to_dict(),
             'device': device.to_dict(),
             'recipientName': recipient_name.to_dict() if recipient_name else None,
             'notificationAddress': (
                 notification_address.to_dict() if notification_address else None
             ),
-            'notificationDevice': (notification_device.to_dict() if notification_device else None),
-            'personalization': personalization.to_dict() if personalization else None
+            'notificationDevice': (
+                notification_device.to_dict() if notification_device else None
+            ),
+            'personalization': personalization.to_dict() if personalization else None,
         }
         body = delete_none_values(source=body, recursion=True)
         project_id = get_valid_project_id(
             connection=connection,
             project_id=project_id,
             project_name=project_name,
-            with_fallback=False if project_name else True
+            with_fallback=False if project_name else True,
         )
         response = subscriptions.create_dynamic_recipient_list(
             connection=connection, project_id=project_id, body=body
         ).json()
 
         if config.verbose:
             logger.info(
-                f"Created Dynamic Recipient List named: '{name}' with ID: '{response['id']}'"
+                f"Created Dynamic Recipient List named: '{name}' with ID: '"
+                f"{response['id']}'"
             )
 
         return cls.from_dict(source={**response}, connection=connection)
 
     def alter(
         self,
         name: Optional[str] = None,
@@ -310,15 +337,15 @@
         physical_address: Optional[MappingField] = None,
         linked_user: Optional[MappingField] = None,
         device: Optional[MappingField] = None,
         description: Optional[str] = None,
         recipient_name: Optional[MappingField] = None,
         notification_address: Optional[MappingField] = None,
         notification_device: Optional[MappingField] = None,
-        personalization: Optional[MappingField] = None
+        personalization: Optional[MappingField] = None,
     ) -> None:
         """Alter a DynamicRecipientList's specified properties
 
         Note:
             If one alters the source_report_id, all existing Mapping Fields
             also need to be updated to reflect the new source report.
 
@@ -355,20 +382,24 @@
         notification_device = notification_device or self.notification_device
         personalization = personalization or self.personalization
         properties = filter_params_for_func(self.alter, locals(), exclude=['self'])
         self._alter_properties(**properties)
 
     @staticmethod
     def __find_dynamic_recipient_list_by_name(connection: "Connection", name: str):
-        dynamic_recipient_lists = list_dynamic_recipient_lists(connection=connection, name=name)
+        dynamic_recipient_lists = list_dynamic_recipient_lists(
+            connection=connection, name=name
+        )
 
         if dynamic_recipient_lists:
             number_of_drls = len(dynamic_recipient_lists)
             if number_of_drls > 1:
                 raise ValueError(
                     f"There are {number_of_drls} Dynamic Recipient Lists"
                     " with this name. Please initialize with id."
                 )
             else:
                 return dynamic_recipient_lists[0].to_dict()
         else:
-            raise ValueError(f"There is no DynamicRecipientList with the given name: '{name}'")
+            raise ValueError(
+                f"There is no DynamicRecipientList with the given name: '{name}'"
+            )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/email_subscription.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/email_subscription.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         subscription_id: Optional[str] = None,
         project_id: Optional[str] = None,
-        project_name: Optional[str] = None
+        project_name: Optional[str] = None,
     ):
         """Initialize EmailSubscription object, populates it with I-Server data
         if id or subscription_id is passed.
         Specify either `project_id` or `project_name`.
         When `project_id` is provided (not `None`), `project_name` is omitted.
 
         Args:
@@ -48,25 +48,26 @@
         allow_unsubscribe: bool = True,
         send_now: Optional[bool] = None,
         owner_id: Optional[str] = None,
         schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
         contents: Optional[Content] = None,
         recipients: list[str] | list[dict] = None,
         delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
         contact_security: Optional[bool] = None,
         space_delimiter: Optional[str] = None,
         email_subject: Optional[str] = None,
         email_message: Optional[str] = None,
         email_send_content_as: str = 'data',
         overwrite_older_version: bool = False,
         filename: Optional[str] = None,
         compress: bool = False,
         zip_filename: Optional[str] = None,
         zip_password_protect: Optional[bool] = None,
-        zip_password: Optional[str] = None
+        zip_password: Optional[str] = None,
     ):
         """Creates a new email subscription.
 
         Args:
             connection (Connection): a MicroStrategy connection object
             name (str): name of the subscription,
             project_id (str, optional): project ID,
@@ -84,14 +85,16 @@
             schedules (str | list[str] | Schedule | list[Schedule], optional):
                 Schedules IDs or Schedule objects,
             contents (Content, optional): The content settings.
             recipients (list[str] | list[dict], optional): list of recipients
                 IDs or dicts,
             delivery_expiration_date (str, optional): expiration date of the
                 subscription, format should be yyyy - MM - dd,
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription, example value 'Europe/London'
             contact_security (bool): whether to use contact security for each
                 contact group member
             filename (str, optional): the filename that will be delivered when
                 the subscription is executed,
             compress (bool): whether to compress the file
             space_delimiter (str, optional): space delimiter,
             email_subject (str, optional): email subject associated with
@@ -119,19 +122,20 @@
             send_now=send_now,
             owner_id=owner_id,
             schedules=schedules,
             contents=contents,
             recipients=recipients,
             delivery_mode='EMAIL',
             delivery_expiration_date=delivery_expiration_date,
+            delivery_expiration_timezone=delivery_expiration_timezone,
             contact_security=contact_security,
             email_subject=email_subject,
             email_message=email_message,
             filename=filename,
             compress=compress,
             space_delimiter=space_delimiter,
             email_send_content_as=email_send_content_as,
             overwrite_older_version=overwrite_older_version,
             zip_filename=zip_filename,
             zip_password_protect=zip_password_protect,
-            zip_password=zip_password
+            zip_password=zip_password,
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/file_subscription.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/file_subscription.py`

 * *Files 4% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         subscription_id: Optional[str] = None,
         project_id: Optional[str] = None,
-        project_name: Optional[str] = None
+        project_name: Optional[str] = None,
     ):
         """Initializes FileSubscription object and populates it with
         I-Server data if id or subscription_id is passed.
         Specify either `project_id` or `project_name`.
         When `project_id` is provided (not `None`), `project_name` is omitted.
 
         Args:
@@ -51,22 +51,23 @@
         send_now: Optional[bool] = None,
         owner_id: Optional[str] = None,
         schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
         contents: Optional[Content] = None,
         recipients: Optional[list[dict] | list[str]] = None,
         delivery: Optional[Delivery | dict] = None,
         delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
         contact_security: bool = True,
         zip_filename: Optional[str] = None,
         zip_password_protect: Optional[bool] = None,
         zip_password: Optional[str] = None,
         file_burst_sub_folder: Optional[str] = None,
         space_delimiter: Optional[str] = None,
         delivery_notification_enabled: bool = False,
-        delivery_personal_notification_address_id: Optional[str] = None
+        delivery_personal_notification_address_id: Optional[str] = None,
     ) -> "FileSubscription":
         """Creates a new file subscription.
         Args:
             connection (Connection): a MicroStrategy connection object
             name (str): name of the subscription
             filename (str): the filename that will be delivered when
                 the subscription is executed
@@ -88,28 +89,32 @@
                 Schedules IDs or Schedule objects
             contents (Content, optional): The content settings
             recipients (list[dict] | dict, optional): list of recipients IDs
                 or dicts
             delivery (dict | Delivery, optional): delivery object or dict
             delivery_expiration_date (string, optional): expiration date
                 of the subscription, format should be yyyy - MM - dd
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription, example value 'Europe/London'
             contact_security (bool): whether to use contact security for each
                 contact group member
             zip_filename(str, optional): filename of the compressed content
             zip_password_protect(bool, optional): whether to password protect
                 zip file
             zip_password(str, optional): optional password for the compressed
                 file
             file_burst_sub_folder(str, optional): burst sub folder
             space_delimiter(str, optional): space delimiter
             delivery_notification_enabled (bool): Whether notification is
                 enabled, notification applies to cache
             delivery_personal_notification_address_id (str, optional):
                 Notification details
         """
+        notification_address_id = delivery_personal_notification_address_id
+
         return super()._Subscription__create(
             connection=connection,
             name=name,
             filename=filename,
             project_id=project_id,
             project_name=project_name,
             multiple_contents=multiple_contents,
@@ -120,22 +125,23 @@
             owner_id=owner_id,
             schedules=schedules,
             contents=contents,
             recipients=recipients,
             delivery=delivery,
             delivery_mode=Delivery.DeliveryMode.FILE,
             delivery_expiration_date=delivery_expiration_date,
+            delivery_expiration_timezone=delivery_expiration_timezone,
             contact_security=contact_security,
             zip_filename=zip_filename,
             zip_password_protect=zip_password_protect,
             zip_password=zip_password,
             file_burst_sub_folder=file_burst_sub_folder,
             space_delimiter=space_delimiter,
             delivery_notification_enabled=delivery_notification_enabled,
-            delivery_personal_notification_address_id=delivery_personal_notification_address_id
+            delivery_personal_notification_address_id=notification_address_id,
         )
 
     def alter(
         self,
         name: Optional[str] = None,
         filename: Optional[str] = None,
         multiple_contents: Optional[bool] = None,
@@ -145,22 +151,23 @@
         send_now: Optional[bool] = None,
         owner_id: Optional[str] = None,
         schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
         recipients: Optional[list[dict] | list[str]] = None,
         delivery: Optional[Delivery | dict] = None,
         custom_msg: Optional[str] = None,
         delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
         contact_security: bool = True,
         zip_filename: Optional[str] = None,
         zip_password_protect: Optional[bool] = None,
         zip_password: Optional[str] = None,
         file_burst_sub_folder: Optional[str] = None,
         space_delimiter: Optional[str] = None,
         delivery_notification_enabled: bool = False,
-        delivery_personal_notification_address_id: Optional[str] = None
+        delivery_personal_notification_address_id: Optional[str] = None,
     ):
         """Alter the subscription.
         Args:
             name (str, optional): name of the subscription
             filename (str): the filename that will be delivered when
                 the subscription is executed
             multiple_contents (bool, optional): whether multiple contents are
@@ -176,46 +183,51 @@
             owner_id (str, optional): ID of the subscription owner, by
                 default logged in user ID
             schedules (list[str] | str | Schedule | list[Schedule], optional):
                 Schedules IDs or Schedule objects
             recipients (list[dict] | dict, optional): list of recipients IDs
                 or dicts
             delivery (dict | Delivery, optional): delivery object or dict
-            delivery_expiration_date (string, optional): expiration date
+            delivery_expiration_date (str, optional): expiration date
                 of the subscription, format should be yyyy - MM - dd
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription
             contact_security (bool): whether to use contact security for each
                 contact group member
             zip_filename(str, optional): filename of the compressed content
             zip_password_protect(bool, optional): whether to password protect
                 zip file
             zip_password(str, optional): optional password for the compressed
                 file
             file_burst_sub_folder(str, optional): burst sub folder
             space_delimiter(str, optional): space delimiter
             delivery_notification_enabled (bool): Whether notification is
                 enabled, notification applies to cache
             delivery_personal_notification_address_id (str, optional):
                 Notification details
         """
+        notification_address_id = delivery_personal_notification_address_id
+
         return super().alter(
             name=name,
             filename=filename,
             multiple_contents=multiple_contents,
             allow_delivery_changes=allow_delivery_changes,
             allow_personalization_changes=allow_personalization_changes,
             allow_unsubscribe=allow_unsubscribe,
             send_now=send_now,
             owner_id=owner_id,
             schedules=schedules,
             recipients=recipients,
             delivery=delivery,
             custom_msg=custom_msg,
             delivery_expiration_date=delivery_expiration_date,
+            delivery_expiration_timezone=delivery_expiration_timezone,
             contact_security=contact_security,
             zip_filename=zip_filename,
             zip_password_protect=zip_password_protect,
             zip_password=zip_password,
             file_burst_sub_folder=file_burst_sub_folder,
             space_delimiter=space_delimiter,
             delivery_notification_enabled=delivery_notification_enabled,
-            delivery_personal_notification_address_id=delivery_personal_notification_address_id
+            delivery_personal_notification_address_id=notification_address_id,
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/ftp_subscription.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/ftp_subscription.py`

 * *Files 4% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         subscription_id: Optional[str] = None,
         project_id: Optional[str] = None,
-        project_name: Optional[str] = None
+        project_name: Optional[str] = None,
     ):
         """Initializes FTPSubscription object and populates it with
         I-Server data if id or subscription_id is passed.
         Specify either `project_id` or `project_name`.
         When `project_id` is provided (not `None`), `project_name` is omitted.
         Args:
             connection (Connection): MicroStrategy connection object returned
@@ -51,20 +51,21 @@
         send_now: Optional[bool] = None,
         owner_id: Optional[str] = None,
         schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
         contents: Optional[Content] = None,
         recipients: Optional[list[dict] | list[str]] = None,
         delivery: Optional[Delivery | dict] = None,
         delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
         contact_security: bool = True,
         zip_filename: Optional[str] = None,
         zip_password_protect: Optional[bool] = None,
         zip_password: Optional[str] = None,
         delivery_notification_enabled: bool = False,
-        delivery_personal_notification_address_id: Optional[str] = None
+        delivery_personal_notification_address_id: Optional[str] = None,
     ) -> "FTPSubscription":
         """Creates a new FTP subscription.
         Args:
             connection (Connection): a MicroStrategy connection object
             name (str): name of the subscription
             space_delimiter(str): space delimiter,
             filename (str): the filename that will be delivered when
@@ -85,29 +86,33 @@
                 default logged in user ID
             schedules (list[str] | str | Schedule | list[Schedule], optional):
                 Schedules IDs or Schedule objects
             contents (Content, optional): The content settings
             recipients (list[dict] | dict, optional): list of recipients IDs
                 or dicts
             delivery (dict | Delivery, optional): delivery object or dict
-            delivery_expiration_date (string, optional): expiration date
+            delivery_expiration_date (str, optional): expiration date
                 of the subscription, format should be yyyy - MM - dd
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription, example value 'Europe/London'
             contact_security (bool): whether to use contact security for each
                 contact group member
             zip_filename(str, optional): filename of the compressed content
             zip_password_protect(bool, optional): whether to password protect
                 zip file
             zip_password(str, optional): optional password for the compressed
                 file
             space_delimiter(str, optional): space delimiter
             delivery_notification_enabled (bool): Whether notification is
                 enabled, notification applies to cache
             delivery_personal_notification_address_id (str, optional):
                 Notification details
         """
+        notification_address_id = delivery_personal_notification_address_id
+
         return super()._Subscription__create(
             connection=connection,
             name=name,
             space_delimiter=space_delimiter,
             filename=filename,
             project_id=project_id,
             project_name=project_name,
@@ -119,20 +124,21 @@
             owner_id=owner_id,
             schedules=schedules,
             contents=contents,
             recipients=recipients,
             delivery=delivery,
             delivery_mode=Delivery.DeliveryMode.FTP,
             delivery_expiration_date=delivery_expiration_date,
+            delivery_expiration_timezone=delivery_expiration_timezone,
             contact_security=contact_security,
             zip_filename=zip_filename,
             zip_password_protect=zip_password_protect,
             zip_password=zip_password,
             delivery_notification_enabled=delivery_notification_enabled,
-            delivery_personal_notification_address_id=delivery_personal_notification_address_id
+            delivery_personal_notification_address_id=notification_address_id,
         )
 
     def alter(
         self,
         name: Optional[str] = None,
         filename: Optional[str] = None,
         multiple_contents: Optional[bool] = None,
@@ -142,21 +148,22 @@
         send_now: Optional[bool] = None,
         owner_id: Optional[str] = None,
         schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
         recipients: Optional[list[dict] | list[str]] = None,
         delivery: Optional[Delivery | dict] = None,
         custom_msg: Optional[str] = None,
         delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
         contact_security: bool = True,
         zip_filename: Optional[str] = None,
         zip_password_protect: Optional[bool] = None,
         zip_password: Optional[str] = None,
         space_delimiter: Optional[str] = None,
         delivery_notification_enabled: bool = False,
-        delivery_personal_notification_address_id: Optional[str] = None
+        delivery_personal_notification_address_id: Optional[str] = None,
     ):
         """Alter the subscription.
         Args:
             name (str, optional): name of the subscription
             filename (str): the filename that will be delivered when
                 the subscription is executed
             multiple_contents (bool, optional): whether multiple contents are
@@ -172,44 +179,49 @@
             owner_id (str, optional): ID of the subscription owner, by
                 default logged in user ID
             schedules (list[str] | str | Schedule | list[Schedule], optional):
                 Schedules IDs or Schedule objects
             recipients (list[dict] | dict, optional): list of recipients IDs
                 or dicts
             delivery (dict | Delivery, optional): delivery object or dict
-            delivery_expiration_date (string, optional): expiration date
+            delivery_expiration_date (str, optional): expiration date
                 of the subscription, format should be yyyy - MM - dd
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription
             contact_security (bool): whether to use contact security for each
                 contact group member
             zip_filename(str, optional): filename of the compressed content
             zip_password_protect(bool, optional): whether to password protect
                 zip file
             zip_password(str, optional): optional password for the compressed
                 file
             space_delimiter(str, optional): space delimiter
             delivery_notification_enabled (bool): Whether notification is
                 enabled, notification applies to cache
             delivery_personal_notification_address_id (str, optional):
                 Notification details
         """
+        notification_address_id = delivery_personal_notification_address_id
+
         return super().alter(
             name=name,
             filename=filename,
             multiple_contents=multiple_contents,
             allow_delivery_changes=allow_delivery_changes,
             allow_personalization_changes=allow_personalization_changes,
             allow_unsubscribe=allow_unsubscribe,
             send_now=send_now,
             owner_id=owner_id,
             schedules=schedules,
             recipients=recipients,
             delivery=delivery,
             custom_msg=custom_msg,
             delivery_expiration_date=delivery_expiration_date,
+            delivery_expiration_timezone=delivery_expiration_timezone,
             contact_security=contact_security,
             zip_filename=zip_filename,
             zip_password_protect=zip_password_protect,
             zip_password=zip_password,
             space_delimiter=space_delimiter,
             delivery_notification_enabled=delivery_notification_enabled,
-            delivery_personal_notification_address_id=delivery_personal_notification_address_id
+            delivery_personal_notification_address_id=notification_address_id,
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/history_list_subscription.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/history_list_subscription.py`

 * *Files 3% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         subscription_id: Optional[str] = None,
         project_id: Optional[str] = None,
-        project_name: Optional[str] = None
+        project_name: Optional[str] = None,
     ):
         """Initializes HistoryListSubscription object and populates it with
         I-Server data if id or subscription_id is passed.
         Specify either `project_id` or `project_name`.
         When `project_id` is provided (not `None`), `project_name` is omitted.
         Args:
             connection (Connection): MicroStrategy connection object returned
@@ -50,20 +50,21 @@
         send_now: Optional[bool] = None,
         owner_id: Optional[str] = None,
         schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
         contents: Optional[Content] = None,
         recipients: Optional[list[dict] | list[str]] = None,
         delivery: Optional[Delivery | dict] = None,
         delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
         contact_security: bool = True,
         do_not_create_update_caches: bool = True,
         overwrite_older_version: bool = False,
         re_run_hl: bool = True,
         delivery_notification_enabled: bool = False,
-        delivery_personal_notification_address_id: Optional[str] = None
+        delivery_personal_notification_address_id: Optional[str] = None,
     ) -> "HistoryListSubscription":
         """Creates a new history list subscription.
         Args:
             connection (Connection): a MicroStrategy connection object
             name (str): name of the subscription
             project_id (str, optional): project ID
             project_name (str, optional): project name
@@ -81,30 +82,34 @@
                 default logged in user ID
             schedules (list[str] | str | Schedule | list[Schedule], optional):
                 Schedules IDs or Schedule objects
             contents (Content, optional): The content settings
             recipients (list[dict] | dict, optional): list of recipients IDs
                 or dicts
             delivery (dict | Delivery, optional): delivery object or dict
-            delivery_expiration_date (string, optional): expiration date
+            delivery_expiration_date (str, optional): expiration date
                 of the subscription, format should be yyyy - MM - dd
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription, example value 'Europe/London'
             contact_security (bool): whether to use contact security for each
                 contact group member
             do_not_create_update_caches (bool): whether the current subscription
                 will overwrite earlier versions of the same report or document
                 cache in the history list
             overwrite_older_version (bool): whether the current subscription
                 will overwrite earlier versions of the same report or document
                 in the history list
             re_run_hl (bool): whether subscription will re-run against warehouse
             delivery_notification_enabled (bool): Whether notification is
                 enabled, notification applies to cache
             delivery_personal_notification_address_id (str, optional):
                 Notification details
         """
+        notification_address_id = delivery_personal_notification_address_id
+
         return super()._Subscription__create(
             connection=connection,
             name=name,
             project_id=project_id,
             project_name=project_name,
             multiple_contents=multiple_contents,
             allow_delivery_changes=allow_delivery_changes,
@@ -114,20 +119,21 @@
             owner_id=owner_id,
             schedules=schedules,
             contents=contents,
             recipients=recipients,
             delivery=delivery,
             delivery_mode=Delivery.DeliveryMode.HISTORY_LIST,
             delivery_expiration_date=delivery_expiration_date,
+            delivery_expiration_timezone=delivery_expiration_timezone,
             contact_security=contact_security,
             do_not_create_update_caches=do_not_create_update_caches,
             overwrite_older_version=overwrite_older_version,
             re_run_hl=re_run_hl,
             delivery_notification_enabled=delivery_notification_enabled,
-            delivery_personal_notification_address_id=delivery_personal_notification_address_id
+            delivery_personal_notification_address_id=notification_address_id,
         )
 
     def alter(
         self,
         name: Optional[str] = None,
         multiple_contents: Optional[bool] = None,
         allow_delivery_changes: Optional[bool] = None,
@@ -136,20 +142,21 @@
         send_now: Optional[bool] = None,
         owner_id: Optional[str] = None,
         schedules: Optional[str | list[str] | Schedule | list[Schedule]] = None,
         recipients: Optional[list[dict] | list[str]] = None,
         delivery: Optional[Delivery | dict] = None,
         custom_msg: Optional[str] = None,
         delivery_expiration_date: Optional[str] = None,
+        delivery_expiration_timezone: Optional[str] = None,
         contact_security: bool = True,
         do_not_create_update_caches: bool = True,
         overwrite_older_version: bool = False,
         re_run_hl: bool = True,
         delivery_notification_enabled: bool = False,
-        delivery_personal_notification_address_id: Optional[str] = None
+        delivery_personal_notification_address_id: Optional[str] = None,
     ):
         """Alter the subscription.
         Args:
             name (str, optional): name of the subscription
             multiple_contents (bool, optional): whether multiple contents are
                 allowed
             allow_delivery_changes (bool, optional): whether the
@@ -163,16 +170,18 @@
             owner_id (str, optional): ID of the subscription owner, by
                 default logged in user ID
             schedules (list[str] | str | Schedule | list[Schedule], optional):
                 Schedules IDs or Schedule objects
             recipients (list[dict] | dict, optional): list of recipients IDs
                 or dicts
             delivery (dict | Delivery, optional): delivery object or dict
-            delivery_expiration_date (string, optional): expiration date
+            delivery_expiration_date (str, optional): expiration date
                 of the subscription, format should be yyyy - MM - dd
+            delivery_expiration_timezone (str, optional): expiration timezone
+                of the subscription
             contact_security (bool): whether to use contact security for each
                 contact group member
             do_not_create_update_caches (bool): whether the current subscription
                 will overwrite earlier versions of the same report or document
                 cache in the history list
             overwrite_older_version (bool): whether the current subscription
                 will overwrite earlier versions of the same report or document
@@ -180,27 +189,30 @@
             re_run_hl (bool): whether subscription will re-run against
                 warehouse
             delivery_notification_enabled (bool): Whether notification is
                 enabled, notification applies to cache
             delivery_personal_notification_address_id (str, optional):
                 Notification details
         """
+        notification_address_id = delivery_personal_notification_address_id
+
         return super().alter(
             name=name,
             multiple_contents=multiple_contents,
             allow_delivery_changes=allow_delivery_changes,
             allow_personalization_changes=allow_personalization_changes,
             allow_unsubscribe=allow_unsubscribe,
             send_now=send_now,
             owner_id=owner_id,
             schedules=schedules,
             recipients=recipients,
             delivery=delivery,
             custom_msg=custom_msg,
             delivery_expiration_date=delivery_expiration_date,
+            delivery_expiration_timezone=delivery_expiration_timezone,
             contact_security=contact_security,
             do_not_create_update_caches=do_not_create_update_caches,
             overwrite_older_version=overwrite_older_version,
             re_run_hl=re_run_hl,
             delivery_notification_enabled=delivery_notification_enabled,
-            delivery_personal_notification_address_id=delivery_personal_notification_address_id
+            delivery_personal_notification_address_id=notification_address_id,
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/subscription/subscription_manager.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/subscription/subscription_manager.py`

 * *Files 3% similar despite different names*

```diff
@@ -11,30 +11,30 @@
 
 from . import (
     CacheUpdateSubscription,
     EmailSubscription,
     FileSubscription,
     FTPSubscription,
     HistoryListSubscription,
-    Subscription
+    Subscription,
 )
 from .content import Content
 from .delivery import Delivery
 
 logger = logging.getLogger(__name__)
 
 
 @method_version_handler('11.2.0203')
 def list_subscriptions(
     connection: Connection,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> list["Subscription"] | list[dict]:
     """Get all subscriptions per project as list of Subscription objects or
     dictionaries.
 
     Optionally filter the subscriptions by specifying filters.
     Specify either `project_id` or `project_name`.
     When `project_id` is provided (not `None`), `project_name` is omitted.
@@ -43,26 +43,29 @@
         connection(object): MicroStrategy connection object
         project_id: Project ID
         project_name: Project name
         to_dictionary: If True returns a list of subscription dicts,
             otherwise (default) returns a list of subscription objects
         limit: limit the number of elements returned. If `None` (default), all
             objects are returned.
-        **filters: Available filter parameters: ['id', 'name', 'editable',
-            'allowDeliveryChanges', 'allowPersonalizationChanges',
-            'allowUnsubscribe', 'dateCreated', 'dateModified', 'owner',
-            'schedules', 'contents', 'recipients', 'delivery']
+        **filters: Available filter parameters: ['id', 'multiple_contents',
+            'name', 'editable', 'allow_delivery_changes'
+            'allow_personalization_changes', 'allow_unsubscribe',
+            'date_created', 'date_modified', 'owner', 'delivery']
     """
     project_id = helper.get_valid_project_id(
         connection=connection,
         project_id=project_id,
         project_name=project_name,
     )
-    chunk_size = 1000 if version.parse(connection.iserver_version
-                                       ) >= version.parse('11.3.0300') else 1000000
+    chunk_size = (
+        1000
+        if version.parse(connection.iserver_version) >= version.parse('11.3.0300')
+        else 1000000
+    )
     msg = 'Error getting subscription list.'
     objects = helper.fetch_objects_async(
         connection=connection,
         api=subscriptions_.list_subscriptions,
         async_api=subscriptions_.list_subscriptions_async,
         limit=limit,
         chunk_size=chunk_size,
@@ -76,25 +79,26 @@
         return objects
     else:
         return [
             dispatch_from_dict(
                 source=obj,
                 connection=connection,
                 project_id=project_id,
-            ) for obj in objects
+            )
+            for obj in objects
         ]
 
 
 DeliveryMode = Delivery.DeliveryMode
 subscription_type_from_delivery_mode_dict = {
     DeliveryMode.CACHE: CacheUpdateSubscription,
     DeliveryMode.EMAIL: EmailSubscription,
     DeliveryMode.FILE: FileSubscription,
     DeliveryMode.FTP: FTPSubscription,
-    DeliveryMode.HISTORY_LIST: HistoryListSubscription
+    DeliveryMode.HISTORY_LIST: HistoryListSubscription,
 }
 
 
 def get_subscription_type_from_delivery_mode(mode: DeliveryMode):
     """Returns the subscription type of the provided Delivery Mode.
 
     Args:
@@ -120,15 +124,15 @@
 class SubscriptionManager:
     """Manage subscriptions."""
 
     def __init__(
         self,
         connection: Connection,
         project_id: Optional[str] = None,
-        project_name: Optional[str] = None
+        project_name: Optional[str] = None,
     ):
         """Initialize the SubscriptionManager object.
         Specify either `project_id` or `project_name`.
         When `project_id` is provided (not `None`), `project_name` is omitted.
 
         Args:
             connection: MicroStrategy connection object returned
@@ -162,55 +166,65 @@
                 'schedules', 'contents', 'recipients', 'delivery']
         """
         return list_subscriptions(
             connection=self.connection,
             project_id=self.project_id,
             to_dictionary=to_dictionary,
             limit=limit,
-            **filters
+            **filters,
         )
 
-    def delete(self, subscriptions: list[Subscription] | list[str], force=False) -> bool:
+    def delete(
+        self, subscriptions: list[Subscription] | list[str], force=False
+    ) -> bool:
         """Deletes all passed subscriptions. Returns True if successfully
         removed all subscriptions.
 
         Args:
             subscriptions: list of subscriptions to be deleted
         """
-        subscriptions = subscriptions if isinstance(subscriptions, list) else [subscriptions]
+        subscriptions = (
+            subscriptions if isinstance(subscriptions, list) else [subscriptions]
+        )
         if not subscriptions and config.verbose:
             logger.info('No subscriptions passed.')
         else:
             temp_subs = []
             for subscription in subscriptions:
                 if not isinstance(subscription, Subscription):
                     subscription = Subscription(
-                        connection=self.connection, id=subscription, project_id=self.project_id
+                        connection=self.connection,
+                        id=subscription,
+                        project_id=self.project_id,
                     )
                 temp_subs.append(subscription)
             subscriptions = temp_subs
             succeeded = 0
             user_input = 'N'
             if not force:
                 to_be_deleted = [
-                    f"Subscription '{sub.name}' with ID: '{sub.id}'" for sub in subscriptions
+                    f"Subscription '{sub.name}' with ID: '{sub.id}'"
+                    for sub in subscriptions
                 ]
                 print("Found subscriptions:")
                 for sub in to_be_deleted:
                     print(sub)
-                user_input = input("Are you sure you want to delete all of them? [Y/N]: ")
+                user_input = input(
+                    "Are you sure you want to delete all of them? [Y/N]: "
+                )
             if force or user_input == 'Y':
                 succeeded = 0
                 for subscription in subscriptions:
                     response = subscriptions_.remove_subscription(
                         self.connection,
                         subscription.id,
                         self.project_id,
-                        error_msg="Subscription '{}' with id '{}'' could not be deleted.".format(
-                            subscription.name, subscription.id
+                        error_msg=(
+                            f"Subscription '{subscription.name}' with id "
+                            f"'{subscription.id}' could not be deleted."
                         ),
                         exception_type=UserWarning,
                     )
                     if response.ok:
                         succeeded += 1
                         if config.verbose:
                             logger.info(
@@ -225,27 +239,36 @@
 
         Args:
             subscriptions: list of subscriptions to be executed
         """
         if not subscriptions and config.verbose:
             logger.info('No subscriptions passed.')
         else:
-            subscriptions = subscriptions if isinstance(subscriptions, list) else [subscriptions]
+            subscriptions = (
+                subscriptions if isinstance(subscriptions, list) else [subscriptions]
+            )
             for subscription in subscriptions:
                 if not isinstance(subscription, Subscription):
                     subscription = Subscription(
-                        connection=self.connection, id=subscription, project_id=self.project_id
+                        connection=self.connection,
+                        id=subscription,
+                        project_id=self.project_id,
                     )
-                if subscription.delivery.mode in ('EMAIL', 'FILE', 'HISTORY_LIST', 'FTP'):
+                if subscription.delivery.mode in (
+                    'EMAIL',
+                    'FILE',
+                    'HISTORY_LIST',
+                    'FTP',
+                ):
                     subscription.execute()
                 else:
                     msg = (
-                        f"Subscription '{subscription.name}' with ID '{subscription.id}' "
-                        f"could not be executed. Delivery mode '{subscription.delivery.mode}'"
-                        " is not supported."
+                        f"Subscription '{subscription.name}' with ID "
+                        f"'{subscription.id}' could not be executed. Delivery mode "
+                        f"'{subscription.delivery.mode}' is not supported."
                     )
                     helper.exception_handler(msg, UserWarning)
 
     @method_version_handler('11.3.0000')
     def available_bursting_attributes(self, content: dict | Content):
         """Get a list of available attributes for bursting feature, for a given
         content.
@@ -266,15 +289,15 @@
 
     @method_version_handler('11.3.0000')
     def available_recipients(
         self,
         content_id: Optional[str] = None,
         content_type: Optional[str] = None,
         content: Optional["Content"] = None,
-        delivery_type='EMAIL'
+        delivery_type='EMAIL',
     ) -> list[dict]:
         """List available recipients for a subscription contents.
         Specify either both `content_id` and `content_type` or just `content`
         object.
 
         Args:
             content_id: ID of the content
@@ -290,17 +313,15 @@
             content_type = content.type
         else:
             helper.exception_handler(
                 'Specify either a content ID and type or content object.', ValueError
             )
 
         body = {
-            "contents": [{
-                "id": content_id, "type": content_type
-            }],
+            "contents": [{"id": content_id, "type": content_type}],
         }
 
         response = subscriptions_.available_recipients(
             self.connection, self.project_id, body, delivery_type
         )
 
         if response.ok and config.verbose:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/distribution_services/transmitter/transmitter.py` & `mstrio-py-11.3.9.103/mstrio/distribution_services/transmitter/transmitter.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,15 +6,18 @@
 from mstrio import config
 from mstrio.api import objects, transmitters
 from mstrio.types import ObjectTypes
 from mstrio.users_and_groups import User
 from mstrio.utils.entity import DeleteMixin, Entity
 from mstrio.utils.enum_helper import AutoName, get_enum_val
 from mstrio.utils.helper import (
-    Dictable, fetch_objects, get_args_from_func, get_default_args_from_func
+    Dictable,
+    fetch_objects,
+    get_args_from_func,
+    get_default_args_from_func,
 )
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
 logger = logging.getLogger(__name__)
@@ -77,15 +80,15 @@
         recipient_field_type: RecipientFieldType = RecipientFieldType.TO,
         save_message_to_file: bool = False,
         send_message_to_file: bool = False,
         send_message_via_smtp: bool = False,
         save_file_path: Optional[str] = None,
         notify_on_success: bool = False,
         notify_on_failure: bool = False,
-        notification_email_address: Optional[str] = None
+        notification_email_address: Optional[str] = None,
     ):
         self.sender_display_name = sender_display_name
         self.sender_email_address = sender_email_address
         self.reply_to_display_name = reply_to_display_name
         self.reply_to_email_address = reply_to_email_address
         self.recipient_field_type = recipient_field_type
         self.save_message_to_file = save_message_to_file
@@ -95,29 +98,33 @@
         self.notify_on_success = notify_on_success
         self.notify_on_failure = notify_on_failure
         self.notification_email_address = notification_email_address
 
 
 @method_version_handler('11.3.0100')
 def list_transmitters(
-    connection: "Connection", to_dictionary: bool = False, limit: Optional[int] = None, **filters
+    connection: "Connection",
+    to_dictionary: bool = False,
+    limit: Optional[int] = None,
+    **filters,
 ) -> Union[List["Transmitter"], List[dict]]:
     """Get all transmitters as list of Transmitter objects or
     dictionaries.
 
     Optionally filter the transmitters by specifying filters.
 
     Args:
         connection(object): MicroStrategy connection object
         to_dictionary: If True returns a list of transmitter dicts,
             otherwise returns a list of transmitter objects
         limit: limit the number of elements returned. If `None` (default), all
             objects are returned.
-        **filters: Available filter parameters: ['id', 'name', 'description',
-            'delivery_type']
+        **filters: Available filter parameters: ['id', 'name', 'date_created',
+            'date_modified', 'description', 'delivery_type',
+             'email_transmitter_properties']
     """
     return Transmitter._list_transmitters(
         connection=connection, to_dictionary=to_dictionary, limit=limit, **filters
     )
 
 
 @class_version_handler('11.3.0100')
@@ -135,15 +142,15 @@
     """
 
     _OBJECT_TYPE = ObjectTypes.SUBSCRIPTION_TRANSMITTER
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'owner': User.from_dict,
         'delivery_type': TransmitterDeliveryType,
-        'email_transmitter_properties': EmailTransmitterProperties.from_dict
+        'email_transmitter_properties': EmailTransmitterProperties.from_dict,
     }
     _API_GETTERS = {
         (
             'abbreviation',
             'type',
             'subtype',
             'ext_type',
@@ -151,28 +158,42 @@
             'date_modified',
             'version',
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
-            'acl'
+            'acl',
         ): objects.get_object_info,
-        ('id', 'name', 'description', 'delivery_type',
-         'email_transmitter_properties'): transmitters.get_transmitter
+        (
+            'id',
+            'name',
+            'description',
+            'delivery_type',
+            'email_transmitter_properties',
+        ): transmitters.get_transmitter,
     }
     _API_DELETE = staticmethod(transmitters.delete_transmitter)
     _API_PATCH: dict = {
-        ("name", "description",
-         "email_transmitter_properties"): (transmitters.update_transmitter, "put")
+        ("name", "description", "email_transmitter_properties"): (
+            transmitters.update_transmitter,
+            "put",
+        )
+    }
+    _PATCH_PATH_TYPES = {
+        "name": str,
+        "description": str,
+        "email_transmitter_properties": dict,
     }
-    _PATCH_PATH_TYPES = {"name": str, "description": str, "email_transmitter_properties": dict}
 
     def __init__(
-        self, connection: "Connection", id: Optional[str] = None, name: Optional[str] = None
+        self,
+        connection: "Connection",
+        id: Optional[str] = None,
+        name: Optional[str] = None,
     ):
         """Initialize Transmitter object.
 
         Note:
             In case both `id` and `name` are provided, then `id` is used when
             fetching.
 
@@ -183,15 +204,17 @@
             name (str, optional): Name of the pre-existing transmitter
 
         Raises:
             `ValueError` when neither `id` nor `name` are specified.
         """
 
         if id is None and name is None:
-            raise ValueError("Please specify either 'id' or 'name' parameter in the constructor.")
+            raise ValueError(
+                "Please specify either 'id' or 'name' parameter in the constructor."
+            )
 
         if id is None:
             objects_info = Transmitter._list_transmitters(
                 connection=connection,
                 name=name,
                 to_dictionary=True,
             )
@@ -201,28 +224,35 @@
             else:
                 raise ValueError(f"There is no Transmitter: '{name}'")
         else:
             super().__init__(connection=connection, object_id=id)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
-        self._delivery_type = TransmitterDeliveryType(kwargs["delivery_type"]
-                                                      ) if kwargs.get("delivery_type") else None
-        self.email_transmitter_properties = EmailTransmitterProperties.from_dict(
-            kwargs["email_transmitter_properties"]
-        ) if kwargs.get("email_transmitter_properties") else None
+        self._delivery_type = (
+            TransmitterDeliveryType(kwargs["delivery_type"])
+            if kwargs.get("delivery_type")
+            else None
+        )
+        self.email_transmitter_properties = (
+            EmailTransmitterProperties.from_dict(kwargs["email_transmitter_properties"])
+            if kwargs.get("email_transmitter_properties")
+            else None
+        )
 
     @classmethod
     def create(
         cls,
         connection: "Connection",
         name: str,
         delivery_type: Union[str, TransmitterDeliveryType],
         description: Optional[str] = None,
-        email_transmitter_properties: Optional[Union[dict, EmailTransmitterProperties]] = None
+        email_transmitter_properties: Optional[
+            Union[dict, EmailTransmitterProperties]
+        ] = None,
     ) -> "Transmitter":
         """Create transmitter.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             delivery_type: type of the transmitter
@@ -232,78 +262,86 @@
                 to email transmitter. In transmitter with type `email` those
                 properties must be provided. Otherwise they cannot be provided.
 
         Returns:
             `Transmitter` object
         """
         delivery_type = get_enum_val(delivery_type, TransmitterDeliveryType)
-        email_transmitter_properties = email_transmitter_properties.to_dict() if isinstance(
-            email_transmitter_properties, EmailTransmitterProperties
-        ) else email_transmitter_properties
+        email_transmitter_properties = (
+            email_transmitter_properties.to_dict()
+            if isinstance(email_transmitter_properties, EmailTransmitterProperties)
+            else email_transmitter_properties
+        )
         body = {
             'name': name,
             'description': description,
             'deliveryType': delivery_type,
-            'emailTransmitterProperties': email_transmitter_properties
+            'emailTransmitterProperties': email_transmitter_properties,
         }
 
         res = transmitters.create_transmitter(connection, body).json()
         if config.verbose:
             logger.info(
                 f"Successfully created transmitter named: '{res.get('name')}' "
                 f"with ID: '{res.get('id')}'"
             )
         return cls.from_dict(res, connection)
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
-        email_transmitter_properties: Optional[Union[dict, EmailTransmitterProperties]] = None
+        email_transmitter_properties: Optional[
+            Union[dict, EmailTransmitterProperties]
+        ] = None,
     ):
         """Alter transmitter properties.
 
         Args:
             name (str): transmitter's name
             description (str): transmitter's description
             email_transmitter_properties (dict or object): properties specific
                 to email transmitter. Only in transmitter with type `email`
                 altering those properties is possible
         """
-        email_transmitter_properties = email_transmitter_properties.to_dict() if isinstance(
-            email_transmitter_properties, EmailTransmitterProperties
-        ) else email_transmitter_properties
+        email_transmitter_properties = (
+            email_transmitter_properties.to_dict()
+            if isinstance(email_transmitter_properties, EmailTransmitterProperties)
+            else email_transmitter_properties
+        )
         func = self.alter
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        defaults_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        defaults_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = defaultdict(dict)
         for property_key in defaults_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
         self._alter_properties(**properties)
 
     @classmethod
     def _list_transmitters(
         cls,
         connection: "Connection",
         to_dictionary: bool = False,
         limit: Optional[int] = None,
-        **filters
+        **filters,
     ) -> Union[List["Transmitter"], List[dict]]:
         """Helper method for listing transmitters."""
         objects = fetch_objects(
             connection=connection,
             api=transmitters.get_transmitters,
             limit=limit,
             filters=filters,
             dict_unpack_value="transmitters",
         )
 
         if to_dictionary:
             return objects
-        return [Transmitter.from_dict(source=obj, connection=connection) for obj in objects]
+        return [
+            Transmitter.from_dict(source=obj, connection=connection) for obj in objects
+        ]
 
     @property
     def delivery_type(self):
         return self._delivery_type
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/expression/__init__.py` & `mstrio-py-11.3.9.103/mstrio/modeling/expression/__init__.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/expression/dynamic_date_time.py` & `mstrio-py-11.3.9.103/mstrio/modeling/expression/dynamic_date_time.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,47 +1,53 @@
 from dataclasses import asdict, dataclass
 from enum import auto, Enum
 from typing import Optional, Type, TYPE_CHECKING
 
-from stringcase import camelcase, capitalcase, snakecase
+from stringcase import capitalcase
+from humps import camelize, decamelize
 
 from mstrio.utils.enum_helper import AutoName
 from mstrio.utils.helper import Dictable, snake_to_camel, delete_none_values
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
 
 class DynamicDateTimeType(AutoName):
     """Enumeration constant indicating type of dynamic date time object"""
+
     DATE = auto()
     TIME = auto()
     DATE_TIME = auto()
 
 
 class DateMode(AutoName):
     """Enumeration constant indicating mode of date"""
+
     DYNAMIC = auto()
     STATIC = auto()
 
 
 class HourMode(AutoName):
     """Enumeration constant indicating mode of hour"""
+
     DYNAMIC = auto()
     STATIC = auto()
 
 
 class MinuteAndSecondMode(AutoName):
     """Enumeration constant indicating mode of minute and second"""
+
     DYNAMIC = auto()
     STATIC = auto()
 
 
 class DayOfWeek(Enum):
     """Enumeration used to indicate day of week"""
+
     SUNDAY = 0
     MONDAY = 1
     TUESDAY = 2
     WEDNESDAY = 3
     THURSDAY = 4
     FRIDAY = 5
     SATURDAY = 6
@@ -49,15 +55,17 @@
 
 class VersatileDate(Dictable):
     """Base class for classes representing dynamic or static date objects"""
 
     _MODE = None
 
     @staticmethod
-    def dispatch(source, connection: Optional['Connection'] = None) -> Type['VersatileDate']:
+    def dispatch(
+        source, connection: Optional['Connection'] = None
+    ) -> Type['VersatileDate']:
         """Returns an appropriate VersatileDate type object from the
             provided source
 
         Args:
             source: object that specifies the VersatileDate object that
                 will be returned
             connection (optional): MicroStrategy connection object returned
@@ -226,33 +234,38 @@
     def to_dict(self, camel_case: bool = True) -> dict:
         result = asdict(self)
         result['mode'] = self._MODE.value
 
         # every type of adjustment has its own unique attribute name
         # and only one can be present in json
         # so generate it based on class name
-        attr_name = snakecase(self.adjustment.__class__.__name__)
+        attr_name = decamelize(self.adjustment.__class__.__name__)
         result[attr_name] = result.pop('adjustment')
 
         result = delete_none_values(
             result, recursion=False, whitelist_attributes=self._ALLOW_NONE_ATTRIBUTES
         )
         return snake_to_camel(result) if camel_case else result
 
     @classmethod
     def from_dict(
         cls, source: dict, connection: Optional['Connection'] = None, to_snake_case=True
     ) -> 'DynamicVersatileDate':
         try:
             key, value = next(
-                (key, value) for key, value in source.items() if key.startswith('adjustment'))
+                (key, value)
+                for key, value in source.items()
+                if key.startswith('adjustment')
+            )
         except StopIteration:
-            raise AttributeError("Missing field for adjustment of a date in source data.")
+            raise AttributeError(
+                "Missing field for adjustment of a date in source data."
+            )
 
-        cls_name = capitalcase(camelcase(key))
+        cls_name = capitalcase(camelize(key))
         cls_obj = globals()[cls_name]
         adjustment = cls_obj(**value)
 
         result = super().from_dict(source, connection, to_snake_case)
         result.adjustment = adjustment
 
         return result
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/expression/enums.py` & `mstrio-py-11.3.9.103/mstrio/modeling/expression/enums.py`

 * *Files 7% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 
 from mstrio.utils.enum_helper import AutoName
 
 
 class Function(AutoName):
     """Enumeration constant used to specify the function used for calculation
     in expression nodes"""
+
     THIRD_PARTY = auto()
     CUSTOM = auto()
     PLUS = auto()
     MINUS = auto()
     TIMES = auto()
     DIVIDE = auto()
     UNARY_MINUS = auto()
@@ -199,14 +200,15 @@
     PARENTS = auto()
     CHILDREN = auto()
     TUPLE = auto()
 
 
 class ExpressionType(AutoName):
     """Enumeration constant indicating the expression type of expression node"""
+
     DYNAMIC = auto()
     STATIC = auto()
     GENERIC = auto()
     FILTER_SINGLE_BASE_FORM_QUAL = auto()
     FILTER_MULTI_BASE_FORM_QUAL = auto()
     FILTER_JOINT_FORM_QUAL = auto()
     FILTER_LIST_QUAL = auto()
@@ -236,35 +238,38 @@
     CSI_INSERT = auto()
     CSI_DELETE = auto()
     CSI_GROUP = auto()
 
 
 class DimtyType(AutoName):
     """Enumeration constant  indicating the dimty type of expression node"""
+
     NONE = auto()
     CONTINUATION = auto()
     EXCLUSIVE_CONTINUATION = auto()
     OUTPUT_LEVEL = auto()
     BREAK_BY = auto()
     EMBEDDED = auto()
     UNSPECIFIED = auto()
     PARAMETER = auto()
 
 
 class DependenceType(AutoName):
     """Enumeration constant indicating the dependence type of expression node"""
+
     DEFAULT = auto()
     INDEPENDENT = auto()
     DEPENDENT = auto()
 
 
 class NodeType(AutoName):
     """Enumeration constant indicating the type of node within
     the expression tree
     """
+
     OPERATOR = auto()
     OBJECT_REFERENCE = auto()
     COLUMN_REFERENCE = auto()
     CONSTANT = auto()
     RELATIONSHIP = auto()
     FORM_SHORTCUT = auto()
     DYNAMIC_DATE_TIME = auto()
@@ -281,22 +286,24 @@
     PREDICATE_BANDING_COUNT = auto()
     PREDICATE_BANDING_POINTS = auto()
     PREDICATE_BANDING_DISTINCT = auto()
 
 
 class IsIndependent(Enum):
     """Flag that indicates whether a node will be evaluated independently
-     of other parts of the larger expression"""
+    of other parts of the larger expression"""
+
     YES = 1
     NO = 0
 
 
 class ExpressionFormat(AutoName):
-    """"Expression format to be fetched from server, it might be tree or token:
+    """ "Expression format to be fetched from server, it might be tree or token:
     - tree: tree data structure fully defining the expression. This format can
     be used if you want to examine and modify the expression programmatically.
     - tokens: list of parsed tokens. This format can be used if you want
     to examine and modify the expression using the parser component. Note that
     generating tokens requires additional time.
     """
+
     TREE = auto()
     TOKENS = auto()
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/expression/expression.py` & `mstrio-py-11.3.9.103/mstrio/modeling/expression/expression.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,19 @@
 
 from mstrio.modeling.schema.helpers import ObjectSubType, SchemaObjectReference
 from mstrio.object_management import search_operations
 from mstrio.object_management.search_enums import SearchPattern
 from mstrio.types import ObjectSubTypes, ObjectTypes
 from mstrio.utils.enum_helper import AutoName
 from mstrio.utils.helper import (
-    camel_to_snake, delete_none_values, Dictable, get_valid_project_id, snake_to_camel
+    camel_to_snake,
+    delete_none_values,
+    Dictable,
+    get_valid_project_id,
+    snake_to_camel,
 )
 
 from .enums import DependenceType, DimtyType, ExpressionType, NodeType
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
@@ -35,23 +39,26 @@
     def to_dict(self, camel_case: bool = True) -> dict:
         result = super().to_dict(camel_case)
         result['type'] = self._TYPE.value
 
         return result
 
     @staticmethod
-    def dispatch(source, connection: Optional['Connection'] = None) -> Type['ExpressionNode']:
+    def dispatch(
+        source, connection: Optional['Connection'] = None
+    ) -> Type['ExpressionNode']:
         """Method dispatching node data to appropriate class that represents
         this type of node.
         """
         data = source.copy()
         node_type = NodeType(data.pop('type'))
 
         # this import is here due to circular imports issue
         from mstrio.modeling.expression.expression_nodes import NODE_TYPE_TO_CLASS_MAP
+
         cls = NODE_TYPE_TO_CLASS_MAP[node_type]
 
         return cls.from_dict(data, connection)
 
 
 @dataclass
 class Token(Dictable):
@@ -71,14 +78,15 @@
 
         attribute_form: If the token represents an attribute form in the context
            of an object (say City@DESC) then provide attribute form id
     """
 
     class Type(AutoName):
         """Enumeration constant that classifies the text within a token"""
+
         END_OF_TEXT = auto()
         ERROR = auto()
         UNKNOWN = auto()
         EMPTY = auto()
         CHARACTER = auto()
         LITERAL = auto()
         IDENTIFIER = auto()
@@ -96,21 +104,23 @@
         ELEMENTS = auto()
         DATE_TIME = auto()
 
     class Level(AutoName):
         """Enumeration constant describing the amount of processing performed
         on a parser token
         """
+
         CLIENT = auto()
         LEXED = auto()
         RESOLVED = auto()
         PARSED = auto()
 
     class State(AutoName):
         """Enumeration constant describing whether token in an error or not"""
+
         ERROR = auto()
         INITIAL = auto()
         OKAY = auto()
 
     _FROM_DICT_MAP = {
         'type': Type,
         'target': SchemaObjectReference,
@@ -133,15 +143,18 @@
             }
 
         result = delete_none_values(result, recursion=False)
         return snake_to_camel(result) if camel_case else result
 
     @classmethod
     def from_dict(
-        cls, source: dict, connection: Optional['Connection'] = None, to_snake_case: bool = True
+        cls,
+        source: dict,
+        connection: Optional['Connection'] = None,
+        to_snake_case: bool = True,
     ):
         data = camel_to_snake(source) if to_snake_case else source.copy()
 
         attribute_form = data.get('attribute_form')
         data['attribute_form'] = attribute_form['object_id'] if attribute_form else None
 
         return super().from_dict(data, connection, to_snake_case=False)
@@ -270,12 +283,14 @@
         return objects
 
     objects = [
         {
             **obj,
             'object_id': obj.get('id'),
             'sub_type': ObjectSubType.FUNCTION
-            if obj.get('subtype') == ObjectSubTypes.FUNCTION.value else None,  # noqa
-        } for obj in objects
+            if obj.get('subtype') == ObjectSubTypes.FUNCTION.value
+            else None,  # noqa
+        }
+        for obj in objects
     ]
 
     return [SchemaObjectReference.from_dict(obj, connection) for obj in objects]
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/expression/expression_nodes.py` & `mstrio-py-11.3.9.103/mstrio/modeling/expression/expression_nodes.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,14 +21,15 @@
 
     Attributes:
         predicate_id: String identifier that uniquely identifies this predicate
             within the context of its larger filter. Any non-empty string of
             printable characters can be used as a predicate.
         predicate_text: Text representation of a predicate
     """
+
     predicate_id: Optional[str] = None
     predicate_text: Optional[str] = None
 
     def to_dict(self, camel_case: bool = True) -> dict:
         result = {
             'type': self._TYPE.value,
             'predicate_id': self.predicate_id,
@@ -37,20 +38,25 @@
         }
 
         result = delete_none_values(result, recursion=False)
         return snake_to_camel(result) if camel_case else result
 
     @classmethod
     def from_dict(
-        cls, source: dict, connection: Optional['Connection'] = None, to_snake_case: bool = True
+        cls,
+        source: dict,
+        connection: Optional['Connection'] = None,
+        to_snake_case: bool = True,
     ) -> Type['PredicateNode']:
         data = camel_to_snake(source) if to_snake_case else source.copy()
         # get a dict under predicate_tree attribute to unpack it
         predicate_tree = data.pop('predicate_tree')
-        return super().from_dict({**data, **predicate_tree}, connection, to_snake_case=False)
+        return super().from_dict(
+            {**data, **predicate_tree}, connection, to_snake_case=False
+        )
 
     def _get_node_data(self):
         """Return dictionary that contains data unique to particular predicate
         node that should be merged with data common to all predicate nodes in
         to_dict.
         """
         pass
@@ -157,14 +163,15 @@
                when evaluating the metric.
     """
 
     class MetricFunction(AutoName):
         """Enumeration constant that describes how the metric is used
         within the predicate.
         """
+
         VALUE = auto()
         RANK_DESCEND = auto()
         RANK_ASCEND = auto()
         PERCENTILE_DESCEND = auto()
         PERCENTILE_ASCEND = auto()
 
     _TYPE = NodeType.PREDICATE_METRIC_QUALIFICATION
@@ -191,19 +198,23 @@
     is_independent: IsIndependent = IsIndependent.YES
 
     def _get_node_data(self):
         result = {
             'predicate_tree': {
                 'function': self.function.value,
                 'parameters': [item.to_dict() for item in self.parameters],
-                'level': [item.to_dict() for item in self.level] if self.level else None,
+                'level': [item.to_dict() for item in self.level]
+                if self.level
+                else None,
                 'level_type': self.level_type,
                 'metric': self.metric.to_dict(),
                 'metric_function': self.metric_function.value,
-                'break_by': [item.to_dict() for item in self.break_by] if self.break_by else None,
+                'break_by': [item.to_dict() for item in self.break_by]
+                if self.break_by
+                else None,
                 'null_include': self.null_include,
                 'is_independent': self.is_independent.value,
             }
         }
 
         return delete_none_values(
             result, recursion=True, whitelist_attributes=self._ALLOW_NONE_ATTRIBUTES
@@ -296,15 +307,17 @@
     def _get_node_data(self):
         result = {
             'predicate_tree': {
                 'level': [item.to_dict() for item in self.level],
                 'guide': self.guide.to_dict() if self.guide else None,
                 'is_independent': self.is_independent.value,
             },
-            'children': [item.to_dict() for item in self.children] if self.children else None,
+            'children': [item.to_dict() for item in self.children]
+            if self.children
+            else None,
         }
 
         return delete_none_values(result, recursion=True)
 
 
 @dataclass(kw_only=True)
 class JointElementListPredicate(PredicateNode):
@@ -339,15 +352,18 @@
     level: List[SchemaObjectReference]
     tuples: List[List[AttributeElement]]
 
     def _get_node_data(self):
         return {
             'predicate_tree': {
                 'level': [item.to_dict() for item in self.level],
-                'tuples': [[item.to_dict() for item in tuple_item] for tuple_item in self.tuples],
+                'tuples': [
+                    [item.to_dict() for item in tuple_item]
+                    for tuple_item in self.tuples
+                ],
             },
         }
 
 
 @dataclass(kw_only=True)
 class ElementListPredicate(PredicateNode):
     """Specialized expression node that contains an element list predicate.
@@ -377,14 +393,15 @@
             - NOT_IN (the filter accepts any element not included in the list)
     """
 
     class ElementListFunction(AutoName):
         """Enumeration constant that describes what functions can be used
         within ElementListPredicate
         """
+
         IN = auto()
         NOT_IN = auto()
 
     _TYPE = NodeType.PREDICATE_ELEMENT_LIST
     _FROM_DICT_MAP = {
         **ExpressionNode._FROM_DICT_MAP,
         'attribute': SchemaObjectReference,
@@ -398,17 +415,20 @@
     elements_prompt: Optional[SchemaObjectReference] = None
     function: ElementListFunction = ElementListFunction.IN
 
     def _get_node_data(self):
         result = {
             'predicate_tree': {
                 'attribute': self.attribute.to_dict() if self.attribute else None,
-                'elements': [item.to_dict() for item in self.elements] if self.elements else None,
+                'elements': [item.to_dict() for item in self.elements]
+                if self.elements
+                else None,
                 'elements_prompt': self.elements_prompt.to_dict()
-                if self.elements_prompt else None,  # noqa
+                if self.elements_prompt
+                else None,  # noqa
                 'function': self.function.value,
             }
         }
 
         return delete_none_values(result, recursion=True)
 
 
@@ -474,15 +494,15 @@
 
     _TYPE = NodeType.PREDICATE_FORM_QUALIFICATION
     _FROM_DICT_MAP = {
         **ExpressionNode._FROM_DICT_MAP,
         'parameters': [PredicateParameter.dispatch],
         'attribute': SchemaObjectReference,
         'form': SchemaObjectReference,
-        'function': Function
+        'function': Function,
     }
     _ALLOW_NONE_ATTRIBUTES = ['parameters']
 
     function: Function
     attribute: SchemaObjectReference
     form: SchemaObjectReference
     # in swagger is required, but can be empty list
@@ -670,14 +690,15 @@
             apps.
     """
 
     class LevelType(AutoName):
         """Enumeration value indicating how the predicate's level should be
         determined
         """
+
         NONE = auto()
         METRIC_LEVEL = auto()
         GRID_LEVEL = auto()
         EXPLICIT_LEVEL = auto()
 
     _TYPE = NodeType.OPERATOR
     _FROM_DICT_MAP = {
@@ -747,14 +768,15 @@
             the default behavior.
     """
 
     class SubstituteFunctionType(AutoName):
         """Enumeration constant that specify how to merge multiple answers
         if the predicate's value is obtained via a prompt.
         """
+
         AND = auto()
         OR = auto()
 
     _TYPE = NodeType.OBJECT_REFERENCE
     _FROM_DICT_MAP = {
         **ExpressionNode._FROM_DICT_MAP,
         'target': SchemaObjectReference,
@@ -862,14 +884,15 @@
             elements selected by the predicate will be different for different
             locales. But we do not want the meaning of a filter to vary based
             on the locale preferences of the user executing the filter. So this
             property is used to specify the data locale to be used for the
             qualification. When set it will override the user's personal data
             locale preference.
     """
+
     _TYPE = NodeType.FORM_SHORTCUT
     _FROM_DICT_MAP = {
         **ExpressionNode._FROM_DICT_MAP,
         'attribute': SchemaObjectReference,
         'form': SchemaObjectReference,
     }
 
@@ -931,14 +954,15 @@
             the predicate ids used in the larger filter. Thus, an individual
             node within this expression can be manipulated by treating it as a
             manipulation of the larger filter in the usual manner.
 
             We use a list so that this value matches the list value of the
             same name used in an operator node.
     """
+
     _TYPE = NodeType.RELATIONSHIP
     _FROM_DICT_MAP = {
         **ExpressionNode._FROM_DICT_MAP,
         'level': [SchemaObjectReference],
         'guide': SchemaObjectReference,
         'is_independent': IsIndependent,
         'children': [ExpressionNode.dispatch],
@@ -977,14 +1001,15 @@
         band_names: list of band names, a band name cannot contain "#;" or "#,"
     """
 
     class BandMetricFunction(AutoName):
         """Enumeration constant used to specify function used to slice
         metric values into bands
         """
+
         VALUE = auto()
         RANK_DESCEND = auto()
         PERCENTILE_DESCEND = auto()
 
     _FROM_DICT_MAP = {
         **ExpressionNode._FROM_DICT_MAP,
         'level': [SchemaObjectReference],
@@ -1101,18 +1126,20 @@
 
     _TYPE = NodeType.PREDICATE_BANDING_POINTS
     points: List[float]
     band_names: Optional[List[str]] = None
 
     def _get_node_data(self):
         result = self._get_banding_common_data()
-        result['predicate_tree'].update({
-            'points': self.points,
-            'band_names': self.band_names,
-        })
+        result['predicate_tree'].update(
+            {
+                'points': self.points,
+                'band_names': self.band_names,
+            }
+        )
 
         return result
 
 
 @dataclass(kw_only=True)
 class BandingDistinctPredicate(BandingPredicate):
     """The Band for each distinct metric value type of banding qualification
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/expression/fact_expression.py` & `mstrio-py-11.3.9.103/mstrio/modeling/expression/fact_expression.py`

 * *Files 2% similar despite different names*

```diff
@@ -64,15 +64,18 @@
         result = super().to_dict(camel_case)
         result['expressionId'] = result.pop('id', None)
 
         return result
 
     @classmethod
     def from_dict(
-        cls, source: dict, connection: Optional['Connection'] = None, to_snake_case: bool = True
+        cls,
+        source: dict,
+        connection: Optional['Connection'] = None,
+        to_snake_case: bool = True,
     ) -> 'FactExpression':
         data = source.copy()
         data['id'] = data.get('expressionId', None)
 
         return super().from_dict(data, connection, to_snake_case)
 
     def local_alter(
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/expression/parameters.py` & `mstrio-py-11.3.9.103/mstrio/modeling/expression/parameters.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,24 +11,26 @@
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
 
 class ParameterType(AutoName):
     """Enumeration constant indicating type of parameter"""
+
     CONSTANT = auto()
     OBJECT_REFERENCE = auto()
     EXPRESSION = auto()
     PROMPT = auto()
     ARRAY = auto()
     DYNAMIC_DATE_TIME = auto()
 
 
 class VariantType(AutoName):
     """Enumeration constant indicating type of value of a variant object"""
+
     INT32 = auto()
     INT64 = auto()
     DATE = auto()
     TIME = auto()
     BOOLEAN = auto()
     STRING = auto()
     DOUBLE = auto()
@@ -43,15 +45,17 @@
     def to_dict(self, camel_case: bool = True) -> dict:
         result = super().to_dict(camel_case)
         result[camel_case and 'parameterType' or 'parameter_type'] = self._TYPE.value
 
         return result
 
     @staticmethod
-    def dispatch(source, connection: Optional['Connection'] = None) -> Type['PredicateParameter']:
+    def dispatch(
+        source, connection: Optional['Connection'] = None
+    ) -> Type['PredicateParameter']:
         """Returns an appropriate PredicateParameter object from the
             provided source
 
         Args:
             source: object that specifies PredicateParameter that will be
                 returned
             connection (optional): MicroStrategy connection object returned
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/filter/filter.py` & `mstrio-py-11.3.9.103/mstrio/modeling/filter/filter.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,25 @@
 import logging
-from typing import Optional, TYPE_CHECKING
+from functools import partial
+from typing import TYPE_CHECKING, Optional
 
 from mstrio import config
 from mstrio.api import filters, objects
 from mstrio.modeling.schema import ObjectSubType
-from mstrio.object_management import search_operations, SearchPattern
+from mstrio.object_management import SearchPattern, search_operations
 from mstrio.object_management.folder import Folder
 from mstrio.types import ObjectSubTypes, ObjectTypes
 from mstrio.users_and_groups import User
 from mstrio.utils.entity import CopyMixin, DeleteMixin, Entity, MoveMixin
 from mstrio.utils.enum_helper import get_enum_val
-from mstrio.utils.helper import delete_none_values, filter_params_for_func, get_valid_project_id
+from mstrio.utils.helper import (
+    delete_none_values,
+    filter_params_for_func,
+    get_valid_project_id,
+)
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 from mstrio.modeling.expression import Expression, ExpressionFormat  # isort:skip
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
@@ -28,15 +33,15 @@
     to_dictionary: bool = False,
     limit: Optional[int] = None,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     search_pattern: SearchPattern | int = SearchPattern.CONTAINS,
     show_expression_as: ExpressionFormat | str = ExpressionFormat.TREE,
     show_filter_tokens: bool = False,
-    **filters
+    **filters,
 ) -> list["Filter"] | list[dict]:
     """Get a list of Filter objects or dicts. Optionally filter the
     objects by specifying filters parameter.
 
     Specify either `project_id` or `project_name`.
     When `project_id` is provided (not `None`), `project_name` is omitted.
 
@@ -70,17 +75,17 @@
             (expression is returned in `text` and `tokens` formats)
         show_filter_tokens (bool, optional): Specify whether "qualification"
             is returned in "tokens" format,
             along with `text` and `tree` formats.
             - If omitted or false, only `text` and `tree`
             formats are returned.
             - If true, all `text`, `tree` and `tokens` formats are returned.
-        **filters: Available filter parameters: ['id', 'name', 'description',
+        **filters: Available filter parameters: ['id', 'name',
             'type', 'subtype', 'date_created', 'date_modified', 'version',
-            'acg', 'icon_path', 'owner']
+            'acg', 'owner', 'ext_type']
     Returns:
         list of filter objects or list of filter dictionaries.
     """
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
         project_name=project_name,
@@ -98,21 +103,22 @@
     )
     if to_dictionary:
         return objects
     return [
         Filter.from_dict(
             {
                 "show_expression_as": show_expression_as
-                if isinstance(show_expression_as, ExpressionFormat) else
-                ExpressionFormat(show_expression_as),
+                if isinstance(show_expression_as, ExpressionFormat)
+                else ExpressionFormat(show_expression_as),
                 "show_filter_tokens": show_filter_tokens,
                 **obj,
             },
             connection,
-        ) for obj in objects
+        )
+        for obj in objects
     ]
 
 
 @class_version_handler('11.3.0000')
 class Filter(Entity, CopyMixin, DeleteMixin, MoveMixin):
     """Python representation of MicroStrategy Filter object.
 
@@ -158,35 +164,40 @@
             'ext_type',
             'date_created',
             'date_modified',
             'version',
             'owner',
             'ancestors',
             'acg',
-            'acl'
+            'acl',
         ): objects.get_object_info,
         (
             'id',
             'name',
             'description',
             'sub_type',
             'date_created',
             'date_modified',
             'path',
             'version_id',
             'is_embedded',
             'primary_locale',
             'qualification',
-            'destination_folder_id'
-        ): filters.get_filter
+            'destination_folder_id',
+        ): filters.get_filter,
     }
     _API_PATCH: dict = {
-        ('name', 'description', 'qualification', 'destination_folder_id',
-         'is_embedded'): (filters.update_filter, "put"),
-        ('folder_id'): (objects.update_object, 'partial_put')
+        (
+            'name',
+            'description',
+            'qualification',
+            'destination_folder_id',
+            'is_embedded',
+        ): (filters.update_filter, "put"),
+        ('folder_id'): (objects.update_object, 'partial_put'),
     }
     _PATCH_PATH_TYPES = {
         'name': str,
         'description': str,
         'destination_folder_id': str,
         'qualification': dict,
         'is_embedded': bool,
@@ -196,15 +207,15 @@
 
     def __init__(
         self,
         connection: "Connection",
         id: Optional[str] = None,
         name: Optional[str] = None,
         show_expression_as: ExpressionFormat | str = ExpressionFormat.TREE,
-        show_filter_tokens: bool = False
+        show_filter_tokens: bool = False,
     ):
         """Initialize filter object by its identifier.
 
         Args:
             connection: MicroStrategy connection object returned
                 by `connection.Connection()`
             id (str, optional): identifier of a pre-existing filter containing
@@ -219,37 +230,48 @@
             show_filter_tokens (bool, optional): specify whether `qualification`
                 is returned in `tokens` format, along with `text` and `tree`
                 format
         """
         connection._validate_project_selected()
         if id is None:
             found_filter = super()._find_object_with_name(
-                connection=connection, name=name, listing_function=list_filters
+                connection=connection,
+                name=name,
+                listing_function=partial(
+                    list_filters, search_pattern=SearchPattern.EXACTLY
+                ),
             )
             id = found_filter['id']
         super().__init__(
             connection=connection,
             object_id=id,
             show_expression_as=show_expression_as,
             show_filter_tokens=show_filter_tokens,
         )
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self.primary_locale = kwargs.get('primary_locale')
         self.is_embedded = kwargs.get('is_embedded')
         self.destination_folder_id = kwargs.get('destination_folder_id')
-        self.qualification = Expression.from_dict(kwargs.get('qualification'), self.connection
-                                                  ) if kwargs.get('qualification') else None
-        self._sub_type = ObjectSubType(kwargs.get('sub_type')) if kwargs.get('sub_type') else None
+        self.qualification = (
+            Expression.from_dict(kwargs.get('qualification'), self.connection)
+            if kwargs.get('qualification')
+            else None
+        )
+        self._sub_type = (
+            ObjectSubType(kwargs.get('sub_type')) if kwargs.get('sub_type') else None
+        )
         self._path = kwargs.get('path')
         show_expression_as = kwargs.get('show_expression_as', 'tree')
-        self._show_expression_as = show_expression_as if isinstance(
-            show_expression_as, ExpressionFormat
-        ) else ExpressionFormat(show_expression_as)
+        self._show_expression_as = (
+            show_expression_as
+            if isinstance(show_expression_as, ExpressionFormat)
+            else ExpressionFormat(show_expression_as)
+        )
         self._show_filter_tokens = kwargs.get('show_filter_tokens', False)
 
     @classmethod
     def create(
         cls,
         connection: "Connection",
         name: str,
@@ -300,31 +322,37 @@
         """
         qualification = {} if qualification is None else qualification
         body = {
             "information": {
                 "name": name,
                 "description": description,
                 "destinationFolderId": destination_folder.id
-                if isinstance(destination_folder, Folder) else destination_folder,
+                if isinstance(destination_folder, Folder)
+                else destination_folder,
                 "primaryLocale": primary_locale,
                 "isEmbedded": is_embedded,
             }
         }
         body = delete_none_values(body, recursion=True)
         body["qualification"] = (
-            qualification.to_dict() if isinstance(qualification, Expression) else qualification
+            qualification.to_dict()
+            if isinstance(qualification, Expression)
+            else qualification
         )
         response = filters.create_filter(
             connection=connection,
             body=body,
             show_expression_as=get_enum_val(show_expression_as, ExpressionFormat),
             show_filter_tokens=show_filter_tokens,
         ).json()
         if config.verbose:
-            logger.info(f"Successfully created filter named: '{name}' with ID: '{response['id']}'")
+            logger.info(
+                f"Successfully created filter named: '{name}' with ID: '"
+                f"{response['id']}'"
+            )
         return cls.from_dict(
             source={
                 **response,
                 'show_expression_as': show_expression_as,
                 'show_filter_tokens': show_filter_tokens,
             },
             connection=connection,
@@ -347,15 +375,17 @@
                 used to distinguish between objects within the same project
             qualification (Expression, dict, optional): the filter definition
                 written as an expression tree over predicate nodes
             is_embedded (bool, optional): if true indicates that the target
                 object of this reference is embedded within this object
         """
         qualification = (
-            {} if self.qualification is None and qualification is None else qualification
+            {}
+            if self.qualification is None and qualification is None
+            else qualification
         )
         properties = filter_params_for_func(self.alter, locals(), exclude=['self'])
         self._alter_properties(**properties)
 
     @property
     def sub_type(self):
         return self._sub_type
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/metric/dimensionality.py` & `mstrio-py-11.3.9.103/mstrio/modeling/metric/dimensionality.py`

 * *Files 2% similar despite different names*

```diff
@@ -52,15 +52,15 @@
         IGNORE = auto()
         NONE = auto()
 
     _FROM_DICT_MAP = {
         'dimensionality_unit_type': DimensionalityUnitType,
         'filtering': Filtering,
         'aggregation': Aggregation,
-        'target': SchemaObjectReference.from_dict
+        'target': SchemaObjectReference.from_dict,
     }
 
     dimensionality_unit_type: DimensionalityUnitType
     aggregation: Optional[Aggregation] = None
     filtering: Optional[Filtering] = None
     group_by: Optional[bool] = None
     relative_position: Optional[int] = None
@@ -95,25 +95,29 @@
             absent in report or level(dimensionality)
         allowAddingUnit: boolean whether to allow other users
             to add extra units
         prompt: reference to a prompt
     """
 
     _FROM_DICT_MAP = {
-        'dimensionality_units': [DimensionalityUnit], 'prompt': SchemaObjectReference
+        'dimensionality_units': [DimensionalityUnit],
+        'prompt': SchemaObjectReference,
     }
 
     dimensionality_units: Optional[list[DimensionalityUnit]] = None
     exclude_attribute: Optional[bool] = None
     allow_adding_unit: Optional[bool] = None
     prompt: Optional[SchemaObjectReference] = None
 
     @classmethod
     def from_dict(
-        cls, source: dict, connection: Optional['Connection'] = None, to_snake_case: bool = True
+        cls,
+        source: dict,
+        connection: Optional['Connection'] = None,
+        to_snake_case: bool = True,
     ):
         data = source.copy()
         data['dimensionality_units'] = data.get('dimty_units', [])
         return super().from_dict(data, connection, to_snake_case)
 
     def to_dict(cls, camel_case: bool = True) -> dict:
         obj_dict = super().to_dict(camel_case=camel_case)
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/metric/metric.py` & `mstrio-py-11.3.9.103/mstrio/modeling/metric/metric.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,25 +1,33 @@
-from dataclasses import dataclass
-from enum import auto, Enum
 import logging
-from typing import Optional, TYPE_CHECKING
+from dataclasses import dataclass
+from enum import Enum, auto
+from functools import partial
+from typing import TYPE_CHECKING, Optional
 
 from mstrio import config
 from mstrio.api import metrics, objects
 from mstrio.connection import Connection
 from mstrio.modeling.expression import Expression, ExpressionFormat
 from mstrio.modeling.metric import Dimensionality, FormatProperty, MetricFormat
-from mstrio.modeling.schema.helpers import DataType, ObjectSubType, SchemaObjectReference
-from mstrio.object_management import Folder, search_operations, SearchPattern
+from mstrio.modeling.schema.helpers import (
+    DataType,
+    ObjectSubType,
+    SchemaObjectReference,
+)
+from mstrio.object_management import Folder, SearchPattern, search_operations
 from mstrio.types import ObjectTypes
 from mstrio.users_and_groups.user import User
 from mstrio.utils.entity import CopyMixin, DeleteMixin, Entity, MoveMixin
 from mstrio.utils.enum_helper import AutoName, get_enum_val
 from mstrio.utils.helper import (
-    delete_none_values, Dictable, filter_params_for_func, get_valid_project_id
+    Dictable,
+    delete_none_values,
+    filter_params_for_func,
+    get_valid_project_id,
 )
 from mstrio.utils.version_helper import method_version_handler
 
 if TYPE_CHECKING:
     from mstrio.modeling.metric import Metric
 
 logger = logging.getLogger(__name__)
@@ -32,15 +40,15 @@
     metric_type: ObjectTypes = ObjectTypes.METRIC,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
     search_pattern: SearchPattern | int = SearchPattern.CONTAINS,
     show_expression_as: ExpressionFormat | str = ExpressionFormat.TOKENS,
-    **filters
+    **filters,
 ) -> list["Metric"] | list[dict]:
     """Get list of Metric objects or dicts with them.
 
     Optionally use `to_dictionary` to choose output format.
 
     Wildcards available for 'name':
         ? - any character
@@ -80,16 +88,14 @@
             name (str): Metric's name
             date_created (str): format: 2001-01-02T20:48:05.000+0000
             date_modified (str): format: 2001-01-02T20:48:05.000+0000
             version (str): Metric's version
             owner dict: e.g. {'id': <user's id>, 'name': <user's name>},
                 with one or both of the keys: id, name
             acg (str | int): access control group
-            root (str): Folder ID of the root folder where the search
-                will be performed.
 
     Returns:
         list with Metric objects or list of dictionaries
     """
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
@@ -100,74 +106,95 @@
     objects_ = search_operations.full_search(
         connection,
         object_types=metric_type,
         project=project_id,
         name=name,
         pattern=search_pattern,
         limit=limit,
-        **filters
+        **filters,
     )
+    for obj_ in objects_:
+        obj_['project_id'] = project_id
+
     if to_dictionary:
         return objects_
     else:
-        show_expression_as = show_expression_as if isinstance(
-            show_expression_as, ExpressionFormat
-        ) else ExpressionFormat(show_expression_as)
+        show_expression_as = (
+            show_expression_as
+            if isinstance(show_expression_as, ExpressionFormat)
+            else ExpressionFormat(show_expression_as)
+        )
         return [
-            Metric.from_dict({
-                **obj_, 'show_expression_as': show_expression_as
-            }, connection) for obj_ in objects_
+            Metric.from_dict(
+                {**obj_, 'show_expression_as': show_expression_as}, connection
+            )
+            for obj_ in objects_
         ]
 
 
 class DefaultSubtotals(Enum):
     AGGREGATION = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='F225147A4CA0BB97368A5689D9675E73'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='F225147A4CA0BB97368A5689D9675E73',
     )
     AVERAGE = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='B328C60462634223B2387D4ADABEEB53'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='B328C60462634223B2387D4ADABEEB53',
     )
     COUNT = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='078C50834B484EE29948FA9DD5300ADF'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='078C50834B484EE29948FA9DD5300ADF',
     )
     GEOMETRIC_MEAN = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='E1853D5A36C74F59A9F8DEFB3F9527A1'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='E1853D5A36C74F59A9F8DEFB3F9527A1',
     )
     MAXIMUM = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='B1F4AA7DE683441BA559AA6453C5113E'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='B1F4AA7DE683441BA559AA6453C5113E',
     )
     MEDIAN = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='83A663067F7E43B2ABF67FD38ECDC7FE'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='83A663067F7E43B2ABF67FD38ECDC7FE',
     )
     MINIMUM = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='00B7BFFF967F42C4B71A4B53D90FB095'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='00B7BFFF967F42C4B71A4B53D90FB095',
     )
     MODE = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='36226A4048A546139BE0AF5F24737BA8'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='36226A4048A546139BE0AF5F24737BA8',
     )
     PRODUCT = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='54E7BFD129514717A92BC44CF1FE5A32'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='54E7BFD129514717A92BC44CF1FE5A32',
     )
     RESERVED = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='F341109B11D5D528C00084916B98494F'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='F341109B11D5D528C00084916B98494F',
     )
     STANDARD_DEVIATION = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='7FBA414995194BBAB2CF1BB599209824'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='7FBA414995194BBAB2CF1BB599209824',
     )
     SUM_OF_WYA = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='F7AE84A511D78008B00092BE4E571AD0'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='F7AE84A511D78008B00092BE4E571AD0',
     )
     TOTAL = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='96C487AF4D12472A910C1ACACFB56EFB'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='96C487AF4D12472A910C1ACACFB56EFB',
     )
     VARIANCE = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='1769DBFCCF2D4392938E40418C6E065E'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='1769DBFCCF2D4392938E40418C6E065E',
     )
     WEIGHTED_YEARLY_AVERAGE = SchemaObjectReference(
-        sub_type=ObjectSubType.SYSTEM_SUBTOTAL, object_id='F7AE852A11D78008B00092BE4E571AD0'
+        sub_type=ObjectSubType.SYSTEM_SUBTOTAL,
+        object_id='F7AE852A11D78008B00092BE4E571AD0',
     )
 
 
 @dataclass
 class Threshold(Dictable):
     """Object that specifies a threshold
 
@@ -251,15 +278,15 @@
         format: MetricFormat object that stores the formatting of the metric
         subtotal_from_base: bool used to specify whether the metric is
             a subtotal from base type
         column_name_alias: name for the column representing the metric in SQL
         metric_format_type: specifies whether the metric has HTML content,
             MetricFormatType enumerator
         thresholds: list of Threshold for the metric
-        """
+    """
 
     @dataclass
     class Conditionality(Dictable):
         """Object that specifies the conditionality
 
         This class can only be used for simple metrics.
         For creation and altering of compound metrics, conditionality needs to
@@ -314,20 +341,24 @@
         }
 
         def __init__(
             self,
             definition: SchemaObjectReference | DefaultSubtotals | None = None,
             implementation: SchemaObjectReference | DefaultSubtotals | None = None,
         ) -> None:
-            self.definition = definition.value if isinstance(
-                definition, DefaultSubtotals
-            ) else definition
-            self.implementation = implementation.value if isinstance(
-                implementation, DefaultSubtotals
-            ) else implementation
+            self.definition = (
+                definition.value
+                if isinstance(definition, DefaultSubtotals)
+                else definition
+            )
+            self.implementation = (
+                implementation.value
+                if isinstance(implementation, DefaultSubtotals)
+                else implementation
+            )
 
     class MetricFormatType(AutoName):
         RESERVED = auto()
         HTML_TAG = auto()
         LAST_ONE = auto()
 
     class SmartTotal(AutoName):
@@ -356,15 +387,15 @@
             'formula_join_type',
             'smart_total',
             'data_type',
             'format',
             'subtotal_from_base',
             'column_name_alias',
             'metric_format_type',
-            'thresholds'
+            'thresholds',
         ): metrics.get_metric,
         (
             'abbreviation',
             'type',
             'ext_type',
             'date_created',
             'date_modified',
@@ -372,16 +403,16 @@
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
             'acg',
             'acl',
-            'target_info'
-        ): objects.get_object_info
+            'target_info',
+        ): objects.get_object_info,
     }
     _API_PATCH = {
         (
             'id',
             'sub_type',
             'name',
             'is_embedded',
@@ -395,39 +426,36 @@
             'formula_join_type',
             'smart_total',
             'data_type',
             'format',
             'subtotal_from_base',
             'column_name_alias',
             'metric_format_type',
-            'thresholds'
-        ): (metrics.update_metric, 'partial_put'),  # noqa: E131
-        ('folder_id'): (objects.update_object, 'partial_put')
+            'thresholds',
+        ): (metrics.update_metric, 'partial_put'),
+        'folder_id': (objects.update_object, 'partial_put'),
     }
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'owner': User.from_dict,
         'sub_type': ObjectSubType,
         'expression': Expression.from_dict,
         'dimensionality': Dimensionality.from_dict,
         'conditionality': Conditionality.from_dict,
-        'metric_subtotals': (
-            lambda source,
-            connection:
-            [Metric.MetricSubtotal.from_dict(content, connection) for content in source]
-        ),
+        'metric_subtotals': lambda source, connection: [
+            Metric.MetricSubtotal.from_dict(content, connection) for content in source
+        ],
         'formula_join_type': FormulaJoinType,
         'data_type': DataType.from_dict,
         'smart_total': SmartTotal,
         'format': MetricFormat.from_dict,
         'metric_format_type': MetricFormatType,
-        'thresholds': (
-            lambda source,
-            connection: [Threshold.from_dict(content, connection) for content in source]
-        ),
+        'thresholds': lambda source, connection: [
+            Threshold.from_dict(content, connection) for content in source
+        ],
     }
     _REST_ATTR_MAP = {
         'dimty': 'dimensionality',
     }
 
     @classmethod
     @method_version_handler('11.3.0500')
@@ -438,15 +466,15 @@
 
     @method_version_handler('11.3.0500')
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         name: Optional[str] = None,
-        show_expression_as: ExpressionFormat | str = ExpressionFormat.TOKENS
+        show_expression_as: ExpressionFormat | str = ExpressionFormat.TOKENS,
     ) -> None:
         """Initializes a new instance of Metric class
 
         Args:
             connection (Connection): MicroStrategy connection object returned
                 by `connection.Connection()`
             id (str, optional): Metric's ID. Defaults to None.
@@ -464,60 +492,89 @@
 
         Raises:
             ValueError: if both `id` and `name` are not provided
                 or if Metric with the given `name` doesn't exist.
         """
         if id is None:
             metric = super()._find_object_with_name(
-                connection=connection, name=name, listing_function=list_metrics
+                connection=connection,
+                name=name,
+                listing_function=partial(
+                    list_metrics, search_pattern=SearchPattern.EXACTLY
+                ),
             )
             id = metric['id']
         super().__init__(
-            connection=connection, object_id=id, name=name, show_expression_as=show_expression_as
+            connection=connection,
+            object_id=id,
+            name=name,
+            show_expression_as=show_expression_as,
         )
 
     @method_version_handler('11.3.0500')
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
-        self._id = kwargs.get('id')
-        self._sub_type = ObjectSubType(kwargs.get('sub_type')) if kwargs.get('sub_type') else None
-        self.name = kwargs.get('name')
+        self._sub_type = (
+            ObjectSubType(kwargs.get('sub_type')) if kwargs.get('sub_type') else None
+        )
         self._is_embedded = kwargs.get('is_embedded')
-        self.description = kwargs.get('description')
         self.destination_folder_id = kwargs.get('destination_folder_id')
 
-        self.expression = Expression.from_dict(exp) if (exp := kwargs.get('expression')) else None
-        self.dimensionality = Dimensionality.from_dict(dimty) if (
-            dimty := kwargs.get('dimensionality')
-        ) else None
-        self.conditionality = Metric.Conditionality.from_dict(cond) if (
-            cond := kwargs.get('conditionality')
-        ) else None
-        self.metric_subtotals = [
-            Metric.MetricSubtotal.from_dict(subtotal) for subtotal in subtotals
-        ] if (subtotals := kwargs.get('metric_subtotals')) else None
+        self.expression = (
+            Expression.from_dict(exp) if (exp := kwargs.get('expression')) else None
+        )
+        self.dimensionality = (
+            Dimensionality.from_dict(dimty)
+            if (dimty := kwargs.get('dimensionality'))
+            else None
+        )
+        self.conditionality = (
+            Metric.Conditionality.from_dict(cond)
+            if (cond := kwargs.get('conditionality'))
+            else None
+        )
+        self.metric_subtotals = (
+            [Metric.MetricSubtotal.from_dict(subtotal) for subtotal in subtotals]
+            if (subtotals := kwargs.get('metric_subtotals'))
+            else None
+        )
         self.aggregate_from_base = kwargs.get('aggregate_from_base')
-        self.formula_join_type = Metric.FormulaJoinType(join_type) if (
-            join_type := kwargs.get('formula_join_type')
-        ) else None
-        self.smart_total = Metric.SmartTotal(tot) if (tot := kwargs.get('smart_total')) else None
-        self.data_type = DataType.from_dict(dtype) if (dtype := kwargs.get('data_type')) else None
-        self.format = MetricFormat.from_dict(form) if (form := kwargs.get('format')) else None
+        self.formula_join_type = (
+            Metric.FormulaJoinType(join_type)
+            if (join_type := kwargs.get('formula_join_type'))
+            else None
+        )
+        self.smart_total = (
+            Metric.SmartTotal(tot) if (tot := kwargs.get('smart_total')) else None
+        )
+        self.data_type = (
+            DataType.from_dict(dtype) if (dtype := kwargs.get('data_type')) else None
+        )
+        self.format = (
+            MetricFormat.from_dict(form) if (form := kwargs.get('format')) else None
+        )
         self.subtotal_from_base = kwargs.get('subtotal_from_base')
         self.column_name_alias = kwargs.get('column_name_alias')
-        self.metric_format_type = Metric.MetricFormatType(fromat_type) if (
-            fromat_type := kwargs.get('metric_format_type')
-        ) else None
-        self.thresholds = [Threshold.from_dict(threshold) for threshold in thresholds
-                           ] if (thresholds := kwargs.get('thresholds')) else None  # noqa: E124
+        self.metric_format_type = (
+            Metric.MetricFormatType(fromat_type)
+            if (fromat_type := kwargs.get('metric_format_type'))
+            else None
+        )
+        self.thresholds = (
+            [Threshold.from_dict(threshold) for threshold in thresholds]
+            if (thresholds := kwargs.get('thresholds'))
+            else None
+        )
 
         show_expression_as = kwargs.get('show_expression_as', 'tree')
-        self.show_expression_as = show_expression_as if isinstance(
-            show_expression_as, ExpressionFormat
-        ) else ExpressionFormat(show_expression_as)
+        self.show_expression_as = (
+            show_expression_as
+            if isinstance(show_expression_as, ExpressionFormat)
+            else ExpressionFormat(show_expression_as)
+        )
 
     @classmethod
     @method_version_handler('11.3.0500')
     def create(
         cls,
         connection: 'Connection',
         name: str,
@@ -585,46 +642,56 @@
         """
         body = {
             'information': {
                 'name': name,
                 'subType': get_enum_val(sub_type, ObjectSubType),
                 'isEmbedded': is_embedded,
                 'description': description,
-                'destinationFolderId': destination_folder.id
-                if isinstance(destination_folder, Folder) else destination_folder,
+                'destinationFolderId': (
+                    destination_folder.id
+                    if isinstance(destination_folder, Folder)
+                    else destination_folder
+                ),
             },
             'expression': expression.to_dict() if expression else None,
             'dimty': dimensionality.to_dict() if dimensionality else None,
             'conditionality': conditionality.to_dict() if conditionality else None,
-            'metricSubtotals': [sub.to_dict() for sub in metric_subtotals]
-            if metric_subtotals else None,  # noqa: E131
+            'metricSubtotals': (
+                [sub.to_dict() for sub in metric_subtotals]
+                if metric_subtotals
+                else None
+            ),
             'aggregateFromBase': aggregate_from_base,
             'formulaJoinType': formula_join_type.value if formula_join_type else None,
             'smartTotal': smart_total.value if smart_total else None,
             'dataType': data_type.to_dict() if data_type else None,
             'format': format.to_dict() if format else None,
             'subtotalFromBase': subtotal_from_base,
             'columnNameAlias': column_name_alias,
-            'metricFormatType': metric_format_type.value if metric_format_type else None,
+            'metricFormatType': (
+                metric_format_type.value if metric_format_type else None
+            ),
             'thresholds': [x.to_dict() for x in thresholds] if thresholds else None,
         }
         body = delete_none_values(body, recursion=True)
         response = metrics.create_metric(
             connection,
             body=body,
-            show_expression_as=get_enum_val(show_expression_as, ExpressionFormat)
+            show_expression_as=get_enum_val(show_expression_as, ExpressionFormat),
         ).json()
 
         if config.verbose:
-            logger.info(f"Successfully created metric named: '{name}' with ID: '{response['id']}'")
+            logger.info(
+                f"Successfully created metric named: '{name}' with ID:"
+                f" '{response['id']}'"
+            )
 
         return cls.from_dict(
-            source={
-                **response, 'show_expression_as': show_expression_as
-            }, connection=connection
+            source={**response, 'show_expression_as': show_expression_as},
+            connection=connection,
         )
 
     @method_version_handler('11.3.0500')
     def alter(
         self,
         name: str = None,
         destination_folder_id: str = None,
@@ -693,7 +760,11 @@
     @property
     def sub_type(self):
         return self._sub_type
 
     @property
     def is_embedded(self):
         return self._is_embedded
+
+    @property
+    def project_id(self):
+        return self._project_id if self._project_id else self.connection.project_id
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/metric/metric_format.py` & `mstrio-py-11.3.9.103/mstrio/modeling/metric/metric_format.py`

 * *Files 6% similar despite different names*

```diff
@@ -174,35 +174,46 @@
             return (
                 format(int(r, original_base), format_spec[desired_base]),
                 format(int(g, original_base), format_spec[desired_base]),
                 format(int(b, original_base), format_spec[desired_base]),
             )
 
         def _init_from_hex(self, hex_val: str) -> str:
-            r, g, b = self._rgb_base_converter(r=hex_val[1:3], g=hex_val[3:5], b=hex_val[5:7],
-                                               original_base=16, desired_base=2)
+            r, g, b = self._rgb_base_converter(
+                r=hex_val[1:3],
+                g=hex_val[3:5],
+                b=hex_val[5:7],
+                original_base=16,
+                desired_base=2,
+            )
             self.server_value = str(int(r + g + b, 2))
             self.hex_value = hex_val
             self.red, self.green, self.blue = self._rgb_base_converter(r, g, b, 2, 10)
 
         def _init_from_rest(self, rest_val: str) -> str:
             bin_color = format(int(rest_val), '0>24b')
-            r, g, b = self._rgb_base_converter(r=bin_color[0:8], g=bin_color[8:16],
-                                               b=bin_color[16:24], original_base=2,
-                                               desired_base=16)
+            r, g, b = self._rgb_base_converter(
+                r=bin_color[0:8],
+                g=bin_color[8:16],
+                b=bin_color[16:24],
+                original_base=2,
+                desired_base=16,
+            )
             self.server_value = rest_val
             self.hex_value = f'#{r}{g}{b}'
             self.red, self.green, self.blue = self._rgb_base_converter(r, g, b, 16, 10)
 
         def _init_from_rgb(self, red: str, green: str, blue: str) -> str:
-            r, g, b = self._rgb_base_converter(r=red, g=green, b=blue, original_base=10,
-                                               desired_base=2)
+            r, g, b = self._rgb_base_converter(
+                r=red, g=green, b=blue, original_base=10, desired_base=2
+            )
             self.server_value = str(int(r + g + b, 2))
-            r, g, b = self._rgb_base_converter(r=red, g=green, b=blue, original_base=10,
-                                               desired_base=16)
+            r, g, b = self._rgb_base_converter(
+                r=red, g=green, b=blue, original_base=10, desired_base=16
+            )
             self.hex_value = f'#{r}{g}{b}'
             self.red, self.green, self.blue = red, green, blue
 
         hex_value: str
         server_value: str
         red: str
         green: str
@@ -210,15 +221,15 @@
 
         def __init__(
             self,
             hex_value: str | None = None,
             red: int | None = None,
             green: int | None = None,
             blue: int | None = None,
-            server_value: str | None = None
+            server_value: str | None = None,
         ):
             """Create an object representing color value of a `FormatProperty`.
              It can be created by providing either hex value, server readable
              value or all three RGB components. Two other representation will
              be generated automatically based on the one provided by the user.
              If more than one representation provided, priority goes as follows:
              server_value->hex_value->RGB values.
@@ -226,28 +237,33 @@
             Args:
                 hex_value(str): color expressed in hex format (e.g. '#ff02ef')
                 server_value(str): color translated for server readable format
                 red(int): component of a RGB format, expressed as decimal
                 green(int): component of a RGB format, expressed as decimal
                 blue(int): component of a RGB format, expressed as decimal"""
 
-            if server_value is not None and isinstance(server_value,
-                                                       str) and server_value.isnumeric():
+            if (
+                server_value is not None
+                and isinstance(server_value, str)
+                and server_value.isnumeric()
+            ):
                 self._init_from_rest(rest_val=server_value)
             elif hex_value is not None and hex_value[0] == '#' and len(hex_value) == 7:
                 self._init_from_hex(hex_val=hex_value)
             elif red in range(256) and green in range(256) and blue in range(256):
                 self._init_from_rgb(str(red), str(green), str(blue))
             else:
-                raise ValueError('Invalid parameter for Color value of the format property.')
+                raise ValueError(
+                    'Invalid parameter for Color value of the format property.'
+                )
 
         def __repr__(self):
             return (
-                f'hex_value: {self.hex_value}, rgb: ({self.red}, {self.green}, {self.blue}), '
-                f'server_value: {self.server_value}'
+                f'hex_value: {self.hex_value}, rgb: ({self.red}, {self.green}, '
+                f'{self.blue}), server_value: {self.server_value}'
             )
 
     _FROM_DICT_MAP = {
         'type': FormatType,
     }
     type: FormatType
     value: Union[str, "FormatProperty.Color"]
@@ -258,24 +274,25 @@
         return {'type': self.type.value, 'value': self.value}
 
     @classmethod
     def from_dict(
         cls,
         source: Dict[str, Any],
         connection: Optional["Connection"] = None,
-        to_snake_case: bool = True
+        to_snake_case: bool = True,
     ) -> "FormatProperty":
         if source.get('type'):
             if 'color' in source.get('type'):
                 return FormatProperty(
                     type=FormatProperty.FormatType(source.get('type')),
-                    value=FormatProperty.Color(server_value=source.get('value'))
+                    value=FormatProperty.Color(server_value=source.get('value')),
                 )
             return FormatProperty(
-                type=FormatProperty.FormatType(source.get('type')), value=source.get('value')
+                type=FormatProperty.FormatType(source.get('type')),
+                value=source.get('value'),
             )
 
 
 @dataclass
 class MetricFormat(Dictable):
     """Object that specifies the formatting of the metric's values and headers
 
@@ -284,18 +301,20 @@
             of the metric
         header (list[FormatProperty]): list of format properties for the header
             of the metric
     """
 
     _FROM_DICT_MAP = {
         'values': (
-            lambda source,
-            connection: [FormatProperty.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                FormatProperty.from_dict(content, connection) for content in source
+            ]
         ),
         'header': (
-            lambda source,
-            connection: [FormatProperty.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                FormatProperty.from_dict(content, connection) for content in source
+            ]
         ),
     }
 
     values: list[FormatProperty]
     header: list[FormatProperty]
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/attribute/attribute.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/attribute/attribute.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,32 +1,41 @@
-from copy import deepcopy
 import logging
-from typing import Callable, Optional, TYPE_CHECKING, Union
 import warnings
+from copy import deepcopy
+from functools import partial
+from typing import TYPE_CHECKING, Callable, Optional, Union
 
 from mstrio import config
 from mstrio.api import attributes, hierarchies, objects, tables
 from mstrio.connection import Connection
 from mstrio.modeling.expression import Expression, ExpressionFormat, FactExpression
-from mstrio.modeling.schema.attribute import AttributeForm, Relationship
+from mstrio.modeling.schema.attribute import (
+    AttributeForm,
+    Relationship,
+    RelationshipType,
+)
 from mstrio.modeling.schema.helpers import (
     AttributeDisplays,
     AttributeSorts,
     DataType,
     FormReference,
     ObjectSubType,
-    SchemaObjectReference
+    SchemaObjectReference,
 )
 from mstrio.object_management import search_operations
 from mstrio.object_management.folder import Folder
 from mstrio.object_management.search_enums import SearchPattern
 from mstrio.types import ObjectSubTypes, ObjectTypes
 from mstrio.utils.entity import CopyMixin, DeleteMixin, Entity, MoveMixin
 from mstrio.utils.enum_helper import get_enum_val
-from mstrio.utils.helper import delete_none_values, filter_params_for_func, get_valid_project_id
+from mstrio.utils.helper import (
+    delete_none_values,
+    filter_params_for_func,
+    get_valid_project_id,
+)
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 if TYPE_CHECKING:
     from mstrio.modeling.schema.attribute import Attribute
 
 logger = logging.getLogger(__name__)
 
@@ -83,20 +92,23 @@
             should be presented
             Available values:
                 - `ExpressionFormat.TREE` or `tree` (default)
                 - `ExpressionFormat.TOKENS or `tokens`
         **filters: Available filter parameters:
             id str: Attribute's ID
             name str: Attribute's name
+            description str: Attribute's description
             date_created str: format: 2001-01-02T20:48:05.000+0000
             date_modified str: format: 2001-01-02T20:48:05.000+0000
             version str: Attribute's version
             owner dict: e.g. {'id': <user's id>, 'name': <user's name>},
                 with one or both of the keys: id, name
             acg str | int: access control group
+            subtype str: object's subtype
+            ext_type str: object's extended type
 
     Returns:
         list with Attribute objects or list of dictionaries
     """
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
@@ -114,21 +126,24 @@
         pattern=search_pattern,
         limit=limit,
         **filters,
     )
     if to_dictionary:
         return objects_
     else:
-        show_expression_as = show_expression_as if isinstance(
-            show_expression_as, ExpressionFormat
-        ) else ExpressionFormat(show_expression_as)
+        show_expression_as = (
+            show_expression_as
+            if isinstance(show_expression_as, ExpressionFormat)
+            else ExpressionFormat(show_expression_as)
+        )
         return [
-            Attribute.from_dict({
-                **obj_, 'show_expression_as': show_expression_as
-            }, connection) for obj_ in objects_
+            Attribute.from_dict(
+                {**obj_, 'show_expression_as': show_expression_as}, connection
+            )
+            for obj_ in objects_
         ]
 
 
 @class_version_handler('11.3.0100')
 class Attribute(Entity, CopyMixin, MoveMixin, DeleteMixin):  # noqa
     """Python representation of MicroStrategy Attribute object.
 
@@ -158,15 +173,16 @@
         is_embedded: If true indicates that the target object of this
             reference is embedded within this object. Alternatively if
             this object is itself embedded, then it means that the target
             object is embedded in the same container as this object.
         owner: User object that is the owner
         acg: access rights (See EnumDSSXMLAccessRightFlags for possible values)
         acl: object access control list
-        """
+        hidden: Specifies whether the object is hidden.
+    """
 
     _OBJECT_TYPE = ObjectTypes.ATTRIBUTE
     _API_GETTERS = {
         (
             'id',
             'sub_type',
             'name',
@@ -174,15 +190,15 @@
             'description',
             'destination_folder_id',
             'forms',
             'attribute_lookup_table',
             'key_form',
             'displays',
             'sorts',
-            'relationships'
+            'relationships',
         ): attributes.get_attribute,
         (
             'abbreviation',
             'type',
             'subtype',
             'ext_type',
             'date_created',
@@ -191,53 +207,58 @@
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
             'acg',
             'acl',
-            'target_info'
-        ): objects.get_object_info
+            'target_info',
+            'hidden',
+        ): objects.get_object_info,
     }
     _API_PATCH = {
         (
             'id',
             'sub_type',
             'name',
             'is_embedded',
             'description',
             'destination_folder_id',
             'forms',
             'attribute_lookup_table',
             'key_form',
             'displays',
-            'sorts'
+            'sorts',
         ): (attributes.update_attribute, 'partial_put'),
-        ('relationships'): (hierarchies.update_attribute_relationships, 'partial_put'),
-        ('folder_id'): (objects.update_object, 'partial_put')
+        'relationships': (hierarchies.update_attribute_relationships, 'partial_put'),
+        ('folder_id', 'hidden'): (objects.update_object, 'partial_put'),
     }
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         "forms": (
-            lambda source,
-            connection: [AttributeForm.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                AttributeForm.from_dict(content, connection) for content in source
+            ]
         ),
         "relationships": (
-            lambda source,
-            connection: [Relationship.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                Relationship.from_dict(content, connection) for content in source
+            ]
         ),
         "attribute_lookup_table": SchemaObjectReference.from_dict,
         "key_form": FormReference.from_dict,
         "displays": AttributeDisplays.from_dict,
         "sorts": AttributeSorts.from_dict,
     }
 
     @staticmethod
     def validate_key_form(
-        key_form: FormReference, forms: list[AttributeForm], error_msg: Optional[str] = None
+        key_form: FormReference,
+        forms: list[AttributeForm],
+        error_msg: Optional[str] = None,
     ) -> FormReference:
         """Validate whether the key form exists in the list of attribute forms
             provided
 
         Args:
             key_form: a key form of an attribute to perform validation on
             forms: the list of the attribute forms
@@ -248,15 +269,17 @@
             A validated key form."""
 
         # if forms is None or len(forms) < 1:
         if not forms:
             raise AttributeError("`forms` can not be empty.")
         elif len(forms) == 1:
             return FormReference(name=forms[0].name)
-        elif key_form is None or not any(form.is_referenced_by(key_form) for form in forms):
+        elif key_form is None or not any(
+            form.is_referenced_by(key_form) for form in forms
+        ):
             raise AttributeError(
                 error_msg or "Please select a `key_form` from the `forms` provided."
             )
         return key_form
 
     @staticmethod
     def check_if_referenced_forms_exist(
@@ -284,29 +307,36 @@
             forms: list of AttributeForm objects of the Attribute
 
         Returns:
             Validated, non-empty and properly referencing Attribute Displays"""
         # Displays CAN'T be empty. Create and populate with form refs
         if displays is None:
             form_refs = [FormReference(id=form.id) for form in forms]
-            return AttributeDisplays(report_displays=form_refs, browse_displays=form_refs)
+            return AttributeDisplays(
+                report_displays=form_refs, browse_displays=form_refs
+            )
         if displays.report_displays == []:
             displays.report_displays = [FormReference(id=form.id) for form in forms]
         if displays.browse_displays == []:
             displays.browse_displays = [FormReference(id=form.id) for form in forms]
 
         # Validate if displays use form refs not present in forms
         error_msg = "FormReference present in `displays` is not present in `forms`."
-        Attribute.check_if_referenced_forms_exist(error_msg, forms, displays.report_displays)
-        Attribute.check_if_referenced_forms_exist(error_msg, forms, displays.browse_displays)
+        Attribute.check_if_referenced_forms_exist(
+            error_msg, forms, displays.report_displays
+        )
+        Attribute.check_if_referenced_forms_exist(
+            error_msg, forms, displays.browse_displays
+        )
         return displays
 
     @staticmethod
-    def validate_sorts(sorts: AttributeSorts,
-                       forms: list[AttributeForm]) -> Optional[AttributeSorts]:
+    def validate_sorts(
+        sorts: AttributeSorts, forms: list[AttributeForm]
+    ) -> Optional[AttributeSorts]:
         """Validate whether the sorts use form references that aren't present
             in the provided forms
 
         Args:
             sorts: the collections of attribute sorts and browse sorts
                 of the attribute
             forms: list of AttributeForm objects of the Attribute
@@ -387,47 +417,49 @@
         body = {
             'information': {
                 'name': name,
                 'subType': get_enum_val(sub_type, ObjectSubType),
                 'isEmbedded': is_embedded,
                 'description': description,
                 'destinationFolderId': destination_folder.id
-                if isinstance(destination_folder, Folder) else destination_folder,
+                if isinstance(destination_folder, Folder)
+                else destination_folder,
             },
             'forms': [form.to_dict() for form in forms] if forms else None,
             'attributeLookupTable': attribute_lookup_table.to_dict()
-            if attribute_lookup_table else None,
+            if attribute_lookup_table
+            else None,
             'keyForm': key_form.to_dict() if key_form else None,
             'displays': displays.to_dict() if displays else None,
             'sorts': sorts.to_dict() if sorts else None,
         }
         body = delete_none_values(body, recursion=True)
         response = attributes.create_attribute(
             connection,
             body=body,
-            show_expression_as=get_enum_val(show_expression_as, ExpressionFormat)
+            show_expression_as=get_enum_val(show_expression_as, ExpressionFormat),
         ).json()
 
         if config.verbose:
             logger.info(
-                f"Successfully created attribute named: '{name}' with ID: '{response['id']}'"
+                f"Successfully created attribute named: '{name}' with ID: '"
+                f"{response['id']}'"
             )
 
         return cls.from_dict(
-            source={
-                **response, 'show_expression_as': show_expression_as
-            }, connection=connection
+            source={**response, 'show_expression_as': show_expression_as},
+            connection=connection,
         )
 
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         name: Optional[str] = None,
-        show_expression_as: Union[ExpressionFormat, str] = ExpressionFormat.TREE
+        show_expression_as: Union[ExpressionFormat, str] = ExpressionFormat.TREE,
     ) -> None:
         """Initializes a new instance of Attribute class
 
         Args:
             connection (Connection): MicroStrategy connection object returned
                 by `connection.Connection()`
             id (str, optional): Attribute's ID. Defaults to None.
@@ -445,61 +477,85 @@
 
         Raises:
             ValueError: if both `id` and `name` are not provided or
             if Attribute with the given `name` doesn't exist.
         """
         if id is None:
             attribute = super()._find_object_with_name(
-                connection=connection, name=name, listing_function=list_attributes
+                connection=connection,
+                name=name,
+                listing_function=partial(
+                    list_attributes, search_pattern=SearchPattern.EXACTLY
+                ),
             )
             id = attribute['id']
         super().__init__(
-            connection=connection, object_id=id, name=name, show_expression_as=show_expression_as
+            connection=connection,
+            object_id=id,
+            name=name,
+            show_expression_as=show_expression_as,
         )
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
-        self._id = kwargs.get('id')
         self._sub_type = kwargs.get('sub_type')
-        self.name = kwargs.get('name')
         self._is_embedded = kwargs.get('is_embedded')
-        self.description = kwargs.get('description')
         self._destination_folder_id = kwargs.get('destination_folder_id')
-        self._forms = [
-            AttributeForm.from_dict(expr, self._connection) for expr in kwargs.get('forms')
-        ] if kwargs.get('forms') else None
-        self._attribute_lookup_table = SchemaObjectReference.from_dict(
-            kwargs.get('attribute_lookup_table')
-        ) if kwargs.get('attribute_lookup_table') else None
-        self._key_form = FormReference.from_dict(kwargs.get('key_form')
-                                                 ) if kwargs.get('key_form') else None
-        self._displays = AttributeDisplays.from_dict(kwargs.get('displays')
-                                                     ) if kwargs.get('displays') else None
-        self._sorts = AttributeSorts.from_dict(kwargs.get('sorts')
-                                               ) if kwargs.get('sorts') else None
-        self._relationships = [kwargs.get('relationships')
-                               ] if kwargs.get('relationships') else None  # noqa
+        self._forms = (
+            [
+                AttributeForm.from_dict(expr, self._connection)
+                for expr in kwargs.get('forms')
+            ]
+            if kwargs.get('forms')
+            else None
+        )
+        self._attribute_lookup_table = (
+            SchemaObjectReference.from_dict(kwargs.get('attribute_lookup_table'))
+            if kwargs.get('attribute_lookup_table')
+            else None
+        )
+        self._key_form = (
+            FormReference.from_dict(kwargs.get('key_form'))
+            if kwargs.get('key_form')
+            else None
+        )
+        self._displays = (
+            AttributeDisplays.from_dict(kwargs.get('displays'))
+            if kwargs.get('displays')
+            else None
+        )
+        self._sorts = (
+            AttributeSorts.from_dict(kwargs.get('sorts'))
+            if kwargs.get('sorts')
+            else None
+        )
+        self._relationships = (
+            [kwargs.get('relationships')] if kwargs.get('relationships') else None
+        )
         show_expression_as = kwargs.get('show_expression_as', 'tree')
-        self._show_expression_as = show_expression_as if isinstance(
-            show_expression_as, ExpressionFormat
-        ) else ExpressionFormat(show_expression_as)
+        self._show_expression_as = (
+            show_expression_as
+            if isinstance(show_expression_as, ExpressionFormat)
+            else ExpressionFormat(show_expression_as)
+        )
 
     def alter(
         self,
         sub_type: Optional[str] = None,
         name: Optional[str] = None,
         is_embedded: Optional[bool] = None,
         description: Optional[str] = None,
         destination_folder_id: Optional[str] = None,
         forms: Optional[list[AttributeForm]] = None,
         attribute_lookup_table: Optional[SchemaObjectReference] = None,
         key_form: Optional[FormReference] = None,
         displays: Optional[AttributeDisplays] = None,
         sorts: Optional[AttributeSorts] = None,
         relationships: Optional[Relationship] = None,
+        hidden: Optional[bool] = None,
     ):
         """Alter attribute properties.
 
         Args:
             name: attribute's name
             description: attribute's description
             is_embedded: If true indicates that the target object of this
@@ -517,74 +573,91 @@
                 the referenced objects.
             key_form: a key form of an attribute
             displays: The collections of attribute displays and browse displays
                 of the attribute.
             sorts: The collections of attribute sorts and browse sorts
                 of the attribute.
             relationships: the list of relationships that one attribute has.
+            hidden: Specifies whether the attribute is hidden.
         """
-        key_form = self.validate_key_form(key_form or self.key_form, forms or self.forms)
-        displays = self.validate_displays(displays or self.displays, forms or self.forms)
+        # REST doesn't return hidden attribute if its value is False.
+        # If attribute is not present in response, the mstrio engine
+        # interprets this as 'no value' and sets its value to None.
+        # But if attribute's value is not None, and REST returns nothing
+        # the engine does nothing, and doesn't change its value.
+        # So if 'hidden' has value True, and is changed to False,
+        # the REST will return nothing, and locally its value will stay True.
+        # This line is to update local value of 'hidden'.
+        self._hidden = hidden
+
+        key_form = self.validate_key_form(
+            key_form or self.key_form, forms or self.forms
+        )
+        displays = self.validate_displays(
+            displays or self.displays, forms or self.forms
+        )
         sorts = self.validate_sorts(sorts or self.sorts, forms or self.forms)
 
         properties = filter_params_for_func(self.alter, locals(), exclude=['self'])
         self._alter_properties(**properties)
 
     # Attribute relationships management
     def add_child(
         self,
         child: Optional[SchemaObjectReference] = None,
         joint_child: Optional[list[SchemaObjectReference]] = None,
-        relationship_type: Relationship.RelationshipType = Relationship.RelationshipType
-        .ONE_TO_MANY,
-        table: Optional[SchemaObjectReference] = None
+        relationship_type: RelationshipType = RelationshipType.ONE_TO_MANY,
+        table: Optional[SchemaObjectReference] = None,
     ) -> None:
         """Add a child to the attribute.
 
         Args:
             child: SchemaObjectReference of an attribute
             joint_child: list of SchemaObjectReferences of an attributes
             relationship_type: RelationshipType enum object, by default
                 RelationshipType.ONE_TO_MANY
             table: SchemaObjectReference of a lookup table, if not passed
                 attribute lookup table is used
         """
         if (child and joint_child) or (not child and not joint_child):
-            raise ValueError("Please specify either 'child' or 'joint_child' parameter.")
+            raise ValueError(
+                "Please specify either 'child' or 'joint_child' parameter."
+            )
         elif child:
             for rel in self.relationships:
                 if hasattr(rel, 'child') and rel.child == child:
                     warnings.warn(
                         f"{child.name} already is a child of the attribute '{self.id}'"
                         " and will be omitted."
                     )
                     return None
         elif joint_child:
             for rel in self.relationships:
                 if hasattr(rel, 'joint_child') and rel.joint_child == joint_child:
-                    children = "[" + ", ".join(child.name for child in joint_child) + "]"
+                    children = (
+                        "[" + ", ".join(child.name for child in joint_child) + "]"
+                    )
                     warnings.warn(
-                        f"{children} already is a joint_child of the attribute '{self.id}'"
-                        " and will be omitted."
+                        f"{children} already is a joint_child of the attribute '"
+                        f"{self.id}' and will be omitted."
                     )
                     return None
 
         parent = SchemaObjectReference.create_from(self)
         table = table or self.attribute_lookup_table
 
         return self._update_relationships(
             Relationship(relationship_type, table, parent, child, joint_child)
         )
 
     def add_parent(
         self,
         parent: SchemaObjectReference,
-        relationship_type: Relationship.RelationshipType = Relationship.RelationshipType
-        .ONE_TO_MANY,
-        table: Optional[SchemaObjectReference] = None
+        relationship_type: RelationshipType = RelationshipType.ONE_TO_MANY,
+        table: Optional[SchemaObjectReference] = None,
     ) -> None:
         """Add a parent to the attribute.
 
         Args:
             parent: SchemaObjectReference of an attribute
             relationship_type: RelationshipType enum object, by default
                 RelationshipType.ONE_TO_MANY
@@ -597,31 +670,35 @@
                     f"{parent.name} already is a parent of the attribute '{self.id}'"
                     " and will be omitted."
                 )
                 return None
         child = SchemaObjectReference.create_from(self)
         table = table or self.attribute_lookup_table
 
-        return self._update_relationships(Relationship(relationship_type, table, parent, child))
+        return self._update_relationships(
+            Relationship(relationship_type, table, parent, child)
+        )
 
     def remove_child(
         self,
         child: Optional[SchemaObjectReference] = None,
-        joint_child: Optional[list[SchemaObjectReference]] = None
+        joint_child: Optional[list[SchemaObjectReference]] = None,
     ) -> None:
         """Removes a child of the attribute.
 
         Args:
             child: SchemaObjectReference of an attribute to be removed
                 from child relationship
             joint_child: list of SchemaObjectReferences of an attributes
                 to be removed from joint child relationship
         """
         if (child and joint_child) or (not child and not joint_child):
-            raise ValueError("Please specify either 'child' or 'joint_child' parameter.")
+            raise ValueError(
+                "Please specify either 'child' or 'joint_child' parameter."
+            )
         elif joint_child:
             for rel in self.relationships:
                 if hasattr(rel, 'joint_child') and rel.joint_child == joint_child:
                     return self._update_relationships(rel, add=False)
             child_name = "[" + ", ".join(child.name for child in joint_child) + "]"
         elif child:
             for rel in self.relationships:
@@ -642,15 +719,16 @@
                 from parent relationship
         """
         for rel in self.relationships:
             if rel.parent.object_id == parent.object_id and parent.object_id != self.id:
                 return self._update_relationships(rel, add=False)
 
         warnings.warn(
-            f"{parent.name} is not a parent of the attribute '{self.id}' and will be omitted."
+            f"{parent.name} is not a parent of the attribute '{self.id}' and will be "
+            f"omitted."
         )
 
     def _update_relationships(self, relationship: Relationship, add=True) -> None:
         """Inner method for sending updated relationships list.
 
         Args:
             relationship: relationship to add or remove
@@ -676,15 +754,18 @@
         Returns:
             Dictionary with table names as keys and list
             of SchemaObjectReferences of the attributes as values
             if to_dictionary set to True, list of SchemaObjectReference
             of attributes as list otherwise.
         """
         key_form_expressions = [
-            expr for form in self.forms if form.id == self.key_form.id for expr in form.expressions
+            expr
+            for form in self.forms
+            if form.id == self.key_form.id
+            for expr in form.expressions
         ]
         potential_tables = [tab for exp in key_form_expressions for tab in exp.tables]
 
         result = {}
         for tab in potential_tables:
             table = tables.get_table(
                 self.connection, tab.object_id, project_id=self.connection.project_id
@@ -705,24 +786,29 @@
 
         if already_used is False:
             children = [
                 rel.child
                 for rel in self.relationships
                 if hasattr(rel, 'child') and rel.child.object_id != self.id
             ]
-            parents = [rel.parent for rel in self.relationships if rel.parent.object_id != self.id]
+            parents = [
+                rel.parent
+                for rel in self.relationships
+                if rel.parent.object_id != self.id
+            ]
             used = [*children, *parents]
             result = {
                 tab: [candidate for candidate in candidates if candidate not in used]
-                for tab,
-                candidates in result.items()
+                for tab, candidates in result.items()
             }
 
         if to_dictionary is False:
-            result = list({ref for references in list(result.values()) for ref in references})
+            result = list(
+                {ref for references in list(result.values()) for ref in references}
+            )
 
         return result
 
     def list_tables(
         self, expression: Optional[Union[FactExpression, str]] = None
     ) -> list[SchemaObjectReference]:
         """List all tables in the given expression. If expression is not
@@ -734,15 +820,17 @@
         Returns:
             List of tables in the given expression or all tables for attribute.
         """
         expressions = [
             expr for form in self.forms if form.expressions for expr in form.expressions
         ]
         if expression:
-            expression_id = expression.id if isinstance(expression, FactExpression) else expression
+            expression_id = (
+                expression.id if isinstance(expression, FactExpression) else expression
+            )
             expressions = [expr for expr in expressions if expr.id == expression_id]
 
         table_list = {tab for expr in expressions for tab in expr.tables}
 
         return list(table_list)
 
     # Attribute forms management
@@ -776,16 +864,17 @@
         elif name:
             for form in self.forms:
                 if form.name == name:
                     return form
         else:
             raise ValueError("Provide id or name.")
 
-    def get_fact_expression(self, expression_id: str, form_id: str = None,
-                            form_name: str = None) -> Optional[FactExpression]:
+    def get_fact_expression(
+        self, expression_id: str, form_id: str = None, form_name: str = None
+    ) -> Optional[FactExpression]:
         """Retrieve a certain fact expression of a local instance of
         Attribute object.
 
         Args:
             form_id: ID of the attribute form. It have priority over `name`
                 parameter
             form_name: name of the attribute form
@@ -809,15 +898,15 @@
         geographical_role: Optional[AttributeForm.GeographicalRole] = None,
         time_role: Optional[AttributeForm.TimeRole] = None,
         is_form_group: bool = False,
         is_multilingual: bool = False,
     ):
         """Create new attribute form and add it to the `attribute.forms` list.
         The form can be added from completed `AttributeForm` objects provided
-        in `form` patameter, or by filling other parameters.
+        in `form` parameter, or by filling other parameters.
 
         Args:
             form: complete `AttibuteForm` object that will be added to
                 the Attribute
             name: The name of the attribute form set by the attribute. Unlike
                 category, which is the systemic name associated with each
                 reusable form, this name is specific to the attribute using this
@@ -853,24 +942,28 @@
         if form and isinstance(form, AttributeForm):
             self._alter_properties(forms=self.forms + [form])
         elif expressions and lookup_table:
             properties = filter_params_for_func(
                 AttributeForm.local_create, locals(), exclude=['self']
             )
             properties = delete_none_values(properties, recursion=True)
-            new_form = AttributeForm.local_create(connection=self.connection, **properties)
+            new_form = AttributeForm.local_create(
+                connection=self.connection, **properties
+            )
             self._alter_properties(forms=self.forms + [new_form])
         else:
             raise AttributeError(
                 'Please provide either `form` or `expressions` and `lookup_table`'
             )
 
     @staticmethod
     def _remove_form_from_displays(
-        form_to_be_removed: AttributeForm, forms: list[AttributeForm], displays: AttributeDisplays
+        form_to_be_removed: AttributeForm,
+        forms: list[AttributeForm],
+        displays: AttributeDisplays,
     ) -> AttributeDisplays:
         """Remove all references to the form from local instance of displays,
         AttributeDisplays object.
 
         Args:
             form_to_be_removed: form that will be removed
             forms: Attribute.forms list without the form that will be
@@ -889,15 +982,17 @@
             if form_to_be_removed.is_referenced_by(displays.browse_displays[index]):
                 displays.browse_displays.pop(index)
                 break
         return Attribute.validate_displays(displays, forms)
 
     @staticmethod
     def _remove_form_from_sorts(
-        form_to_be_removed: AttributeForm, forms: list[AttributeForm], sorts: AttributeSorts
+        form_to_be_removed: AttributeForm,
+        forms: list[AttributeForm],
+        sorts: AttributeSorts,
     ) -> AttributeSorts:
         """Remove all references to the form from local instance of displays,
         AttributeSorts object.
 
         Args:
             form_to_be_removed: form that will be removed
             forms: Attribute.forms list without the form that will be
@@ -945,20 +1040,25 @@
             raise ValueError(
                 f'Attribute with ID {self.id} does not '
                 f'contain attribute form with ID {form_id}.'
             )
         elif len(new_forms) == 0:
             raise ValueError('You can not delete the last attribute form')
         elif form_to_del.is_referenced_by(self.key_form):
-            error_msg = 'You are trying to delete the current key form. Please chose new key form.'
+            error_msg = (
+                'You are trying to delete the current key form. Please chose '
+                'new key form.'
+            )
             # Assign new key form if possible
             new_key_form = self.validate_key_form(new_key_form, new_forms, error_msg)
 
         # Make sure the form that is also removed from displays and sorts
-        displays = self._remove_form_from_displays(form_to_del, new_forms, self.displays)
+        displays = self._remove_form_from_displays(
+            form_to_del, new_forms, self.displays
+        )
         sorts = self._remove_form_from_sorts(form_to_del, new_forms, self.sorts)
 
         self._alter_properties(
             key_form=new_key_form, forms=new_forms, displays=displays, sorts=sorts
         )
 
     def alter_form(
@@ -1027,17 +1127,16 @@
             tables: new tables of the fact expression
         """
         expression_properties = filter_params_for_func(
             AttributeForm._alter_expression, locals(), exclude=['self']
         )
         self.__alter_form_with_id(
             form_id,
-            AttributeForm._alter_expression, {
-                'fact_expression_id': fact_expression_id, **expression_properties
-            }
+            AttributeForm._alter_expression,
+            {'fact_expression_id': fact_expression_id, **expression_properties},
         )
 
     def add_fact_expression(self, form_id: str, expression: FactExpression):
         """Add expression to the form.
         Args:
             form_id: ID of the form to which the expression is to be added,
             expression: the expression that is to be added,
@@ -1046,30 +1145,32 @@
             form_id, AttributeForm._add_fact_expression, {'expression': expression}
         )
 
     def remove_fact_expression(
         self,
         form_id: str,
         fact_expression_id: str,
-        new_lookup_table: Optional[SchemaObjectReference] = None
+        new_lookup_table: Optional[SchemaObjectReference] = None,
     ):
         """Remove expression from the form. If the expressions left are
         not using lookup table assigned to the form, provide new lookup
         table for the form.
 
         Args:
             form_id: ID of the form from which the expression is to be removed,
             expression_id: ID of the expression that is to be removed,
             new_lookup_table: new lookup table of the form
         """
         self.__alter_form_with_id(
             form_id,
-            AttributeForm._remove_fact_expression, {
-                'fact_expression_id': fact_expression_id, 'new_lookup_table': new_lookup_table
-            }
+            AttributeForm._remove_fact_expression,
+            {
+                'fact_expression_id': fact_expression_id,
+                'new_lookup_table': new_lookup_table,
+            },
         )
 
     def to_dict(self, camel_case: bool = True) -> dict:
         result = super().to_dict(camel_case)
         result.pop('_showExpressionAs', None)
 
         return result
@@ -1105,7 +1206,11 @@
     @property
     def sorts(self):
         return self._sorts
 
     @property
     def relationships(self):
         return self._relationships
+
+    @property
+    def hidden(self):
+        return self._hidden or False
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/attribute/attribute_form.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/attribute/attribute_form.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,18 +1,26 @@
 from enum import auto
-from typing import List, Optional, TYPE_CHECKING
+from typing import TYPE_CHECKING, Optional
 
 from mstrio.api import objects
 from mstrio.connection import Connection
 from mstrio.modeling.expression import Expression, FactExpression
-from mstrio.modeling.schema.helpers import DataType, FormReference, SchemaObjectReference
+from mstrio.modeling.schema.helpers import (
+    DataType,
+    FormReference,
+    SchemaObjectReference,
+)
 from mstrio.types import ObjectTypes
 from mstrio.utils.entity import Entity
 from mstrio.utils.enum_helper import AutoName
-from mstrio.utils.helper import delete_none_values, exception_handler, filter_params_for_func
+from mstrio.utils.helper import (
+    delete_none_values,
+    exception_handler,
+    filter_params_for_func,
+)
 
 if TYPE_CHECKING:
     from mstrio.modeling.schema.attribute.attribute_form import AttributeForm
 
 
 class AttributeForm(Entity):  # noqa
     """The Attribute Form Object
@@ -55,20 +63,22 @@
         is_multilingual: A boolean field indicating whether this field is
             multilingual. Any key form of the attribute is not allowed to be
             set as multilingual.
     """
 
     class FormType(AutoName):
         """Enumeration constants used to specify a type of this form."""
+
         CUSTOM = auto()
         SYSTEM = auto()
 
     class DisplayFormat(AutoName):
         """Enumeration constants used to specify display format of
         the attribute form."""
+
         NUMBER = auto()
         TEXT = auto()
         PICTURE = auto()
         URL = auto()
         EMAIL = auto()
         HTML_TAG = auto()
         DATE = auto()
@@ -77,14 +87,15 @@
         PHONE_NUMBER = auto()
         DATE_TIME = auto()
         BIG_DECIMAL = auto()
 
     class GeographicalRole(AutoName):
         """Enumeration constants used to specify geographical role of
         the attribute form."""
+
         NONE = auto()
         CITY = auto()
         STATE = auto()
         COUNTRY = auto()
         LOCATION = auto()
         LATITUDE = auto()
         LONGITUDE = auto()
@@ -93,14 +104,15 @@
         COUNTY = auto()
         AREA_CODE = auto()
         GEOMETRY = auto()
 
     class TimeRole(AutoName):
         """Enumeration constants used to specify time role of
         the attribute form."""
+
         NONE = auto()
         DATE = auto()
         TIME = auto()
         SECOND = auto()
         MINUTE = auto()
         HOUR = auto()
         DAY = auto()
@@ -143,100 +155,119 @@
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
             'acg',
             'acl',
-            'target_info'
+            'target_info',
         ): objects.get_object_info
     }
 
     def __init__(self, connection: Connection, id: str) -> None:
         super().__init__(connection=connection, object_id=id)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
-        self._id = kwargs.get('id')
-        self.name = kwargs.get('name')
-        self.description = kwargs.get('description')
         self.category = kwargs.get('category')
         if self.FormType.has_value(kwargs.get('type')):
             self.form_type = self.FormType(kwargs.get('type'))
         elif kwargs.get('type'):
             self.type = kwargs.get('type')
 
         self.is_multilingual = kwargs.get('is_multilingual', False)
         self.is_form_group = kwargs.get('is_form_group', False)
-        self.geographical_role = self.GeographicalRole(
-            kwargs.get('geographical_role')
-        ) if kwargs.get('geographical_role') else None
-        self.time_role = self.TimeRole(kwargs.get('time_role')
-                                       ) if kwargs.get('time_role') else None
-        self.display_format = self.DisplayFormat(kwargs.get('display_format')
-                                                 ) if kwargs.get('display_format') else None
-        self.data_type = DataType.from_dict(kwargs.get('data_type')
-                                            ) if kwargs.get('data_type') else None
-
-        self.expressions = [
-            FactExpression.from_dict(expr, self._connection) for expr in kwargs.get('expressions')
-        ] if kwargs.get('expressions') else None
+        self.geographical_role = (
+            self.GeographicalRole(kwargs.get('geographical_role'))
+            if kwargs.get('geographical_role')
+            else None
+        )
+        self.time_role = (
+            self.TimeRole(kwargs.get('time_role')) if kwargs.get('time_role') else None
+        )
+        self.display_format = (
+            self.DisplayFormat(kwargs.get('display_format'))
+            if kwargs.get('display_format')
+            else None
+        )
+        self.data_type = (
+            DataType.from_dict(kwargs.get('data_type'))
+            if kwargs.get('data_type')
+            else None
+        )
+
+        self.expressions = (
+            [
+                FactExpression.from_dict(expr, self._connection)
+                for expr in kwargs.get('expressions')
+            ]
+            if kwargs.get('expressions')
+            else None
+        )
 
         self.alias = kwargs.get('alias')
-        self.lookup_table = SchemaObjectReference.from_dict(
-            kwargs.get('lookup_table')
-        ) if kwargs.get('lookup_table') else None
-
-        self.child_forms = [
-            FormReference.from_dict(expr, self._connection) for expr in kwargs.get('child_forms')
-        ] if kwargs.get('child_forms') else None
+        self.lookup_table = (
+            SchemaObjectReference.from_dict(kwargs.get('lookup_table'))
+            if kwargs.get('lookup_table')
+            else None
+        )
+
+        self.child_forms = (
+            [
+                FormReference.from_dict(expr, self._connection)
+                for expr in kwargs.get('child_forms')
+            ]
+            if kwargs.get('child_forms')
+            else None
+        )
 
     @classmethod
     def local_create(
         cls,
         connection: Connection,
         name: str,
         description: Optional[str] = None,
         category: Optional[str] = None,
         display_format: Optional[DisplayFormat] = None,
         data_type: Optional[DataType] = None,
-        expressions: Optional[List[FactExpression]] = None,
+        expressions: Optional[list[FactExpression]] = None,
         alias: Optional[str] = None,
         lookup_table: Optional[SchemaObjectReference] = None,
-        child_forms: Optional[List[FormReference]] = None,
+        child_forms: Optional[list[FormReference]] = None,
         geographical_role: Optional[GeographicalRole] = None,
         time_role: Optional[TimeRole] = None,
         is_form_group: bool = False,
         is_multilingual: bool = False,
     ) -> "AttributeForm":
         """Internal method that creates ONLY LOCAL AttributeForm object.
         In order to create an AttributeForm object on the server,
         use `Attribute.add_form()` method of a corresponding Attribute object.
         """
-        properties = filter_params_for_func(cls.local_create, locals(), exclude=['connection'])
+        properties = filter_params_for_func(
+            cls.local_create, locals(), exclude=['connection']
+        )
         properties = delete_none_values(properties, recursion=True)
 
         obj = cls.__new__(cls)
         for key, val in properties.items():
             setattr(obj, key, val)
         obj._id = None
         obj._connection = connection
         return obj
 
     def list_properties(self, camel_case=True) -> dict:
         """Lists all properties of attribute form."""
         return super().to_dict(camel_case=camel_case)
 
     def to_dict(self, camel_case=True) -> dict:
-
         return {
             key: val
-            for key,
-            val in self.list_properties(camel_case).items()
-            if key not in [
+            for key, val in self.list_properties(camel_case).items()
+            if key
+            not in [
                 'id',
                 'abbreviation',
                 'type',
                 'subtype',
                 'ext_type',
                 'date_created',
                 'date_modified',
@@ -245,28 +276,28 @@
                 'icon_path',
                 'view_media',
                 'ancestors',
                 'certified_info',
                 'acg',
                 'acl',
                 'target_info',
-                'formType'
+                'formType',
             ]
         }
 
     def local_alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
         display_format: Optional[DisplayFormat] = None,
         data_type: Optional[DataType] = None,
-        expressions: Optional[List[FactExpression]] = None,
+        expressions: Optional[list[FactExpression]] = None,
         alias: Optional[str] = None,
         lookup_table: Optional[SchemaObjectReference] = None,
-        child_forms: Optional[List[FormReference]] = None,
+        child_forms: Optional[list[FormReference]] = None,
         geographical_role: Optional[GeographicalRole] = None,
         time_role: Optional[TimeRole] = None,
         is_form_group: Optional[bool] = None,
         is_multilingual: Optional[bool] = None,
     ):
         """Make changes to a local copy of AttributeForm. In order to change
         an AttributeForm object on the server, use `Attribute.alter_form()`
@@ -303,15 +334,17 @@
             form_id: id of the form to which the expression is to be added,
             expression: the expression that is to be added,
         """
         self.verify_is_simple_form(method_name_if_error='Adding expression')
         self.expressions.append(expression)
 
     def _remove_fact_expression(
-        self, fact_expression_id: str, new_lookup_table: Optional[SchemaObjectReference] = None
+        self,
+        fact_expression_id: str,
+        new_lookup_table: Optional[SchemaObjectReference] = None,
     ):
         """
         Internal method that affects ONLY LOCAL AttributeForm object.
         To make changes on the server, use `Attribute._remove_fact_expression()`
         method of a corresponding Attribute object.
         Remove expression from the form. If the expressions left are
         not using lookup table assigned to the form, provide new lookup
@@ -324,73 +357,78 @@
                 expression that is going to be removed used the current one
         """
         self.verify_is_simple_form(method_name_if_error='Removing expression')
         if len(self.expressions) == 1:
             exception_handler(
                 "You can't remove the only expression "
                 f"from the attribute form with id: {self.id}.",
-                ValueError
+                ValueError,
             )
         ex_postition = next(
-            (i for i, ex in enumerate(self.expressions) if ex.id == fact_expression_id), None
+            (i for i, ex in enumerate(self.expressions) if ex.id == fact_expression_id),
+            None,
         )
         if ex_postition is None:
             exception_handler(
                 f"The form with id: {self.id}, don't use "
                 f"expression with id: {fact_expression_id}.",
-                ValueError
+                ValueError,
             )
         removed_ex = self.expressions.pop(ex_postition)
 
         # AttributeForm can't use `lookup_table` that is not used in any of
         # its expressions.
         if self.lookup_table in removed_ex.tables:
             if len(self.expressions) == 1 and len(self.expressions[0].tables) == 1:
                 self.lookup_table = self.expressions[0].tables[0]
             elif new_lookup_table is None:
                 exception_handler(
                     "Please provide new lookup_table for the attribute form "
                     f"with id: {self.id}.",
-                    AttributeError
+                    AttributeError,
                 )
             else:
                 self.lookup_table = new_lookup_table
 
     def _alter_expression(
         self,
         fact_expression_id: str,
         expression: Optional[Expression] = None,
-        tables: Optional[List[SchemaObjectReference]] = None,
+        tables: Optional[list[SchemaObjectReference]] = None,
     ):
         """Internal method that affects ONLY LOCAL AttributeForm object.
         To make changes on the server, use `Attribute.alter_fact_expression()`
         method of a corresponding Attribute object.
 
         Args:
             fact_expression_id: id of the fact expression that is to be altered,
             expression: new expressions of the fact expression
             tables: new tables of the fact expression
         """
         self.verify_is_simple_form(method_name_if_error='Altering expressions')
         try:
-            fact_expr = next(expr for expr in self.expressions if expr.id == fact_expression_id)
+            fact_expr = next(
+                expr for expr in self.expressions if expr.id == fact_expression_id
+            )
             fact_expr.local_alter(expression, tables)
         except StopIteration:
             exception_handler(
                 f"Attribute Form: {self.id} does not have Fact Expression"
                 f" with ID: {fact_expression_id}.",
-                ValueError
+                ValueError,
             )
 
     def verify_is_simple_form(self, method_name_if_error: str):
         """Verify whether the form is a simple form and not a group form"""
         if self.is_form_group:
             exception_handler(
-                f"{method_name_if_error} is not available for the form group.", AttributeError
+                f"{method_name_if_error} is not available for the form group.",
+                AttributeError,
             )
 
     def is_referenced_by(self, form_reference: FormReference) -> bool:
         """Check if attribute form is referenced in `form_reference`."""
-        if ((self.id is not None and self.id == form_reference.id)
-                or (self.name is not None and self.name == form_reference.name)):
+        if (self.id is not None and self.id == form_reference.id) or (
+            self.name is not None and self.name == form_reference.name
+        ):
             return True
         return False
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/attribute/relationship.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/attribute/relationship.py`

 * *Files 16% similar despite different names*

```diff
@@ -2,76 +2,92 @@
 from typing import List, Optional
 
 from mstrio.modeling.schema.helpers import SchemaObjectReference
 from mstrio.utils.enum_helper import AutoName
 from mstrio.utils.helper import Dictable
 
 
+class RelationshipType(AutoName):
+    """Enumeration constants used to specify type of the relationship"""
+
+    ONE_TO_MANY = auto()
+    ONE_TO_ONE = auto()
+    MANY_TO_MANY = auto()
+
+
 class Relationship(Dictable):
     """Python representation of MicroStrategy Attributes Relationship object.
 
     Attributes:
         parent: parent in a relationship
         child: child in a relationship
         joint_child: list of joint children in a relationship
         relationship_table: relationship table in a relationship
         ralationship_type: type of relationship, one of:
             one_to_many, one_to_one, many_to_many
     """
 
-    class RelationshipType(AutoName):
-        """Enumeration constants used to specify type of the relationship"""
-        ONE_TO_MANY = auto()
-        ONE_TO_ONE = auto()
-        MANY_TO_MANY = auto()
+    # For backwards compatibility, to avoid deprecation.
+    RelationshipType = RelationshipType
 
     _FROM_DICT_MAP = {
         'parent': SchemaObjectReference.from_dict,
         'child': SchemaObjectReference.from_dict,
         'joint_child': [SchemaObjectReference.from_dict],
         'relationship_table': SchemaObjectReference.from_dict,
-        'relationship_type': RelationshipType
+        'relationship_type': RelationshipType,
     }
 
     def __init__(
         self,
         relationship_type: RelationshipType,
         relationship_table: SchemaObjectReference,
         parent: SchemaObjectReference,
         child: Optional[SchemaObjectReference] = None,
-        joint_child: Optional[List[SchemaObjectReference]] = None
+        joint_child: Optional[List[SchemaObjectReference]] = None,
     ) -> None:
         self.relationship_type = relationship_type
         self.relationship_table = relationship_table
         self.parent = parent
         if (child and joint_child) or (child is None and joint_child is None):
             raise AttributeError(
-                "Please specify either 'child' or 'joint_child' parameter in the constructor."
+                "Please specify either 'child' or 'joint_child' parameter in the "
+                "constructor."
             )
         elif child:
             self.child = child
         elif joint_child:
-            self.joint_child = joint_child if isinstance(joint_child, list) else [joint_child]
+            self.joint_child = (
+                joint_child if isinstance(joint_child, list) else [joint_child]
+            )
 
     def __eq__(self, other):
         if not isinstance(other, Relationship):
             # don't attempt to compare against unrelated types
             return False
 
         if hasattr(self, 'child') and hasattr(other, 'child'):
-            return self.relationship_type == other.relationship_type \
-                and self.relationship_table == other.relationship_table \
-                and self.parent == other.parent and self.child == other.child
+            return (
+                self.relationship_type == other.relationship_type
+                and self.relationship_table == other.relationship_table
+                and self.parent == other.parent
+                and self.child == other.child
+            )
         elif hasattr(self, 'joint_child') and hasattr(other, 'joint_child'):
-            return self.relationship_type == other.relationship_type \
-                and self.relationship_table == other.relationship_table \
-                and self.parent == other.parent and bool(
-                    set(self.joint_child).intersection(other.joint_child))
+            return (
+                self.relationship_type == other.relationship_type
+                and self.relationship_table == other.relationship_table
+                and self.parent == other.parent
+                and bool(set(self.joint_child).intersection(other.joint_child))
+            )
         else:
             return False
 
     def __repr__(self):
         if hasattr(self, 'child'):
             child_name = self.child.name
         else:
             child_name = "[" + ", ".join(child.name for child in self.joint_child) + "]"
-        return f'{self.parent.name} -> {self.relationship_type.name} -> {child_name} relationship'
+        return (
+            f'{self.parent.name} -> {self.relationship_type.name} -> {child_name} '
+            f'relationship'
+        )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/fact/fact.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/fact/fact.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,20 @@
 import logging
+from functools import partial
 from typing import Optional
 
 from mstrio import config
 from mstrio.api import facts, objects
 from mstrio.connection import Connection
 from mstrio.modeling.expression import ExpressionFormat, FactExpression
-from mstrio.modeling.schema.helpers import DataType, ObjectSubType, SchemaObjectReference
+from mstrio.modeling.schema.helpers import (
+    DataType,
+    ObjectSubType,
+    SchemaObjectReference,
+)
 from mstrio.object_management import search_operations
 from mstrio.object_management.folder import Folder
 from mstrio.object_management.search_enums import SearchPattern
 from mstrio.types import ObjectTypes
 from mstrio.users_and_groups import User
 from mstrio.utils.entity import CopyMixin, DeleteMixin, Entity, MoveMixin
 from mstrio.utils.enum_helper import get_enum_val
@@ -56,17 +61,17 @@
             ENUM mstrio.object_management.SearchPattern.
             Default value is CONTAINS (4).
         show_expression_as (optional, enum or str): specify how expressions
             should be presented.
             Available values:
                 - `ExpressionFormat.TREE` or `tree` (default)
                 - `ExpressionFormat.TOKENS or `tokens`
-        **filters: Available filter parameters: ['id', 'name', 'description',
+        **filters: Available filter parameters: ['id', 'name',
             'type', 'subtype', 'date_created', 'date_modified', 'version',
-            'acg', 'icon_path', 'owner']
+            'acg', 'owner', 'ext_type']
 
     Returns:
         list of fact objects or list of fact dictionaries.
     """
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
@@ -82,22 +87,28 @@
         pattern=search_pattern,
         limit=limit,
         **filters,
     )
     if to_dictionary:
         return objects
     else:
-        show_expression_as = show_expression_as if isinstance(
-            show_expression_as, ExpressionFormat
-        ) else ExpressionFormat(show_expression_as)
+        show_expression_as = (
+            show_expression_as
+            if isinstance(show_expression_as, ExpressionFormat)
+            else ExpressionFormat(show_expression_as)
+        )
         return [
-            Fact.from_dict({
-                'show_expression_as': show_expression_as,
-                **obj,
-            }, connection) for obj in objects
+            Fact.from_dict(
+                {
+                    'show_expression_as': show_expression_as,
+                    **obj,
+                },
+                connection,
+            )
+            for obj in objects
         ]
 
 
 @class_version_handler('11.3.0100')
 class Fact(Entity, CopyMixin, DeleteMixin, MoveMixin):
     """Python representation for Microstrategy `Fact` object.
 
@@ -134,28 +145,29 @@
             operation.
         owner: `User` object that is the owner
         acg: access rights (see `EnumDSSXMLAccessRightFlags` for possible
             values)
         acl: object access control list
         version_id: the version number this object is currently carrying
     """
+
     _OBJECT_TYPE = ObjectTypes.FACT
 
     _API_GETTERS = {
         (
             'id',
             'sub_type',
             'name',
             'is_embedded',
             'description',
             'destination_folder_id',
             'path',
             'data_type',
             'expressions',
-            'entry_level'
+            'entry_level',
         ): facts.read_fact,
         (
             'abbreviation',
             'type',
             'ext_type',
             'date_created',
             'date_modified',
@@ -163,44 +175,46 @@
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
             'acg',
             'acl',
-            'target_info'
-        ): objects.get_object_info
+            'target_info',
+        ): objects.get_object_info,
     }
     _API_PATCH = {
         ('data_type', 'expressions'): (facts.update_fact, 'partial_put'),
         ('name', 'description'): (objects.update_object, 'partial_put'),
-        ('folder_id'): (objects.update_object, 'partial_put')
+        ('folder_id'): (objects.update_object, 'partial_put'),
     }
 
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'owner': User.from_dict,
         'data_type': DataType.from_dict,
         'expressions': (
-            lambda source,
-            connection: [FactExpression.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                FactExpression.from_dict(content, connection) for content in source
+            ]
         ),
         'entry_level': (
-            lambda source,
-            connection:
-            [SchemaObjectReference.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                SchemaObjectReference.from_dict(content, connection)
+                for content in source
+            ]
         ),
     }
 
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         name: Optional[str] = None,
-        show_expression_as: ExpressionFormat | str = ExpressionFormat.TREE
+        show_expression_as: ExpressionFormat | str = ExpressionFormat.TREE,
     ) -> None:
         """Initialize a new instance of Fact class.
 
         Note:
             Parameter `name` is not used when fetching. If only `name` parameter
             is provided, `id` will be found automatically if such object exists.
 
@@ -222,46 +236,56 @@
                 are multiple facts with given `name`, if project is not
                 selected in provided `connection` or if Fact with given `name`
                 doesn't exist.
         """
         connection._validate_project_selected()
         if id is None:
             fact = super()._find_object_with_name(
-                connection=connection, name=name, listing_function=list_facts
+                connection=connection,
+                name=name,
+                listing_function=partial(
+                    list_facts, search_pattern=SearchPattern.EXACTLY
+                ),
             )
             id = fact['id']
         super().__init__(
-            connection=connection, object_id=id, name=name, show_expression_as=show_expression_as
+            connection=connection,
+            object_id=id,
+            name=name,
+            show_expression_as=show_expression_as,
         )
 
     def _init_variables(self, **kwargs) -> None:
         """Initialize all properties when creating `Fact` object from
         a dictionary."""
         super()._init_variables(**kwargs)
-        self._id = kwargs.get('id')
         self._sub_type = kwargs.get('sub_type')
-        self.name = kwargs.get('name')
         self._is_embedded = kwargs.get('is_embedded')
-        self.description = kwargs.get('description')
         self._destination_folder_id = kwargs.get('destination_folder_id')
         data_type = kwargs.get('data_type')
         self.data_type = None if data_type is None else DataType.from_dict(data_type)
         expressions = kwargs.get('expressions')
-        self._expressions = None if expressions is None else [
-            FactExpression.from_dict(expression) for expression in expressions
-        ]
+        self._expressions = (
+            None
+            if expressions is None
+            else [FactExpression.from_dict(expression) for expression in expressions]
+        )
         entry_level = kwargs.get('entry_level')
-        self._entry_level = None if entry_level is None else [
-            SchemaObjectReference.from_dict(obj) for obj in entry_level
-        ]
+        self._entry_level = (
+            None
+            if entry_level is None
+            else [SchemaObjectReference.from_dict(obj) for obj in entry_level]
+        )
         self._version_id = kwargs.get('version_id')
         show_expression_as = kwargs.get('show_expression_as', 'tree')
-        self._show_expression_as = show_expression_as if isinstance(
-            show_expression_as, ExpressionFormat
-        ) else ExpressionFormat(show_expression_as)
+        self._show_expression_as = (
+            show_expression_as
+            if isinstance(show_expression_as, ExpressionFormat)
+            else ExpressionFormat(show_expression_as)
+        )
 
     @classmethod
     def create(
         cls,
         connection: Connection,
         name: str,
         destination_folder: Folder | str,
@@ -307,32 +331,38 @@
         body = {
             "information": {
                 "name": name,
                 "subType": ObjectSubType.FACT.value,
                 "isEmbedded": is_embedded,
                 "description": description,
                 "destinationFolderId": destination_folder.id
-                if isinstance(destination_folder, Folder) else destination_folder,
+                if isinstance(destination_folder, Folder)
+                else destination_folder,
             },
-            "dataType": data_type.to_dict() if isinstance(data_type, DataType) else data_type,
-            "expressions": [(e.to_dict() if isinstance(e, Dictable) else e) for e in expressions],
-            "entryLevel": []
+            "dataType": data_type.to_dict()
+            if isinstance(data_type, DataType)
+            else data_type,
+            "expressions": [
+                (e.to_dict() if isinstance(e, Dictable) else e) for e in expressions
+            ],
+            "entryLevel": [],
         }
         response = facts.create_fact(
             connection=connection,
             body=body,
-            show_expression_as=get_enum_val(show_expression_as, ExpressionFormat)
+            show_expression_as=get_enum_val(show_expression_as, ExpressionFormat),
         ).json()
         if config.verbose:
-            logger.info(f"Successfully created fact named: '{name}' with ID: '{response['id']}'.")
+            logger.info(
+                f"Successfully created fact named: '{name}' with ID: '"
+                f"{response['id']}'."
+            )
 
         return cls.from_dict(
-            source={
-                **response, 'show_expression_as': show_expression_as
-            },
+            source={**response, 'show_expression_as': show_expression_as},
             connection=connection,
         )
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
@@ -349,27 +379,29 @@
         if data_type:
             properties['expressions'] = self.expressions
         self._alter_properties(**properties)
 
     def get_tables(
         self, expression: Optional[FactExpression | str] = None
     ) -> list[SchemaObjectReference]:
-        """ Get list of all tables in given fact expression. If expression
+        """Get list of all tables in given fact expression. If expression
         argument is not specified, list all tables for fact.
 
         Args:
             expression (optional, str or object): id of the fact expression or
                 `FactExpression` object to get tables from.
 
         Returns:
             List of tables in given `FactExpression` or all tables for fact.
         """
         expressions = [expr for expr in self.expressions]
         if expression:
-            expression_id = expression.id if isinstance(expression, FactExpression) else expression
+            expression_id = (
+                expression.id if isinstance(expression, FactExpression) else expression
+            )
             expressions = [expr for expr in expressions if expr.id == expression_id]
         tables_list = {tab for expr in expressions for tab in expr.tables}
         return list(tables_list)
 
     def add_expression(self, expression: FactExpression | dict) -> None:
         """Add expression to the fact.
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/helpers.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/helpers.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,14 +19,15 @@
     it can be useful to see one "report" concept rather than to have to always
     distinguish between different kinds of reports. But there are cases
     (e.g. filters versus custom-groups or users versus user-groups ) where
     users want to see the different subtypes of the same type as fundamentally
     different.
     Used across different modeling modules e.g. attributes, user hierarchies.
     """
+
     FILTER = auto()
     CUSTOM_GROUP = auto()
     FILTER_PARTITION = auto()
     SEGMENT = auto()
     TEMPLATE = auto()
     REPORT_GRID = auto()
     REPORT_GRAPH = auto()
@@ -235,43 +236,48 @@
         return self.object_id == other.object_id and self.sub_type == other.sub_type
 
     def __hash__(self):
         return hash(self.object_id)
 
     @classmethod
     def create_from(
-        cls, schema_object: Union["Attribute", "UserHierarchy"], is_embedded: bool = None
+        cls,
+        schema_object: Union["Attribute", "UserHierarchy"],
+        is_embedded: bool = None,
     ) -> "SchemaObjectReference":
         """Converts a schema object into a schema object reference
 
-            Args:
-                schema_object: a schema object
-                is_embeded: a boolean indicating whether the schema object
-                    is embedded or not
+        Args:
+            schema_object: a schema object
+            is_embeded: a boolean indicating whether the schema object
+                is embedded or not
 
-            Returns:
-                SchemaObjectReference of the given schema object
+        Returns:
+            SchemaObjectReference of the given schema object
         """
         reference_body = {
             "object_id": schema_object.id,
             "name": schema_object.name,
             "sub_type": schema_object.sub_type,
-            "is_embeded": is_embedded
+            "is_embeded": is_embedded,
         }
         return cls.from_dict(reference_body)
 
-    def to_object(self, connection: "Connection") -> Union["Attribute", "UserHierarchy"]:
+    def to_object(
+        self, connection: "Connection"
+    ) -> Union["Attribute", "UserHierarchy"]:
         """Converts a schema object reference into a schema object.
 
-            Args:
-                connection: a connection object required to fetch
-                    the schema object
+        Args:
+            connection: a connection object required to fetch
+                the schema object
         """
         if self.sub_type == ObjectSubType.ATTRIBUTE:
             from mstrio.modeling.schema.attribute import Attribute
+
             return Attribute(connection, id=self.object_id)
         else:
             raise NotSupportedError(
                 f"{self.sub_type} object sub type is not supported."
             )
 
 
@@ -285,14 +291,15 @@
         scale: for relevant data types, the fixed position used
         in the representation
     """
 
     class Type(AutoName):
         """String literal used to identify the gross data type of an actual
         or proposed column in a database."""
+
         UNKNOWN = auto()
         RESERVED = auto()
         INTEGER = auto()
         UNSIGNED = auto()
         NUMERIC = auto()
         DECIMAL = auto()
         REAL = auto()
@@ -324,47 +331,51 @@
     def __init__(self, type: Type, precision: str, scale: str) -> None:
         self.type = type
         self.precision = precision
         self.scale = scale
 
 
 class FormReference(Dictable):
-    """	The reference that identifies a form object within the context of a
-        given attribute. When writing back an attribute, either id or name is
-        needed to identify a form, and if both are provided, id will take
-        the higher priority.
-
-        Attributes:
-            id: id of the form
-            name: name of the form
+    """The reference that identifies a form object within the context of a
+    given attribute. When writing back an attribute, either id or name is
+    needed to identify a form, and if both are provided, id will take
+    the higher priority.
+
+    Attributes:
+        id: id of the form
+        name: name of the form
     """
 
     def __init__(self, id: str = None, name: str = None) -> None:
         if id is None and name is None:
-            exception_handler("Provide either `id` or `name` of a form object.", AttributeError)
+            exception_handler(
+                "Provide either `id` or `name` of a form object.", AttributeError
+            )
         self.id = id
         self.name = name
 
 
 class AttributeDisplays(Dictable):
     """The collections of report displays and browse displays of the attribute.
 
     Attributes:
         report_displays: list of an AttributeSorts for report displays
         browse_displays: list of an AttributeSorts for browse displays
     """
 
     _FROM_DICT_MAP = {
         "report_displays": (
-            lambda source,
-            connection: [FormReference.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                FormReference.from_dict(content, connection) for content in source
+            ]
         ),
         "browse_displays": (
-            lambda source,
-            connection: [FormReference.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                FormReference.from_dict(content, connection) for content in source
+            ]
         ),
     }
 
     def __init__(
         self, report_displays: list[FormReference], browse_displays: list[FormReference]
     ) -> None:
         self.report_displays = report_displays
@@ -392,40 +403,42 @@
     Attributes:
         report_sorts: list of an AttributeSorts for report sorts
         browse_sorts: list of an AttributeSorts for browse sorts
     """
 
     _FROM_DICT_MAP = {
         "report_sorts": (
-            lambda source,
-            connection: [AttributeSort.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                AttributeSort.from_dict(content, connection) for content in source
+            ]
         ),
         "browse_sorts": (
-            lambda source,
-            connection: [AttributeSort.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                AttributeSort.from_dict(content, connection) for content in source
+            ]
         ),
     }
 
     def __init__(
         self,
         report_sorts: Optional[list[AttributeSort]] = None,
-        browse_sorts: Optional[list[AttributeSort]] = None
+        browse_sorts: Optional[list[AttributeSort]] = None,
     ) -> None:
         self.report_sorts = report_sorts
         self.browse_sorts = browse_sorts
 
 
 @dataclass
 class TableColumn(Dictable):
     """An object representation of a physical column that might
-       appear in some data source. In addition to representing physical
-       columns, we also use this object to represent columns that do not
-       actually appear in any data source but which the engine should
-       create if it needs to make a column to contain data for some higher
-       level construct (e.g. a fact, an attribute form etc.)."""
+    appear in some data source. In addition to representing physical
+    columns, we also use this object to represent columns that do not
+    actually appear in any data source but which the engine should
+    create if it needs to make a column to contain data for some higher
+    level construct (e.g. a fact, an attribute form etc.)."""
 
     _FROM_DICT_MAP = {"data_type": DataType, "sub_type": ObjectSubType}
     data_type: DataType
     column_name: Optional[str] = None  # When retrieved as part of a logical tab
     name: Optional[str] = None  # When retrieved from datasources API
     id: Optional[str] = None
     sub_type: Optional[ObjectSubType] = None
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/schema_management.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/schema_management.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,22 +13,24 @@
 logger = logging.getLogger(__name__)
 
 
 class SchemaLockType(AutoName):
     """Enumeration constants used to specify a type of lock that can be placed
     on schema. Type `UNLOCKED` is used only when displaying status.
     """
+
     ABSOLUTE_INDIVIDUAL = auto()
     EXCLUSIVE_CONSTITUENT = auto()
     ABSOLUTE_CONSTITUENT = auto()
     UNLOCKED = "none"
 
 
 class SchemaUpdateType(AutoName):
     """Enumeration constants used to specify type of update for the schema."""
+
     TABLE_KEY = auto()
     ENTRY_LEVEL = auto()
     LOGICAL_SIZE = auto()
     CLEAR_ELEMENT_CACHE = auto()
 
 
 class SchemaLockStatus(Dictable):
@@ -44,15 +46,15 @@
     def __init__(
         self,
         lock_type: Union['SchemaLockType', str],
         date_created: Optional[str] = None,
         comment: Optional[str] = None,
         machine_name: Optional[str] = None,
         owner_name: Optional[str] = None,
-        owner_id: Optional[str] = None
+        owner_id: Optional[str] = None,
     ):
         """Initialize schema lock status. When schema is unlocked, only its
         `lock_type` is provided.
 
         Args:
             lock_type (str, enum): a type of lock status that could be returned
                 from the schema. The lock state any of the lock types, but it is
@@ -83,33 +85,38 @@
             `TypeError` if `lock_type` is neither a string nor
             a `SchemaLockType`.
             `ValueError` if `lock_type` is specified as a string which is not
             a proper value of enum `SchemaLockType`.
         """
 
         self.lock_type = get_enum(lock_type, SchemaLockType)
-        self.date_created = map_str_to_datetime("date_created", date_created, self._FROM_DICT_MAP)
+        self.date_created = map_str_to_datetime(
+            "date_created", date_created, self._FROM_DICT_MAP
+        )
         self.comment = comment
         self.machine_name = machine_name
         self.owner_name = owner_name
         self.owner_id = owner_id
 
 
 class SchemaTaskStatus(AutoName):
     """Enumeration constants used to specify status of the task."""
+
     RUNNING = auto()
     COMPLETED = auto()
     FAILED = auto()
 
 
 class SchemaTaskError(Dictable):
     """Representation of properties used to report an error related to schema
     task."""
 
-    def __init__(self, code: str, message: str, additional_properties: Optional[dict] = None):
+    def __init__(
+        self, code: str, message: str, additional_properties: Optional[dict] = None
+    ):
         """Initialize task error.
 
         Args:
             code (str): Internal application error code.
             message (str): Description of error.
             additional_properties (dict, optional): Additional information
                 related to the error (if any).
@@ -122,15 +129,15 @@
 class SchemaTask(Dictable):
     """Detailed information about a task which is performed on the schema."""
 
     _FROM_DICT_MAP = {
         'status': SchemaTaskStatus,
         'start_time': DatetimeFormats.FULLDATETIME,
         'end_time': DatetimeFormats.FULLDATETIME,
-        'errors': [SchemaTaskError]
+        'errors': [SchemaTaskError],
     }
 
     def __init__(
         self,
         id: str,
         status: Union[str, SchemaTaskStatus],
         start_time: Optional[str] = None,
@@ -155,24 +162,26 @@
             `TypeError` if `status` is neither a string nor
             a `SchemaTaskStatus`.
             `ValueError` if `status` is specified as a string which is not
             a proper value of enum `SchemaTaskStatus`.
         """
         self.id = id
         self.status = get_enum(status, SchemaTaskStatus)
-        self.start_time = map_str_to_datetime("start_time", start_time, self._FROM_DICT_MAP)
+        self.start_time = map_str_to_datetime(
+            "start_time", start_time, self._FROM_DICT_MAP
+        )
         self.end_time = map_str_to_datetime("end_time", end_time, self._FROM_DICT_MAP)
         self.errors = errors
 
     def __repr__(self) -> str:
         param_dict = auto_match_args_entity(
             self.__init__,
             self,
             exclude=['self', 'start_time', 'end_time', 'errors'],
-            include_defaults=False
+            include_defaults=False,
         )
 
         params = [f'{param}={repr(value)}' for param, value in param_dict.items()]
         formatted_params = ", ".join(params)
 
         return f"SchemaTask({formatted_params})"
 
@@ -229,18 +238,18 @@
         self._lock_type = None
 
     def __repr__(self) -> str:
         param_dict = auto_match_args_entity(
             self.__init__, self, exclude=['self'], include_defaults=False
         )
         params = [
-            f"{param}" if
-            (param == "connection" and isinstance(value, Connection)) else f'{param}={repr(value)}'
-            for param,
-            value in param_dict.items()
+            f"{param}"
+            if (param == "connection" and isinstance(value, Connection))
+            else f'{param}={repr(value)}'
+            for param, value in param_dict.items()
         ]
         formatted_params = ', '.join(params)
 
         return f'SchemaManagement({formatted_params})'
 
     def get_lock_status(self) -> "SchemaLockStatus":
         """Get the lock status of the schema.
@@ -292,25 +301,28 @@
             unlocked. `False` when procedure of unlocking schema failed.
         """
 
         if self.lock_type == SchemaLockType.UNLOCKED:
             logger.info('Schema is already unlocked.')
             return True
 
-        res = schema.unlock_schema(self.connection, project_id=self.project_id, throw_error=False)
+        res = schema.unlock_schema(
+            self.connection, project_id=self.project_id, throw_error=False
+        )
         if res.ok:
             self.get_lock_status()
             return True
         return False
 
     def reload(
         self,
-        update_types: Optional[Union[List[Union[str, "SchemaUpdateType"]],
-                                     Union[str, "SchemaUpdateType"]]] = None,
-        respond_async: bool = True
+        update_types: Optional[
+            Union[List[Union[str, "SchemaUpdateType"]], Union[str, "SchemaUpdateType"]]
+        ] = None,
+        respond_async: bool = True,
     ) -> Optional["SchemaTask"]:
         """Reload (update) the schema. This operation can be performed
         asynchronously. In that case the task is created and it is saved in
         property `tasks` to help tracking its status.
 
         Args:
             update_types (optional, list or object or string): Field with update
@@ -343,15 +355,17 @@
         """
         if not update_types:
             update_types = []
         elif not isinstance(update_types, list):
             update_types = [update_types]
         update_types = [get_enum_val(t, SchemaUpdateType) for t in update_types]
 
-        res = schema.reload_schema(self.connection, self.project_id, update_types, respond_async)
+        res = schema.reload_schema(
+            self.connection, self.project_id, update_types, respond_async
+        )
         if res.ok and respond_async:
             return self._save_task(res.json())
 
     def get_task(self, task_index: int) -> "SchemaTask":
         """Get all details of the task which is stored at a given
         `task_index` in a list from property `tasks`.
 
@@ -364,16 +378,16 @@
             index. When index is not proper then `None` is returned and warning
             with explanation message is shown.
         """
         try:
             task_id = self.tasks[task_index].id
         except IndexError:
             msg = (
-                f"Cannot get task with index {task_index} from the list of tasks for this "
-                "schema management object. Check the list using property `tasks`."
+                f"Cannot get task with index {task_index} from the list of tasks for "
+                f"this schema management object. Check the list using property `tasks`."
             )
             exception_handler(msg, Warning)
             return
 
         res = schema.read_task_status(self.connection, task_id, self.project_id)
         return self._save_task(res.json())
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/table/logical_table.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/table/logical_table.py`

 * *Files 8% similar despite different names*

```diff
@@ -10,30 +10,30 @@
 from mstrio.modeling.schema import ObjectSubType, SchemaObjectReference
 from mstrio.modeling.schema.attribute import Attribute
 from mstrio.modeling.schema.fact import Fact
 from mstrio.modeling.schema.helpers import (
     PhysicalTableType,
     TableColumn,
     TableColumnMergeOption,
-    TablePrefixOption
+    TablePrefixOption,
 )
 from mstrio.modeling.schema.table.physical_table import PhysicalTable
 from mstrio.object_management import Folder
 from mstrio.object_management.search_operations import full_search
 from mstrio.types import ObjectTypes
 from mstrio.users_and_groups import User
 from mstrio.utils.entity import DeleteMixin, Entity, MoveMixin
 from mstrio.utils.enum_helper import get_enum, get_enum_val
 from mstrio.utils.helper import (
     delete_none_values,
     exception_handler,
     fetch_objects,
     get_args_from_func,
     get_default_args_from_func,
-    get_valid_project_id
+    get_valid_project_id,
 )
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 NO_PROJECT_ERR_MSG = "You must specify or select a project."
 
 logger = logging.getLogger(__name__)
 
@@ -45,15 +45,15 @@
     table_type: Optional[PhysicalTableType] = None,
     name: Optional[str] = None,
     folder_id: Optional[str] = None,
     folder_name: Optional[str] = None,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     filters: Optional[dict] = None,
-    limit: Optional[int] = None
+    limit: Optional[int] = None,
 ) -> list["LogicalTable"] | list[dict]:
     """List all logical tables in a project mapped to a specified connection.
        Optionally, you can filter by physical table type.
 
     Args:
         connection (Connection): Object representation of MSTR Connection.
         name (Optional[str], optional): Name of a table.
@@ -64,16 +64,19 @@
             logical tables. Defaults to None.
         folder_name (Optional[str], optional): Name of a folder in which to look
             for logical tables. Defaults to None.
         to_dictionary (bool, optional): If True returns a list of dictionaries.
             Defaults to False.
         table_type(PhysicalTableType, optional): If specified, returns a list
             of logical tables with physical table with this type.
-        filters: dict that specifies filter expressions. Available filters are
-            `name`, `folder_id`, `folder_name`, `project_id` and `project_name`
+        filters: dict that specifies filter expressions. Only used if a name,
+            folder_id, folder_name, project_id or project_name are provided.
+            Available filters are:
+            ['date_created', 'date_modified', 'version_id', 'acg',
+             'primary_locale', 'sub_type', 'name', 'id']
         limit: limit the number of elements returned. If `None` (default), all
             objects are returned.
 
     Returns:
         list["LogicalTable"] | list[dict]: A list of LogicalTable objects
             or dictionaries representing logical tables.
     """
@@ -82,15 +85,15 @@
             connection=connection,
             to_dictionary=to_dictionary,
             name=name,
             folder_id=folder_id,
             folder_name=folder_name,
             project_id=project_id,
             project_name=project_name,
-            limit=limit
+            limit=limit,
         )
     else:
         if table_type:
             logical_tables = fetch_objects(
                 connection,
                 tables_api.get_tables,
                 limit=None,
@@ -116,28 +119,32 @@
                 tables_api.get_tables,
                 limit=limit,
                 filters=filters or {},
                 dict_unpack_value="tables",
                 fields="information",
             )
 
-        return logical_tables if to_dictionary else LogicalTable.bulk_from_dict(
-            source_list=logical_tables, connection=connection
+        return (
+            logical_tables
+            if to_dictionary
+            else LogicalTable.bulk_from_dict(
+                source_list=logical_tables, connection=connection
+            )
         )
 
 
 def _full_search_logical_tables(
     connection: Connection,
     name: Optional[str] = None,
     folder_id: Optional[str] = None,
     folder_name: Optional[str] = None,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     limit: Optional[int] = None,
-    to_dictionary: bool = False
+    to_dictionary: bool = False,
 ) -> list[type["LogicalTable"]] | list[dict]:
     """Searches for a logical table in a specified project. You can narrow the
        search result by folder's id or name.
 
     Specify either `project_id` or `project_name`.
     When `project_id` is provided (not `None`), `project_name` is omitted.
 
@@ -185,52 +192,64 @@
     )
 
     if folder_name and not folder_id:
         folders = full_search(
             connection=connection,
             project=project_id,
             object_types=ObjectTypes.FOLDER,
-            limit=limit
+            limit=limit,
+        )
+        folder = next(
+            filter(lambda _folder: _folder.get("name") == folder_name, folders), None
         )
-        folder = next(filter(lambda _folder: _folder.get("name") == folder_name, folders), None)
-        folder_id = folder["id"] if folder else exception_handler(
-            'Folder with a given name was not found.', exception_type=ValueError
+        folder_id = (
+            folder["id"]
+            if folder
+            else exception_handler(
+                'Folder with a given name was not found.', exception_type=ValueError
+            )
         )
 
     logical_tables = full_search(
         connection=connection,
         name=name,
         project=project_id,
         object_types=ObjectTypes.TABLE,
         root=folder_id,
+        limit=limit,
     )
     return (
-        logical_tables if to_dictionary else
-        LogicalTable.bulk_from_dict(source_list=logical_tables, connection=connection)
+        logical_tables
+        if to_dictionary
+        else LogicalTable.bulk_from_dict(
+            source_list=logical_tables, connection=connection
+        )
     )
 
 
 @method_version_handler('11.3.0100')
 def list_changeset_tables(
     connection: Connection,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     limit: Optional[int] = None,
     changeset_id: Optional[str] = None,
     **filters,
 ) -> list[type["LogicalTable"]]:
     # Changeset must be specified
     if not changeset_id:
-        exception_handler(msg="You must specify changeset ID.", exception_type=ValueError)
+        exception_handler(
+            msg="You must specify changeset ID.", exception_type=ValueError
+        )
 
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
         project_name=project_name,
-        with_fallback=False if project_name else True
+        with_fallback=False if project_name else True,
     )
 
     tables_list = fetch_objects(
         connection=connection,
         api=tables_api.get_tables,
         limit=limit,
         project_id=project_id,
@@ -376,27 +395,28 @@
         ): tables_api.get_table,
     }
     _API_PATCH: dict = {
         (
             "name",
             "description",
             "logical_size",
+            "is_logical_size_locked",
             "is_true_key",
             "primary_data_source",
             "enclose_sql_in_parentheses",
             "physical_table",
             "secondary_data_sources",
         ): (tables_api.patch_table, "partial_put"),
         "folder_id": (objects.update_object, "partial_put"),
     }
     _PATCH_PATH_TYPES = {
         "name": str,
         "description": str,
         "logical_size": int,
-        "is_logical_size_locked": str,
+        "is_logical_size_locked": bool,
         "is_true_key": bool,
         "primary_data_source": dict,
         "enclose_sql_in_parentheses": bool,
         "physical_table": dict,
         "secondary_data_sources": list,
         "folder_id": str,
     }
@@ -443,15 +463,15 @@
             >>> LogicalTable(connection, name='lu_day_of_week')
         """
 
         project_id = get_valid_project_id(
             connection=connection,
             project_id=project_id,
             project_name=project_name,
-            with_fallback=False if project_name else True
+            with_fallback=False if project_name else True,
         )
 
         if not id and not name:
             exception_handler(
                 msg="You must specify table's id or table's name.",
                 exception_type=ValueError,
             )
@@ -472,60 +492,69 @@
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
 
         attributes = kwargs.get("attributes")
         self.attributes = (
             Attribute.bulk_from_dict(source_list=attributes, connection=self.connection)
-            if attributes else None
+            if attributes
+            else None
         )
 
         ancestors = kwargs.get("ancestors")
         self.folder_id = ancestors[-1].get("id") if ancestors else None
         self.destination_folder_id = kwargs.get("destination_folder_id")
 
         facts = kwargs.get("facts")
         if facts:
             [f.update(f.pop("information")) for f in facts]
         self.facts = (
-            Fact.bulk_from_dict(source_list=facts, connection=self.connection) if facts else None
+            Fact.bulk_from_dict(source_list=facts, connection=self.connection)
+            if facts
+            else None
         )
         self.is_logical_size_locked = kwargs.get("is_logical_size_locked")
         self.is_part_of_partition = kwargs.get("is_part_of_partition")
         self.is_true_key = kwargs.get("is_true_key")
         self.logical_size = kwargs.get("logical_size")
 
         physical_table = kwargs.get("physical_table")
         self.physical_table = (
             PhysicalTable.from_dict(source=physical_table, connection=self.connection)
-            if physical_table else None
+            if physical_table
+            else None
         )
 
         primary_data_source = kwargs.get("primary_data_source")
         self.primary_data_source = (
             SchemaObjectReference.from_dict(source=primary_data_source)
-            if primary_data_source else None
+            if primary_data_source
+            else None
         )
         self.primary_locale = kwargs.get("primary_locale")
 
         secondary_data_sources = kwargs.get("secondary_data_sources")
         self.secondary_data_sources = (
             SchemaObjectReference.bulk_from_dict(
                 source_list=secondary_data_sources, connection=self.connection
-            ) if secondary_data_sources else None
+            )
+            if secondary_data_sources
+            else None
         )
 
         sub_type = kwargs.get("sub_type")
         self._sub_type = ObjectSubType(sub_type) if sub_type else None
 
         table_key = kwargs.get("table_key")
         self.table_key = (
             SchemaObjectReference.bulk_from_dict(
                 source_list=table_key, connection=self.connection
-            ) if table_key else None
+            )
+            if table_key
+            else None
         )
         self._version = kwargs.get("version_id")
 
     @classmethod
     def create(
         cls,
         connection: "Connection",
@@ -543,15 +572,17 @@
         columns: Optional[list[TableColumn] | list[dict]] = None,
         sql_statement: Optional[str] = None,
         logical_size: Optional[int] = None,
         is_part_of_partition: Optional[bool] = None,
         is_true_key: Optional[bool] = None,
         enclose_sql_in_parentheses: Optional[bool] = None,
         check_secondary_data_source_table: Optional[bool] = None,
-        column_merge_option: Optional[TableColumnMergeOption] = TableColumnMergeOption.REUSE_ANY,
+        column_merge_option: Optional[
+            TableColumnMergeOption
+        ] = TableColumnMergeOption.REUSE_ANY,
         table_prefix_option: Optional[TablePrefixOption] = None,
     ) -> type["LogicalTable"]:
         """Create a new table in a specific project.
 
         Args:
             connection (object): MicroStrategy connection object returned by
                 `connection.Connection()`.
@@ -639,71 +670,82 @@
                     physical_table_namespace="public",
                     primary_data_source=SchemaObjectReference(
                             object_id="DAD6CAD6457DAF29E34463961688EA60",
                             sub_type=ObjectSubType.DB_ROLE),
                     table_name="New Table", table_description="New Description",
                     sub_type=ObjectSubType.LOGICAL_TABLE))
         """
-        if physical_table and any([
+        if physical_table and any(
+            [
                 physical_table_name,
                 physical_table_namespace,
                 physical_table_prefix,
                 sql_statement,
                 columns,
-        ]):
+            ]
+        ):
             msg = (
-                "You can either pass the `physical table` object or specify parameters related "
-                "to the physical table, not both."
+                "You can either pass the `physical table` object or specify "
+                "parameters related to the physical table, not both."
             )
             exception_handler(msg, exception_type=ValueError)
 
         physical_table = (
             PhysicalTable(connection=connection, id=physical_table.get("id"))
-            if isinstance(physical_table, dict) else physical_table
+            if isinstance(physical_table, dict)
+            else physical_table
         )
 
-        if get_enum_val(getattr(physical_table, "table_type", physical_table_type)
-                        ) == get_enum_val(PhysicalTableType.WAREHOUSE_PARTITION):
+        if get_enum_val(
+            getattr(physical_table, "table_type", physical_table_type)
+        ) == get_enum_val(PhysicalTableType.WAREHOUSE_PARTITION):
             exception_handler(
                 msg="Warehouse Partition tables are not supported.",
                 exception_type=TypeError,
             )
 
         if (physical_table_name and physical_table_namespace) and sql_statement:
             msg = (
                 "Specify either a `physical_table_name` and `physical_table_namespace`"
                 " or `sql_statement`"
             )
             exception_handler(msg, exception_type=ValueError)
 
         primary_data_source = (
             primary_data_source.to_dict()
-            if isinstance(primary_data_source, SchemaObjectReference) else primary_data_source
+            if isinstance(primary_data_source, SchemaObjectReference)
+            else primary_data_source
         )
 
         physical_table = {
             "type": get_enum_val(
                 getattr(physical_table, "table_type", physical_table_type),
                 PhysicalTableType,
             ),
             "tableName": getattr(physical_table, "table_name", physical_table_name),
             "namespace": getattr(physical_table, "namespace", physical_table_namespace),
-            "tablePrefix": getattr(physical_table, "table_prefix", physical_table_prefix),
-            "columns": [col.to_dict() if isinstance(col, TableColumn) else col for col in cols] if
-            (cols := getattr(physical_table, "columns", columns)) else None,
+            "tablePrefix": getattr(
+                physical_table, "table_prefix", physical_table_prefix
+            ),
+            "columns": [
+                col.to_dict() if isinstance(col, TableColumn) else col for col in cols
+            ]
+            if (cols := getattr(physical_table, "columns", columns))
+            else None,
             "sqlStatement": getattr(physical_table, "sql_statement", sql_statement),
         }
 
         body = {
             "information": {
                 "name": table_name,
                 "description": table_description,
                 "subType": get_enum_val(sub_type, ObjectSubType),
                 "destinationFolderId": destination_folder.id
-                if isinstance(destination_folder, Folder) else destination_folder,
+                if isinstance(destination_folder, Folder)
+                else destination_folder,
                 "isEmbedded": is_embedded,
             },
             "logicalSize": logical_size,
             "isPartOfPartition": is_part_of_partition,
             "isTrueKey": is_true_key,
             "primaryDataSource": primary_data_source,
             "encloseSqlInParentheses": enclose_sql_in_parentheses,
@@ -711,15 +753,17 @@
         }
         body = delete_none_values(body, recursion=True)
 
         response = tables_api.post_table(
             connection=connection,
             data=body,
             check_secondary_data_source_table=check_secondary_data_source_table,
-            column_merge_option=get_enum_val(column_merge_option, TableColumnMergeOption),
+            column_merge_option=get_enum_val(
+                column_merge_option, TableColumnMergeOption
+            ),
             table_prefix_option=get_enum_val(table_prefix_option, TablePrefixOption),
         ).json()
 
         if config.verbose:
             logger.info(
                 f"Successfully created table named: '{response['name']}' "
                 f"with ID: '{response['id']}'"
@@ -763,15 +807,17 @@
         self,
         name: Optional[str] = None,
         is_true_key: Optional[bool] = None,
         logical_size: Optional[int] = None,
         description: Optional[str] = None,
         is_logical_size_locked: Optional[bool] = None,
         primary_data_source: Optional[SchemaObjectReference] = None,
-        secondary_data_sources: Optional[list[SchemaObjectReference] | list[dict]] = None,
+        secondary_data_sources: Optional[
+            list[SchemaObjectReference] | list[dict]
+        ] = None,
         physical_table_object_name: Optional[str] = None,
         physical_table_name: Optional[str] = None,
         physical_table_prefix: Optional[str] = None,
         sql_statement: Optional[str] = None,
         enclose_sql_in_parentheses: Optional[bool] = None,
         columns: Optional[list[TableColumn] | list[dict]] = None,
         folder_id: Optional[str] = None,
@@ -841,56 +887,60 @@
                                      name="Altered Name"
                                  )
         """
         self.__validate_physical_table_type()
         func = self.alter
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
 
         physical_table_type = self.physical_table.table_type
-        if physical_table_type == PhysicalTableType.NORMAL and (sql_statement or columns):
+        if physical_table_type == PhysicalTableType.NORMAL and (
+            sql_statement or columns
+        ):
             exception_handler(
                 msg=(
-                    "You cannot change `sql_statement` nor `columns` attributes when a logical"
-                    " table depends upon a normal physical table."
+                    "You cannot change `sql_statement` nor `columns` attributes when "
+                    "a logical table depends upon a normal physical table."
                 ),
                 exception_type=TypeError,
             )
-        elif physical_table_type == PhysicalTableType.SQL and (physical_table_prefix
-                                                               or physical_table_name):
+        elif physical_table_type == PhysicalTableType.SQL and (
+            physical_table_prefix or physical_table_name
+        ):
             exception_handler(
                 msg=(
-                    "You cannot change `physical_table_name` nor `physical_table_prefix` when"
-                    "a logical table depends upon a freeform sql physical table."
+                    "You cannot change `physical_table_name` nor "
+                    "`physical_table_prefix` when a logical table depends upon "
+                    "a freeform sql physical table."
                 ),
                 exception_type=TypeError,
             )
 
         physical_table = (
-            {
-                "information": {
-                    "name": properties.pop("physical_table_object_name")
-                }
-            } if properties.get("physical_table_object_name") else {}
+            {"information": {"name": properties.pop("physical_table_object_name")}}
+            if properties.get("physical_table_object_name")
+            else {}
         )
         physical_table.update(
             {
                 "table_prefix": properties.pop("physical_table_prefix", None),
                 "table_name": properties.pop("physical_table_name", None),
                 "sql_statement": properties.pop("sql_statement", None),
                 "columns": properties.pop("columns", None),
             }
         )
-        properties["physical_table"] = delete_none_values(physical_table, recursion=True)
+        properties["physical_table"] = delete_none_values(
+            physical_table, recursion=True
+        )
 
         self._alter_properties(**properties)
 
     def update_physical_table_structure(
         self, col_merge_option: TableColumnMergeOption | str
     ) -> None:
         """Updates a structure of a physical table upon which the logical table
@@ -920,15 +970,16 @@
             id=self.id,
             body=None,
             column_merge_option=col_merge_option,
         )
         if res.ok:
             data = res.json().get("physicalTable")
             logger.info(
-                f"Successfully modified a structure of a physical table '{data.get('tableName')}' "
+                f"Successfully modified a structure of a physical table '"
+                f"{data.get('tableName')}' "
                 f"with ID: '{data.get('information').get('objectId')}' "
                 f"in a '{data.get('namespace')}' namespace "
                 f"with a '{data.get('tablePrefix')}' table prefix."
             )
 
     @classmethod
     def update_physical_table_structure_for_all_tables(
@@ -943,18 +994,25 @@
             connection (Connection): Object representation of MSTR Connection.
             col_merge_option (TableColumnMergeOption | str): A new
                 structure for a physical table upon which the logical table
                 depends.
         """
         col_merge_option = get_enum(col_merge_option, TableColumnMergeOption)
         logical_tables = list_logical_tables(connection)
-        with tqdm(total=len(logical_tables), desc="Updating structures...") as progress_bar:
+        with tqdm(
+            total=len(logical_tables), desc="Updating structures..."
+        ) as progress_bar:
             for table in logical_tables:
-                if (table.physical_table.table_type != PhysicalTableType.WAREHOUSE_PARTITION):
-                    table.update_physical_table_structure(col_merge_option=col_merge_option)
+                if (
+                    table.physical_table.table_type
+                    != PhysicalTableType.WAREHOUSE_PARTITION
+                ):
+                    table.update_physical_table_structure(
+                        col_merge_option=col_merge_option
+                    )
                 progress_bar.update()
 
     def __validate_physical_table_type(self) -> bool:
         """Validates whether a table can be modified by checking if a physical
             table type upon which the logical table depends is
             "Warehouse Partition Table"
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/table/physical_table.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/table/physical_table.py`

 * *Files 2% similar despite different names*

```diff
@@ -25,15 +25,15 @@
 def list_physical_tables(
     connection: Connection,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     filters: Optional[dict] = None,
     limit: Optional[int] = None,
     to_dictionary: bool = False,
-    include_unassigned_tables: bool = False
+    include_unassigned_tables: bool = False,
 ) -> Union[list["PhysicalTable"], list[dict]]:
     """List all physical tables in a project.
 
     Specify either `project_id` or `project_name`.
     When `project_id` is provided (not `None`), `project_name` is omitted.
 
     Note:
@@ -59,23 +59,23 @@
         Union[list["PhysicalTable"], list[dict]]: A list of PhysicalTable
             objects or dictionaries representing physical tables.
     """
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
         project_name=project_name,
-        with_fallback=False if project_name else True
+        with_fallback=False if project_name else True,
     )
     if include_unassigned_tables:
         tables = full_search(
             connection=connection,
             project=project_id,
             object_types=ObjectTypes.DBTABLE,
             limit=limit,
-            **(filters or {})
+            **(filters or {}),
         )
     else:
         tables = fetch_objects(
             connection=connection,
             api=tables_api.get_tables,
             limit=limit,
             project_id=project_id,
@@ -83,42 +83,47 @@
             dict_unpack_value="tables",
             fields="physicalTable",
         )
 
         tables = list({item['id']: item for item in tables}.values())
 
     return (
-        tables if to_dictionary else
-        PhysicalTable.bulk_from_dict(source_list=tables, connection=connection)
+        tables
+        if to_dictionary
+        else PhysicalTable.bulk_from_dict(source_list=tables, connection=connection)
     )
 
 
 @method_version_handler('11.3.0100')
 def list_tables_prefixes(
-        connection: Connection,
-        project_id: Optional[str] = None,
-        project_name: Optional[str] = None,
+    connection: Connection,
+    project_id: Optional[str] = None,
+    project_name: Optional[str] = None,
 ):
     """Returns the prefixes for the physical tables
 
     Args:
         connection: Object representation of MSTR Connection
         project_id (Optional[str], optional): ID of a project. Defaults to None
         project_name (Optional[str], optional): Name of a project. Defaults to
             None.
 
     Returns:
         A dictionary of prefixes for all the physical tables
     """
-    project_id = get_valid_project_id(connection=connection,
-                                      project_id=project_id,
-                                      project_name=project_name,
-                                      with_fallback=False if project_name else True)
+    project_id = get_valid_project_id(
+        connection=connection,
+        project_id=project_id,
+        project_name=project_name,
+        with_fallback=False if project_name else True,
+    )
 
-    physical_tables = list_physical_tables(connection, project_id=project_id, to_dictionary=True)
+    physical_tables = list_physical_tables(
+        connection, project_id=project_id, to_dictionary=True
+    )
     return {table.get("table_prefix") for table in physical_tables}
 
 
 @method_version_handler('11.3.0100')
 def list_namespaces(
     connection: "Connection",
     id: str,
@@ -190,15 +195,15 @@
 
     def __init__(
         self,
         connection: Connection,
         id: str,
         name: Optional[str] = None,
         project_id: Optional[str] = None,
-        project_name: Optional[str] = None
+        project_name: Optional[str] = None,
     ):
         """Initializes a PhysicalTable object. You have to provide ID of a
             physical table object. You can get this ID e.g. using
             `mstrio.project_object.schema.tables.list_physical_tables()`. It
             will try to fetch as much information as possible. To start, it will
             fetch all information related to Entity class. If the physical table
             has at least one logical table associated with it (in a project
@@ -225,24 +230,24 @@
         Examples:
             >>> PhysicalTable(connection, id='5DE0F8934CBD82437D6FA1AFF75F6C58')
         """
         project_id = get_valid_project_id(
             connection=connection,
             project_id=project_id,
             project_name=project_name,
-            with_fallback=False if project_name else True
+            with_fallback=False if project_name else True,
         )
 
         super().__init__(connection=connection, object_id=id)
         try:
             # If the physical table is included in a project, more info can be
             # fetched.
-            physical_tables: list[dict] = list_physical_tables(connection, project_id,
-                                                               to_dictionary=True,
-                                                               filters={'id': id})
+            physical_tables: list[dict] = list_physical_tables(
+                connection, project_id, to_dictionary=True, filters={'id': id}
+            )
             table = physical_tables[0]
             table.update({"table_type": table.pop("type", None)})
             self._set_object_attributes(**table)
         except LookupError:
             pass
 
     def _init_variables(self, **kwargs) -> None:
@@ -258,16 +263,19 @@
                     **information,
                 }
             )
             super()._init_variables(**kwargs)
 
             columns = kwargs.get("columns")
             self.columns = (
-                TableColumn.bulk_from_dict(source_list=columns, connection=self.connection)
-                if columns else None
+                TableColumn.bulk_from_dict(
+                    source_list=columns, connection=self.connection
+                )
+                if columns
+                else None
             )
             self.namespace = kwargs.get("namespace")
             self.primary_locale = kwargs.get("primary_locale")
 
             sub_type = kwargs.get("sub_type")
             self._sub_type = ObjectSubType(sub_type) if sub_type else None
             self.table_name = kwargs.get("table_name")
@@ -305,13 +313,15 @@
             table_id (str): ID of a physical table.
             force: (bool): If True then prompt will be skipped.
         """
         dependent_logical_tables = self.list_dependent_logical_tables()
         if dependent_logical_tables:
             logger.warning("Following dependent logical tables will be deleted: ")
             logger.warning(",".join(str(table) for table in dependent_logical_tables))
-            confirmed_delete = (force or input("Do you want to continue? [Y/n]: ").lower() == "y")
+            confirmed_delete = (
+                force or input("Do you want to continue? [Y/n]: ").lower() == "y"
+            )
             if confirmed_delete:
                 [table.delete(force=True) for table in dependent_logical_tables]
                 logger.info(f"Successfully removed Warehouse Table with id: {self.id}")
         else:
             logger.error("This table is not included in a project.")
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/table/warehouse_table.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/table/warehouse_table.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 from tqdm import tqdm
 
 from mstrio.api import datasources
 from mstrio.api import tables as tables_api
 from mstrio.connection import Connection
 from mstrio.datasources.datasource_instance import (
     DatasourceInstance,
-    list_connected_datasource_instances
+    list_connected_datasource_instances,
 )
 from mstrio.modeling.schema import ObjectSubType, SchemaObjectReference
 from mstrio.modeling.schema.helpers import TableColumn, TableColumnMergeOption
 from mstrio.modeling.schema.table.logical_table import list_logical_tables, LogicalTable
 from mstrio.utils.helper import Dictable, fetch_objects
 from mstrio.utils.sessions import FuturesSessionWithRenewal
 from mstrio.utils.version_helper import method_version_handler
@@ -26,15 +26,15 @@
 @method_version_handler('11.3.0100')
 def list_datasource_warehouse_tables(
     connection: Connection,
     datasource_id: str,
     namespace_id: str,
     name: str = None,
     to_dictionary: bool = False,
-    limit: Optional[int] = None
+    limit: Optional[int] = None,
 ) -> list[Type["WarehouseTable"]] | list[dict]:
     """Lists available warehouse tables in a specified datasource within a
        specified namespace.
 
     Args:
         connection (Connection): Object representation of MSTR Connection.
         datasource_id (str): ID of a datasource.
@@ -64,30 +64,29 @@
         limit=limit,
         filters={'name': name} if name else None,
         dict_unpack_value="tables",
         datasource_id=datasource_id,
         namespace_id=namespace_id,
     )
     [
-        table.update({
-            "datasource": {
-                "id": datasource_id
-            }, "namespace_id": namespace_id
-        }) for table in tables
+        table.update(
+            {"datasource": {"id": datasource_id}, "namespace_id": namespace_id}
+        )
+        for table in tables
     ]
     if to_dictionary:
         return tables
     return WarehouseTable.bulk_from_dict(source_list=tables, connection=connection)
 
 
 def list_warehouse_tables(
     connection: Connection,
     to_dictionary: bool = False,
     name: Optional[str] = None,
-    datasource_id: Optional[str] = None
+    datasource_id: Optional[str] = None,
 ) -> list["WarehouseTable"] | list[dict]:
     """Fetches all available warehouse table. This operation is done
        asynchronously and is heavy: a lot of requests are performed to fetch
        all connected and available datasources, namespaces and finally
        warehouse tables for each combination. Additionally, the result could be
        filtered. Available filters are table name and datasource id. These
        filters can be combined.
@@ -141,15 +140,17 @@
         id: str,
         connection: Connection,
         datasource: DatasourceInstance,
         namespace_id: str,
         name: str,
         namespace: str,
     ):
-        self.__id = id  # Non-persistent. It will change if the table name or namespace changes.
+        self.__id = (
+            id  # Non-persistent. It will change if the table name or namespace changes.
+        )
         self.connection = connection
         self.datasource = datasource
         self.name = name
         self.namespace = namespace
         self.namespace_id = namespace_id
         # When table is added to a project, it will get a persistent ID
         self.physical_table_id = None
@@ -188,17 +189,15 @@
             physical_table_namespace=self.namespace,
         )
         self.physical_table_id = lt.physical_table.id
         self.list_dependent_logical_tables(refresh=True)
         return lt
 
     def list_dependent_logical_tables(
-        self,
-        to_dictionary: bool = False,
-        refresh: bool = False
+        self, to_dictionary: bool = False, refresh: bool = False
     ) -> list["LogicalTable"] | list[dict]:
         """Get all dependent logical tables.
 
         Args:
             to_dictionary (bool, optional): If True, returns a list of
                 dictionaries. Defaults to False.
             refresh(bool, optional): If True, refreshes the result stored in
@@ -209,20 +208,23 @@
                 objects or dictionaries representing logical tables.
         """
         if self._dependent_logical_tables and not refresh:
             return self._dependent_logical_tables
         logical_tables = list_logical_tables(connection=self.connection)
         if self.physical_table_id:
             dependent_logical_tables = [
-                table for table in logical_tables
+                table
+                for table in logical_tables
                 if table.physical_table.id == self.physical_table_id
             ]
         else:
             dependent_logical_tables = [
-                table for table in logical_tables if table.physical_table.table_name == self.name
+                table
+                for table in logical_tables
+                if table.physical_table.table_name == self.name
             ]
 
         self._dependent_logical_tables = dependent_logical_tables
 
         if to_dictionary:
             return [table.to_dict() for table in dependent_logical_tables]
 
@@ -234,26 +236,30 @@
         tables if they themselves have no dependent objects. This function
         corresponds to "REMOVE WHTABLE" statement from MSTR Command Manager.
         """
         dependent_logical_tables = self.list_dependent_logical_tables(refresh=True)
         if dependent_logical_tables:
             logger.warning("Following logical tables will be deleted: ")
             [logger.info(f"{str(table)}") for table in dependent_logical_tables]
-            confirmed_delete = (force or input("Would you like to continue? Y/n").lower() == "y")
+            confirmed_delete = (
+                force or input("Would you like to continue? Y/n").lower() == "y"
+            )
             if confirmed_delete:
-                statuses = [table.delete(force=True) for table in dependent_logical_tables]
-                self.physical_table_id = (None if all(statuses) else self.physical_table_id)
+                statuses = [
+                    table.delete(force=True) for table in dependent_logical_tables
+                ]
+                self.physical_table_id = (
+                    None if all(statuses) else self.physical_table_id
+                )
                 return statuses
         else:
             logger.error("This table is not included in a project.")
 
     def list_columns(
-        self,
-        to_dictionary: bool = False,
-        refresh: bool = False
+        self, to_dictionary: bool = False, refresh: bool = False
     ) -> list[Type[TableColumn]] | list[dict]:
         """Get columns for a specific database table.
 
         Args:
             to_dictionary (bool, optional): If True, returns a list of
                 dictionaries. Defaults to False.
             refresh (bool, optional): If True, refetches and overwrites the
@@ -264,15 +270,16 @@
             Union[list[TableColumn], list[dict]]: A list of TableColumn objects
                 or dictionaries representing table columns.
         """
         if self._columns and not refresh:
             return self._columns
         datasource_id = (
             self.datasource.id
-            if isinstance(self.datasource, DatasourceInstance) else self.datasource.get("id")
+            if isinstance(self.datasource, DatasourceInstance)
+            else self.datasource.get("id")
         )
         columns = fetch_objects(
             connection=self.connection,
             api=datasources.get_table_columns,
             limit=None,
             filters={},
             dict_unpack_value="columns",
@@ -292,15 +299,15 @@
 
     @classmethod
     def _list_warehouse_tables(
         cls,
         connection: Connection,
         to_dictionary: bool = False,
         name: Optional[str] = None,
-        datasource_id: Optional[str] = None
+        datasource_id: Optional[str] = None,
     ) -> list["WarehouseTable"] | list[dict]:
         """Fetches all available warehouse table in a project mapped to the
            Connection object. This operation is done asynchronously and is
            heavy: a lot of requests are performed to fetch all connected and
            available datasources, namespaces and finally warehouse tables for
            each combination. Additionally, the result could be filtered.
            Available filters are table name and datasource id. These
@@ -315,30 +322,32 @@
             datasource_id (str, optional): ID of a datasource.
 
         Returns:
             list[WarehouseTable] | list[dict]: A list of dictionaries
                 or WarehouseTable objects.
         """
         if name or datasource_id:
-            tables = cls._filter(connection=connection, name=name, datasource_id=datasource_id)
+            tables = cls._filter(
+                connection=connection, name=name, datasource_id=datasource_id
+            )
             if to_dictionary:
                 return [table.to_dict() for table in tables]
             return tables
 
         return cls._list_available_warehouse_tables(
             connection=connection,
             to_dictionary=to_dictionary,
         )
 
     @classmethod
     def _filter(
         cls,
         connection: Connection,
         name: Optional[str] = None,
-        datasource_id: Optional[str] = None
+        datasource_id: Optional[str] = None,
     ) -> list["WarehouseTable"]:
         """Fetches (if not yet fetched) and filters all available warehouse
            tables. Available filters are table name and datasource id. These
            filters can be combined.
 
            Args:
             connection (Connection): Object representation of MSTR Connection.
@@ -354,24 +363,26 @@
         if name and datasource_id:
             datasource_tables = [
                 table
                 for table in available_tables
                 if table.datasource.id == datasource_id
             ]
             available_tables = [
-                table
-                for table in datasource_tables
-                if table.name == name.lower()
+                table for table in datasource_tables if table.name == name.lower()
             ]
 
         elif name:
-            available_tables = [table for table in available_tables if table.name == name.lower()]
+            available_tables = [
+                table for table in available_tables if table.name == name.lower()
+            ]
         elif datasource_id:
             available_tables = [
-                table for table in available_tables if table.datasource.id == datasource_id
+                table
+                for table in available_tables
+                if table.datasource.id == datasource_id
             ]
         return available_tables
 
     @classmethod
     def _list_available_warehouse_tables(
         cls,
         connection: Connection,
@@ -387,39 +398,45 @@
            to_dictionary (bool): If True, returns a list of dictionaries.
 
         Returns:
             Union[list[dict], list["WarehouseTable"]]: A list of dictionaries
                 or WarehouseTable objects.
         """
 
-        connected_datasource_instances: list[dict] = list_connected_datasource_instances(
-            connection, to_dictionary=True)
-        urls: dict[str, str] = cls._get_namespaces_urls(connection, connected_datasource_instances)
+        connected_datasource_instances: list[
+            dict
+        ] = list_connected_datasource_instances(connection, to_dictionary=True)
+        urls: dict[str, str] = cls._get_namespaces_urls(
+            connection, connected_datasource_instances
+        )
 
         with FuturesSessionWithRenewal(connection=connection) as session:
-            namespaces: dict[str, list[dict]] = cls._get_namespaces(connection, urls, session)
+            namespaces: dict[str, list[dict]] = cls._get_namespaces(
+                connection, urls, session
+            )
 
             warehouse_tables_futures = cls._get_warehouse_tables_futures(
-                connection, session, namespaces)
+                connection, session, namespaces
+            )
 
-            warehouse_tables: list[dict] = cls._get_warehouse_tables(connection,
-                                                                     warehouse_tables_futures)
-
-            available_tables = cls.bulk_from_dict(source_list=warehouse_tables,
-                                                  connection=connection)
+            warehouse_tables: list[dict] = cls._get_warehouse_tables(
+                connection, warehouse_tables_futures
+            )
+
+            available_tables = cls.bulk_from_dict(
+                source_list=warehouse_tables, connection=connection
+            )
         if to_dictionary:
             return warehouse_tables
 
         return available_tables
 
     @classmethod
     def _get_warehouse_tables(
-        cls,
-        connection: Connection,
-        warehouse_tables_futures: list[Future]
+        cls, connection: Connection, warehouse_tables_futures: list[Future]
     ) -> list[dict]:
         """Retrieves warehouse tables from a list of provided futures.
 
         Args:
             connection (Connection): Object representation of MSTR Connection.
             warehouse_tables_futures (list[Future]): A list of futures that
             resolve to warehouse tables in a given datasource in a given
@@ -427,30 +444,31 @@
 
         Returns:
             list[dict]: A list of warehouse tables retrieved from all the
                 futures.
         """
 
         warehouse_tables: list[dict] = []
-        with tqdm(total=len(warehouse_tables_futures),
-                  desc="Retrieving warehouse tables...") as pbar:
+        with tqdm(
+            total=len(warehouse_tables_futures), desc="Retrieving warehouse tables..."
+        ) as pbar:
             for future in as_completed(warehouse_tables_futures):
-                namespace_tables = cls._get_future_with_request_exceptions_handlers_and_pbar(
-                    cls._get_tables_from_future, future, pbar, connection=connection)
+                namespace_tables = (
+                    cls._get_future_with_request_exceptions_handlers_and_pbar(
+                        cls._get_tables_from_future, future, pbar, connection=connection
+                    )
+                )
                 if namespace_tables:
                     warehouse_tables += namespace_tables
 
         return warehouse_tables
 
     @classmethod
     def _get_namespaces(
-        cls,
-        connection: Connection,
-        urls: dict,
-        session: FuturesSessionWithRenewal
+        cls, connection: Connection, urls: dict, session: FuturesSessionWithRenewal
     ) -> dict[str, list[dict]]:
         """Retrieves namespaces for every url using provided session object.
 
         Args:
             connection (Connection): Object representation of MSTR Connection.
             urls (dict): A dictionary with datasource ID as a key and list of
                 namespace urls as a value.
@@ -460,22 +478,23 @@
         Returns:
             dict[str, list[dict]]: A dictionary which keys are datasource ids
                 and which values are lists of namespaces.
         """
         namespaces: dict[str, list[dict]] = {}
         namespaces_futures = cls._get_namespaces_futures(connection, session, urls)
         with tqdm(
-                total=len(namespaces_futures),
-                desc="Retrieving namespaces from available datasources...",
+            total=len(namespaces_futures),
+            desc="Retrieving namespaces from available datasources...",
         ) as pbar:
             for future in as_completed(namespaces_futures):
                 namespaces[
-                    future
-                    .datasource_id] = cls._get_future_with_request_exceptions_handlers_and_pbar(
-                        cls._get_namespaces_from_future, future, pbar)
+                    future.datasource_id
+                ] = cls._get_future_with_request_exceptions_handlers_and_pbar(
+                    cls._get_namespaces_from_future, future, pbar
+                )
         return namespaces
 
     @classmethod
     def _get_future_with_request_exceptions_handlers_and_pbar(
         cls, func, future, pbar, **func_kwargs
     ):
         try:
@@ -483,16 +502,15 @@
         except (ReadTimeout, HTTPError, ConnectionError) as e:
             logger.error(e)
         finally:
             pbar.update()
 
     @staticmethod
     def _get_namespaces_urls(
-        connection: "Connection",
-        connected_datasource_instances: list[dict]
+        connection: "Connection", connected_datasource_instances: list[dict]
     ) -> dict[str, str]:
         """Creates urls to api/datasources/{datasource_id}/catalog/namespaces
            that are later used to fetch all namespaces from a specified
            datasource
 
         Args:
             connection (Connection): Object representation of MSTR Connection.
@@ -500,25 +518,27 @@
                 representing connected datasource instances.
 
         Returns:
             dict[str, str]: a dictionary with datasource id as a key,
                 and matching namespaces url as a value
         """
         return {
-            connected_datasource_instance.get("id"):
-            (f"{connection.base_url}/api/datasources/{connected_datasource_instance.get('id')}"
-             f"/catalog/namespaces")
+            connected_datasource_instance.get("id"): (
+                f"{connection.base_url}/api/datasources/"
+                f"{connected_datasource_instance.get('id')}"
+                f"/catalog/namespaces"
+            )
             for connected_datasource_instance in connected_datasource_instances
         }
 
     @staticmethod
     def _get_namespaces_futures(
         connection: "Connection",
         session: FuturesSessionWithRenewal,
-        urls: dict[str, str]
+        urls: dict[str, str],
     ) -> list[Future]:
         """Creates Future objects using specified FuturesSession object for each
            url.
 
         Args:
             connection (Connection): Object representation of MSTR Connection.
             session (FuturesSession): A FuturesSession object used to fetch
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/transformation/transformation.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/transformation/transformation.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,11 @@
+import logging
 from dataclasses import dataclass
 from enum import auto
-import logging
+from functools import partial
 from typing import Optional
 
 from mstrio import config
 from mstrio.api import objects, transformations
 from mstrio.connection import Connection
 from mstrio.modeling.expression import Expression, ExpressionFormat
 from mstrio.modeling.schema import SchemaObjectReference
@@ -12,18 +13,18 @@
 from mstrio.object_management import search_operations
 from mstrio.object_management.folder import Folder
 from mstrio.object_management.search_enums import SearchPattern
 from mstrio.types import ObjectTypes
 from mstrio.utils.entity import DeleteMixin, Entity, MoveMixin
 from mstrio.utils.enum_helper import AutoName, get_enum_val
 from mstrio.utils.helper import (
-    delete_none_values,
     Dictable,
+    delete_none_values,
     filter_params_for_func,
-    get_valid_project_id
+    get_valid_project_id,
 )
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 logger = logging.getLogger(__name__)
 
 
 @method_version_handler('11.3.0500')
@@ -32,15 +33,15 @@
     name: Optional[str] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     search_pattern: SearchPattern | int = SearchPattern.CONTAINS,
     show_expression_as: ExpressionFormat | str = ExpressionFormat.TREE,
-    **filters
+    **filters,
 ) -> list["Transformation"] | list[dict]:
     """Get list of Transformation objects or dicts with them.
 
     Optionally use `to_dictionary` to choose output format.
     Optionally filter transformations by specifying 'name'.
 
     Wildcards available for 'name':
@@ -74,20 +75,23 @@
             should be presented
             Available values:
                 - `ExpressionFormat.TREE` or `tree` (default)
                 - `ExpressionFormat.TOKENS or `tokens`
         **filters: Available filter parameters:
             id str: Transformation's ID
             name str: Transformation's name
+            description str: Transformation's description
             date_created str: format: 2001-01-02T20:48:05.000+0000
             date_modified str: format: 2001-01-02T20:48:05.000+0000
             version str: Transformation's version
             owner dict: e.g. {'id': <user's id>, 'name': <user's name>},
                 with one or both of the keys: id, name
             acg str | int: access control group
+            subtype str: object's subtype
+            ext_type str: object's extended type
 
     Returns:
         list with Transformation objects or list of dictionaries
     """
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
@@ -98,33 +102,35 @@
     objects_ = search_operations.full_search(
         connection,
         object_types=Transformation._OBJECT_TYPE,
         project=project_id,
         name=name,
         pattern=search_pattern,
         limit=limit,
-        **filters
+        **filters,
     )
     if to_dictionary:
         return objects_
     else:
-        show_expression_as = show_expression_as if isinstance(
-            show_expression_as, ExpressionFormat
-        ) else ExpressionFormat(show_expression_as)
+        show_expression_as = (
+            show_expression_as
+            if isinstance(show_expression_as, ExpressionFormat)
+            else ExpressionFormat(show_expression_as)
+        )
         return [
             Transformation.from_dict(
-                {
-                    **obj_, 'show_expression_as': show_expression_as
-                }, connection
-            ) for obj_ in objects_
+                {**obj_, 'show_expression_as': show_expression_as}, connection
+            )
+            for obj_ in objects_
         ]
 
 
 class MappingType(AutoName):
     """Enumeration constants used to specify mapping type"""
+
     ONE_TO_ONE = auto()
     MANY_TO_MANY = auto()
 
 
 @class_version_handler('11.3.0500')
 class Transformation(Entity, MoveMixin, DeleteMixin):
     """Python representation of MicroStrategy Transformation object.
@@ -146,46 +152,65 @@
         primary_locale: The primary locale of the object, in the IETF BCP 47
             language tag format, such as "en-US".If no particular locale is set
             as the primary locale (for example, if the project is not
             internationalized), the field will be omitted.
         acg: access rights (See EnumDSSXMLAccessRightFlags for possible values)
         acl: object access control list
     """
+
     _OBJECT_TYPE = ObjectTypes.ROLE
     _API_GETTERS = {
         (
             'id',
             'sub_type',
             'name',
             'description',
             'date_created',
             'date_modified',
             'primary_locale',
             'mapping_type',
             'attributes',
-            'is_embedded'
+            'is_embedded',
         ): transformations.get_transformation,
-        ('type', 'subtype', 'version', 'owner', 'acg', 'acl', 'ext_type'): objects.get_object_info
+        (
+            'type',
+            'subtype',
+            'version',
+            'owner',
+            'acg',
+            'acl',
+            'ext_type',
+        ): objects.get_object_info,
     }
     _API_PATCH = {
-        ('name', 'description', 'mapping_type', 'attributes',
-         'destination_folder_id'): (transformations.update_transformation, 'partial_put'),
+        (
+            'name',
+            'description',
+            'mapping_type',
+            'attributes',
+            'destination_folder_id',
+        ): (transformations.update_transformation, 'partial_put'),
     }
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         "attributes": (
-            lambda source,
-            connection:
-            [TransformationAttribute.from_dict(content, connection) for content in source]
+            lambda source, connection: [
+                TransformationAttribute.from_dict(content, connection)
+                for content in source
+            ]
         ),
         "mapping_type": MappingType,
     }
 
     def __init__(
-        self, connection: Connection, id=None, name=None, show_expression_as=ExpressionFormat.TREE
+        self,
+        connection: Connection,
+        id=None,
+        name=None,
+        show_expression_as=ExpressionFormat.TREE,
     ):
         """Initializes a new instance of Transformation class
 
         Args:
             connection (Connection): MicroStrategy connection object returned
                 by `connection.Connection()`
             id (str, optional): Transformation's ID. Defaults to None.
@@ -200,48 +225,61 @@
 
         Raises:
             AttributeError: if both `id` and `name` are not provided.
             ValueError: if Transformation with the given `name` doesn't exist.
         """
         if id is None:
             transformation = super()._find_object_with_name(
-                connection=connection, name=name, listing_function=list_transformations
+                connection=connection,
+                name=name,
+                listing_function=partial(
+                    list_transformations, search_pattern=SearchPattern.EXACTLY
+                ),
             )
             id = transformation['id']
         super().__init__(
-            connection=connection, object_id=id, name=name, show_expression_as=show_expression_as
+            connection=connection,
+            object_id=id,
+            name=name,
+            show_expression_as=show_expression_as,
         )
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self._sub_type = kwargs.get('sub_type')
         self._is_embedded = kwargs.get('is_embedded')
-        self._attributes = [
-            TransformationAttribute.from_dict(attr, self._connection)
-            for attr in kwargs.get('attributes')
-        ] if kwargs.get('attributes') else None
+        self._attributes = (
+            [
+                TransformationAttribute.from_dict(attr, self._connection)
+                for attr in kwargs.get('attributes')
+            ]
+            if kwargs.get('attributes')
+            else None
+        )
         self._mapping_type = kwargs.get('mapping_type')
         self._version_id = kwargs.get('version_id')
         self._primary_locale = kwargs.get('primary_locale')
         show_expression_as = kwargs.get('show_expression_as', 'tree')
-        self._show_expression_as = show_expression_as if isinstance(
-            show_expression_as, ExpressionFormat
-        ) else ExpressionFormat(show_expression_as)
+        self._show_expression_as = (
+            show_expression_as
+            if isinstance(show_expression_as, ExpressionFormat)
+            else ExpressionFormat(show_expression_as)
+        )
 
     def list_properties(self):
         properties = super().list_properties()
         redundant_keys = [
             'hidden',
             'icon_path',
             'comments',
             'certified_info',
             'project_id',
             'target_info',
             'view_media',
-            'abbreviation'
+            'abbreviation',
         ]
         [properties.pop(key, None) for key in redundant_keys]
         return properties
 
     @classmethod
     @method_version_handler('11.3.0500')
     def create(
@@ -250,15 +288,15 @@
         sub_type: ObjectSubType | str,
         name: str,
         destination_folder: Folder | str,
         attributes: list,
         mapping_type: MappingType | str,
         is_embedded: bool = False,
         description: Optional[str] = None,
-        show_expression_as: ExpressionFormat | str = ExpressionFormat.TREE
+        show_expression_as: ExpressionFormat | str = ExpressionFormat.TREE,
     ) -> 'Transformation':
         """Create Transformation object.
 
         Args:
             connection: MicroStrategy connection object returned
                 by `connection.Connection()`
             sub_type: transformation's sub_type
@@ -285,44 +323,44 @@
         """
         body = {
             'information': {
                 'subType': get_enum_val(sub_type, ObjectSubType),
                 'name': name,
                 'isEmbedded': is_embedded,
                 'description': description,
-                'destinationFolderId': destination_folder
+                'destinationFolderId': destination_folder,
             },
             'attributes': [attribute.to_dict() for attribute in attributes],
-            'mappingType': mapping_type
+            'mappingType': mapping_type,
         }
         body = delete_none_values(body, recursion=True)
         response = transformations.create_transformation(
             connection=connection,
             body=body,
-            show_expression_as=get_enum_val(show_expression_as, ExpressionFormat)
+            show_expression_as=get_enum_val(show_expression_as, ExpressionFormat),
         ).json()
 
         if config.verbose:
             logger.info(
-                f"Successfully created transformation named: '{name}' with ID: '{response['id']}'"
+                f"Successfully created transformation named: '{name}' with ID: '"
+                f"{response['id']}'"
             )
 
         return cls.from_dict(
-            source={
-                **response, 'show_expression_as': show_expression_as
-            }, connection=connection
+            source={**response, 'show_expression_as': show_expression_as},
+            connection=connection,
         )
 
     def alter(
         self,
         name: Optional[str] = None,
         destination_folder_id: Optional[Folder | str] = None,
         attributes: Optional[list] = None,
         mapping_type: Optional[MappingType] = None,
-        description: Optional[str] = None
+        description: Optional[str] = None,
     ):
         """Alter transformation properties.
 
         Args:
             name: transformation's name
             destination_folder_id: A globally unique identifier used to
                 distinguish between metadata objects within the same project.
@@ -404,15 +442,15 @@
         base_attribute: Object that specifies the base attribute of the
             transformation attribute.
         forms: Object that specifies the transformation attribute form.
     """
 
     _FROM_DICT_MAP = {
         "base_attribute": SchemaObjectReference,
-        "forms": ([TransformationAttributeForm.from_dict])
+        "forms": ([TransformationAttributeForm.from_dict]),
     }
 
     id: str
     base_attribute: SchemaObjectReference
     forms: list[TransformationAttributeForm]
 
     def list_properties(self, camel_case=True) -> dict:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/schema/user_hierarchy/user_hierarchy.py` & `mstrio-py-11.3.9.103/mstrio/modeling/schema/user_hierarchy/user_hierarchy.py`

 * *Files 9% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 from mstrio.utils.enum_helper import AutoName
 from mstrio.utils.helper import (
     delete_none_values,
     Dictable,
     fetch_objects,
     get_args_from_func,
     get_default_args_from_func,
-    get_enum_val
+    get_enum_val,
 )
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
 logger = logging.getLogger(__name__)
@@ -46,16 +46,15 @@
     Args:
         connection: MicroStrategy connection object returned by
             `connection.Connection()`
         to_dictionary: If True returns dict, by default (False) returns
             User Hierarchy objects.
         limit: limit the number of elements returned. If `None` (default), all
             objects are returned.
-        **filters: Available filter parameters: ['id', 'name', 'description',
-            'date_created', 'date_modified', 'acg']
+        **filters: Available filter parameters: ['id', 'name', 'sub_type']
 
     Examples:
         >>> list_user_hierarchies(connection, name='hierarchy_name')
     """
     return UserHierarchy._list_user_hierarchies(
         connection=connection,
         to_dictionary=to_dictionary,
@@ -76,36 +75,44 @@
         filters: the list of filters defined on this hierarchy attribute
         limit: the element display limit when element_display_option
             is limited_elements
     """
 
     _FROM_DICT_MAP = {
         'element_display_option': ElementDisplayOption,
-        'filters': [SchemaObjectReference.from_dict]
+        'filters': [SchemaObjectReference.from_dict],
     }
 
     def __init__(
         self,
         object_id: str,
         entry_point: bool,
         name: str,
         element_display_option: Union[ElementDisplayOption, str],
         filters: Union[List[SchemaObjectReference], List[dict]] = None,
-        limit: Optional[int] = None
+        limit: Optional[int] = None,
     ):
         self.object_id = object_id
         self.entry_point = entry_point
         self.name = name
-        self.element_display_option = element_display_option if isinstance(
-            element_display_option, ElementDisplayOption
-        ) else ElementDisplayOption(element_display_option)
-        self.filters = [
-            SchemaObjectReference.from_dict(obj_ref)
-            if not isinstance(obj_ref, SchemaObjectReference) else object_id for obj_ref in filters
-        ] if filters else None
+        self.element_display_option = (
+            element_display_option
+            if isinstance(element_display_option, ElementDisplayOption)
+            else ElementDisplayOption(element_display_option)
+        )
+        self.filters = (
+            [
+                SchemaObjectReference.from_dict(obj_ref)
+                if not isinstance(obj_ref, SchemaObjectReference)
+                else object_id
+                for obj_ref in filters
+            ]
+            if filters
+            else None
+        )
         self.limit = limit
 
     def __eq__(self, other):
         if isinstance(self, dict):
             self = HierarchyAttribute.from_dict(self)
         if isinstance(other, dict):
             other = HierarchyAttribute.from_dict(other)
@@ -122,26 +129,33 @@
             SchemaObjectReference object
         child: an information about an object representing a
             child in a current hierarchy relationship,
             SchemaObjectReference object
     """
 
     _FROM_DICT_MAP = {
-        'parent': SchemaObjectReference.from_dict, 'child': SchemaObjectReference.from_dict
+        'parent': SchemaObjectReference.from_dict,
+        'child': SchemaObjectReference.from_dict,
     }
 
     def __init__(
         self,
         parent: Union[SchemaObjectReference, dict],
-        child: Union[SchemaObjectReference, dict]
+        child: Union[SchemaObjectReference, dict],
     ):
-        self.parent = parent if isinstance(parent, SchemaObjectReference
-                                           ) else SchemaObjectReference.from_dict(parent)
-        self.child = child if isinstance(child, SchemaObjectReference
-                                         ) else SchemaObjectReference.from_dict(child)
+        self.parent = (
+            parent
+            if isinstance(parent, SchemaObjectReference)
+            else SchemaObjectReference.from_dict(parent)
+        )
+        self.child = (
+            child
+            if isinstance(child, SchemaObjectReference)
+            else SchemaObjectReference.from_dict(child)
+        )
 
     def __eq__(self, other):
         if isinstance(self, dict):
             self = HierarchyRelationship.from_dict(self)
         if isinstance(other, dict):
             other = HierarchyRelationship.from_dict(other)
         return self.parent == other.parent and self.child == other.child
@@ -188,28 +202,28 @@
 
     _OBJECT_TYPE = ObjectTypes.DIMENSION
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'owner': User.from_dict,
         'sub_type': UserHierarchySubType,
         'attributes': [HierarchyAttribute.from_dict],
-        'relationships': [HierarchyRelationship.from_dict]
+        'relationships': [HierarchyRelationship.from_dict],
     }
     _API_GETTERS = {
         (
             'type',
             'subtype',
             'ext_type',
             'date_created',
             'date_modified',
             'version',
             'owner',
             'ancestors',
             'acg',
-            'acl'
+            'acl',
         ): objects.get_object_info,
         (
             'id',
             'name',
             'description',
             'sub_type',
             'date_created',
@@ -217,29 +231,29 @@
             'path',
             'version_id',
             'use_as_drill_hierarchy',
             'is_embedded',
             'primary_locale',
             'attributes',
             'relationships',
-            'destination_folder_id'
-        ): user_hierarchies.get_user_hierarchy
+            'destination_folder_id',
+        ): user_hierarchies.get_user_hierarchy,
     }
     _API_PATCH: dict = {
         (
             'name',
             'description',
             'relationships',
             'use_as_drill_hierarchy',
             'destination_folder_id',
             'sub_type',
             'is_embedded',
-            'attributes'
+            'attributes',
         ): (user_hierarchies.update_user_hierarchy, "put"),
-        ('folder_id'): (objects.update_object, 'partial_put')
+        ('folder_id'): (objects.update_object, 'partial_put'),
     }
     _API_DELETE = staticmethod(user_hierarchies.delete_user_hierarchy)
     _PATCH_PATH_TYPES = {
         'name': str,
         'description': str,
         'sub_type': str,
         'use_as_drill_hierarchy': bool,
@@ -249,47 +263,68 @@
         'relationships': list,
     }
     _REST_ATTR_MAP = {
         "object_id": "id",
     }
 
     def __init__(
-        self, connection: "Connection", id: Optional[str] = None, name: Optional[str] = None
+        self,
+        connection: "Connection",
+        id: Optional[str] = None,
+        name: Optional[str] = None,
     ):
         """Initialize user hierarchy object by its identifier.
 
         Note:
             Parameter `name` is not used when fetching. If only `name` parameter
             is provided, `id` will be found automatically if such object exists.
 
         Args:
 
         """
         if id is None:
-            object_info, object_info["connection"] = super()._find_object_with_name(
-                connection=connection, name=name,
-                listing_function=list_user_hierarchies), connection
+            object_info, object_info["connection"] = (
+                super()._find_object_with_name(
+                    connection=connection,
+                    name=name,
+                    listing_function=list_user_hierarchies,
+                ),
+                connection,
+            )
             self._init_variables(**object_info)
         else:
             super().__init__(connection, id)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
-        self.sub_type = UserHierarchySubType(kwargs.get('sub_type')
-                                             ) if kwargs.get('sub_type') else None
+        self.sub_type = (
+            UserHierarchySubType(kwargs.get('sub_type'))
+            if kwargs.get('sub_type')
+            else None
+        )
         self.primary_locale = kwargs.get('primary_locale')
         self.is_embedded = kwargs.get('is_embedded')
         self.destination_folder_id = kwargs.get('destination_folder_id')
         self.use_as_drill_hierarchy = kwargs.get('use_as_drill_hierarchy')
-        self.attributes = [
-            HierarchyAttribute.from_dict(source=attr) for attr in kwargs.get("attributes")
-        ] if kwargs.get('attributes') else None
-        self.relationships = [
-            HierarchyRelationship.from_dict(source=rel) for rel in kwargs.get("relationships")
-        ] if kwargs.get('attributes') else None
+        self.attributes = (
+            [
+                HierarchyAttribute.from_dict(source=attr)
+                for attr in kwargs.get("attributes")
+            ]
+            if kwargs.get('attributes')
+            else None
+        )
+        self.relationships = (
+            [
+                HierarchyRelationship.from_dict(source=rel)
+                for rel in kwargs.get("relationships")
+            ]
+            if kwargs.get('attributes')
+            else None
+        )
         self._path = kwargs.get('path')
         self._version_id = kwargs.get('version_id')
 
     @classmethod
     def create(
         cls,
         connection: "Connection",
@@ -297,15 +332,15 @@
         sub_type: Union[str, UserHierarchySubType],
         destination_folder_id: str,
         attributes: Union[List[HierarchyAttribute], List[dict]],
         use_as_drill_hierarchy: bool = True,
         description: str = None,
         is_embedded: bool = False,
         primary_locale: str = None,
-        relationships: Union[List[HierarchyRelationship], List[dict]] = None
+        relationships: Union[List[HierarchyRelationship], List[dict]] = None,
     ):
         """Create a new user hierarchy in a specific project.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             name (str): name of a new user hierarchy.
@@ -325,33 +360,38 @@
                 in the IETF BCP 47 language tag format, such as "en-US"
             relationships (list, optional): the list of attribute
                 relationships stored in the system hierarchy
         Returns:
             UserHierarchy object
         """
         attributes = [
-            attr.to_dict() if isinstance(attr, HierarchyAttribute) else attr for attr in attributes
+            attr.to_dict() if isinstance(attr, HierarchyAttribute) else attr
+            for attr in attributes
         ]
-        relationships = [
-            rel.to_dict() if isinstance(rel, HierarchyRelationship) else rel
-            for rel in relationships
-        ] if relationships else None
+        relationships = (
+            [
+                rel.to_dict() if isinstance(rel, HierarchyRelationship) else rel
+                for rel in relationships
+            ]
+            if relationships
+            else None
+        )
         body = {
             "information": {
                 "name": name,
                 "description": description,
                 "subType": get_enum_val(sub_type, UserHierarchySubType),
                 "destinationFolderId": destination_folder_id,
                 "isEmbedded": is_embedded,
-                "primaryLocale": primary_locale
+                "primaryLocale": primary_locale,
             },
             "useAsDrillHierarchy": use_as_drill_hierarchy,
             "primaryLocale": primary_locale,
             "attributes": attributes,
-            "relationships": relationships
+            "relationships": relationships,
         }
         body = delete_none_values(body, recursion=True)
         response = user_hierarchies.create_user_hierarchy(connection, body).json()
         if config.verbose:
             logger.info(
                 f"Successfully created user hierarchy named: '{response['name']}' "
                 f"with ID: '{response['id']}'"
@@ -363,15 +403,15 @@
         name: str = None,
         sub_type: Union[str, UserHierarchySubType] = None,
         attributes: Union[List[HierarchyAttribute], List[dict], None] = None,
         use_as_drill_hierarchy: Optional[bool] = None,
         description: Optional[str] = None,
         is_embedded: bool = False,
         destination_folder_id: Optional[str] = None,
-        relationships: Union[List[HierarchyRelationship], List[dict], None] = None
+        relationships: Union[List[HierarchyRelationship], List[dict], None] = None,
     ):
         """Alter the user hierarchies properties.
 
         Args:
             name (str, optional): name of a user hierarchy
             sub_type (str, enum, optional):  string literal used to identify
                 the type of a metadata object, UserHierarchySubType enum
@@ -386,15 +426,15 @@
                 used to distinguish between objects within the same project
             relationships (list, optional): the list of attribute
                 relationships stored in the system hierarchy
         """
         func = self.alter
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
         self._alter_properties(**properties)
 
@@ -429,27 +469,33 @@
     def remove_relationship(self, relationship: Union[HierarchyRelationship, dict]):
         """Remove relationship from an existing user hierarchy.
 
         Args:
             relationship: (HierarchyRelationship, dict): a relationship
                 to be removed from the hierarchy
         """
-        relationships = [rel.to_dict() for rel in self.relationships if rel != relationship]
+        relationships = [
+            rel.to_dict() for rel in self.relationships if rel != relationship
+        ]
         body = self.to_dict()
         body['relationships'] = relationships
         response = user_hierarchies.update_user_hierarchy(
             connection=self.connection, id=self.id, body=body
         )
         if response.ok:
             response = response.json()
             self._set_object_attributes(**response)
 
     @classmethod
     def _list_user_hierarchies(
-        cls, connection: "Connection", to_dictionary: bool = False, limit: int = None, **filters
+        cls,
+        connection: "Connection",
+        to_dictionary: bool = False,
+        limit: int = None,
+        **filters,
     ) -> Union[List["UserHierarchy"], List[dict]]:
         objects = fetch_objects(
             connection=connection,
             api=user_hierarchies.get_user_hierarchies,
             dict_unpack_value="hierarchies",
             limit=limit,
             filters=filters,
```

### Comparing `mstrio-py-11.3.9.101/mstrio/modeling/security_filter/security_filter.py` & `mstrio-py-11.3.9.103/mstrio/modeling/security_filter/security_filter.py`

 * *Files 3% similar despite different names*

```diff
@@ -5,32 +5,37 @@
 from mstrio import config
 from mstrio.api import objects, security_filters
 from mstrio.modeling import ExpressionFormat
 from mstrio.modeling.schema import ObjectSubType, SchemaObjectReference
 from mstrio.object_management.folder import Folder
 from mstrio.types import ObjectTypes
 from mstrio.users_and_groups import User, UserGroup
-from mstrio.utils.entity import CopyMixin, DeleteMixin, Entity, MoveMixin, ObjectSubTypes
+from mstrio.utils.entity import (
+    CopyMixin,
+    DeleteMixin,
+    Entity,
+    MoveMixin,
+    ObjectSubTypes,
+)
 from mstrio.utils.enum_helper import get_enum_val
 from mstrio.utils.helper import (
     delete_none_values,
     exception_handler,
     fetch_objects,
     filter_params_for_func,
     get_valid_project_id,
-    get_valid_project_name
+    get_valid_project_name,
 )
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 from mstrio.modeling.expression import Expression  # isort:skip
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
-
 logger = logging.getLogger(__name__)
 
 
 @method_version_handler('11.3.0200')
 def list_security_filters(
     connection: "Connection",
     name_contains: Optional[str] = None,
@@ -87,16 +92,15 @@
             formats are returned.
             - If true, all `text`, `tree` and `tokens` formats are returned.
         user (str or object, optional): Id of user or `User` object used to
             filter security filters
         user_group (str or object, optional): Id of user group or `UserGroup`
             object used to filter security filters
         **filters: Available filter parameters: ['id', 'name', 'description',
-            'type', 'subtype', 'date_created', 'date_modified', 'version',
-            'acg', 'icon_path', 'owner']
+            'date_created', 'date_modified', 'total_users', 'total_user_groups']
     Returns:
         list of security filter objects or list of security filter dictionaries.
     """
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
         project_name=project_name,
@@ -104,32 +108,35 @@
     )
     project_name = get_valid_project_name(
         connection=connection,
         project_id=project_id,
     )
     if user and user_group:
         exception_handler(
-            "You cannot filter by both `user` and `user_group` at the same time.")
+            "You cannot filter by both `user` and `user_group` at the same time."
+        )
 
     if user:
         user = User(connection, id=user) if isinstance(user, str) else user
         # Filter security filters by user for project defined by
         # `project_name` - assigned based on valid `project_id`
-        objects = user.list_security_filters(
-            project_id, to_dictionary=True
-        ).get(project_name, [])
+        objects = user.list_security_filters(project_id, to_dictionary=True).get(
+            project_name, []
+        )
     elif user_group:
-        user_group = UserGroup(
-            connection, id=user_group
-        ) if isinstance(user_group, str) else user_group
+        user_group = (
+            UserGroup(connection, id=user_group)
+            if isinstance(user_group, str)
+            else user_group
+        )
         # filter security filters by the user group for project defined by
         # `project_name` - assigned based on valid `project_id`
-        objects = user_group.list_security_filters(
-            project_id, to_dictionary=True
-        ).get(project_name, [])
+        objects = user_group.list_security_filters(project_id, to_dictionary=True).get(
+            project_name, []
+        )
     else:
         objects = fetch_objects(
             connection=connection,
             project_id=project_id,
             api=security_filters.get_security_filters,
             limit=limit,
             offset=offset,
@@ -202,26 +209,55 @@
         'owner': User.from_dict,
         'sub_type': ObjectSubType,
         'qualification': Expression.from_dict,
         'top_level': [SchemaObjectReference.from_dict],
         'bottom_level': [SchemaObjectReference.from_dict],
     }
     _API_GETTERS = {
-        ('type', 'subtype', 'ext_type', 'date_created', 'date_modified', 'version', 'owner',
-         'ancestors', 'acg', 'acl'): objects.get_object_info,
-        ('id', 'name', 'description', 'sub_type', 'date_created', 'date_modified', 'path',
-         'version_id', 'is_embedded', 'primary_locale', 'qualification', 'destination_folder_id',
-         'top_level', 'bottom_level'): security_filters.get_security_filter,
+        (
+            'type',
+            'subtype',
+            'ext_type',
+            'date_created',
+            'date_modified',
+            'version',
+            'owner',
+            'ancestors',
+            'acg',
+            'acl',
+        ): objects.get_object_info,
+        (
+            'id',
+            'name',
+            'description',
+            'sub_type',
+            'date_created',
+            'date_modified',
+            'path',
+            'version_id',
+            'is_embedded',
+            'primary_locale',
+            'qualification',
+            'destination_folder_id',
+            'top_level',
+            'bottom_level',
+        ): security_filters.get_security_filter,
         ('users',): security_filters.get_security_filter_members,
     }
     _API_PATCH: dict = {
-        ('name', 'description', 'qualification', 'destination_folder_id', 'is_embedded',
-         'top_level', 'bottom_level'):
-        (security_filters.update_security_filter, "put"),
-        ('folder_id',): (objects.update_object, 'partial_put')
+        (
+            'name',
+            'description',
+            'qualification',
+            'destination_folder_id',
+            'is_embedded',
+            'top_level',
+            'bottom_level',
+        ): (security_filters.update_security_filter, "put"),
+        ('folder_id',): (objects.update_object, 'partial_put'),
     }
     _PATCH_PATH_TYPES = {
         'name': str,
         'description': str,
         'destination_folder_id': str,
         'qualification': dict,
         'is_embedded': bool,
@@ -270,30 +306,48 @@
         )
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self.primary_locale = kwargs.get('primary_locale')
         self.is_embedded = kwargs.get('is_embedded')
         self.destination_folder_id = kwargs.get('destination_folder_id')
-        self.qualification = Expression.from_dict(
-            kwargs.get('qualification'), self.connection) if kwargs.get('qualification') else None
-        self._sub_type = ObjectSubType(kwargs.get('sub_type')) if kwargs.get('sub_type') else None
+        self.qualification = (
+            Expression.from_dict(kwargs.get('qualification'), self.connection)
+            if kwargs.get('qualification')
+            else None
+        )
+        self._sub_type = (
+            ObjectSubType(kwargs.get('sub_type')) if kwargs.get('sub_type') else None
+        )
         self._path = kwargs.get('path')
         show_expression_as = kwargs.get('show_expression_as', 'tree')
-        self.show_expression_as = show_expression_as if isinstance(
-            show_expression_as, ExpressionFormat) else ExpressionFormat(show_expression_as)
+        self.show_expression_as = (
+            show_expression_as
+            if isinstance(show_expression_as, ExpressionFormat)
+            else ExpressionFormat(show_expression_as)
+        )
         self.show_filter_tokens = kwargs.get('show_filter_tokens', False)
         top_level = kwargs.get('top_level')
-        self.top_level = [
-            SchemaObjectReference.from_dict(level, self.connection) for level in top_level
-        ] if top_level else None
+        self.top_level = (
+            [
+                SchemaObjectReference.from_dict(level, self.connection)
+                for level in top_level
+            ]
+            if top_level
+            else None
+        )
         bottom_level = kwargs.get('bottom_level')
-        self.bottom_level = [
-            SchemaObjectReference.from_dict(level, self.connection) for level in bottom_level
-        ] if bottom_level else None
+        self.bottom_level = (
+            [
+                SchemaObjectReference.from_dict(level, self.connection)
+                for level in bottom_level
+            ]
+            if bottom_level
+            else None
+        )
         self.users = None
         self._members = kwargs.get("members")
 
     @classmethod
     def create(
         cls,
         connection: "Connection",
@@ -355,41 +409,43 @@
                 "description": description,
                 "destinationFolderId": destination_folder.id
                 if isinstance(destination_folder, Folder)
                 else destination_folder,
                 "primaryLocale": primary_locale,
                 "isEmbedded": is_embedded,
             },
-            "topLevel": [
-                SchemaObjectReference.to_dict(level) for
-                level in top_level
-            ] if top_level and all(
-                [isinstance(level, SchemaObjectReference) for level in top_level]
-            ) else top_level,
+            "topLevel": [SchemaObjectReference.to_dict(level) for level in top_level]
+            if top_level
+            and all([isinstance(level, SchemaObjectReference) for level in top_level])
+            else top_level,
             "bottomLevel": [
-                SchemaObjectReference.to_dict(level) for
-                level in bottom_level
-            ] if bottom_level and all(
+                SchemaObjectReference.to_dict(level) for level in bottom_level
+            ]
+            if bottom_level
+            and all(
                 [isinstance(level, SchemaObjectReference) for level in bottom_level]
-            ) else bottom_level,
+            )
+            else bottom_level,
         }
         body = delete_none_values(body, recursion=True)
         body["qualification"] = (
-            qualification.to_dict() if isinstance(qualification, Expression)
+            qualification.to_dict()
+            if isinstance(qualification, Expression)
             else qualification
         )
         response = security_filters.create_security_filter(
             connection=connection,
             body=body,
             show_expression_as=get_enum_val(show_expression_as, ExpressionFormat),
             show_filter_tokens=show_filter_tokens,
         ).json()
         if config.verbose:
             logger.info(
-                f"Successfully created security filter named: '{name}' with ID: '{response['id']}'"
+                f"Successfully created security filter named: '{name}' with ID: '"
+                f"{response['id']}'"
             )
         return cls.from_dict(
             source={
                 **response,
                 'show_expression_as': show_expression_as,
                 'show_filter_tokens': show_filter_tokens,
             },
@@ -476,44 +532,43 @@
             List[User] | List[UserGroup] | List[str] | User | UserGroup | str
         ] = None,
     ):
         """Update members of security filter."""
         users_or_groups = self._retrieve_ids_from_list(users_and_groups)
         body = {
             "operationList": [
-                {
-                    "op": op.value,
-                    "path": "/members",
-                    "value": users_or_groups
-                }
+                {"op": op.value, "path": "/members", "value": users_or_groups}
             ]
         }
         res = security_filters.update_security_filter_members(
-            self.connection, self.id, body, self.connection.project_id, throw_error=False
+            self.connection,
+            self.id,
+            body,
+            self.connection.project_id,
+            throw_error=False,
         )
         if res.ok:
             self._get_members()
-            logger.info(f"Successfully updated members for security filter '{self.name}'")
+            logger.info(
+                f"Successfully updated members for security filter '{self.name}'"
+            )
         return res.ok
 
     @staticmethod
     def _retrieve_ids_from_list(
         objects: Optional[
             List[User] | List[UserGroup] | List[str] | User | UserGroup | str
         ] = None,
     ) -> List[str]:
         """Parsing a list which can contain at the same time User object(s),
         UserGroup object(s), id(s) to a list with id(s)."""
 
         objects = objects if isinstance(objects, list) else [objects]
 
-        return [
-            obj if isinstance(obj, str) else obj.id
-            for obj in objects
-        ]
+        return [obj if isinstance(obj, str) else obj.id for obj in objects]
 
     def _get_members(self):
         """Get the users and user groups that the specified security filter is
         applied to."""
         self._members = []
         self.fetch("users")
         for member in self.users:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/object_management/folder.py` & `mstrio-py-11.3.9.103/mstrio/object_management/folder.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,30 +6,30 @@
 from mstrio.object_management import PredefinedFolders
 from mstrio.types import ObjectTypes
 from mstrio.users_and_groups import User
 from mstrio.utils.entity import CopyMixin, DeleteMixin, Entity, MoveMixin
 from mstrio.utils.helper import (
     fetch_objects_async,
     get_default_args_from_func,
-    get_valid_project_id
+    get_valid_project_id,
 )
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
 logger = logging.getLogger(__name__)
 
 
 def list_folders(
     connection: "Connection",
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> list["Folder"] | list[dict]:
     """Get a list of folders - either all folders in a specific project or all
     folders that are outside of projects, called configuration-level folders.
     The list of configuration-level folders includes folders such as users, user
     groups, databases, etc. which are not project-specific. If you pass
     a `project_id` or `project_name`, you get folders in that project;
     if not, then you get configuration-level folders.
@@ -46,16 +46,18 @@
             `connection.Connection()`
         project_id (string, optional): project ID
         project_name (string, optional): project name
         to_dictionary (bool, optional): If True returns dicts, by default
             (False) returns objects.
         limit (int): limit the number of elements returned. If `None` (default),
             all objects are returned.
-        **filters: Available filter parameters: ['id', 'name', 'description',
-            'date_created', 'date_modified', 'acg']
+        **filters: Available filter parameters: ['name', 'id', 'type',
+            'subtype', 'date_created', 'date_modified', 'version', 'acg',
+             'owner', 'hidden',
+          'ext_type']
 
     Returns:
         list of `Folder` objects or list of dictionaries
     """
     # Project is validated only if project was specified in arguments -
     # otherwise fetch is performed from a non-project area.
     if project_id or project_name:
@@ -67,21 +69,22 @@
     objects = fetch_objects_async(
         connection,
         folders.list_folders,
         folders.list_folders_async,
         limit=limit,
         chunk_size=1000,
         project_id=project_id,
-        filters=filters
+        filters=filters,
     )
 
     if to_dictionary:
         return objects
     else:
         from mstrio.utils.object_mapping import map_objects_list
+
         return map_objects_list(connection, objects)
 
 
 def get_my_personal_objects_contents(
     connection: "Connection",
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
@@ -115,25 +118,26 @@
     )
 
     objects = folders.get_my_personal_objects_contents(connection, project_id).json()
     if to_dictionary:
         return objects
     else:
         from mstrio.utils.object_mapping import map_objects_list
+
         return map_objects_list(connection, objects)
 
 
 def get_predefined_folder_contents(
     connection: "Connection",
     folder_type: PredefinedFolders,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> list:
     """Get contents of a pre-defined MicroStrategy folder in a specific project.
     Available values for `folder_type` are stored in enum `PredefinedFolders`.
 
     Specify either `project_id` or `project_name`.
     When `project_id` is provided (not `None`), `project_name` is omitted.
 
@@ -174,21 +178,22 @@
         connection,
         folders.get_predefined_folder_contents,
         folders.get_predefined_folder_contents_async,
         limit=limit,
         chunk_size=1000,
         folder_type=folder_type.value,
         project_id=project_id,
-        filters=filters
+        filters=filters,
     )
 
     if to_dictionary:
         return objects
     else:
         from mstrio.utils.object_mapping import map_objects_list
+
         return map_objects_list(connection, objects)
 
 
 class Folder(Entity, CopyMixin, MoveMixin, DeleteMixin):
     """Object representation of MicroStrategy Folder object.
 
     Attributes:
@@ -214,20 +219,20 @@
         view_media: view media settings
         certified_info: CertifiedInfo object, certification status, time of
             certification, and information about the certifier (currently only
             for document and report)
         contents: contents of folder
     """
 
-    _FROM_DICT_MAP = {
-        **Entity._FROM_DICT_MAP,
-        'owner': User.from_dict
-    }
+    _FROM_DICT_MAP = {**Entity._FROM_DICT_MAP, 'owner': User.from_dict}
 
-    _API_PATCH: dict = {**Entity._API_PATCH, ('folder_id'): (objects.update_object, 'partial_put')}
+    _API_PATCH: dict = {
+        **Entity._API_PATCH,
+        ('folder_id'): (objects.update_object, 'partial_put'),
+    }
 
     _OBJECT_TYPE = ObjectTypes.FOLDER
     _SIZE_LIMIT = 10000000  # this sets desired chunk size in bytes
 
     def __init__(self, connection: "Connection", id: str, name: Optional[str] = None):
         """Initialize folder object by its identifier.
 
@@ -242,15 +247,19 @@
                 the required data.
             name (str): name of folder.
         """
         super().__init__(connection, id, name=name)
 
     @classmethod
     def create(
-        cls, connection: "Connection", name: str, parent: str, description: Optional[str] = None
+        cls,
+        connection: "Connection",
+        name: str,
+        parent: str,
+        description: Optional[str] = None,
     ) -> "Folder":
         """Create a new folder in a folder selected within connection object
         by providing its name, id of parent folder and optionally description.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
@@ -267,15 +276,17 @@
         if config.verbose:
             logger.info(
                 f"Successfully created folder named: '{response.get('name')}' "
                 f"with ID: '{response.get('id')}'"
             )
         return cls.from_dict(source=response, connection=connection)
 
-    def alter(self, name: Optional[str] = None, description: Optional[str] = None) -> None:
+    def alter(
+        self, name: Optional[str] = None, description: Optional[str] = None
+    ) -> None:
         """Alter the folder properties.
 
         Args:
             name: folder name
             description: folder description
         """
         func = self.alter
@@ -304,15 +315,16 @@
         objects = fetch_objects_async(
             self.connection,
             folders.get_folder_contents,
             folders.get_folder_contents_async,
             limit=None,
             chunk_size=1000,
             id=self.id,
-            filters=filters
+            filters=filters,
         )
 
         if to_dictionary:
             return objects
         else:
             from mstrio.utils.object_mapping import map_objects_list
+
             return map_objects_list(self.connection, objects)
```

### Comparing `mstrio-py-11.3.9.101/mstrio/object_management/migration/migration.py` & `mstrio-py-11.3.9.103/mstrio/object_management/migration/migration.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,19 +1,23 @@
-from enum import auto, Enum
 import logging
+from enum import Enum, auto
 from pathlib import Path
-from typing import Callable, List, Optional, Union
+from typing import Callable, Optional
 
 from mstrio import config
 from mstrio.api.exceptions import VersionException
 from mstrio.connection import Connection
-from mstrio.object_management.migration.package import Package, PackageConfig, PackageImport
+from mstrio.object_management.migration.package import (
+    Package,
+    PackageConfig,
+    PackageImport,
+)
 from mstrio.utils.helper import Dictable, exception_handler
 from mstrio.utils.progress_bar_mixin import ProgressBarMixin
-from mstrio.utils.wip import module_wip, WipLevels
+from mstrio.utils.wip import WipLevels, module_wip
 
 module_wip(globals(), level=WipLevels.PREVIEW)
 
 logger = logging.getLogger(__name__)
 
 
 class MigrationStatus(Enum):
@@ -72,23 +76,23 @@
         self,
         save_path: Optional[str] = f"{Path.cwd()}/migration.mmp",
         source_connection: Optional[Connection] = None,
         configuration: Optional[PackageConfig] = None,
         target_connection: Optional[Connection] = None,
         custom_package_path: Optional[str] = None,
         name: Optional[str] = None,
-        create_undo: bool = True
+        create_undo: bool = True,
     ):
         if not self._validate_envs_version(source_connection, target_connection):
             exception_handler(
                 msg=(
                     "Environments must run IServer version 11.3.0200 or newer. "
                     "Please update your environments to use this feature."
                 ),
-                exception_type=VersionException
+                exception_type=VersionException,
             )
         self.name = name
         self.source_connection = source_connection
         self.target_connection = target_connection
         self.configuration = configuration
         self.create_undo = create_undo
         self._status = MigrationStatus.NOT_STARTED
@@ -96,30 +100,34 @@
         self._check_file_path(save_path, "save_path")
         self.save_path = save_path
 
         self._package = None
         self._package_import = None
         self._undo_binary = None
 
-        if custom_package_path and self._check_file_path(custom_package_path,
-                                                         "custom_package_path"):
+        if custom_package_path and self._check_file_path(
+            custom_package_path, "custom_package_path"
+        ):
             self.save_path = custom_package_path
             filename, file_extension = self._decompose_file_path(custom_package_path)
             with open(f"{filename}{file_extension}", "rb") as f:
                 self._package_binary = f.read()
         else:
             self._package_binary = None
 
     @staticmethod
     def _validate_envs_version(
         source_connection: Connection, target_connection: Connection
     ) -> bool:
         return (
-            (source_connection is None or source_connection._iserver_version >= '11.3.0200')
-            and (target_connection is None or target_connection._iserver_version >= '11.3.0200')
+            source_connection is None
+            or source_connection._iserver_version >= '11.3.0200'
+        ) and (
+            target_connection is None
+            or target_connection._iserver_version >= '11.3.0200'
         )
 
     @staticmethod
     def _decompose_file_path(file_path: str) -> tuple:
         file_path = Path(file_path)
         filename, file_extension = file_path.parent / file_path.stem, file_path.suffix
         if file_extension == '':
@@ -130,44 +138,51 @@
     def _check_file_path(file_path: str, var_name: str):
         file_path = Path(file_path)
 
         if file_path.parent.is_dir() and not file_path.is_dir():
             return True
         else:
             exception_handler(
-                msg=f"Invalid save path. Parent directory specified in `{var_name}` is incorrect.",
-                exception_type=AttributeError
+                msg=f"Invalid save path. Parent directory specified in `{var_name}` is"
+                f" incorrect.",
+                exception_type=AttributeError,
             )
 
     def perform_full_migration(self) -> bool:
         """Perform 'create_package()' and 'migrate_package()' using
         configuration provided when creating `Migration` object.
         """
-        if not isinstance(self.source_connection, Connection) or self.source_connection is None:
+        if (
+            not isinstance(self.source_connection, Connection)
+            or self.source_connection is None
+        ):
             exception_handler(
                 msg=(
                     "Migration object missing `source_connection`. "
                     "`perform_full_migration()` unavailable."
                 ),
-                exception_type=AttributeError
+                exception_type=AttributeError,
             )
-        if not isinstance(self.target_connection, Connection) or self.target_connection is None:
+        if (
+            not isinstance(self.target_connection, Connection)
+            or self.target_connection is None
+        ):
             exception_handler(
                 msg=(
                     "Migration object missing `target_connection`. "
                     "`perform_full_migration()` unavailable."
                 ),
-                exception_type=AttributeError
+                exception_type=AttributeError,
             )
 
         self._display_progress_bar(
             desc='Migration status: ',
             unit='Migration',
             total=4,
-            bar_format='{desc} |{bar:50}| {percentage:3.0f}%'
+            bar_format='{desc} |{bar:50}| {percentage:3.0f}%',
         )
 
         if not self.create_package():
             return False
 
         if not self.migrate_package():
             return False
@@ -179,32 +194,40 @@
         """Performs import of the object described in the migration
         configuration from the source environment and save it in a file
         at location specified in `save_path` parameter.
 
         Raises AttributeError if `source_connection` is not specified.
 
         Raises FileExistsError if a package or undo package with the same name
-        already exist at`save_path` location. """
-        if not isinstance(self.source_connection, Connection) or self.source_connection is None:
+        already exist at`save_path` location."""
+        if (
+            not isinstance(self.source_connection, Connection)
+            or self.source_connection is None
+        ):
             exception_handler(
-                msg=("Migration object does not have `source_connection`. Import unavailable."),
-                exception_type=AttributeError
+                msg=(
+                    "Migration object does not have `source_connection`. Import "
+                    "unavailable."
+                ),
+                exception_type=AttributeError,
             )
 
         filename, file_extension = self._decompose_file_path(self.save_path)
         """File existence checked here instead of using "xb" mode in context
         manager to avoid creation of package if it should not be saved"""
-        if Path(f"{filename}{file_extension}").exists() or Path(f"{filename}_undo{file_extension}"
-                                                                ).exists():
+        if (
+            Path(f"{filename}{file_extension}").exists()
+            or Path(f"{filename}_undo{file_extension}").exists()
+        ):
             exception_handler(
                 msg=(
                     "Migration file / undo package with this name already exists."
                     "Please use other location / filename in `save_path` parameter."
                 ),
-                exception_type=FileExistsError
+                exception_type=FileExistsError,
             )
 
         self.__private_status = MigrationStatus.CREATING_PACKAGE
         self._create_package_holder(self.source_connection)
         if not self._update_package_holder():
             self.__private_status = MigrationStatus.CREATING_PACKAGE_FAILED
             return False
@@ -212,52 +235,65 @@
         self._download_package_binary()
         self._delete_package_holder()
         self._save_package_binary_locally(filename, file_extension, self.package_binary)
 
         self.__private_status = MigrationStatus.CREATING_PACKAGE_COMPLETED
         return True
 
-    def migrate_package(self, custom_package_path: Optional[str] = None, is_undo=False) -> bool:
+    def migrate_package(
+        self, custom_package_path: Optional[str] = None, is_undo=False
+    ) -> bool:
         """Performs migration of already created package to the target
         environment. Import package will be loaded from `custom_package_path`.
         If `custom_package_path` not provided, the object previously acquired
         with the `create_package()` will be used.
         If `create_undo` parameter is set to True, package needed for undo
         process will be downloaded.
 
         Raises AttributeError if `target_connection` is not specified.
         """
 
-        if not isinstance(self.target_connection, Connection) or self.target_connection is None:
+        if (
+            not isinstance(self.target_connection, Connection)
+            or self.target_connection is None
+        ):
             exception_handler(
-                msg=("Migration object does not have `target_connection`. "
-                     "Export unavailable."),
-                exception_type=AttributeError
+                msg=(
+                    "Migration object does not have `target_connection`. "
+                    "Export unavailable."
+                ),
+                exception_type=AttributeError,
             )
 
-        if custom_package_path and self._check_file_path(custom_package_path,
-                                                         "custom_package_path"):
+        if custom_package_path and self._check_file_path(
+            custom_package_path, "custom_package_path"
+        ):
             self.save_path = custom_package_path
             filename, file_extension = self._decompose_file_path(custom_package_path)
             with open(f"{filename}{file_extension}", "rb") as f:
                 return self._migrate_package(f.read(), is_undo=is_undo)
         return self._migrate_package(
-            self._package_binary, custom_package_path=custom_package_path, is_undo=is_undo
+            self._package_binary,
+            custom_package_path=custom_package_path,
+            is_undo=is_undo,
         )
 
     def _migrate_package(
-        self, binary: bytes, is_undo: bool = False, custom_package_path: Optional[str] = None
+        self,
+        binary: bytes,
+        is_undo: bool = False,
+        custom_package_path: Optional[str] = None,
     ) -> bool:
         if binary is None:
             exception_handler(
                 msg=(
                     "Import package is None. Run `create_package()` first, "
                     "or specify `custom_package_path`."
                 ),
-                exception_type=AttributeError
+                exception_type=AttributeError,
             )
 
         self.__private_status = MigrationStatus.MIGRATION_IN_PROGRESS
         self._create_package_holder(self.target_connection)
         self._upload_package_binary(binary)
         if not self._create_import(self.target_connection):
             self.__private_status = MigrationStatus.MIGRATION_FAILED
@@ -266,15 +302,15 @@
         if not is_undo and self.create_undo:
             self._download_undo_binary()
             file_path = custom_package_path if custom_package_path else self.save_path
             filename, file_extension = self._decompose_file_path(file_path)
             self._save_package_binary_locally(
                 filename=f"{filename}_undo",
                 file_extension=file_extension,
-                _bytes=self.undo_binary
+                _bytes=self.undo_binary,
             )
 
         self._delete_package_holder()
         self._delete_import()
 
         self.__private_status = MigrationStatus.MIGRATION_COMPLETED
         return True
@@ -294,52 +330,63 @@
                 '`undo_binary` is None. Perform migration with `create_undo`'
                 ' parameter set to True'
             )
             exception_handler(msg, exception_type=AttributeError)
         self.__private_status = MigrationStatus.UNDO_COMPLETED
 
     def _create_package_holder(self, conn: Connection):
-        self._package = Package.create(conn, progress_bar=self._progress_bar is not None)
+        self._package = Package.create(
+            conn, progress_bar=self._progress_bar is not None
+        )
 
     def _update_package_holder(self):
         return self._package.update_config(self.configuration)
 
     def _download_package_binary(self):
         self._package_binary = self._package.download_package_binary(
             progress_bar=self._progress_bar is not None
         )
 
     def _upload_package_binary(self, binary: bytes):
-        self._package.upload_package_binary(binary, progress_bar=self._progress_bar is not None)
+        self._package.upload_package_binary(
+            binary, progress_bar=self._progress_bar is not None
+        )
 
     def _delete_package_holder(self):
         self._package.delete(force=True)
         self._package = None
 
     def _create_import(self, conn: Connection) -> bool:
         self._package_import = PackageImport.create(
-            conn, self.package.id, self.create_undo, progress_bar=self._progress_bar is not None
+            conn,
+            self.package.id,
+            self.create_undo,
+            progress_bar=self._progress_bar is not None,
         )
         if self._package_import is False:
             return False
         return True
 
     def _delete_import(self):
         self._package_import.delete(force=True)
         self._package_import = None
 
     def _download_undo_binary(self):
         self._undo_binary = self._package_import.download_undo_binary(
             progress_bar=self._progress_bar is not None
         )
 
-    def _save_package_binary_locally(self, filename: str, file_extension: str, _bytes: bytes):
+    def _save_package_binary_locally(
+        self, filename: str, file_extension: str, _bytes: bytes
+    ):
         with open(f"{filename}{file_extension}", "wb") as f:
             f.write(_bytes)
-        logger.info(f'Package / package undo binary created at:{filename}{file_extension}')
+        logger.info(
+            f'Package / package undo binary created at:{filename}{file_extension}'
+        )
 
     @property
     def package(self):
         return self._package
 
     @property
     def package_binary(self):
@@ -359,42 +406,46 @@
 
     @property
     def __private_status(self):
         return self._status
 
     @__private_status.setter
     def __private_status(self, var: MigrationStatus):
-        self._update_progress_bar_if_needed(new_description=f'[{self.name}] Status: {var.name}')
+        self._update_progress_bar_if_needed(
+            new_description=f'[{self.name}] Status: {var.name}'
+        )
         self._status = var
 
 
-def bulk_full_migration(migrations: Union[Migration, List[Migration]], verbose: bool = False):
+def bulk_full_migration(migrations: Migration | list[Migration], verbose: bool = False):
     """Run `perform_full_migration()` for each of the migrations provided.
     Args:
         migrations: migrations to be executed
         verbose: if True, information about each step will be printed
     """
     __run_func_for_all_migrations(Migration.perform_full_migration, migrations, verbose)
 
 
-def bulk_migrate_package(migrations: Union[Migration, List[Migration]], verbose: bool = False):
+def bulk_migrate_package(
+    migrations: Migration | list[Migration], verbose: bool = False
+):
     """Run `migrate_package()` for each of the migrations provided.
     Args:
         migrations: migrations to be executed
         verbose: if True, information about each step will be printed
     """
     __run_func_for_all_migrations(Migration.migrate_package, migrations, verbose)
 
 
 def __run_func_for_all_migrations(
     func: Callable,
-    migrations: Union[Migration, List[Migration]],
+    migrations: Migration | list[Migration],
     verbose: bool = False,
     *args,
-    **kwargs
+    **kwargs,
 ):
     if type(migrations) is Migration:
         migrations = [migrations]
     original_verbose = config.verbose
     config.verbose = verbose
     for migration in migrations:
         func(migration, *args, **kwargs)
```

### Comparing `mstrio-py-11.3.9.101/mstrio/object_management/migration/package.py` & `mstrio-py-11.3.9.103/mstrio/object_management/migration/package.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-from enum import auto
 import logging
+from enum import auto
 from time import sleep
-from typing import Any, Dict, List, Optional, Union
+from typing import Optional
 
 from mstrio import config
 from mstrio.api import migration
 from mstrio.connection import Connection
 from mstrio.types import ObjectTypes
 from mstrio.users_and_groups.user import User
 from mstrio.utils import helper
 from mstrio.utils.entity import DeleteMixin, EntityBase
 from mstrio.utils.enum_helper import AutoName
 from mstrio.utils.helper import Dictable, exception_handler
-from mstrio.utils.wip import module_wip, WipLevels
+from mstrio.utils.wip import WipLevels, module_wip
 
 module_wip(globals(), level=WipLevels.PREVIEW)
 
 logger = logging.getLogger(__name__)
 
 TIMEOUT = 60
 TIMEOUT_INCREMENT = 0.25
@@ -40,34 +40,37 @@
         any changes to schema objects. Use the recalculate table keys and fact
         entry levels if you changed the key structure of a table or if you
         changed the level at which a fact is stored.Use the recalculate table
         logical sizes to override any modifications that you have made to
         logical table sizes. (Logical table sizes affect how the MicroStrategy
         SQL Engine determines which tables to use in a query.)
         """
+
         RECAL_TABLE_LOGICAL_SIZE = auto()
         RECAL_TABLE_KEYS_FACT_ENTRY_LEVEL = auto()
 
     class AclOnReplacingObjects(AutoName):
         """If you resolve a conflict with the "Replace" action, and the access
         control lists (ACL) of the objects are different between the two
         projects, you can choose whether to keep the existing ACL in the
         destination project or replace it with the ACL from the source project.
         Note: This is not supported for project security packages.
         """
+
         USE_EXISTING = auto()
         REPLACE = auto()
 
     class AclOnNewObjects(AutoName):
         """If you add a new object to the destination project with the
         "Create New" or "Keep Both action", you can choose to have the object
         inherit its ACL from the destination folder instead of keeping its own
         ACL. This is helpful when copying an object into a user's profile
         folder, so that the user can have full control over the object.
         """
+
         KEEP_ACL_AS_SOURCE_OBJECT = auto()
         INHERIT_ACL_AS_DEST_FOLDER = auto()
 
     class DefaultAction(AutoName):
         """The default action used for objects which don't have actions
         explicitly, for example the dependents objects.
         USE_EXISTING: No change is made to the destination object.
@@ -104,43 +107,50 @@
         DELETE: Delete the object from the destination project. The version
         of the object in the update package is not imported into the destination
         project.Warning: If the object in the destination has any used-by
         dependencies when you import the update package, the import will fail.
         FORCE_KEEP_BOTH: No change is made to the destination object. The source
         object is always saved as a new object.
         """
+
         USE_EXISTING = auto()
         REPLACE = auto()
         KEEP_BOTH = auto()
         USE_NEWER = auto()
         USE_OLDER = auto()
         FORCE_REPLACE = auto()
         DELETE = auto()
         FORCE_KEEP_BOTH = auto()
 
     _FROM_DICT_MAP = {
         'default_action': DefaultAction,
         'update_schema': [UpdateSchema],
         'acl_on_replacing_objects': AclOnReplacingObjects,
-        'acl_on_new_objects': [AclOnNewObjects]
+        'acl_on_new_objects': [AclOnNewObjects],
     }
 
     def __init__(
         self,
         default_action: DefaultAction = DefaultAction.USE_EXISTING,
         update_schema: Optional[UpdateSchema] = None,
         acl_on_replacing_objects: Optional[AclOnReplacingObjects] = None,
-        acl_on_new_objects: Optional[AclOnNewObjects] = None
+        acl_on_new_objects: Optional[AclOnNewObjects] = None,
     ):
         self.default_action = default_action
-        self.update_schema = (update_schema if isinstance(update_schema, list)
-                              or not update_schema else [update_schema])
+        self.update_schema = (
+            update_schema
+            if isinstance(update_schema, list) or not update_schema
+            else [update_schema]
+        )
         self.acl_on_replacing_objects = acl_on_replacing_objects
-        self.acl_on_new_objects = acl_on_new_objects if isinstance(acl_on_new_objects,
-                                                                   list) else [acl_on_new_objects]
+        self.acl_on_new_objects = (
+            acl_on_new_objects
+            if isinstance(acl_on_new_objects, list)
+            else [acl_on_new_objects]
+        )
 
 
 class PackageContentInfo(Dictable):
     """Object representation of package content information
 
     Attributes:
         id(str): object ID
@@ -194,14 +204,15 @@
         DELETE: Delete the object from the destination project. The version
         of the object in the update package is not imported into the destination
         project.Warning: If the object in the destination has any used-by
         dependencies when you import the update package, the import will fail.
         FORCE_KEEP_BOTH: No change is made to the destination object. The source
         object is always saved as a new object.
         """
+
         USE_EXISTING = auto()
         REPLACE = auto()
         KEEP_BOTH = auto()
         USE_NEWER = auto()
         USE_OLDER = auto()
         FORCE_REPLACE = auto()
         DELETE = auto()
@@ -217,55 +228,66 @@
         This class overrides `from_dict()` and `__init__()` methods as
         PackageContentInfo inherits from `Dictable` and not `EntityBase`.
         Therefore, despite `Owner` being a `User`, `connection` param here is
         optional. If `connection` is specified, `User` constructor will be used
         """
 
         @classmethod
-        def from_dict(cls, source: Dict[str, Any], connection: Optional["Connection"] = None):
+        def from_dict(
+            cls, source: dict[str, any], connection: Optional["Connection"] = None
+        ):
             return super().from_dict(source, connection)
 
         def __init__(self, id: str, connection: Optional["Connection"] = None):
             if connection:
                 super().__init__(id, connection)
             else:
                 self._id = id
 
         def _init_variables(self, **kwargs) -> None:
             self._connection = kwargs.get("connection")
             self._id = kwargs.get("id")
 
-    _FROM_DICT_MAP = {'type': ObjectTypes, 'action': Action, 'level': Level, 'owner': Owner}
+    _FROM_DICT_MAP = {
+        'type': ObjectTypes,
+        'action': Action,
+        'level': Level,
+        'owner': Owner,
+    }
 
     def __init__(
         self,
         id: str,
-        action: Union[Action, str] = Action.USE_EXISTING,
+        action: Action | str = Action.USE_EXISTING,
         name: Optional[str] = None,
         version: Optional[str] = None,
         type: Optional[ObjectTypes] = None,
         owner: Optional[Owner] = None,
         date_created: Optional[str] = None,
         date_modified: Optional[str] = None,
         include_dependents: Optional[bool] = None,
         explicit_included: Optional[bool] = None,
-        level: Optional[Union[Level, str]] = None
+        level: Optional[Level | str] = None,
     ):
         self.id = id
         self.name = name
         self.version = version
         self.type = type
         self.owner = owner
         self.date_created = date_created
         self.date_modified = date_modified
         self.include_dependents = include_dependents
         self.explicit_included = explicit_included
         try:
-            self.level = PackageContentInfo.Level(level) if isinstance(level, str) else level
-            self.action = PackageContentInfo.Action(action) if isinstance(action, str) else action
+            self.level = (
+                PackageContentInfo.Level(level) if isinstance(level, str) else level
+            )
+            self.action = (
+                PackageContentInfo.Action(action) if isinstance(action, str) else action
+            )
         except ValueError:
             exception_handler(msg="Wrong enum value", exception_type=ValueError)
 
 
 class PackageConfig(Dictable):
     """Package Update Data Transfer Object
 
@@ -273,37 +295,40 @@
         type(PackageUpdateType): type of package update
         settings(PackageSettings): settings details of package
         content(PackageContentInfo, List[PackageContentInfo]): content details
             of package
     """
 
     class PackageUpdateType(AutoName):
-        """ Package update type:
+        """Package update type:
         PROJECT: For users input, only accept non configuration object. But
             the actual package contains all kinds of objects, including
             configuration objects.
         CONFIGURATION: Only contains configuration objects. 12 types in total,
             including Database connection, Transmitter, Database Instance,
             Database login, DBMS, Device, Event, Language, Schedule,
             Security Role,User, User group.
         PROJECT_SECURITY: Only contains user objects.
         """
+
         PROJECT = auto()
         PROJECT_SECURITY = auto()
         CONFIGURATION = auto()
 
     _FROM_DICT_MAP = {
-        'type': PackageUpdateType, 'settings': PackageSettings, 'content': [PackageContentInfo]
+        'type': PackageUpdateType,
+        'settings': PackageSettings,
+        'content': [PackageContentInfo],
     }
 
     def __init__(
         self,
         type: PackageUpdateType,
         settings: PackageSettings,
-        content: Union[List[PackageContentInfo], PackageContentInfo]
+        content: list[PackageContentInfo] | PackageContentInfo,
     ):
         self.type = type
         self.settings = settings
         self.content = [content] if not isinstance(content, list) else content
 
 
 class Package(EntityBase, DeleteMixin):
@@ -313,15 +338,17 @@
         connection(Connection): a MicroStrategy connection object
         id(str): package ID
         status(str): status of a package
         settings(PackageSettings): settings details of package
         content(PackageContentInfo): content details of package
     """
 
-    _API_GETTERS = {("id", "status", "settings", "content"): migration.get_package_holder}
+    _API_GETTERS = {
+        ("id", "status", "settings", "content"): migration.get_package_holder
+    }
     _API_DELETE = staticmethod(migration.delete_package_holder)
 
     _FROM_DICT_MAP = {
         'settings': PackageSettings.from_dict,
         'content': [PackageContentInfo.from_dict],
     }
 
@@ -332,15 +359,15 @@
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`
             id: ID of package import process
         """
         if id is None:
             exception_handler(
                 "Please provide actual value for id argument, other than None.",
-                exception_type=ValueError
+                exception_type=ValueError,
             )
 
         super().__init__(connection, id)
 
     def _init_variables(self, **kwargs) -> None:
         self.settings = None
         self.content = None
@@ -378,16 +405,17 @@
         body = helper.delete_none_values(body, recursion=True)
         body = helper.snake_to_camel(body)
         migration.update_package_holder(self.connection, body, self.id).json()
 
         total_time = 0
         # Wait until update ready
         while True:
-            response = migration.get_package_holder(self.connection, self.id,
-                                                    show_content=False).json()
+            response = migration.get_package_holder(
+                self.connection, self.id, show_content=False
+            ).json()
             if response.get('status') == 'ready':
                 break
             sleep(TIMEOUT_INCREMENT)
             total_time += TIMEOUT_INCREMENT
 
             if total_time > TIMEOUT:
                 logger.warning('Time out on updating package')
@@ -399,19 +427,22 @@
     def upload_package_binary(self, package_binary: bytes, progress_bar: bool = False):
         """Uploads a binary of a package.
 
         Args:
             package_binary: binary of the package to be uploaded
             progress_bar: boolean value that decides whether a progress bar will
                 be displayed. defaults to False"""
-        response = migration.upload_package(self.connection, self.id, package_binary).json()
+        response = migration.upload_package(
+            self.connection, self.id, package_binary
+        ).json()
         self.status = response.get('status')
         if config.verbose and not progress_bar:
             logger.info(
-                f"Uploaded package binary to package holder with ID: '{response.get('id')}'"
+                f"Uploaded package binary to package holder with ID: "
+                f"'{response.get('id')}'"
             )
 
     def download_package_binary(self, progress_bar: bool = False) -> bytes:
         """Downloads a binary of a package.
 
         Args:
             progress_bar: boolean value that decides whether a progress bar will
@@ -432,59 +463,66 @@
         connection(Connection): A MicroStrategy connection object
         id(str): PackageImport ID
         status(str): status of an import
         undo_package_created(bool): if the undo package have been created
         progress(int): progress of package import process
     """
 
-    _API_GETTERS = {("id", "status", "undo_package_created", "progress"): migration.get_import}
+    _API_GETTERS = {
+        ("id", "status", "undo_package_created", "progress"): migration.get_import
+    }
     _API_DELETE = staticmethod(migration.delete_import)
     _progress_bar = True
 
     def __init__(self, connection: Connection, id: str) -> None:
         """Initialize PackageImport object.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             id: ID of package import process
         """
         if id is None:
             exception_handler(
                 "Please provide actual value for id argument, other than None.",
-                exception_type=ValueError
+                exception_type=ValueError,
             )
 
         super().__init__(connection, id)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self.undo_package_created = kwargs.get("undo_package_created")
         self.status = kwargs.get("status")
         self.progress = kwargs.get("progress")
 
     @classmethod
     def create(
-        cls, connection: Connection, package_id: str, generate_undo: bool, progress_bar=False
+        cls,
+        connection: Connection,
+        package_id: str,
+        generate_undo: bool,
+        progress_bar=False,
     ):
         """Create a package import process.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             package_id: ID of the package that is to be imported
             generate_undo: boolean value that specifies whether an undo package
                 has to also be created
             progress_bar: boolean value that decides whether a progress bar will
                 be displayed. defaults to False
 
         Returns:
             A PackageImport object."""
-        response = migration.create_import(connection, package_id,
-                                           generate_undo=generate_undo).json()
+        response = migration.create_import(
+            connection, package_id, generate_undo=generate_undo
+        ).json()
 
         total_time = 0
         # Wait until update ready
         while True:
             response = migration.get_import(connection, response.get('id')).json()
             if response.get('status') == 'imported':
                 break
@@ -492,15 +530,17 @@
             total_time += TIMEOUT_INCREMENT
 
             if total_time > TIMEOUT:
                 logger.warning('Time out on creating import')
                 return False
 
         if config.verbose and not progress_bar:
-            logger.info(f"Created package import process with ID: '{response.get('id')}'")
+            logger.info(
+                f"Created package import process with ID: '{response.get('id')}'"
+            )
         return cls.from_dict(source=response, connection=connection)
 
     def download_undo_binary(self, progress_bar=False):
         """Download undo package binary for this import process.
 
         Args:
         progress_bar: boolean value that decides whether a progress bar will
@@ -520,9 +560,12 @@
 
             if total_time > TIMEOUT:
                 logger.warning('Time out on downloading undo binary')
                 return False
 
         response = migration.create_undo(self.connection, self.id)
         if config.verbose and not progress_bar:
-            logger.info(f"Downloaded undo package binary for import process with ID: '{self.id}'")
+            logger.info(
+                f"Downloaded undo package binary for import process with ID: "
+                f"'{self.id}'"
+            )
         return response.content
```

### Comparing `mstrio-py-11.3.9.101/mstrio/object_management/object.py` & `mstrio-py-11.3.9.103/mstrio/object_management/object.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,32 +1,37 @@
 import logging
 from typing import Optional, TYPE_CHECKING
 
 from mstrio.api import objects
-from mstrio.object_management.search_operations import full_search, SearchDomain, SearchPattern
+from mstrio.object_management.search_operations import (
+    full_search,
+    SearchDomain,
+    SearchPattern,
+)
 from mstrio.types import ObjectTypes
 from mstrio.users_and_groups.user import User
 from mstrio.utils.acl import ACLMixin
 from mstrio.utils.certified_info import CertifiedInfo
 from mstrio.utils.entity import CertifyMixin, CopyMixin, DeleteMixin, Entity, MoveMixin
+from mstrio.utils.enum_helper import get_enum
 from mstrio.utils.helper import (
     get_args_from_func,
     get_default_args_from_func,
-    get_valid_project_id
+    get_valid_project_id,
 )
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
 
 logger = logging.getLogger(__name__)
 
 
 def list_objects(
     connection: "Connection",
-    object_type: ObjectTypes,
+    object_type: ObjectTypes | int,
     name: Optional[str] = None,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     domain: SearchDomain | int = SearchDomain.CONFIGURATION,
     search_pattern: SearchPattern | int = SearchPattern.CONTAINS,
     to_dictionary: bool = False,
     limit: int = None,
@@ -54,25 +59,25 @@
             for, such as Begin With or Exactly. Possible values are available in
             ENUM mstrio.object_management.SearchPattern.
             Default value is CONTAINS (4).
         to_dictionary: If True returns dict, by default (False) returns Objects.
         limit: limit the number of elements returned. If `None` (default), all
             objects are returned.
         **filters: Available filter parameters: ['id', 'name', 'description',
-            'date_created', 'date_modified', 'acg']
+            'date_created', 'date_modified', 'acg', 'owner', 'ext_type']
 
     Examples:
         >>> list_objects(connection, object_type=ObjectTypes.USER)
     """
 
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
         project_name=project_name,
-        with_fallback=True
+        with_fallback=True,
     )
 
     result = Object._list_objects(
         connection=connection,
         object_type=object_type,
         name=name,
         project_id=project_id,
@@ -143,80 +148,85 @@
             'view_media',
             'ancestors',
             'certified_info',
             'acl',
             'comments',
             'project_id',
             'hidden',
-            'target_info'
+            'target_info',
         ): objects.get_object_info
     }
-    _API_PATCH: dict = {**Entity._API_PATCH, ('folder_id'): (objects.update_object, 'partial_put')}
+    _API_PATCH: dict = {
+        **Entity._API_PATCH,
+        ('folder_id'): (objects.update_object, 'partial_put'),
+    }
 
     def __init__(self, connection: "Connection", type: ObjectTypes, id: str):
         """Initialize object by ID.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             id (str): Identifier of an existing object.
             type (ObjectTypes): object type
         """
 
         super().__init__(connection=connection, object_id=id, type=type)
 
     def _init_variables(self, **kwargs) -> None:
-        self._OBJECT_TYPE = ObjectTypes(kwargs.get("type")) if ObjectTypes.contains(
-            kwargs.get("type")
-        ) else ObjectTypes.NONE
+        self._OBJECT_TYPE = (
+            ObjectTypes(kwargs.get("type"))
+            if ObjectTypes.contains(kwargs.get("type"))
+            else ObjectTypes.NONE
+        )
         super()._init_variables(**kwargs)
 
     def __str__(self):
         return f"Object named: '{self.name}' with ID: '{self.id}'"
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
-        abbreviation: Optional[str] = None
+        abbreviation: Optional[str] = None,
     ) -> None:
         """Alter the object properties.
 
         Args:
             name: object name
             description: object description
             abbreviation: abbreviation
         """
         func = self.alter
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
         self._alter_properties(**properties)
 
     @classmethod
     def _list_objects(
         cls,
         connection: "Connection",
-        object_type: ObjectTypes,
+        object_type: ObjectTypes | int,
         name: Optional[str] = None,
         project_id: Optional[str] = None,
         to_dictionary: bool = False,
         domain: int | SearchDomain = SearchDomain.CONFIGURATION,
         pattern: int | SearchPattern = SearchPattern.CONTAINS,
         limit: Optional[int] = None,
         **filters,
     ) -> list["Object"] | list[dict]:
         objects = full_search(
             connection,
-            object_types=object_type,
+            object_types=get_enum(object_type, ObjectTypes),
             name=name,
             project=project_id,
             domain=domain,
             pattern=pattern,
             limit=limit,
             **filters,
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/object_management/predefined_folders.py` & `mstrio-py-11.3.9.103/mstrio/object_management/predefined_folders.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 from enum import Enum
 
 
 class PredefinedFolders(Enum):
     """Enumeration constants used to specify names of pre-defined folders.
     Values are specified according to `EnumDSSXMLFolderNames`."""
+
     AUTO_STYLES = 57
     BLACK_LISTED = 1000
     CONFIGURE_DB_ROLES = 73
     CONFIGURE_MONITORS = 58
     CONFIGURE_SERVER_DEFINITIONS = 59
     DB_CONNECTIONS = 81
     DB_LOGINS = 82
```

### Comparing `mstrio-py-11.3.9.101/mstrio/object_management/search_enums.py` & `mstrio-py-11.3.9.103/mstrio/object_management/search_enums.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,38 +1,42 @@
 from enum import Enum, IntEnum
 
 
 class CertifiedStatus(Enum):
     """Enumeration that represents what can be passed in the certified_status
     attribute of the IServer quick search command."""
+
     ALL = 'ALL'
     CERTIFIED_ONLY = 'CERTIFIED_ONLY'
     NOT_CERTIFIED_ONLY = 'NOT_CERTIFIED_ONLY'
     OFF = 'OFF'
 
 
 class SearchPattern(IntEnum):
     """Enumeration constants used to specify searchType used to control BI
     Search. More details can be found in EnumDSSXMLSearchTypes in a browser."""
+
     CONTAINS_ANY_WORD = 0
     BEGIN_WITH = 1
     EXACTLY = 2
     BEGIN_WITH_PHRASE = 3
     CONTAINS = 4
     END_WITH = 5
 
 
 class SearchDomain(IntEnum):
     """Enumeration constants used to specify the search domains. More details
-     can be found in EnumDSSXMLSearchDomain in a browser."""
+    can be found in EnumDSSXMLSearchDomain in a browser."""
+
     LOCAL = 1
     PROJECT = 2
     REPOSITORY = 3
     CONFIGURATION = 4
     CONFIGURATION_AND_ALL_PROJECTS = 5
 
 
 class SearchResultsFormat(Enum):
     """Enumeration constants used to specify the format to return
     from search functions."""
+
     LIST = 'LIST'
     TREE = 'TREE'
```

### Comparing `mstrio-py-11.3.9.101/mstrio/object_management/search_operations.py` & `mstrio-py-11.3.9.103/mstrio/object_management/search_operations.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,29 +1,32 @@
 import itertools
 import logging
 from concurrent.futures import as_completed
-from typing import Optional, TYPE_CHECKING, Type
+from typing import TYPE_CHECKING, Optional
 
 from mstrio.api import browsing, objects
 from mstrio.connection import Connection
 from mstrio.object_management.search_enums import (
-    CertifiedStatus, SearchDomain, SearchPattern, SearchResultsFormat
+    CertifiedStatus,
+    SearchDomain,
+    SearchPattern,
+    SearchResultsFormat,
 )
 from mstrio.server import Environment
 from mstrio.server.project import Project
 from mstrio.types import ObjectSubTypes, ObjectTypes
 from mstrio.users_and_groups import User
 from mstrio.utils.entity import CopyMixin, Entity, EntityBase, MoveMixin
 from mstrio.utils.helper import (
     exception_handler,
     fetch_objects_async,
     get_args_from_func,
     get_enum_val,
     get_objects_id,
-    merge_id_and_type
+    merge_id_and_type,
 )
 from mstrio.utils.sessions import FuturesSessionWithRenewal
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 if TYPE_CHECKING:
     from mstrio.types import TypeOrSubtype
 
@@ -52,15 +55,18 @@
         ancestors: List of ancestor folders
         acg: Access rights (See EnumDSSXMLAccessRightFlags for possible values)
         acl: Object access control list
     """
 
     _OBJECT_TYPE = ObjectTypes.SEARCH
     _FROM_DICT_MAP = {**Entity._FROM_DICT_MAP, 'owner': User.from_dict}
-    _API_PATCH: dict = {**Entity._API_PATCH, ('folder_id'): (objects.update_object, 'partial_put')}
+    _API_PATCH: dict = {
+        **Entity._API_PATCH,
+        ('folder_id'): (objects.update_object, 'partial_put'),
+    }
 
     def __init__(self, connection: "Connection", id: str) -> None:
         """Initialize SearchObject object and synchronize with server.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
@@ -79,15 +85,15 @@
     object_types: Optional["TypeOrSubtype"] = None,
     get_ancestors: bool = False,
     cross_cluster: bool = False,
     hidden: Optional[bool] = None,
     certified_status: CertifiedStatus = CertifiedStatus.ALL,
     limit: Optional[int] = None,
     offset: Optional[int] = None,
-    to_dictionary: bool = True
+    to_dictionary: bool = True,
 ):
     """Use the stored results of the Quick Search engine to return
      search results and display them as a list. The Quick Search
      engine periodically indexes the metadata and stores the results in memory,
      making Quick Search very fast but with results that may not be the
      most recent.
 
@@ -125,36 +131,39 @@
         offset (int): Starting point within the collection of returned
             results. Used to control paging behavior. Default is 0.
         to_dictionary (bool): If True returns dicts, by default
             (False) returns objects.
 
     Returns:
          list of objects or list of dictionaries
-     """
+    """
     from mstrio.utils.object_mapping import map_objects_list
+
     project_id = get_objects_id(project, Project)
     if object_types and not isinstance(object_types, list):
         object_types = [get_enum_val(object_types, (ObjectTypes, ObjectSubTypes))]
     elif object_types:
-        object_types = [get_enum_val(t, (ObjectTypes, ObjectSubTypes)) for t in object_types]
+        object_types = [
+            get_enum_val(t, (ObjectTypes, ObjectSubTypes)) for t in object_types
+        ]
     pattern = get_enum_val(pattern, SearchPattern)
     certified_status = get_enum_val(certified_status, CertifiedStatus)
     resp = browsing.get_quick_search_result(
         connection,
         project_id=project_id,
         name=name,
         pattern=pattern,
         object_types=object_types,
         root=root,
         get_ancestors=get_ancestors,
         hidden=hidden,
         cross_cluster=cross_cluster,
         limit=limit,
         certified_status=certified_status,
-        offset=offset
+        offset=offset,
     )
     objects = resp.json()["result"]
     if to_dictionary:
         return objects
     return map_objects_list(connection, objects)
 
 
@@ -164,15 +173,15 @@
     project: Project | str,
     search_object: SearchObject | str,
     include_ancestors: bool = False,
     include_acl: bool = False,
     subtypes: Optional[ObjectSubTypes | list[ObjectSubTypes] | int | list[int]] = None,
     limit: Optional[int] = None,
     offset: Optional[int] = None,
-    to_dictionary: bool = True
+    to_dictionary: bool = True,
 ):
     """Perform a quick search based on a predefined Search Object.
     Use an existing search object for Quick Search engine to return
     search results and display them as a list.
 
     Args:
         connection (object): MicroStrategy connection object returned by
@@ -193,40 +202,41 @@
         to_dictionary (bool): If True returns dicts, by default
             (False) returns objects.
 
     Returns:
         list of objects or list of dictionaries
     """
     from mstrio.utils.object_mapping import map_objects_list
+
     project_id = get_objects_id(project, Project)
     search_object_id = get_objects_id(search_object, SearchObject)
     subtypes = get_enum_val(subtypes, ObjectSubTypes)
     resp = browsing.get_quick_search_result_from_object(
         connection,
         project_id,
         search_object_id,
         subtypes=subtypes,
         include_ancestors=include_ancestors,
         include_acl=include_acl,
         limit=limit,
-        offset=offset
+        offset=offset,
     )
     objects = resp.json()["result"]
     if to_dictionary:
         return objects
     return map_objects_list(connection, objects)
 
 
 @method_version_handler('11.3.0000')
 def get_search_suggestions(
     connection: Connection,
     project: Optional[Project | str] = None,
     key: Optional[str] = None,
     max_results: int = 4,
-    cross_cluster: Optional[bool] = None
+    cross_cluster: Optional[bool] = None,
 ) -> list[str]:
     """Request search suggestions from the server.
 
     Args:
         connection (object): MicroStrategy REST API connection object
         project (string, optional): `Project` object or ID
         key (string, optional): value the search pattern is set to, which will
@@ -238,45 +248,49 @@
             across the cluster, this parameter only takes effect for I-Server
             with cluster nodes. Default value is `None`
 
     Returns:
         list of search suggestions
     """
     project_id = get_objects_id(project, Project)
-    return browsing.get_search_suggestions(
-        connection=connection,
-        project_id=project_id,
-        key=key,
-        count=max_results,
-        is_cross_cluster=cross_cluster
-    ).json().get('suggestions')
+    return (
+        browsing.get_search_suggestions(
+            connection=connection,
+            project_id=project_id,
+            key=key,
+            count=max_results,
+            is_cross_cluster=cross_cluster,
+        )
+        .json()
+        .get('suggestions')
+    )
 
 
 @method_version_handler('11.3.0000')
 def full_search(
     connection: Connection,
     project: Optional[Project | str] = None,
     name: Optional[str] = None,
     pattern: SearchPattern | int = SearchPattern.CONTAINS,
     domain: SearchDomain | int = SearchDomain.PROJECT,
     root: Optional[str] = None,
-    object_types: Optional["TypeOrSubtype"] = None,
+    object_types: Optional['TypeOrSubtype'] = None,
     uses_object_id: Optional[EntityBase | str] = None,
     uses_object_type: Optional[ObjectTypes | int] = None,
     uses_recursive: bool = False,
     uses_one_of: bool = False,
     used_by_object_id: Optional[EntityBase | str] = None,
     used_by_object_type: Optional[ObjectTypes | str] = None,
     used_by_recursive: bool = False,
     used_by_one_of: bool = False,
     results_format: SearchResultsFormat | str = SearchResultsFormat.LIST,
     limit: Optional[int] = None,
     offset: Optional[int] = None,
     to_dictionary: bool = True,
-    **filters
+    **filters,
 ) -> list[dict] | list[Entity]:
     """Perform a full metadata search and return results.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`
         project (string): `Project` object or ID
@@ -333,16 +347,20 @@
 
     Returns:
         list of objects or list of dictionaries
     """
     passed_params = locals()
     start_search_args = get_args_from_func(start_full_search)
     search_result_args = get_args_from_func(get_search_results)
-    start_search_params = {k: v for k, v in passed_params.items() if k in start_search_args}
-    search_result_params = {k: v for k, v in passed_params.items() if k in search_result_args}
+    start_search_params = {
+        k: v for k, v in passed_params.items() if k in start_search_args
+    }
+    search_result_params = {
+        k: v for k, v in passed_params.items() if k in search_result_args
+    }
     resp = start_full_search(**start_search_params)
     search_result_params["search_id"] = resp["id"]
     del search_result_params["filters"]
     search_result_params.update(**filters)
     return get_search_results(**search_result_params)
 
 
@@ -358,15 +376,15 @@
     uses_object_id: Optional[EntityBase | str] = None,
     uses_object_type: Optional[ObjectTypes | ObjectSubTypes | int] = None,
     uses_recursive: bool = False,
     uses_one_of: bool = False,
     used_by_object_id: Optional[EntityBase | str] = None,
     used_by_object_type: Optional[ObjectTypes | ObjectSubTypes | int] = None,
     used_by_recursive: bool = False,
-    used_by_one_of: bool = False
+    used_by_one_of: bool = False,
 ) -> dict:
     """Search the metadata for objects in a specific project that
     match specific search criteria, and save the results in IServer memory.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`
@@ -415,34 +433,45 @@
 
     Returns:
         dictionary consisting of id (Search ID) and total items number
     """
 
     if uses_object_id and used_by_object_id:
         exception_handler(
-            msg="It is not allowed to use both uses_object and used_by_object in one request.",
-            exception_type=AttributeError
+            msg="It is not allowed to use both uses_object and used_by_object in "
+            "one request.",
+            exception_type=AttributeError,
         )
 
-    uses_object = merge_id_and_type(
-        uses_object_id,
-        uses_object_type,
-        "Please provide both `uses_object_id` and `uses_object_type`."
-    ) if uses_object_id else None
-    used_by_object = merge_id_and_type(
-        used_by_object_id,
-        used_by_object_type,
-        "Please provide both `used_by_object_id` and `uses_object_type`."
-    ) if used_by_object_id else None
+    uses_object = (
+        merge_id_and_type(
+            uses_object_id,
+            uses_object_type,
+            "Please provide both `uses_object_id` and `uses_object_type`.",
+        )
+        if uses_object_id
+        else None
+    )
+    used_by_object = (
+        merge_id_and_type(
+            used_by_object_id,
+            used_by_object_type,
+            "Please provide both `used_by_object_id` and `uses_object_type`.",
+        )
+        if used_by_object_id
+        else None
+    )
 
     project_id = get_objects_id(project, Project)
     if object_types and not isinstance(object_types, list):
         object_types = [get_enum_val(object_types, (ObjectTypes, ObjectSubTypes))]
     elif object_types:
-        object_types = [get_enum_val(t, (ObjectTypes, ObjectSubTypes)) for t in object_types]
+        object_types = [
+            get_enum_val(t, (ObjectTypes, ObjectSubTypes)) for t in object_types
+        ]
     pattern = get_enum_val(pattern, SearchPattern)
     domain = get_enum_val(domain, SearchDomain)
     resp = browsing.store_search_instance(
         connection=connection,
         project_id=project_id,
         name=name,
         pattern=pattern,
@@ -464,15 +493,15 @@
     connection: Connection,
     search_id: str,
     project: Optional[Project | str] = None,
     results_format: SearchResultsFormat = SearchResultsFormat.LIST,
     limit: Optional[int] = None,
     offset: Optional[int] = None,
     to_dictionary: bool = False,
-    **filters
+    **filters,
 ):
     """Retrieve the results of a full metadata search previously stored in
     an instance in IServer memory, may be obtained by `start_full_search`.
 
     Args:
         connection (object): MicroStrategy connection object returned by
             `connection.Connection()`
@@ -510,17 +539,18 @@
 def _get_search_result_list_format(
     connection: Connection,
     search_id: str,
     project_id: Optional[str] = None,
     limit: Optional[int] = None,
     offset: Optional[int] = None,
     to_dictionary: bool = True,
-    **filters
+    **filters,
 ):
     from mstrio.utils.object_mapping import map_objects_list
+
     objects = fetch_objects_async(
         connection=connection,
         api=browsing.get_search_results,
         async_api=browsing.get_search_results_async,
         search_id=search_id,
         project_id=project_id,
         limit=limit,
@@ -535,15 +565,15 @@
 
 
 def _get_search_result_tree_format(
     connection: Connection,
     search_id: str,
     project_id: Optional[str] = None,
     limit: Optional[int] = None,
-    offset: Optional[int] = None
+    offset: Optional[int] = None,
 ):
     resp = browsing.get_search_results_tree_format(
         connection=connection,
         search_id=search_id,
         project_id=project_id,
         limit=limit,
         offset=offset,
@@ -554,15 +584,15 @@
 
 
 def find_objects_with_id(
     connection: Connection,
     object_id: str,
     projects: Optional[list[Project] | list[str]] = None,
     to_dictionary=False,
-) -> list[dict[str, dict | Type[Entity]]]:
+) -> list[dict[str, dict | type[Entity]]]:
     """Find object by its ID only, without knowing project ID and object type.
     The search is performed by iterating over projects and trying to retrieve
     the objects with different type.
 
     Limitation:
         - Only object types supported by mstrio, i.g. present in
             `mstrio.types.ObjecTypes` enum, are used.
```

### Comparing `mstrio-py-11.3.9.101/mstrio/object_management/shortcut.py` & `mstrio-py-11.3.9.103/mstrio/object_management/shortcut.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,14 @@
 class ShortcutInfoFlags(IntFlag):
     DssDossierShortcutInfoBookmark = 0b10
     DssDossierShortcutInfoTOC = 0b01
     DssDossierShortcutInfoDefault = 0b00
 
 
 class Shortcut(Entity, CopyMixin, MoveMixin):
-
     _OBJECT_TYPE = ObjectTypes.SHORTCUT_TYPE
     _API_GETTERS = {
         (
             'name',
             'id',
             'project_id',
             'owned_by_current_user',
@@ -30,15 +29,15 @@
             'last_viewed_time',
             'last_modified_time',
             'stid',
             'current_bookmark',
             'prompted',
             'datasets_cache_info_hash',
             'shortcut_info_flag',
-            'dossier_version_hash'
+            'dossier_version_hash',
         ): browsing.get_shortcut,
         (
             'abbreviation',
             'type',
             'subtype',
             'ext_type',
             'date_created',
@@ -47,30 +46,34 @@
             'owner',
             'icon_path',
             'view_media',
             'ancestors',
             'certified_info',
             'acg',
             'acl',
-            'target_info'
-        ): objects.get_object_info
+            'target_info',
+        ): objects.get_object_info,
     }
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'shortcut_info_flag': ShortcutInfoFlags,
     }
-    _API_PATCH: dict = {**Entity._API_PATCH, ('folder_id'): (objects.update_object, 'partial_put')}
+    _API_PATCH: dict = {
+        **Entity._API_PATCH,
+        ('folder_id'): (objects.update_object, 'partial_put'),
+    }
 
     def __init__(
         self,
         connection: Connection,
         id: str,
         project_id: str = None,
         project_name: str = None,
-        shortcut_info_flag: ShortcutInfoFlags | int = ShortcutInfoFlags.DssDossierShortcutInfoTOC
+        shortcut_info_flag: ShortcutInfoFlags
+        | int = ShortcutInfoFlags.DssDossierShortcutInfoTOC,
     ):
         """Initialize the Shortcut object and populate it with I-Server data.
 
         Specify either `project_id` or `project_name`.
         When `project_id` is provided (not `None`), `project_name` is omitted.
 
         Note:
@@ -95,25 +98,27 @@
                 project_name=project_name,
                 with_fallback=False if project_name else True,
             )
             super().__init__(
                 connection=connection,
                 object_id=id,
                 project_id=project_id,
-                shortcut_info_flag=get_enum_val(shortcut_info_flag, ShortcutInfoFlags)
+                shortcut_info_flag=get_enum_val(shortcut_info_flag, ShortcutInfoFlags),
             )
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self._owned_by_current_user = kwargs.get('owned_by_current_user')
         self._target = kwargs.get('target')
         self._encode_html_content = kwargs.get('encode_html_content')
-        self._shortcut_info_flag = ShortcutInfoFlags(
-            kwargs["shortcut_info_flag"]
-        ) if kwargs.get("shortcut_info_flag") else None
+        self._shortcut_info_flag = (
+            ShortcutInfoFlags(kwargs["shortcut_info_flag"])
+            if kwargs.get("shortcut_info_flag")
+            else None
+        )
         self._current_page_key = kwargs.get('current_page_key')
         self._shared_time = kwargs.get('shared_time')
         self._last_viewed_time = kwargs.get('last_viewed_time')
         self._last_modified_time = kwargs.get('last_modified_time')
         self._stid = kwargs.get('stid')
         self._current_bookmark = kwargs.get('current_bookmark')
         self._prompted = kwargs.get('prompted')
@@ -181,58 +186,61 @@
 
 
 def get_shortcuts(
     connection: Connection,
     shortcut_ids: list[str],
     project_id: str = None,
     project_name: str = None,
-    shortcut_info_flag: ShortcutInfoFlags | int = ShortcutInfoFlags.DssDossierShortcutInfoDefault,
+    shortcut_info_flag: ShortcutInfoFlags
+    | int = ShortcutInfoFlags.DssDossierShortcutInfoDefault,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> list[dict] | list[Shortcut]:
     """Retrieve information about specific published shortcuts
-    in specific project.
+     in specific project.
 
-    Specify either `project_id` or `project_name`.
-    When `project_id` is provided (not `None`), `project_name` is omitted.
+     Specify either `project_id` or `project_name`.
+     When `project_id` is provided (not `None`), `project_name` is omitted.
 
-   Note:
-        When `project_id` is `None` and `project_name` is `None`,
-        then its value is overwritten by `project_id` from `connection` object.
-
-    Args:
-        shortcut_ids: ids of target shortcuts
-        project_id: id of project that the shortcuts are in
-        project_name: Project name
-        shortcut_info_flag: a single ShortcutInfoFlags that describes what
-          exact info are to be fetched
-        to_dictionary: parameter describing output format
-        limit (int): limit the number of elements returned. If `None` (default),
-            all objects are returned.
-    Return:
-        list of dictionaries or Shortcut objects,
-          depending on `to_dictionary` parameter
+    Note:
+         When `project_id` is `None` and `project_name` is `None`,
+         then its value is overwritten by `project_id` from `connection`
+         object.
+
+     Args:
+         shortcut_ids: ids of target shortcuts
+         project_id: id of project that the shortcuts are in
+         project_name: Project name
+         shortcut_info_flag: a single ShortcutInfoFlags that describes what
+           exact info are to be fetched
+         to_dictionary: parameter describing output format
+         limit (int): limit the number of elements returned.
+             If `None` (default), all objects are returned.
+     Return:
+         list of dictionaries or Shortcut objects,
+           depending on `to_dictionary` parameter
     """
     project_id = get_valid_project_id(
         connection=connection,
         project_id=project_id,
         project_name=project_name,
         with_fallback=False if project_name else True,
     )
 
     shortcuts = fetch_objects(
         connection=connection,
         api=browsing.get_shortcuts,
         dict_unpack_value="shortcuts",
         limit=limit,
         filters=filters,
-        body=[{
-            "projectId": project_id, "shortcutIds": shortcut_ids
-        }],
+        body=[{"projectId": project_id, "shortcutIds": shortcut_ids}],
         shortcut_info_flag=get_enum_val(shortcut_info_flag, ShortcutInfoFlags),
     )
 
     if to_dictionary:
         return shortcuts
     else:
-        return [Shortcut.from_dict(source=short, connection=connection) for short in shortcuts]
+        return [
+            Shortcut.from_dict(source=short, connection=connection)
+            for short in shortcuts
+        ]
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/content_cache.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/content_cache.py`

 * *Files 2% similar despite different names*

```diff
@@ -34,18 +34,22 @@
 class ContentCache(Cache, ContentCacheMixin):
     """
     Manage content cache.
 
     _CACHE_TYPE is a variable used by ContentCache class for cache filtering
     purposes.
     """
+
     _CACHE_TYPE = None
 
     def __init__(
-        self, connection: "Connection", id: str, content_cache_dict: Optional[dict] = None
+        self,
+        connection: "Connection",
+        id: str,
+        content_cache_dict: Optional[dict] = None,
     ):
         """Initialize the ContentCache object. If content_cache_dict is provided
         no I-Server request will be sent.
 
         Args:
             connection (Connection): MicroStrategy connection object returned by
                 `connection.Connection()`.
@@ -61,19 +65,25 @@
             self.fetch()
         else:
             self._init_variables(**content_cache_dict)
 
     def _init_variables(self, **kwargs) -> None:
         kwargs = camel_to_snake(kwargs)
         super()._init_variables(**kwargs)
-        self._status = ContentCacheStatus.from_dict(status) if (
-            status := kwargs.get('status')
-        ) else None
-        self._format = ContentCacheFormat(format_) if (format_ := kwargs.get('format')) else None
-        self._combined_id = combined_id if (combined_id := kwargs.get('combined_id')) else None
+        self._status = (
+            ContentCacheStatus.from_dict(status)
+            if (status := kwargs.get('status'))
+            else None
+        )
+        self._format = (
+            ContentCacheFormat(format_) if (format_ := kwargs.get('format')) else None
+        )
+        self._combined_id = (
+            combined_id if (combined_id := kwargs.get('combined_id')) else None
+        )
         self._chapter = kwargs.get('chapter')
         self._report_caches_used = kwargs.get('report_caches_used')
         self._host = kwargs.get('host')
         self._warehouse_tables_used = kwargs.get('warehouse_tables_used')
         self._last_load_time = kwargs.get('last_load_time')
         self._security_filter_id = kwargs.get('security_filter_id')
         self._prompt_answer = kwargs.get('prompt_answer')
@@ -95,75 +105,74 @@
         """Fetches the cache from the server, refreshing the variables to match
         those currently stored on the server."""
         res = ContentCache.list_caches(
             connection=self._connection,
             project_id=self._project_id,
             nodes=self._nodes,
             id=self.id,
-            to_dictionary=True
+            to_dictionary=True,
         )
         if res:
             self._init_variables(**res[0])
 
     def __alter_status(
         self,
         op: str,
         value: Optional[bool] = None,
         status: Optional[str] = None,
-        nodes: Optional[list[str]] = None
+        nodes: Optional[list[str]] = None,
     ) -> Response:
         """Engine for altering ContentCache status
 
         Args:
             op (str): Replace or Remove operation to be performed
             value (bool, optional): Value used by operation [new value used to
                 replace existing value]
             status (str, optional): Status on which the value should be changed
             nodes (list, optional): list of node names for the specified project
 
         Returns:
             Response object
         """
         if not nodes:
-            nodes = ContentCacheMixin.fetch_nodes(self._connection, self._connection.project_id)
-        body = {'operationList': [
-            {
-                'op': op,
-                'path': f'/contentCaches/{self.combined_id}/status/{status}'
-                if status else f'/contentCaches/{self.combined_id}',
-                'value': value
-            }
-        ]}
+            nodes = ContentCacheMixin.fetch_nodes(
+                self._connection, self._connection.project_id
+            )
+        body = {
+            'operationList': [
+                {
+                    'op': op,
+                    'path': f'/contentCaches/{self.combined_id}/status/{status}'
+                    if status
+                    else f'/contentCaches/{self.combined_id}',
+                    'value': value,
+                }
+            ]
+        }
         return monitors.update_contents_caches(self._connection, nodes, body)
 
     def load(self):
         """Load content cache."""
         nodes = self._nodes
         response = self.__alter_status(
-            op='replace',
-            value=True,
-            status='loaded',
-            nodes=nodes
+            op='replace', value=True, status='loaded', nodes=nodes
         )
 
         if config.verbose and response.ok:
             logger.info(f'Successfully loaded content cache with id: {self.id}')
         if response.ok:
             self.fetch()
             return True
         return False
 
     def unload(self):
         """Unload content cache."""
         nodes = self._nodes
         response = self.__alter_status(
-            op='replace',
-            value=False,
-            status='loaded',
-            nodes=nodes
+            op='replace', value=False, status='loaded', nodes=nodes
         )
         if config.verbose and response:
             logger.info(f'Successfully unloaded content cache with id: {self.id}')
         if response.ok:
             self.fetch()
             return True
         return False
@@ -174,41 +183,47 @@
         Args:
             force (bool, optional): If True, then no additional prompt will be
                 shown before deleting object.
 
         Returns:
             Response object."""
         if not force:
-            user_input = input(
-                f"Are you sure you want to delete content cache"
-                f"with ID: '{self.id}'? [Y/N]: "
-            ) or 'N'
+            user_input = (
+                input(
+                    f"Are you sure you want to delete content cache"
+                    f"with ID: '{self.id}'? [Y/N]: "
+                )
+                or 'N'
+            )
         if force or user_input == 'Y':
             nodes = self._nodes
-            response = self.__alter_status(
-                op='remove', nodes=nodes
-            )
+            response = self.__alter_status(op='remove', nodes=nodes)
             if config.verbose and response:
                 logger.info(f"Successfully deleted content cache with ID: '{self.id}'.")
             return response
 
     @classmethod
-    def from_dict(cls, connection: "Connection", caches: list[dict]) -> list["ContentCache"]:
+    def from_dict(
+        cls, connection: "Connection", caches: list[dict]
+    ) -> list["ContentCache"]:
         """Creates Caches from a provided dictionary.
 
         Args:
             cls (object): Class type for objects to be created
             connection (Connection): MicroStrategy connection object returned by
                 `connection.Connection()`
             caches (list[dict]): list of dictionaries the Caches will be created
                 from
 
         Returns:
             List of Caches created from the provided dictionaries."""
-        return [ContentCache(connection, cache_dict['id'], cache_dict) for cache_dict in caches]
+        return [
+            ContentCache(connection, cache_dict['id'], cache_dict)
+            for cache_dict in caches
+        ]
 
     def list_properties(self):
         """List properties for content cache."""
         return {
             **super().list_properties(),
             'status': self.status,
             'format': self.format,
@@ -310,15 +325,14 @@
     @property
     def xml_content(self):
         return self._xml_content
 
 
 @dataclass
 class ContentCacheStatus(Dictable):
-
     ready: bool
     processing: bool
     invalid: bool
     expired: bool
     loaded: bool
     filed: bool
     dirty: bool
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/datasets/cube.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/datasets/cube.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,37 +1,38 @@
-from enum import Enum
 import logging
+from enum import Enum
 from operator import itemgetter
-from typing import Optional, TYPE_CHECKING
+from typing import TYPE_CHECKING, Optional
 
-from pandas.core.frame import DataFrame
 import requests
+from pandas.core.frame import DataFrame
 from tqdm.auto import tqdm
 
 from mstrio import config
 from mstrio.api import cubes, datasets
 from mstrio.connection import Connection
-from mstrio.object_management.search_operations import full_search, SearchPattern
+from mstrio.object_management.search_operations import SearchPattern, full_search
 from mstrio.project_objects.datasets import cube_cache
 from mstrio.types import ObjectSubTypes, ObjectTypes
 from mstrio.users_and_groups.user import User
 from mstrio.utils.certified_info import CertifiedInfo
 from mstrio.utils.entity import DeleteMixin, Entity, VldbMixin
 from mstrio.utils.filter import Filter
 from mstrio.utils.helper import (
     choose_cube,
     exception_handler,
     fallback_on_timeout,
     get_parallel_number,
     get_valid_project_id,
     response_handler,
-    sort_object_properties
+    sort_object_properties,
 )
 from mstrio.utils.parser import Parser
 from mstrio.utils.sessions import FuturesSessionWithRenewal
+from mstrio.utils.exceptions import NotSupportedError
 
 if TYPE_CHECKING:
     from .cube_cache import CubeCache
     from .olap_cube import OlapCube
     from .super_cube import SuperCube
 
 logger = logging.getLogger(__name__)
@@ -92,15 +93,15 @@
     connection: Connection,
     name: Optional[str] = None,
     search_pattern: SearchPattern | int = SearchPattern.CONTAINS,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> list["OlapCube", "SuperCube"] | list[dict]:
     """Get list of Cube objects (OlapCube or SuperCube) or dicts with them.
     Optionally filter cubes by specifying 'name'.
 
     Optionally use `to_dictionary` to choose output format.
 
     Wildcards available for 'name':
@@ -157,27 +158,29 @@
         return objects_
     else:
         all_cubes = []
         for object_ in objects_:
             cube_subtype = object_['subtype']
             if cube_subtype == int(ObjectSubTypes.OLAP_CUBE):
                 from .olap_cube import OlapCube
+
                 all_cubes.append(OlapCube.from_dict(object_, connection))
             elif cube_subtype == int(ObjectSubTypes.SUPER_CUBE):
                 from .super_cube import SuperCube
+
                 all_cubes.append(SuperCube.from_dict(object_, connection))
         return all_cubes
 
 
 def load_cube(
     connection: Connection,
     cube_id: Optional[str] = None,
     cube_name: Optional[str] = None,
     folder_id: Optional[str] = None,
-    instance_id: Optional[str] = None
+    instance_id: Optional[str] = None,
 ) -> "OlapCube | SuperCube | list[OlapCube, SuperCube]":
     """Load single cube specified by either 'cube_id' or both 'cube_name' and
     'folder_id'.
 
     It is also possible to load cube by providing only `cube_name`, but in that
     case we may retrieve more than one cube as cube's name is unique only within
     a folder.
@@ -201,56 +204,63 @@
     Raises:
         ValueError when neither `cube_id` nor `cube_name` are provided.
     """
     connection._validate_project_selected()
 
     if cube_id:
         if cube_name:
-            msg = "Both `cube_id` and `cube_name` provided. Loading cube based on `cube_id`."
+            msg = (
+                "Both `cube_id` and `cube_name` provided. Loading cube based on "
+                "`cube_id`."
+            )
             exception_handler(msg, Warning, False)
         elif folder_id:
             msg = (
                 "Both `cube_id` and `folder_id` provided. "
                 "Loading cube based on `cube_id` from all folders."
             )
             exception_handler(msg, Warning, False)
         objects_ = full_search(
             connection,
             project=connection.project_id,
             object_types=[ObjectSubTypes.OLAP_CUBE, ObjectSubTypes.SUPER_CUBE],
             pattern=SearchPattern.EXACTLY,
-            id=cube_id
+            id=cube_id,
         )
     elif not cube_name:
         msg = "Specify either `cube_id` or `cube_name`."
         raise ValueError(msg)
     else:  # getting cube by `cube_name` and optionally `folder_id`
         objects_ = full_search(
             connection,
             project=connection.project_id,
             name=cube_name,
             object_types=[ObjectSubTypes.OLAP_CUBE, ObjectSubTypes.SUPER_CUBE],
             pattern=SearchPattern.EXACTLY,
-            root=folder_id
+            root=folder_id,
         )
 
     ret_cubes = []
     for object_ in objects_:
-        object_ = object_ if len(objects_) > 1 else {**object_, "instance_id": instance_id}
+        object_ = (
+            object_ if len(objects_) > 1 else {**object_, "instance_id": instance_id}
+        )
 
         ret_cubes.append(choose_cube(connection, object_))
         ret_cubes = [tmp for tmp in ret_cubes if tmp]  # remove `None` values
 
     if len(ret_cubes) == 0:
         exception_handler("Cube was not found.", Warning, False)
         return None
     elif len(ret_cubes) == 1:
         return ret_cubes[0]
     else:
-        exception_handler(f"More than one cube with name {cube_name} was loaded.", Warning, False)
+        exception_handler(
+            f"More than one cube with name {cube_name} was loaded.", Warning, False
+        )
         return ret_cubes
 
 
 class _Cube(Entity, VldbMixin, DeleteMixin):
     """Access, filter, publish, and extract data from MicroStrategy in-memory
     cubes.
 
@@ -261,33 +271,34 @@
     Attributes:
         connection: MicroStrategy connection object returned by
             `connection.Connection()`.
         id: Identifier of a pre-existing cube containing the required data.
         instance_id (str): Identifier of an instance if cube instance has been
             already initialized, NULL by default.
     """
+
     _OBJECT_TYPE = ObjectTypes.REPORT_DEFINITION
     _OBJECT_SUBTYPE = ObjectSubTypes.NONE.value
     # TODO maybe add cube_info call and attribute to
     # TODO API_GETTERS **{('TODO'): cubes.cube_info}
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'owner': User.from_dict,
-        'certified_info': CertifiedInfo.from_dict
+        'certified_info': CertifiedInfo.from_dict,
     }
     _SIZE_LIMIT = 10000000  # this sets desired chunk size in bytes
 
     def __init__(
         self,
         connection: Connection,
         id: str,
         name: Optional[str] = None,
         instance_id: Optional[str] = None,
         parallel: bool = True,
-        progress_bar: bool = True
+        progress_bar: bool = True,
     ):
         """Initialize an instance of a cube by its id.
 
         Note:
             Parameter `name` is not used when fetching. `id` is always used to
             uniquely identify cube.
 
@@ -308,27 +319,27 @@
         super().__init__(
             connection,
             id,
             name=name,
             instance_id=instance_id,
             parallel=parallel,
             progress_bar=progress_bar,
-            subtype=self._OBJECT_SUBTYPE
+            subtype=self._OBJECT_SUBTYPE,
         )
         connection._validate_project_selected()
         self._get_definition()
 
     def _init_variables(self, **kwargs):
         super()._init_variables(**kwargs)
         self.instance_id = kwargs.get("instance_id")
         self._parallel = kwargs.get("parallel", True)
         self._initial_limit = 1000
-        self._progress_bar = True if kwargs.get(
-            "progress_bar", True
-        ) and config.progress_bar else False
+        self._progress_bar = (
+            True if kwargs.get("progress_bar", True) and config.progress_bar else False
+        )
         self._table_definition = {}
         self._dataframe = None
         self._dataframes = []
         self._attr_elements = None
         # these properties were not fetched from self.__definition() and will be
         # lazily fetched when calling properties `attributes` or `metrics`
         self._attributes = []
@@ -351,27 +362,27 @@
         # property `caches`
         self._caches = None
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
-        abbreviation: Optional[str] = None
+        abbreviation: Optional[str] = None,
     ):
         """Alter Cube properties.
 
         Args:
             name: new name of the Dataset
             description: new description of the Dataset
             abbreviation: new abbreviation of the Dataset
         """
         func = self.alter
-        args = func.__code__.co_varnames[:func.__code__.co_argcount]
+        args = func.__code__.co_varnames[: func.__code__.co_argcount]
         defaults = func.__defaults__  # type: ignore
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
         self._alter_properties(**properties)
 
@@ -403,24 +414,23 @@
         """
         if limit:
             self._initial_limit = limit
 
         if self.instance_id is None:
             res = self.__create_cube_instance(self._initial_limit)
         else:
-
             # try to get first chunk from already initialized instance of cube,
             # if not possible, initialize new instance
             try:
                 res = cubes.cube_instance_id(
                     connection=self.connection,
                     cube_id=self._id,
                     instance_id=self.instance_id,
                     offset=0,
-                    limit=self._initial_limit
+                    limit=self._initial_limit,
                 )
             except requests.HTTPError:
                 res = self.__create_cube_instance(self._initial_limit)
 
         # Gets the pagination totals and instance_id from the response object
         _instance = res.json()
         self.instance_id = _instance['instanceId']
@@ -429,49 +439,65 @@
         # initialize parser and process first response
         p = Parser(response=_instance, parse_cube=True)
         p.parse(response=_instance)
 
         # If there are more rows to fetch, fetch them
         if paging['current'] != paging['total']:
             if not limit:
-                limit = max(1000, int((self._initial_limit * self._SIZE_LIMIT) / len(res.content)))
+                limit = max(
+                    1000,
+                    int((self._initial_limit * self._SIZE_LIMIT) / len(res.content)),
+                )
             # Count the number of additional iterations
-            it_total = int((paging['total'] - self._initial_limit) / limit) + \
-                ((paging['total'] - self._initial_limit) % limit != 0)
+            it_total = int((paging['total'] - self._initial_limit) / limit) + (
+                (paging['total'] - self._initial_limit) % limit != 0
+            )
 
             if self._parallel and it_total > 1:
                 threads = get_parallel_number(it_total)
-                with FuturesSessionWithRenewal(connection=self._connection,
-                                               max_workers=threads) as session:
+                with FuturesSessionWithRenewal(
+                    connection=self._connection, max_workers=threads
+                ) as session:
                     fetch_pbar = tqdm(
-                        desc="Downloading", total=it_total + 1, disable=(not self._progress_bar)
+                        desc="Downloading",
+                        total=it_total + 1,
+                        disable=(not self._progress_bar),
+                    )
+                    future = self.__fetch_chunks_future(
+                        session, paging, self.instance_id, limit
                     )
-                    future = self.__fetch_chunks_future(session, paging, self.instance_id, limit)
                     fetch_pbar.update()
                     for i, f in enumerate(future, start=1):
                         response = f.result()
                         if not response.ok:
                             response_handler(response, "Error getting cube contents.")
                         fetch_pbar.update()
                         fetch_pbar.set_postfix(
-                            rows=str(min(self._initial_limit + i * limit, paging['total']))
+                            rows=str(
+                                min(self._initial_limit + i * limit, paging['total'])
+                            )
                         )
                         p.parse(response.json())
                     fetch_pbar.close()
             else:
                 self.__fetch_chunks(p, paging, it_total, self.instance_id, limit)
 
         # return parsed data as a data frame
         self._dataframe = p.dataframe
         # split dataframe to dataframes matching tables in Cube
         if multi_df:
+            if p.has_multiform_attributes():
+                raise NotSupportedError(
+                    "Splitting into multiple dataframes is not supported for cubes "
+                    "containing multiform attributes."
+                )
             # split dataframe to dataframes matching tables in Cube
             self._dataframes = [
-                self._dataframe[columns].copy() for _,
-                columns in self.__multitable_definition().items()
+                self._dataframe[columns].copy()
+                for _, columns in self.__multitable_definition().items()
             ]
             return self._dataframes
         else:
             return self._dataframe
 
     def __fetch_chunks_future(self, future_session, pagination, instance_id, limit):
         """Fetch add'l rows from this object instance from the Intelligence
@@ -480,42 +506,46 @@
             cubes.cube_instance_id_coroutine(
                 future_session,
                 connection=self._connection,
                 cube_id=self._id,
                 instance_id=instance_id,
                 offset=_offset,
                 limit=limit,
-            ) for _offset in range(self._initial_limit, pagination['total'], limit)
+            )
+            for _offset in range(self._initial_limit, pagination['total'], limit)
         ]
 
     def __fetch_chunks(self, parser, pagination, it_total, instance_id, limit):
         """Fetch add'l rows from this object instance from the Intelligence
         Server."""
-        with tqdm(desc="Downloading", total=it_total + 1,
-                  disable=(not self._progress_bar)) as fetch_pbar:
+        with tqdm(
+            desc="Downloading", total=it_total + 1, disable=(not self._progress_bar)
+        ) as fetch_pbar:
             fetch_pbar.update()
             for _offset in range(self._initial_limit, pagination['total'], limit):
                 response = cubes.cube_instance_id(
                     connection=self.connection,
                     cube_id=self._id,
                     instance_id=instance_id,
                     offset=_offset,
-                    limit=limit
+                    limit=limit,
                 )
                 fetch_pbar.update()
-                fetch_pbar.set_postfix(rows=str(min(_offset + limit, pagination['total'])))
+                fetch_pbar.set_postfix(
+                    rows=str(min(_offset + limit, pagination['total']))
+                )
                 parser.parse(response=response.json())
 
     def __create_cube_instance(self, limit):
         inst_pbar = tqdm(
             desc='Initializing an instance of a cube. Please wait...',
             bar_format='{desc}',
             leave=False,
             ncols=280,
-            disable=(not self._progress_bar)
+            disable=(not self._progress_bar),
         )
         # Request a new instance, set instance id
         response = cubes.cube_instance(
             connection=self._connection,
             cube_id=self._id,
             body=self._filter._filter_body(),
             offset=0,
@@ -525,15 +555,15 @@
         return response
 
     def apply_filters(
         self,
         attributes: Optional[list] = None,
         metrics: Optional[list] = None,
         attr_elements: Optional[list] = None,
-        operator: str = 'In'
+        operator: str = 'In',
     ) -> None:
         """Apply filters on the cube's objects.
 
         Filter by attributes, metrics and attribute elements.
 
         Args:
             attributes (list or None, optional): ids of attributes to be
@@ -598,15 +628,17 @@
     def show_status(self) -> list[str]:
         """Show which states are represented by cube's status."""
         return CubeStates.show_status(self.status)
 
     def list_properties(self) -> dict:
         """List all properties of the object."""
 
-        attributes = {key: self.__dict__[key] for key in self.__dict__ if not key.startswith('_')}
+        attributes = {
+            key: self.__dict__[key] for key in self.__dict__ if not key.startswith('_')
+        }
         attributes = {
             **attributes,
             "id": self.id,
             "instance_id": self.instance_id,
             "type": self.type,
             "subtype": self.subtype,
             "ext_type": self.ext_type,
@@ -621,15 +653,18 @@
             "acl": self.acl,
             "size": self.size,
             "status": self.status,
             "path": self.path,
             "attributes": self.attributes,
             "metrics": self.metrics,
         }
-        return {key: attributes[key] for key in sorted(attributes, key=sort_object_properties)}
+        return {
+            key: attributes[key]
+            for key in sorted(attributes, key=sort_object_properties)
+        }
 
     def _get_info(self) -> None:
         """Get metadata for specific cubes.
 
         Implements GET /cubes to retrieve basic metadata.
         """
         if self._id is not None:
@@ -648,63 +683,77 @@
 
     def _get_definition(self) -> None:
         """Get the definition of a cube, including attributes and metrics.
 
         Implements GET /v2/cubes/<cube_id>.
         """
         if self._id is not None:
-            _definition = cubes.cube_definition(connection=self._connection, id=self._id).json()
-            full_attributes = _definition["definition"]["availableObjects"]["attributes"]
+            _definition = cubes.cube_definition(
+                connection=self._connection, id=self._id
+            ).json()
+            full_attributes = _definition["definition"]["availableObjects"][
+                "attributes"
+            ]
             full_metrics = _definition["definition"]["availableObjects"]["metrics"]
             self._attributes = [
-                {
-                    'name': attr['name'], 'id': attr['id']
-                } for attr in full_attributes
+                {'name': attr['name'], 'id': attr['id']} for attr in full_attributes
+            ]
+            self._metrics = [
+                {'name': metr['name'], 'id': metr['id']} for metr in full_metrics
             ]
-            self._metrics = [{'name': metr['name'], 'id': metr['id']} for metr in full_metrics]
 
             self._table_names = self.__multitable_definition().keys()
-            row_counts = [f'Row Count - {table_name}' for table_name in self._table_names]
-            self._row_counts = list(filter(lambda x: x['name'] in row_counts, self._metrics))
+            row_counts = [
+                f'Row Count - {table_name}' for table_name in self._table_names
+            ]
+            self._row_counts = list(
+                filter(lambda x: x['name'] in row_counts, self._metrics)
+            )
             self.__remove_row_count()
             # for lazy fetch properties
             self.__definition_retrieved = True
 
     def __multitable_definition(self):
         """Return all tables names and columns as a dictionary."""
         if not self._table_definition:
             res_tables = datasets.dataset_definition(
                 connection=self._connection,
                 id=self._id,
                 fields=['tables', 'columns'],
-                whitelist=[('ERR001', 500)]
+                whitelist=[('ERR001', 500)],
             )
             if res_tables.ok:
                 ds_definition = res_tables.json()
-                for table in ds_definition['result']['definition']['availableObjects']['tables']:
+                for table in ds_definition['result']['definition']['availableObjects'][
+                    'tables'
+                ]:
                     column_list = [
-                        column['columnName'] for column in ds_definition['result']['definition']
-                        ['availableObjects']['columns'] if table['name'] == column['tableName']
+                        column['columnName']
+                        for column in ds_definition['result']['definition'][
+                            'availableObjects'
+                        ]['columns']
+                        if table['name'] == column['tableName']
                     ]
                     self._table_definition[table['name']] = column_list
         return self._table_definition
 
     def __remove_row_count(self):
         """Remove all Row Count metrics from cube."""
         row_counts = list(map(itemgetter('name'), self._row_counts))
-        self._metrics = list(filter(lambda x: x['name'] not in row_counts, self._metrics))
+        self._metrics = list(
+            filter(lambda x: x['name'] not in row_counts, self._metrics)
+        )
 
     def __get_attr_elements(self, limit=50000):
         """Get elements of report attributes synchronously.
 
         Implements GET /reports/<report_id>/attributes/<attribute_id>/elements.
         """
 
         def fetch_for_attribute(attribute):
-
             @fallback_on_timeout()
             def fetch_for_attribute_given_limit(limit):
                 response = cubes.cube_single_attribute_elements(
                     connection=self._connection,
                     cube_id=self._id,
                     attribute_id=attribute['id'],
                     offset=0,
@@ -727,26 +776,26 @@
                     )
                     elements.extend(response.json())
 
                 # Return attribute data.
                 return {
                     "attribute_name": attribute['name'],
                     "attribute_id": attribute['id'],
-                    "elements": elements
+                    "elements": elements,
                 }
 
             return fetch_for_attribute_given_limit(limit)[0]
 
         attr_elements = []
         if self.attributes:
             pbar = tqdm(
                 self.attributes,
                 desc="Loading attribute elements",
                 leave=False,
-                disable=(not self._progress_bar)
+                disable=(not self._progress_bar),
             )
             attr_elements = [fetch_for_attribute(attribute) for attribute in pbar]
             pbar.close()
 
         return attr_elements
 
     def __get_attr_elements_async(self, limit=50000):
@@ -754,23 +803,24 @@
 
         Implements GET /cubes/<cube_id>/attributes/<attribute_id>/elements.
         """
 
         attr_elements = []
         if self.attributes:
             threads = get_parallel_number(len(self.attributes))
-            with FuturesSessionWithRenewal(connection=self._connection,
-                                           max_workers=threads) as session:
+            with FuturesSessionWithRenewal(
+                connection=self._connection, max_workers=threads
+            ) as session:
                 # Fetch first chunk of attribute elements.
                 futures = self.__fetch_attribute_elements_chunks(session, limit)
                 pbar = tqdm(
                     futures,
                     desc="Loading attribute elements",
                     leave=False,
-                    disable=(not self._progress_bar)
+                    disable=(not self._progress_bar),
                 )
                 for i, future in enumerate(pbar):
                     attr = self.attributes[i]
                     response = future.result()
                     if not response.ok:
                         response_handler(
                             response, f"Error getting attribute {attr['name']} elements"
@@ -788,15 +838,15 @@
                         )
                         elements.extend(response.json())
                     # Append attribute data to the list of attributes.
                     attr_elements.append(
                         {
                             "attribute_name": attr['name'],
                             "attribute_id": attr['id'],
-                            "elements": elements
+                            "elements": elements,
                         }
                     )
                 pbar.close()
 
             return attr_elements
 
     def __fetch_attribute_elements_chunks(self, future_session, limit):
@@ -806,15 +856,16 @@
             cubes.cube_single_attribute_elements_coroutine(
                 future_session,
                 connection=self._connection,
                 cube_id=self._id,
                 attribute_id=attribute['id'],
                 offset=0,
                 limit=limit,
-            ) for attribute in self.attributes
+            )
+            for attribute in self.attributes
         ]
 
     def unpublish(self, force: bool = False) -> bool:
         """Unpublish Cube by removing all of its caches.
 
         Args:
             force: If True, then no additional prompt will be shown before
@@ -822,35 +873,39 @@
 
         Returns:
             True when all of cube's caches were deleted and it was successfully
             unpublished. False otherwise.
         """
         user_input = 'N'
         if not force:
-            user_input = input(
-                f"Are you sure you want to unpublish cube '{self.name}' with ID: "
-                f"{self._id}? This operation will delete all of its caches. "
-                f"[Y/N]: "
-            ) or 'N'
+            user_input = (
+                input(
+                    f"Are you sure you want to unpublish cube '{self.name}' with ID: "
+                    f"{self._id}? This operation will delete all of its caches. "
+                    f"[Y/N]: "
+                )
+                or 'N'
+            )
         if force or user_input == 'Y':
             all_caches_num = len(self.caches)
             deleted_caches_num = 0
             for cache in self.caches:
                 if cache.delete(True):
                     deleted_caches_num += 1
             if all_caches_num == deleted_caches_num:
                 logger.info(
-                    f"Cube '{self.name}' with ID: '{self._id}' was successfully unpublished."
+                    f"Cube '{self.name}' with ID: '{self._id}' was successfully "
+                    f"unpublished."
                 )
                 self._caches = []
                 return True
             else:
                 logger.warning(
-                    f"Cube '{self.name}' with ID: '{self._id}' was not successfully unpublished"
-                    f", because not all of its caches were deleted."
+                    f"Cube '{self.name}' with ID: '{self._id}' was not successfully "
+                    f"unpublished, because not all of its caches were deleted."
                 )
                 return False
         else:
             return False
 
     @property
     def size(self) -> int:
@@ -892,30 +947,31 @@
     def attr_elements(self) -> list:
         if not self.__definition_retrieved:
             self._get_definition()
         if not self._attr_elements and self._id:
             if self._parallel is True:
                 # TODO: move the fallback inside the function to apply
                 # per-attribute, like with non-async version.
-                self._attr_elements = fallback_on_timeout()(self.__get_attr_elements_async
-                                                            )(50000)[0]
+                self._attr_elements = fallback_on_timeout()(
+                    self.__get_attr_elements_async
+                )(50000)[0]
             else:
                 self._attr_elements = self.__get_attr_elements()
             self._filter._populate_attr_elements(self._attr_elements)
         return self._attr_elements
 
     @property
     def _filter(self):
         if not self.__definition_retrieved:
             self._get_definition()
         if self.__filter is None:
             self.__filter = Filter(
                 attributes=self._attributes,
                 metrics=self._metrics,
-                attr_elements=self._attr_elements
+                attr_elements=self._attr_elements,
             )
         return self.__filter
 
     @property
     def selected_attributes(self):
         """Selected attributes for filtering."""
         return self._filter.attr_selected
@@ -931,24 +987,24 @@
         return self._filter.attr_elem_selected
 
     @property
     def dataframe(self) -> DataFrame:
         if self._dataframe is None:
             exception_handler(
                 msg="Dataframe not loaded. Retrieve with Report.to_dataframe().",
-                exception_type=Warning
+                exception_type=Warning,
             )
         return self._dataframe
 
     @property
     def dataframes(self):
         if len(self._dataframes) == 0:
             exception_handler(
                 msg="Dataframe not loaded. Retrieve with Report.to_dataframe().",
-                exception_type=Warning
+                exception_type=Warning,
             )
         return self._dataframes
 
     @property
     def table_definition(self):
         return self._table_definition
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/datasets/cube_cache.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/datasets/cube_cache.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,15 +19,15 @@
     connection: "Connection",
     nodes: Optional[list[str] | str] = None,
     cube_id: Optional[str] = None,
     loaded: Optional[bool] = False,
     db_connection_id: Optional[str] = None,
     project_ids: Optional[list[str]] = None,
     to_dictionary: Optional[bool] = False,
-    limit: Optional[int] = None
+    limit: Optional[int] = None,
 ) -> list["CubeCache"] | list[dict]:
     """List cube caches. You can filter them by cube (`cube_id`), database
     connection (`db_connection_id`) and projects (`project_ids`). You can also
     obtain only loaded caches (`loaded=True`).
 
     You can specify from which `nodes` caches will be retrieved. If `nodes` are
     `None` then all nodes are retrieved from the cluster.
@@ -72,36 +72,42 @@
             async_api=monitors.get_cube_caches_async,
             dict_unpack_value='cubeCaches',
             node=node,
             limit=limit,
             project_ids=project_ids,
             chunk_size=1000,
             loaded=loaded,
-            filters={}
+            filters={},
         )
     if cube_id:
-        caches = [cache for cache in caches if cache.get('source', {}).get('id', '') == cube_id]
+        caches = [
+            cache
+            for cache in caches
+            if cache.get('source', {}).get('id', '') == cube_id
+        ]
     if db_connection_id:
         caches = [
-            cache for cache in caches if db_connection_id in
-            [db.get('id', '') for db in cache.get('databaseConnections', [])]
+            cache
+            for cache in caches
+            if db_connection_id
+            in [db.get('id', '') for db in cache.get('databaseConnections', [])]
         ]
     if to_dictionary:
         return caches
     else:
         return CubeCache.from_dict(connection, caches)
 
 
 def delete_cube_caches(
     connection: "Connection",
     loaded: bool = False,
     force: bool = False,
     nodes: Optional[list[str] | str] = None,
     cube_id: Optional[str] = None,
-    db_connection_id: Optional[str] = None
+    db_connection_id: Optional[str] = None,
 ) -> Optional[dict]:
     """Delete all cube caches on a given node.
 
     Optionally it is possible to specify for which cube or for which database
     connection caches will be deleted. It is also possible to delete only loaded
     caches.
 
@@ -178,15 +184,15 @@
     Manage cube cache.
     """
 
     def __init__(
         self,
         connection: "Connection",
         cache_id: str,
-        cube_cache_dict: Optional[dict] = None
+        cube_cache_dict: Optional[dict] = None,
     ):
         """Initialize the CubeCache object. If cube_cache_dict provided
         no I-Server request will be sent.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
@@ -218,16 +224,20 @@
         self._job_execution_statistics = cube_cache_dict.get('job_execution_statistics')
 
     def fetch(self):
         res = monitors.get_cube_cache_info(self._connection, self._id)
         self._init_variables(**res.json())
 
     @classmethod
-    def from_dict(cls, connection: "Connection", caches: list[dict]) -> list["CubeCache"]:
-        return [CubeCache(connection, cache_dict['id'], cache_dict) for cache_dict in caches]
+    def from_dict(
+        cls, connection: "Connection", caches: list[dict]
+    ) -> list["CubeCache"]:
+        return [
+            CubeCache(connection, cache_dict['id'], cache_dict) for cache_dict in caches
+        ]
 
     def __alter_status(self, active: bool = None, loaded: bool = None) -> str | None:
         if active is not None and loaded is not None:
             msg = 'You cannot set both states during one request'
             exception_handler(msg, UserWarning)
             return None
         res = monitors.alter_cube_cache_status(
@@ -263,18 +273,21 @@
         """
         return self._delete(self._connection, self._id, force)
 
     @staticmethod
     def _delete(connection: "Connection", id: str, force: bool = False):
         user_input = 'N'
         if not force:
-            user_input = input(
-                f"Are you sure you want to delete cube cache"
-                f"with ID: '{id}'? [Y/N]: "
-            ) or 'N'
+            user_input = (
+                input(
+                    f"Are you sure you want to delete cube cache"
+                    f"with ID: '{id}'? [Y/N]: "
+                )
+                or 'N'
+            )
         if force or user_input == 'Y':
             response = monitors.delete_cube_cache(connection, id, False)
             if response.status_code == 204:
                 if config.verbose:
                     logger.info(f"Successfully deleted cube cache with ID: '{id}'.")
                 return True
             else:
@@ -292,15 +305,17 @@
             'open_view_count': self.open_view_count,
             'creator_id': self.creator_id,
             'last_update_job': self.last_update_job,
         }
 
     def get_manipulation_status(self, manipulation_id: str) -> dict:
         """Get manipulation status of cube cache."""
-        res = monitors.get_cube_cache_manipulation_status(self._connection, manipulation_id, False)
+        res = monitors.get_cube_cache_manipulation_status(
+            self._connection, manipulation_id, False
+        )
         return res.json()['status']
 
     @property
     def state(self):
         return self._state
 
     @property
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/datasets/olap_cube.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/datasets/olap_cube.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import logging
 from typing import Optional
 
 import pandas as pd
 
 from mstrio.api import cubes
 from mstrio.connection import Connection
-from mstrio.object_management.search_operations import full_search, SearchPattern
+from mstrio.object_management.search_operations import SearchPattern, full_search
 from mstrio.utils.entity import ObjectSubTypes, ObjectTypes
 from mstrio.utils.helper import exception_handler, get_valid_project_id
 from mstrio.utils.version_helper import class_version_handler
 
 from .cube import _Cube, load_cube
 
 logger = logging.getLogger(__name__)
@@ -108,24 +108,25 @@
         selected_attributes(list): IDs of filtered attributes
         selected_metrics(list): IDs of filtered metrics
         selected_attr_elements(list): IDs of filtered attribute elements
         dataframe(object): content of a cube extracted into a
             Pandas `DataFrame`
         table_definition
     """
+
     _OBJECT_SUBTYPE = ObjectSubTypes.OLAP_CUBE.value
 
     def __init__(
         self,
         connection: Connection,
         id: str,
         name: Optional[str] = None,
         instance_id: Optional[str] = None,
         parallel: bool = True,
-        progress_bar: bool = True
+        progress_bar: bool = True,
     ):
         """Initialize an Olap Cube instance.
 
         Note:
             Parameter `name` is not used when fetching. `id` is always used to
             uniquely identify cube.
 
@@ -145,20 +146,23 @@
         # NOTE use the super.init from _Cube once cube_id is deprecated
         super().__init__(
             connection,
             id=id,
             name=name,
             instance_id=instance_id,
             parallel=parallel,
-            progress_bar=progress_bar
+            progress_bar=progress_bar,
         )
 
     @classmethod
     def available_metrics(
-        cls, connection: Connection, basic_info_only: bool = True, to_dataframe: bool = False
+        cls,
+        connection: Connection,
+        basic_info_only: bool = True,
+        to_dataframe: bool = False,
     ) -> list[dict] | list[pd.DataFrame]:
         """Get all metrics available on I-Server.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`
             basic_info_only(boolean, optional): When True (default value) only
@@ -174,15 +178,18 @@
         """
         return cls.__available_objects(
             connection, ObjectTypes.METRIC, basic_info_only, to_dataframe
         )
 
     @classmethod
     def available_attributes(
-        cls, connection: Connection, basic_info_only: bool = True, to_dataframe: bool = False
+        cls,
+        connection: Connection,
+        basic_info_only: bool = True,
+        to_dataframe: bool = False,
     ) -> list[dict] | list[pd.DataFrame]:
         """Get all attributes available on I-Server.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`
             basic_info_only(boolean, optional): When True (default value) only
@@ -198,15 +205,18 @@
         """
         return cls.__available_objects(
             connection, ObjectTypes.ATTRIBUTE, basic_info_only, to_dataframe
         )
 
     @classmethod
     def available_attribute_forms(
-        cls, connection: Connection, basic_info_only: bool = True, to_dataframe: bool = False
+        cls,
+        connection: Connection,
+        basic_info_only: bool = True,
+        to_dataframe: bool = False,
     ) -> list[dict] | list[pd.DataFrame]:
         """Get all attribute forms available on I-Server.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`
             basic_info_only(boolean, optional): When True (default value) only
@@ -226,39 +236,40 @@
 
     @classmethod
     def __available_objects(
         cls,
         connection: Connection,
         object_type: ObjectTypes | ObjectSubTypes,
         basic_info_only: bool = True,
-        to_dataframe: bool = False
+        to_dataframe: bool = False,
     ) -> list[dict] | list[pd.DataFrame]:
         """Helper function to get available objects based on their type. It
         should be used to get only available attribute, metrics or attribute
         forms."""
         connection._validate_project_selected()
         avl_objects = full_search(
-            connection=connection, object_types=object_type, project=connection.project_id
+            connection=connection,
+            object_types=object_type,
+            project=connection.project_id,
         )
         for a in avl_objects:
             new_type = None
             if a['type'] == ObjectTypes.METRIC.value:
                 new_type = 'metric'
             elif a['type'] == ObjectTypes.ATTRIBUTE.value:
                 new_type = 'attribute'
             elif a['type'] == ObjectTypes.ATTRIBUTE_FORM.value:
                 new_type = 'form'
             if new_type:
                 a['type'] = new_type
 
         if basic_info_only:
             avl_objects = [
-                {
-                    'id': a['id'], 'name': a['name'], 'type': a['type']
-                } for a in avl_objects
+                {'id': a['id'], 'name': a['name'], 'type': a['type']}
+                for a in avl_objects
             ]
         if to_dataframe:
             avl_objects = pd.DataFrame.from_dict(avl_objects)
 
         return avl_objects
 
     @classmethod
@@ -266,15 +277,15 @@
         cls,
         connection: "Connection",
         name: str,
         folder_id: str,
         description: Optional[str] = None,
         overwrite: bool = False,
         attributes: Optional[list[dict]] = None,
-        metrics: Optional[list[dict]] = None
+        metrics: Optional[list[dict]] = None,
     ) -> "OlapCube | None":
         """Create an OLAP Cube by defining its name, description, destination
         folder, attributes and metrics.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
@@ -305,17 +316,20 @@
         metrics = metrics or []
 
         if not OlapCube.__check_objects(attributes, 'attribute'):
             return None
         if not OlapCube.__check_objects(metrics, 'metric'):
             return None
 
-        definition = {'availableObjects': {'attributes': attributes, 'metrics': metrics}}
-        cube_id = cubes.create(connection, name, folder_id, overwrite, description,
-                               definition).json()['id']
+        definition = {
+            'availableObjects': {'attributes': attributes, 'metrics': metrics}
+        }
+        cube_id = cubes.create(
+            connection, name, folder_id, overwrite, description, definition
+        ).json()['id']
         return load_cube(connection, cube_id)
 
     @staticmethod
     def __check_objects(objects_: list[dict], obj_name: str) -> bool:
         """Check objects (attribute or metrics) before creation or update of an
         OLAP Cube."""
         for obj in objects_:
@@ -335,15 +349,18 @@
             msg = f"{obj_name.capitalize()} '{object_['name']}' is missing key 'id'."
             exception_handler(msg, Warning, True)
             return False
 
         if 'type' not in object_:
             object_['type'] = obj_name
         elif object_['type'] != obj_name:
-            msg = f"Each element in dictionary with {obj_name}s must be of a type '{obj_name}'."
+            msg = (
+                f"Each element in dictionary with {obj_name}s must be of a type "
+                f"'{obj_name}'."
+            )
             exception_handler(msg, Warning, True)
             return False
         return True
 
     def update(self, attributes: list[dict] = [], metrics: list[dict] = []) -> bool:
         """Update an OLAP Cube. When Cube is unpublished, then it is possible to
          add or remove attributes and metrics to/from its definition and
@@ -365,23 +382,23 @@
         Returns:
             True when update was successful. False otherwise.
 
         Raises:
             `requests.exceptions.HTTPError` when response returned from request
             to I-Server to update new OLAP Cube was not ok.
         """
-        if not OlapCube.__check_attributes_update(attributes, self.attributes, self.status):
+        if not OlapCube.__check_attributes_update(
+            attributes, self.attributes, self.status
+        ):
             return False
         if not OlapCube.__check_metrics_update(metrics, self.metrics, self.status):
             return False
 
         definition = {
-            'availableObjects': {
-                'attributes': attributes, 'metrics': metrics
-            },
+            'availableObjects': {'attributes': attributes, 'metrics': metrics},
         }
 
         res = cubes.update(self._connection, self._id, definition)
         # refresh definition of cube
         self._get_definition()
         return res.ok
 
@@ -395,44 +412,54 @@
         )
 
     @staticmethod
     def __check_metrics_update(
         metrics: list[dict], existing_metrics: list[dict], status: int
     ) -> bool:
         """Check dictionaries with metrics before update of an OLAP Cube."""
-        return OlapCube.__check_objects_update(metrics, existing_metrics, 'metric', status)
+        return OlapCube.__check_objects_update(
+            metrics, existing_metrics, 'metric', status
+        )
 
     @staticmethod
     def __check_objects_update(
-        objects_: list[dict], existing_objects: list[dict], object_name: str, status: int
+        objects_: list[dict],
+        existing_objects: list[dict],
+        object_name: str,
+        status: int,
     ) -> bool:
         """Check objects (attributes or metrics) represented as dictionaries
         before update of an OLAP Cube. When status of cube is 0, then it is not
         published and it is possible to freely add or delete objects. Otherwise
         it is possible to only rearrange existing objects. For each object it is
         done also the same check as before creation of an OLAP Cube.
         """
         existing_ids = [o['id'] for o in existing_objects]
         reorganised_objects_count = 0  # to check if all existing objects were provided
-        msg = f"It is not possible to add new {object_name}s when editing published cube."
+        msg = (
+            f"It is not possible to add new {object_name}s when editing published cube."
+        )
         for object_ in objects_:
             # check if structure of dictionary with an object is correct
             if not OlapCube.__check_object(object_, object_name):
                 return False
             # check if status of cube is correct in case of new objects
             if object_['id'] not in existing_ids:
                 if status != 0:
                     exception_handler(msg, Warning)
                     return False
             else:
                 reorganised_objects_count += 1
 
         # check if status of cube is correct in case of removing objects
         if reorganised_objects_count != len(existing_ids) and status != 0:
-            msg = f"It is not possible delete existing {object_name}s when editing published cube."
+            msg = (
+                f"It is not possible delete existing {object_name}s when editing "
+                f"published cube."
+            )
             exception_handler(msg, Warning)
             return False
 
         return True
 
     def publish(self) -> None:
         """Publish an OLAP Cube. Request to publish an OLAP Cube is an
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/datasets/super_cube.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/datasets/super_cube.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,18 +1,23 @@
 import logging
 import time
+from dataclasses import dataclass
 from typing import Optional
 
 import pandas as pd
 from tqdm.auto import tqdm
 
 from mstrio import config
 from mstrio.api import cubes, datasets
 from mstrio.connection import Connection
-from mstrio.object_management import Folder, get_predefined_folder_contents, PredefinedFolders
+from mstrio.object_management import (
+    Folder,
+    get_predefined_folder_contents,
+    PredefinedFolders,
+)
 from mstrio.object_management.search_operations import full_search, SearchPattern
 from mstrio.utils import helper
 from mstrio.utils.encoder import Encoder
 from mstrio.utils.entity import CertifyMixin, ObjectSubTypes
 from mstrio.utils.model import Model
 from mstrio.utils.version_helper import is_server_min_version
 from .cube import _Cube
@@ -86,14 +91,74 @@
         **filters,
     )
     if to_dictionary:
         return objects_
     return [SuperCube.from_dict(obj_, connection) for obj_ in objects_]
 
 
+@dataclass
+class SuperCubeFormExpression:
+    """A class representing a form expression used to define multiform
+    attributes for Super Cubes. Links an attribute form to the column
+    in the table.
+
+    Attributes:
+        table (str): name of a table
+        column (str): name of a column
+    """
+
+    table: str
+    column: str
+
+    def to_dict(self):
+        return {
+            'tableName': self.table,
+            'columnName': self.column,
+        }
+
+
+@dataclass
+class SuperCubeAttributeForm:
+    """A class representing an attribute form for used to define multiform
+    attributes for Super Cubes.
+
+    Attributes:
+        category (str): form's category
+        expressions (list[SuperCubeFormExpressions]): list of form expressions
+    """
+
+    category: str
+    expressions: list[SuperCubeFormExpression]
+
+    def to_dict(self):
+        return {
+            'category': self.category,
+            'expressions': [expr.to_dict() for expr in self.expressions],
+        }
+
+
+@dataclass
+class SuperCubeAttribute:
+    """A class representing a multiform attribute for Super Cubes.
+
+    Attributes:
+        name (str): a name of multiform attribute
+        forms (list[SuperCubeAttributeForm]): a list of attribute forms
+    """
+
+    name: str
+    forms: list[SuperCubeAttributeForm]
+
+    def to_dict(self):
+        return {
+            'name': self.name,
+            'attributeForms': [form.to_dict() for form in self.forms],
+        }
+
+
 class SuperCube(_Cube, CertifyMixin):
     """Manage multiple table cube (MTDI aka Super Cube) - according to
     EnumDSSXMLObjectSubTypes its subtype is 779 (DssXmlSubTypeReportEmmaCube).
     It inherits all properties from Cube.
 
     Attributes:
         connection: MicroStrategy connection object returned by
@@ -119,27 +184,28 @@
         selected_attributes(list): IDs of filtered attributes
         selected_metrics(list): IDs of filtered metrics
         selected_attr_elements(list): IDs of filtered attribute elements
         dataframe(object): content of a cube extracted into a
             Pandas `DataFrame`
         table_definition
     """
+
     _OBJECT_SUBTYPE = ObjectSubTypes.SUPER_CUBE.value
     __VALID_POLICY = ['add', 'update', 'replace', 'upsert']
     __MAX_DESC_LEN = 250
 
     def __init__(
         self,
         connection: Connection,
         id: Optional[str] = None,
         name: Optional[str] = None,
         description: Optional[str] = None,
         instance_id: Optional[str] = None,
         progress_bar: bool = True,
-        parallel: bool = True
+        parallel: bool = True,
     ):
         """Initialize super cube.
 
         When creating new super cube, provide its `name` and an optional
         `description`.
         When updating a pre-existing super cube, provide its `id`. This
         identifier will be then used to initialize super cube.
@@ -161,59 +227,63 @@
                 feature will be disabled.
         """
         if name is not None:
             self.__check_param_str(name, msg="Super cube name should be a string.")
             self.__check_param_len(
                 name,
                 msg=f"Super cube name should be <= {self.__MAX_DESC_LEN} characters.",
-                max_length=self.__MAX_DESC_LEN
+                max_length=self.__MAX_DESC_LEN,
             )
 
         if description is not None:
-            self.__check_param_str(description, msg="Super cube description should be a string.")
+            self.__check_param_str(
+                description, msg="Super cube description should be a string."
+            )
             self.__check_param_len(
                 description,
                 msg="Super cube description should be <= {} characters.".format(
                     self.__MAX_DESC_LEN
                 ),
-                max_length=self.__MAX_DESC_LEN
+                max_length=self.__MAX_DESC_LEN,
             )
 
         connection._validate_project_selected()
 
         if id is not None:
             super().__init__(
                 connection=connection,
                 id=id,
                 instance_id=instance_id,
                 parallel=parallel,
-                progress_bar=progress_bar
+                progress_bar=progress_bar,
             )
         else:
             self._init_variables(
                 connection=connection,
                 name=name,
                 description=description,
                 progress_bar=progress_bar,
-                parallel=parallel
+                parallel=parallel,
             )
 
     def _init_variables(self, **kwargs):
         super()._init_variables(**kwargs)
         self._tables = []
         self._session_id = None
         # used to check publish status after completing publish
         self.__last_session_id = None
         self._folder_id = None
         self.__upload_body = None
         # used to store indexes for every table after an update to have correct
         # index in case of doing multiple updates without publish
         self.__update_indexes = {}
 
-    def add_table(self, name, data_frame, update_policy, to_metric=None, to_attribute=None):
+    def add_table(
+        self, name, data_frame, update_policy, to_metric=None, to_attribute=None
+    ):
         """Add a `Pandas.DataFrame` to a collection of tables which are later
         used to populate the MicroStrategy super cube with data.
 
         Args:
             name (str): Logical name of the table that is visible to users of
                 the super cube in MicroStrategy.
             data_frame (:obj:`pandas.DataFrame`): Pandas DataFrame to add or
@@ -233,39 +303,48 @@
             to_attribute (optional, :obj:`list` of str): Logical opposite of
                 `to_metric`. Helpful for formatting an integer-based row
                 identifier as a primary key in the super cube.
         """
         update_policy = update_policy.lower()
 
         if not isinstance(data_frame, pd.DataFrame):
-            raise TypeError("`data_frame` parameter must be a valid `Pandas.DataFrame`.")
+            raise TypeError(
+                "`data_frame` parameter must be a valid `Pandas.DataFrame`."
+            )
         if not helper.check_duplicated_column_names(data_frame):
             raise ValueError(
-                "`DataFrame` column names need to be unique for each table in the super cube."
+                "`DataFrame` column names need to be unique for each table in the super"
+                " cube."
             )
         self.__check_update_policy(update_policy)
         if to_attribute and to_metric and any(col in to_attribute for col in to_metric):
             raise ValueError(
                 "Column name(s) present in `to_attribute` also present in `to_metric`."
             )
 
-        table = {"table_name": name, "data_frame": data_frame, "update_policy": update_policy}
+        table = {
+            "table_name": name,
+            "data_frame": data_frame,
+            "update_policy": update_policy,
+        }
 
         if to_attribute is not None:
             if any(col for col in to_attribute if col not in data_frame.columns):
                 raise ValueError(
-                    "Column name(s) in `to_attribute` were not found in `DataFrame.columns`."
+                    "Column name(s) in `to_attribute` were not found in"
+                    " `DataFrame.columns`."
                 )
             else:
                 table["to_attribute"] = to_attribute
 
         if to_metric is not None:
             if any(col for col in to_metric if col not in data_frame.columns):
                 raise ValueError(
-                    "Column name(s) in `to_metric` were not found in `DataFrame.columns`."
+                    "Column name(s) in `to_metric` were not found in"
+                    " `DataFrame.columns`."
                 )
             else:
                 table["to_metric"] = to_metric
 
         self._tables.append(table)
         if not self.__update_indexes.get(name):
             self.__update_indexes[name] = 0
@@ -299,29 +378,31 @@
         else:
             contents = get_predefined_folder_contents(
                 self.connection, PredefinedFolders.PROFILE_REPORTS, name=name
             )
 
         if contents:
             raise ValueError(
-                f"Super Cube with name {self.name} already exist in {folder_id or 'My Reports'} "
-                "folder. If you want to override already existing cube, add tables with "
-                "update policy `replace` and call 'create()' method with argument 'force=True'."
+                f"Super Cube with name {self.name} already exist in"
+                f" {folder_id or 'My Reports'} folder. If you want to override already"
+                " existing cube, add tables with update policy `replace` and call"
+                " 'create()' method with argument 'force=True'."
             )
 
     def __are_all_tables_with_replace_policy(self):
         return all(table['update_policy'] == 'replace' for table in self.tables)
 
     def create(
         self,
         folder_id: Optional[str] = None,
         auto_upload: bool = True,
         auto_publish: bool = True,
         chunksize: int = 100000,
-        force: bool = False
+        force: bool = False,
+        attribute_forms: Optional[list[SuperCubeAttribute]] = None,
     ) -> None:
         """Create a new super cube and initialize cube object after successful
         creation. This function does not return new super cube, but it updates
         object inplace.
 
         Args:
             folder_id (str, optional): ID of the shared folder in which the
@@ -335,18 +416,27 @@
                 creates the super cube but does not publish it. To publish the
                 super cube, data has to be uploaded first.
             chunksize (int, optional): Number of rows to transmit to the
                 I-Server with each request when uploading.
             force (bool, optional): If True, skip checking if a super cube
                 already exist in the folder with the given name.
                 Defaults to False.
+            attribute_forms (list[SuperCubeAttribute], optional): list
+            of instances of SuperCubeAttribute, that links tables' columns to
+            different forms of the same attribute. If this argugment is not
+            provided, a separate attribute is created for every distinct column
+            name. If it is proveded, it contain mapping of columns to
+            attributes as different form of an attribute. For all columns that
+            are not part of any attribute's form expression, seprate attribute
+            will be created.
         """
         if auto_publish and not auto_upload:
             raise ValueError(
-                "Data needs to be uploaded to the I-Server before the super cube can be published."
+                "Data needs to be uploaded to the I-Server before the super cube can be"
+                " published."
             )
 
         if folder_id is not None:
             self._folder_id = folder_id
         else:
             self._folder_id = ""
 
@@ -355,29 +445,31 @@
 
         if (
             force
             and is_server_min_version(self.connection, '11.2.0300')
             and not self.__are_all_tables_with_replace_policy()
         ):
             raise ValueError(
-                "All the tables must be added with update policy 'replace', when trying to "
-                "override existing Super Cube with 'force=True'."
+                "All the tables must be added with update policy 'replace', when trying"
+                " to override existing Super Cube with 'force=True'."
             )
 
         # generate model of the super cube
-        self.__build_model()
+        self.__build_model(attribute_forms)
 
         # makes request to create the super cube
         response = datasets.create_multitable_dataset(
             connection=self._connection, body=self.__model
         )
         self._set_object_attributes(**response.json())
 
         if config.verbose:
-            logger.info("Created super cube '{}' with ID: '{}'.".format(*[self.name, self._id]))
+            logger.info(
+                "Created super cube '{}' with ID: '{}'.".format(*[self.name, self._id])
+            )
 
         if auto_upload:
             self.update(chunksize=chunksize, auto_publish=auto_publish)
 
         # after creating super cube fetch definition and create filter object
         self._get_definition()
 
@@ -401,19 +493,18 @@
             )
             response_json = response.json()
             self._session_id = response_json['uploadSessionId']
             self.__last_session_id = None
 
         # upload each table
         for ix, _table in enumerate(self._tables):
-
             _df, _name = _table["data_frame"], _table["table_name"]
 
             # break the data up into chunks using a generator
-            chunks = (_df[i:i + chunksize] for i in range(0, _df.shape[0], chunksize))
+            chunks = (_df[i : i + chunksize] for i in range(0, _df.shape[0], chunksize))
 
             total = _df.shape[0]
 
             # Count the number of iterations
             it_total = int(total / chunksize) + (total % chunksize != 0)
 
             pbar = tqdm(chunks, total=it_total, disable=(not self._progress_bar))
@@ -433,21 +524,23 @@
 
                 # make request to upload the data
                 response = datasets.upload(
                     connection=self._connection,
                     id=self._id,
                     session_id=self._session_id,
                     body=body,
-                    throw_error=False
+                    throw_error=False,
                 )
 
                 if not response.ok:
                     # on error, cancel the previously uploaded data
                     datasets.publish_cancel(
-                        connection=self._connection, id=self._id, session_id=self._session_id
+                        connection=self._connection,
+                        id=self._id,
+                        session_id=self._session_id,
                     )
                     self.reset_session()
                     pbar.close()
                     return
 
                 pbar.set_postfix(rows=min((index + 1) * chunksize, total))
             pbar.close()
@@ -462,15 +555,15 @@
             self.publish()
 
     def save_as(
         self,
         name: str,
         description: Optional[str] = None,
         folder_id: Optional[str] = None,
-        table_name: Optional[str] = None
+        table_name: Optional[str] = None,
     ) -> "SuperCube":
         """Creates a new single-table cube with the data frame stored in the
         SuperCube instance `SuperCube.dataframe`.
 
         Args:
             name(str): Name of cube.
             description(str): Description of the cube.
@@ -478,26 +571,29 @@
                 cube should be created within. If `None`, defaults to the user's
                 My Reports folder.
             table_name (str, optional): Name of the table. If None (default),
                 the first table name of the original cube will be used.
         """
         if len(self._table_names) > 1:
             helper.exception_handler(
-                msg="""This feature works only for the single-table cubes.
-                                            \rTo export multi-table cube use `create` method."""
+                msg="This feature works only for the single-table cubes. "
+                "To export multi-table cube use `create` method."
             )
         elif self._dataframe is None:
             raise ValueError(
-                "Current cube has to be fetched with `to_dataframe` method first to create a copy."
+                "Current cube has to be fetched with `to_dataframe` method first to"
+                " create a copy."
             )
         else:
             if table_name is None:
                 table_name = self._table_names[0]["name"]
             new_cube = SuperCube(self._connection, name=name, description=description)
-            new_cube.add_table(name=table_name, data_frame=self.dataframe, update_policy="replace")
+            new_cube.add_table(
+                name=table_name, data_frame=self.dataframe, update_policy="replace"
+            )
             new_cube.create(folder_id=folder_id)
             return new_cube
 
     def publish(self) -> bool:
         """Publish the uploaded data to the selected super cube.
 
         Note:
@@ -537,15 +633,17 @@
             In the 'status' key, "1" denotes completion.
         """
         # after publish, `self._session_id` is reset to force new session
         # creation in the next update, so we have to use its value saved in
         # `self.__last_session_id`
         session_id = self._session_id if self._session_id else self.__last_session_id
 
-        return self.upload_status(connection=self.connection, id=self.id, session_id=session_id)
+        return self.upload_status(
+            connection=self.connection, id=self.id, session_id=session_id
+        )
 
     def reset_session(self):
         """Reset upload session."""
         if self._session_id:
             # save last session id in case of checking status of publish
             self.__last_session_id = self._session_id
             # clear session_id to force new session creation
@@ -558,38 +656,40 @@
         Returns:
             SQL View of a Super Cube.
         """
         res = cubes.get_sql_view(self._connection, self._id)
         sql_statement = res.json()['sqlStatement']
         return sql_statement
 
-    def __build_model(self):
+    def __build_model(self, attr_forms_mapping: list[SuperCubeAttribute] = None):
         """Create json representation of the super cube."""
 
         # generate model
         model = Model(
             tables=self._tables,
             name=self.name,
             description=self.description,
-            folder_id=self._folder_id
+            folder_id=self._folder_id,
+            attr_forms_mapping=attr_forms_mapping,
         )
         self.__model = model.get_model()
 
     def __form_upload_body(self):
         """Form request body for creating an upload session for data
         uploads."""
 
         # generate body string
         body = {
             "tables": [
                 {
                     "name": tbl["table_name"],
                     "updatePolicy": tbl["update_policy"],
-                    "columnHeaders": list(tbl["data_frame"].columns)
-                } for tbl in self._tables
+                    "columnHeaders": list(tbl["data_frame"].columns),
+                }
+                for tbl in self._tables
             ]
         }
         self.__upload_body = body
 
     @staticmethod
     def upload_status(connection: Connection, id: str, session_id: str):
         """Check the status of data that was uploaded to a super cube.
@@ -604,15 +704,17 @@
         Returns:
             status: The status of the publication process as a dictionary. In
                 the 'status' key, "1" denotes completion.
         """
         if not session_id:
             raise AttributeError("No upload session created.")
         else:
-            response = datasets.publish_status(connection=connection, id=id, session_id=session_id)
+            response = datasets.publish_status(
+                connection=connection, id=id, session_id=session_id
+            )
             return response.json()
 
     @staticmethod
     def __check_param_len(param, msg, max_length):
         if len(param) > max_length:
             raise ValueError(msg)
         else:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/document.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/document.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,42 +1,54 @@
 import logging
+from functools import partial
 from typing import Optional
 
-from pandas import concat, DataFrame
+from pandas import DataFrame, concat
 
 from mstrio import config
 from mstrio.api import documents, library, objects
 from mstrio.api.schedules import get_contents_schedule
 from mstrio.connection import Connection
 from mstrio.distribution_services.schedule import Schedule
-from mstrio.object_management import Folder, search_operations, SearchPattern
+from mstrio.object_management import Folder, SearchPattern, search_operations
 from mstrio.project_objects import OlapCube, SuperCube
 from mstrio.server.environment import Environment
 from mstrio.types import ObjectSubTypes
 from mstrio.users_and_groups import User, UserGroup, UserOrGroup
 from mstrio.utils import helper
 from mstrio.utils.cache import CacheSource, ContentCacheMixin
 from mstrio.utils.certified_info import CertifiedInfo
-from mstrio.utils.entity import CopyMixin, DeleteMixin, Entity, MoveMixin, ObjectTypes, VldbMixin
-from mstrio.utils.helper import filter_params_for_func, get_valid_project_id, IServerError
-from mstrio.utils.helper import is_document
+from mstrio.utils.entity import (
+    CopyMixin,
+    DeleteMixin,
+    Entity,
+    MoveMixin,
+    ObjectTypes,
+    VldbMixin,
+)
+from mstrio.utils.helper import (
+    IServerError,
+    filter_params_for_func,
+    get_valid_project_id,
+    is_document,
+)
 from mstrio.utils.version_helper import method_version_handler
 
 logger = logging.getLogger(__name__)
 
 
 def list_documents(
     connection: Connection,
     to_dictionary: bool = False,
     to_dataframe: bool = False,
     limit: Optional[int] = None,
     name: Optional[str] = None,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
-    **filters
+    **filters,
 ) -> list["Document"] | list[dict] | DataFrame:
     """Get all Documents available in the project specified within the
     `connection` object.
 
     Optionally use `to_dictionary` or `to_dataframe` to choose output format.
     If `to_dictionary` is True, `to_dataframe` is omitted.
 
@@ -64,25 +76,25 @@
         connection,
         to_dictionary=to_dictionary,
         name=name,
         limit=limit,
         to_dataframe=to_dataframe,
         project_id=project_id,
         project_name=project_name,
-        **filters
+        **filters,
     )
 
 
 def list_documents_across_projects(
     connection: Connection,
     name: Optional[str] = None,
     to_dictionary: bool = False,
     to_dataframe: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> list["Document"] | list[dict] | DataFrame:
     """Get all Documents stored on the server.
 
     Optionally use `to_dictionary` or `to_dataframe` to choose output format.
     If `to_dictionary` is True, `to_dataframe` is omitted.
 
     Args:
@@ -120,57 +132,66 @@
 
         docs = Document._list_all(
             connection,
             to_dictionary=to_dictionary,
             name=name,
             limit=limit,
             to_dataframe=to_dataframe,
-            **filters
+            **filters,
         )
         if to_dataframe:
             output = concat([output, docs], ignore_index=True)
         else:
             output.extend(docs)
 
     connection.select_project(project_id=project_id_before)
     return output[:limit]
 
 
 class Document(Entity, VldbMixin, CopyMixin, MoveMixin, DeleteMixin, ContentCacheMixin):
-    """ Python representation of MicroStrategy Document object
+    """Python representation of MicroStrategy Document object
 
     _CACHE_TYPE is a variable used by ContentCache class for cache filtering
     purposes.
     """
 
     _OBJECT_TYPE = ObjectTypes.DOCUMENT_DEFINITION
     _CACHE_TYPE = CacheSource.Type.DOCUMENT
     _API_GETTERS = {**Entity._API_GETTERS, 'recipients': library.get_document}
-    _API_PATCH = {('name', 'description', 'folder_id'): (objects.update_object, 'partial_put')}
+    _API_PATCH = {
+        ('name', 'description', 'folder_id'): (objects.update_object, 'partial_put')
+    }
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'owner': User.from_dict,
         'certified_info': CertifiedInfo.from_dict,
-        'recipients': [User.from_dict]
+        'recipients': [User.from_dict],
     }
 
     def __init__(
-        self, connection: Connection, name: Optional[str] = None, id: Optional[str] = None
+        self,
+        connection: Connection,
+        name: Optional[str] = None,
+        id: Optional[str] = None,
     ):
         """Initialize Document object by passing name or id.
 
         Args:
             connection (object): MicroStrategy connection object returned
                 by `connection.Connection()`
             name (string, optional): name of Document
             id (string, optional): ID of Document
         """
         if id is None:
             document = super()._find_object_with_name(
-                connection=connection, name=name, listing_function=self._list_all
+                connection=connection,
+                name=name,
+                listing_function=partial(
+                    self._list_all, search_pattern=SearchPattern.EXACTLY
+                ),
             )
             id = document['id']
         super().__init__(connection=connection, object_id=id, name=name)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self._instance_id = ""
@@ -198,23 +219,23 @@
             'date_modified': self.date_modified,
             'instance_id': self.instance_id,
             'owner': self.owner,
             'recipients': self.recipients,
             'version': self.version,
             'template_info': self.template_info,
             'acg': self.acg,
-            'acl': self.acl
+            'acl': self.acl,
         }
         return properties
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
-        folder_id: Optional[Folder | str] = None
+        folder_id: Optional[Folder | str] = None,
     ):
         """Alter Document name, description and/or folder id.
 
         Args:
             name (string, optional): new name of the Document
             description (string, optional): new description of the Document
             folder_id (string | Folder, optional): A globally unique identifier
@@ -253,15 +274,17 @@
             recipients = [self.connection.user_id]
         elif all([isinstance(el, User) for el in recipients]):
             recipients = [recipient.id for recipient in recipients]
         elif all([isinstance(el, UserGroup) for el in recipients]):
             users = [user for group in recipients for user in group.members]
             recipients = [user["id"] for user in users]
         elif any([not isinstance(el, str) for el in recipients]):
-            raise ValueError('Please provide either list of User, UserGroup or str elements.')
+            raise ValueError(
+                'Please provide either list of User, UserGroup or str elements.'
+            )
         for recipient in recipients:
             if not self.__validate_user(recipient):
                 recipients.remove(recipient)
         body = {'id': self.id, 'recipients': recipients}
         library.publish_document(self.connection, body)
         self.fetch(attr='recipients')
 
@@ -284,43 +307,43 @@
             if all([isinstance(el, User) for el in recipients]):
                 recipients = [recipient.id for recipient in recipients]
             elif all([isinstance(el, UserGroup) for el in recipients]):
                 users = [user for group in recipients for user in group.members]
                 recipients = [user["id"] for user in users]
             elif any([not isinstance(el, str) for el in recipients]):
                 raise ValueError(
-                    'Please provide either list User and UserGroup elements or str elements.'
+                    'Please provide either list User and UserGroup elements or str '
+                    'elements.'
                 )
             for user_id in recipients:
                 if self.__validate_user(user_id):
                     library.unpublish_document_for_user(
                         self.connection, document_id=self.id, user_id=user_id
                     )
         self.fetch(attr='recipients')
 
     @method_version_handler('11.3.0600')
-    def list_available_schedules(self,
-                                 to_dictionary: bool = False) -> list["Schedule"] | list[dict]:
+    def list_available_schedules(
+        self, to_dictionary: bool = False
+    ) -> list["Schedule"] | list[dict]:
         """Get a list of schedules available for the object instance.
 
         Args:
             to_dictionary (bool, optional): If True returns a list of
                 dictionaries, otherwise returns a list of Schedules.
                 False by default.
 
         Returns:
             List of Schedule objects or list of dictionaries.
         """
         schedules_list_response = (
             get_contents_schedule(
                 connection=self.connection,
                 project_id=self.connection.project_id,
-                body={
-                    'id': self.id, 'type': 'document'
-                }
+                body={'id': self.id, 'type': 'document'},
             ).json()
         ).get('schedules')
         if to_dictionary:
             return schedules_list_response
         else:
             return [
                 Schedule.from_dict(connection=self.connection, source=schedule_id)
@@ -344,21 +367,21 @@
         search_pattern: SearchPattern | int = SearchPattern.CONTAINS,
         name: Optional[str] = None,
         to_dictionary: bool = False,
         to_dataframe: bool = False,
         limit: Optional[int] = None,
         project_id: Optional[str] = None,
         project_name: Optional[str] = None,
-        **filters
+        **filters,
     ) -> list["Document"] | list[dict] | DataFrame:
-
         if to_dictionary and to_dataframe:
             helper.exception_handler(
-                "Please select either `to_dictionary=True` or `to_dataframe=True`, but not both.",
-                ValueError
+                "Please select either `to_dictionary=True` or `to_dataframe=True`, but "
+                "not both.",
+                ValueError,
             )
         project_id = get_valid_project_id(
             connection=connection,
             project_id=project_id,
             project_name=project_name,
             with_fallback=False if project_name else True,
         )
@@ -367,17 +390,15 @@
             connection,
             object_types=ObjectSubTypes.REPORT_WRITING_DOCUMENT,
             project=project_id,
             name=name,
             pattern=search_pattern,
             **filters,
         )
-        documents = [
-            obj for obj in objects if is_document(obj['view_media'])
-        ]
+        documents = [obj for obj in objects if is_document(obj['view_media'])]
 
         documents = documents[:limit] if limit else documents
 
         if to_dictionary:
             return documents
         elif to_dataframe:
             return DataFrame(documents)
@@ -405,17 +426,19 @@
             )
             self._instance_id = response.json()['mid']
         return self._instance_id
 
     @property
     def folder_id(self):
         if not self._folder_id:
-            self._folder_id = next(
-                folder['id'] for folder in self.ancestors if folder['level'] == 1
-            ) if self.ancestors else None
+            self._folder_id = (
+                next(folder['id'] for folder in self.ancestors if folder['level'] == 1)
+                if self.ancestors
+                else None
+            )
         return self._folder_id
 
     @property
     def recipients(self):
         return self._recipients
 
     @property
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/dossier.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/dossier.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,38 +1,37 @@
-from dataclasses import dataclass
 import logging
+from dataclasses import dataclass
 from typing import Optional
 
-from pandas import concat, DataFrame
+from pandas import DataFrame, concat
 
 from mstrio import config
 from mstrio.api import documents
 from mstrio.connection import Connection
-from mstrio.object_management import Folder, search_operations, SearchPattern
+from mstrio.object_management import Folder, SearchPattern, search_operations
 from mstrio.project_objects.document import Document
 from mstrio.server.environment import Environment
 from mstrio.types import ObjectSubTypes
 from mstrio.users_and_groups import UserOrGroup
 from mstrio.utils import helper
 from mstrio.utils.cache import CacheSource
-from mstrio.utils.helper import Dictable, get_valid_project_id
-from mstrio.utils.helper import is_dossier
+from mstrio.utils.helper import Dictable, get_valid_project_id, is_dossier
 
 logger = logging.getLogger(__name__)
 
 
 def list_dossiers(
     connection: Connection,
     name: Optional[str] = None,
     to_dictionary: bool = False,
     to_dataframe: bool = False,
     limit: Optional[int] = None,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
-    **filters
+    **filters,
 ) -> list["Dossier"] | list[dict] | DataFrame:
     """Get all Dossiers stored on the server.
 
     Optionally use `to_dictionary` or `to_dataframe` to choose output format.
     If `to_dictionary` is True, `to_dataframe` is omitted.
 
     Args:
@@ -59,25 +58,25 @@
         connection,
         to_dictionary=to_dictionary,
         name=name,
         limit=limit,
         to_dataframe=to_dataframe,
         project_id=project_id,
         project_name=project_name,
-        **filters
+        **filters,
     )
 
 
 def list_dossiers_across_projects(
     connection: Connection,
     name: Optional[str] = None,
     to_dictionary: bool = False,
     to_dataframe: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> list["Dossier"] | list[dict] | DataFrame:
     """Get all Dossiers stored on the server.
 
     Optionally use `to_dictionary` or `to_dataframe` to choose output format.
     If `to_dictionary` is True, `to_dataframe` is omitted.
 
     Args:
@@ -114,15 +113,15 @@
             continue
         dossiers = Dossier._list_all(
             connection,
             to_dictionary=to_dictionary,
             name=name,
             limit=limit,
             to_dataframe=to_dataframe,
-            **filters
+            **filters,
         )
 
         if to_dataframe:
             output = concat([output, dossiers], ignore_index=True)
         else:
             output.extend(dossiers)
 
@@ -130,26 +129,31 @@
     return output[:limit]
 
 
 class Dossier(Document):
     _CACHE_TYPE = CacheSource.Type.DOSSIER
 
     _API_GETTERS = {
-        **Document._API_GETTERS, ('chapters', 'current_chapter'): documents.get_dossier_hierarchy
+        **Document._API_GETTERS,
+        ('chapters', 'current_chapter'): documents.get_dossier_hierarchy,
     }
     _FROM_DICT_MAP = {
         **Document._FROM_DICT_MAP,
         'chapters': (
-            lambda source,
-            connection: [DossierChapter.from_dict(content, connection) for content in source]
-        )
+            lambda source, connection: [
+                DossierChapter.from_dict(content, connection) for content in source
+            ]
+        ),
     }
 
     def __init__(
-        self, connection: Connection, name: Optional[str] = None, id: Optional[str] = None
+        self,
+        connection: Connection,
+        name: Optional[str] = None,
+        id: Optional[str] = None,
     ):
         """Initialize Dossier object by passing name or id.
 
         Args:
             connection (object): MicroStrategy connection object returned
                 by `connection.Connection()`
             name (string, optional): name of Dossier
@@ -169,61 +173,65 @@
         search_pattern: SearchPattern | int = SearchPattern.CONTAINS,
         name: Optional[str] = None,
         to_dictionary: bool = False,
         to_dataframe: bool = False,
         limit: Optional[int] = None,
         project_id: Optional[str] = None,
         project_name: Optional[str] = None,
-        **filters
+        **filters,
     ) -> list["Dossier"] | list[dict] | DataFrame:
-
         if to_dictionary and to_dataframe:
             helper.exception_handler(
-                "Please select either to_dictionary=True or to_dataframe=True, but not both.",
-                ValueError
+                "Please select either to_dictionary=True or to_dataframe=True, but not "
+                "both.",
+                ValueError,
             )
         project_id = get_valid_project_id(
             connection=connection,
             project_id=project_id,
             project_name=project_name,
-            with_fallback=False if project_name else True
+            with_fallback=False if project_name else True,
         )
 
         objects = search_operations.full_search(
             connection,
             object_types=ObjectSubTypes.REPORT_WRITING_DOCUMENT,
             project=project_id,
             name=name,
             pattern=search_pattern,
             **filters,
         )
-        dossiers = [
-            obj for obj in objects if is_dossier(obj['view_media'])
-        ]
+        dossiers = [obj for obj in objects if is_dossier(obj['view_media'])]
         dossiers = dossiers[:limit]
 
         if to_dictionary:
             return dossiers
         elif to_dataframe:
             return DataFrame(dossiers)
         else:
-            return [cls.from_dict(source=dossier, connection=connection) for dossier in dossiers]
+            return [
+                cls.from_dict(source=dossier, connection=connection)
+                for dossier in dossiers
+            ]
 
     def list_properties(self) -> dict:
         """List properties for the dossier."""
         properties = super().list_properties()
-        additional_values = {'chapters': self.chapters, 'current_chapter': self.current_chapter}
+        additional_values = {
+            'chapters': self.chapters,
+            'current_chapter': self.current_chapter,
+        }
         properties.update(additional_values)
         return properties
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
-        folder_id: Optional[Folder | str] = None
+        folder_id: Optional[Folder | str] = None,
     ):
         """Alter Dossier name, description and/or folder id.
 
         Args:
             name (string, optional): new name of the Dossier
             description (string, optional): new description of the Dossier
             folder_id (string | Folder, optional): A globally unique identifier
@@ -280,14 +288,15 @@
     """Object that describes a Visualization Selector
 
     Attributes:
         visualization_key (string): key/id of the selector
         selector_type (string): type of the selector
         current_selection (dict): current selection of the selector
         targets (list[dict], optional): list of the selector's targets"""
+
     visualization_key: str
     selector_type: str
     current_selection: dict
     targets: Optional[list[dict]] = None
 
     def list_properties(self, camel_case=True) -> dict:
         """Lists properties of visualization selector."""
@@ -309,14 +318,15 @@
             defaults to False
         display_style (string, optional): style of the selector display
         available_object_items (list[dict], optional): list of objects available
             for the selector
         targets (list[dict], optional): list of targets of the selector
         name (string, optional): name of the selector
         summary (string, optional): summary of the selector"""
+
     key: str
     selector_type: str
     current_selection: dict
     source: Optional[dict] = None
     multi_selection_allowed: bool = False
     has_all_option: bool = False
     display_style: Optional[str] = None
@@ -362,15 +372,16 @@
         visualizations (list[PageVisualization]): list of visualizations on the
             page
         name (string, optional): name of the page
         selectors (list[PageSelector], optional): list of selectors on the
             page"""
 
     _FROM_DICT_MAP = {
-        'visualizations': [PageVisualization.from_dict], 'selectors': [PageSelector.from_dict]
+        'visualizations': [PageVisualization.from_dict],
+        'selectors': [PageSelector.from_dict],
     }
 
     key: str
     visualizations: list[PageVisualization]
     name: Optional[str] = None
     selectors: Optional[list[PageSelector]] = None
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/incremental_refresh_report/advanced_properties.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/incremental_refresh_report/advanced_properties.py`

 * *Files 2% similar despite different names*

```diff
@@ -119,23 +119,29 @@
     attribute_join_types: Optional[dict] = None
 
     def to_dict(self, camel_case: bool = True) -> dict:
         result = {
             'vldb_properties': {
                 key: value.to_dict(camel_case)
                 for key, value in self.vldb_properties.items()
-            } if self.vldb_properties else None,
+            }
+            if self.vldb_properties
+            else None,
             'metric_join_types': {
                 key: value.to_dict(camel_case)
                 for key, value in self.metric_join_types.items()
-            } if self.metric_join_types else None,
+            }
+            if self.metric_join_types
+            else None,
             'attribute_join_types': {
                 key: value.to_dict(camel_case)
                 for key, value in self.attribute_join_types.items()
-            } if self.attribute_join_types else None,
+            }
+            if self.attribute_join_types
+            else None,
         }
 
         return (
             snake_to_camel(result, whitelist=self._KEEP_CAMEL_CASE)
             if camel_case
             else result
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/incremental_refresh_report/incremental_refresh_report.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/incremental_refresh_report/incremental_refresh_report.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,24 @@
-from enum import auto
 import logging
+from enum import auto
+from functools import partial
 from typing import Optional, Type
 
 import pandas as pd
 
 from mstrio.api import incremental_refresh_reports as refresh_api
 from mstrio.api import objects
 from mstrio.connection import Connection
 from mstrio.modeling import (
     Expression,
     ExpressionFormat,
     ObjectSubType,
     SchemaObjectReference,
 )
-from mstrio.object_management import Folder, full_search
+from mstrio.object_management import Folder, SearchPattern, full_search
 from mstrio.project_objects import OlapCube
 from mstrio.project_objects.incremental_refresh_report import (
     AdvancedProperties,
     Template,
 )
 from mstrio.types import ObjectSubTypes, ObjectTypes
 from mstrio.utils.entity import CopyMixin, DeleteMixin, Entity, MoveMixin
@@ -26,38 +27,40 @@
     delete_none_values,
     filter_params_for_func,
     get_objects_id,
     get_valid_project_id,
 )
 from mstrio.utils.parser import Parser
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
-from mstrio.utils.wip import module_wip, WipLevels
+from mstrio.utils.wip import WipLevels, module_wip
 
 logger = logging.getLogger(__name__)
 
 module_wip(globals(), level=WipLevels.WARNING)
 
 
 @method_version_handler('11.3.0600')
 def list_incremental_refresh_reports(
     connection: Connection,
     name: Optional[str] = None,
+    pattern: SearchPattern | int = SearchPattern.CONTAINS,
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
     folder_id: Optional[str] = None,
     filters: Optional[dict] = None,
     show_expression_as: ExpressionFormat | str = ExpressionFormat.TREE,
     show_filter_tokens: bool = False,
     show_advanced_properties: bool = False,
 ) -> list[Type['IncrementalRefreshReport']] | list[dict]:
     return IncrementalRefreshReport.list(
         connection,
         name,
+        pattern,
         project_id,
         project_name,
         to_dictionary,
         limit,
         folder_id,
         filters,
         show_expression_as,
@@ -166,15 +169,17 @@
         show_filter_tokens: bool = False,
         show_advanced_properties: bool = False,
     ):
         connection._validate_project_selected()
 
         if id is None:
             reports = super()._find_object_with_name(
-                connection=connection, name=name, listing_function=self.list
+                connection=connection,
+                name=name,
+                listing_function=partial(self.list, pattern=SearchPattern.EXACTLY),
             )
             id = reports['id']
 
         super().__init__(
             connection=connection,
             object_id=id,
             show_expression_as=show_expression_as,
@@ -251,23 +256,24 @@
             id=self.id,
             project_id=project_id,
             fields=fields,
         )
 
         if response.ok:
             logger.info(
-                f"Execution of Incremental Refresh Report: '{self.name}' has been successfully "
-                f"scheduled under job: {response.json()}."
+                f"Execution of Incremental Refresh Report: '{self.name}' has been "
+                f"successfully scheduled under job: {response.json()}."
             )
 
     @classmethod
     def list(
         cls,
         connection: Connection,
         name: Optional[str] = None,
+        pattern: SearchPattern | int = SearchPattern.CONTAINS,
         project_id: Optional[str] = None,
         project_name: Optional[str] = None,
         to_dictionary: bool = False,
         limit: Optional[int] = None,
         folder_id: Optional[str] = None,
         filters: Optional[dict] = None,
         show_expression_as: ExpressionFormat | str = ExpressionFormat.TREE,
@@ -286,14 +292,15 @@
             filters = filters | {'root': folder_id}
 
         objects = full_search(
             connection,
             object_types=ObjectSubTypes.INCREMENTAL_REFRESH_REPORT,
             project=project_id,
             name=name,
+            pattern=pattern,
             limit=limit,
             **filters,
         )
 
         if to_dictionary:
             return objects
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/incremental_refresh_report/template.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/incremental_refresh_report/template.py`

 * *Files 0% similar despite different names*

```diff
@@ -23,15 +23,14 @@
     CONSOLIDATION = auto()
     PROMPT = auto()
     RAW_UNIT = auto()
 
 
 @dataclass
 class TemplateUnit(Dictable):
-
     _TYPE = None
 
     @staticmethod
     def dispatch(
         source, connection: Optional[Connection] = None
     ) -> Type['TemplateUnit']:
         data = source.copy()
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/library.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/library.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,14 @@
 from mstrio.connection import Connection
 
 if TYPE_CHECKING:
     from mstrio.project_objects.dossier import Dossier
 
 
 class Library:
-
     def __init__(
         self,
         connection: Connection,
         project_id: Optional[str] = None,
         project_name: Optional[str] = None,
     ):
         self.connection = connection
```

### Comparing `mstrio-py-11.3.9.101/mstrio/project_objects/report.py` & `mstrio-py-11.3.9.103/mstrio/project_objects/report.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,24 +17,24 @@
 from mstrio.utils.entity import (
     CertifyMixin,
     CopyMixin,
     DeleteMixin,
     Entity,
     MoveMixin,
     ObjectTypes,
-    ObjectSubTypes
+    ObjectSubTypes,
 )
 from mstrio.utils.filter import Filter
 from mstrio.utils.helper import (
     exception_handler,
     fallback_on_timeout,
     get_parallel_number,
     get_valid_project_id,
     response_handler,
-    sort_object_properties
+    sort_object_properties,
 )
 from mstrio.utils.parser import Parser
 from mstrio.utils.sessions import FuturesSessionWithRenewal
 
 
 def list_reports(
     connection: Connection,
@@ -102,23 +102,24 @@
         name=name,
         pattern=search_pattern,
         limit=limit,
         root=folder_id,
         **filters,
     )
     reports = [
-        item for item in objects_
-        if Report._is_subtype_supported(item['subtype'])
+        item for item in objects_ if Report._is_subtype_supported(item['subtype'])
     ]
     if to_dictionary:
         return reports
     return [Report.from_dict(report_dict, connection) for report_dict in reports]
 
 
-class Report(Entity, CertifyMixin, CopyMixin, MoveMixin, DeleteMixin, ContentCacheMixin):
+class Report(
+    Entity, CertifyMixin, CopyMixin, MoveMixin, DeleteMixin, ContentCacheMixin
+):
     """Access, filter, publish, and extract data from in-memory reports.
 
     Create a Report object to load basic information on a report dataset.
     Specify subset of report to be fetched through `Report.apply_filters()` and
     `Report.clear_filters()`. Fetch dataset through `Report.to_dataframe()`
     method.
 
@@ -152,14 +153,15 @@
         selected_attributes: IDs of filtered attributes
         selected_metrics: IDs of filtered metrics
         selected_attr_elements: IDs of filtered attribute elements
         dataframe: content of a report extracted into a Pandas `DataFrame`
         acg: Access rights (See EnumDSSXMLAccessRightFlags for possible values)
         acl: Object access control list
     """
+
     _OBJECT_TYPE = ObjectTypes.REPORT_DEFINITION
     _OBJECT_SUBTYPES = [
         ObjectSubTypes.REPORT_GRID,
         ObjectSubTypes.REPORT_GRAPH,
         ObjectSubTypes.REPORT_ENGINE,
         ObjectSubTypes.REPORT_GRID_AND_GRAPH,
         ObjectSubTypes.REPORT_TRANSACTION,
@@ -171,24 +173,24 @@
         'owner': User.from_dict,
         'certified_info': CertifiedInfo.from_dict,
     }
     _SIZE_LIMIT = 10000000  # this sets desired chunk size in bytes
 
     _API_PATCH: dict = {
         **Entity._API_PATCH,
-        ('folder_id',): (objects.update_object, 'partial_put')
+        ('folder_id',): (objects.update_object, 'partial_put'),
     }
 
     def __init__(
         self,
         connection: Connection,
         id: str,
         instance_id: Optional[str] = None,
         parallel: bool = True,
-        progress_bar: bool = True
+        progress_bar: bool = True,
     ):
         """Initialize an instance of a report.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`.
             id (str): Identifier of a pre-existing report containing
@@ -199,15 +201,19 @@
                 of threads to increase the download speed. If False, this
                 feature will be disabled.
             progress_bar(bool, optional): If True (default), show the download
                 progress bar.
         """
         connection._validate_project_selected()
         super().__init__(
-            connection, id, instance_id=instance_id, parallel=parallel, progress_bar=progress_bar
+            connection,
+            id,
+            instance_id=instance_id,
+            parallel=parallel,
+            progress_bar=progress_bar,
         )
 
     def _init_variables(self, **kwargs):
         super()._init_variables(**kwargs)
         self.instance_id = kwargs.get("instance_id")
         self._parallel = kwargs.get("parallel", True)
         self._initial_limit = 1000
@@ -223,27 +229,27 @@
         self.__definition_retrieved = False
         self.__filter = None
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
-        abbreviation: Optional[str] = None
+        abbreviation: Optional[str] = None,
     ):
         """Alter Report properties.
 
         Args:
             name: new name of the Report
             description: new description of the Report
             abbreviation: new abbreviation of the Report
         """
         func = self.alter
-        args = func.__code__.co_varnames[:func.__code__.co_argcount]
+        args = func.__code__.co_varnames[: func.__code__.co_argcount]
         defaults = func.__defaults__  # type: ignore
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
         self._alter_properties(**properties)
 
@@ -284,53 +290,65 @@
         # initialize parser and process first response
         p = Parser(response=_instance, parse_cube=False)
         p.parse(response=_instance)
 
         # If there are more rows to fetch, fetch them
         if paging['current'] != paging['total']:
             if not limit:
-                limit = max(1000, int((self._initial_limit * self._SIZE_LIMIT) / len(res.content)))
+                limit = max(
+                    1000,
+                    int((self._initial_limit * self._SIZE_LIMIT) / len(res.content)),
+                )
             # Count the number of additional iterations
-            it_total = int((paging['total'] - self._initial_limit) / limit) + \
-                ((paging['total'] - self._initial_limit) % limit != 0)
+            it_total = int((paging['total'] - self._initial_limit) / limit) + (
+                (paging['total'] - self._initial_limit) % limit != 0
+            )
 
             if self._parallel and it_total > 1:
                 threads = get_parallel_number(it_total)
-                with FuturesSessionWithRenewal(connection=self._connection,
-                                               max_workers=threads) as session:
+                with FuturesSessionWithRenewal(
+                    connection=self._connection, max_workers=threads
+                ) as session:
                     fetch_pbar = tqdm(
-                        desc="Downloading", total=it_total + 1, disable=(not self._progress_bar)
+                        desc="Downloading",
+                        total=it_total + 1,
+                        disable=(not self._progress_bar),
+                    )
+                    future = self.__fetch_chunks_future(
+                        session, paging, self.instance_id, limit
                     )
-                    future = self.__fetch_chunks_future(session, paging, self.instance_id, limit)
                     fetch_pbar.update()
                     for i, f in enumerate(future, start=1):
                         response = f.result()
                         if not response.ok:
                             response_handler(response, "Error getting report contents.")
                         fetch_pbar.update()
                         fetch_pbar.set_postfix(
-                            rows=str(min(self._initial_limit + i * limit, paging['total']))
+                            rows=str(
+                                min(self._initial_limit + i * limit, paging['total'])
+                            )
                         )
                         p.parse(response.json())
                     fetch_pbar.close()
             else:
                 self.__fetch_chunks(p, paging, it_total, self.instance_id, limit)
 
         # return parsed data as a data frame
         self._dataframe = p.dataframe
 
         # filter dataframe if report had crosstabs and filters were applied
         if self._cross_tab_filter != {}:
             if self._cross_tab_filter['metrics'] is not None:
                 # drop metrics columns from dataframe
                 metr_names = [
-                    el['name'] for el in list(
+                    el['name']
+                    for el in list(
                         filter(
                             lambda x: x['id'] not in self._cross_tab_filter['metrics'],
-                            self.metrics
+                            self.metrics,
                         )
                     )
                 ]
                 self._dataframe = self._dataframe.drop(metr_names, axis=1)
 
             if self._cross_tab_filter['attr_elements'] is not None:
                 # create dict of attributes and elements to iterate through
@@ -339,36 +357,42 @@
                     key = attribute[:32]
                     attr_dict.setdefault(key, []).append(attribute[33:])
                 # initialize indexes series for filter
                 indexes = pd.Series([False] * len(self._dataframe))
 
                 # logical OR for filtered attribute elements
                 for attribute in attr_dict:
-                    attr_name = list(filter(lambda x, attr=attribute: x['id'] in attr,
-                                            self.attributes))[0]['name']
+                    attr_name = list(
+                        filter(
+                            lambda x, attr=attribute: x['id'] in attr, self.attributes
+                        )
+                    )[0]['name']
                     elements = attr_dict[attribute]
                     indexes = indexes | self._dataframe[attr_name].isin(elements)
                 # select dataframe indexes with
                 self._dataframe = self._dataframe[indexes]
 
             if self._cross_tab_filter['attributes'] is not None:
                 attr_names = [
-                    el['name'] for el in list(
+                    el['name']
+                    for el in list(
                         filter(
-                            lambda x: x['id'] not in self._cross_tab_filter['attributes'],
-                            self.attributes
+                            lambda x: x['id']
+                            not in self._cross_tab_filter['attributes'],
+                            self.attributes,
                         )
                     )
                 ]
                 # filtering out attribute forms columns
                 to_be_removed = []
                 to_be_added = []
                 for attr in attr_names:
                     forms = [
-                        column for column in self._dataframe.columns
+                        column
+                        for column in self._dataframe.columns
                         if column.startswith(attr + '@')
                     ]
                     if forms:
                         to_be_removed.append(attr)
                         to_be_added.extend(forms)
                 for elem in to_be_removed:
                     attr_names.remove(elem)
@@ -384,70 +408,80 @@
             reports_api.report_instance_id_coroutine(
                 future_session,
                 connection=self._connection,
                 report_id=self._id,
                 instance_id=instance_id,
                 offset=_offset,
                 limit=limit,
-            ) for _offset in range(self._initial_limit, pagination['total'], limit)
+            )
+            for _offset in range(self._initial_limit, pagination['total'], limit)
         ]
 
     def __fetch_chunks(self, parser, pagination, it_total, instance_id, limit):
         """Fetch added rows from this object instance from the Intelligence
         Server."""
-        with tqdm(desc="Downloading", total=it_total + 1,
-                  disable=(not self._progress_bar)) as fetch_pbar:
+        with tqdm(
+            desc="Downloading", total=it_total + 1, disable=(not self._progress_bar)
+        ) as fetch_pbar:
             fetch_pbar.update()
             for _offset in range(self._initial_limit, pagination['total'], limit):
-                response = self.__get_chunk(instance_id=instance_id, offset=_offset, limit=limit)
+                response = self.__get_chunk(
+                    instance_id=instance_id, offset=_offset, limit=limit
+                )
                 fetch_pbar.update()
-                fetch_pbar.set_postfix(rows=str(min(_offset + limit, pagination['total'])))
+                fetch_pbar.set_postfix(
+                    rows=str(min(_offset + limit, pagination['total']))
+                )
                 parser.parse(response=response.json())
 
     def __initialize_report(self, limit: int) -> requests.Response:
         inst_pbar = tqdm(
             desc='Initializing an instance of a report. Please wait...',
             bar_format='{desc}',
             leave=False,
             ncols=285,
-            disable=(not self._progress_bar)
+            disable=(not self._progress_bar),
         )
 
         # Switch off subtotals if I-Server version is higher than 11.2.1
         body = self._filter._filter_body()
-        if version.parse(self._connection.iserver_version) >= version.parse("11.2.0100"):
+        if version.parse(self._connection.iserver_version) >= version.parse(
+            "11.2.0100"
+        ):
             self._subtotals["visible"] = False
             body["subtotals"] = {"visible": self._subtotals["visible"]}
 
         # Request a new instance, set instance id
         response = reports_api.report_instance(
             connection=self._connection,
             report_id=self._id,
             body=body,
             offset=0,
             limit=self._initial_limit,
         )
         inst_pbar.close()
         return response
 
-    def __get_chunk(self, instance_id: str, offset: int, limit: int) -> requests.Response:
+    def __get_chunk(
+        self, instance_id: str, offset: int, limit: int
+    ) -> requests.Response:
         return reports_api.report_instance_id(
             connection=self._connection,
             report_id=self._id,
             instance_id=instance_id,
             offset=offset,
             limit=limit,
         )
 
     def apply_filters(
         self,
         attributes: Optional[list] = None,
         metrics: Optional[list] = None,
         attr_elements: Optional[list] = None,
-        operator: str = 'In'
+        operator: str = 'In',
     ) -> None:
         """Apply filters on the reports's objects.
 
         Filter by attributes, metrics and attribute elements.
 
         Args:
             attributes (list or None, optional): ids of attributes to be
@@ -463,15 +497,17 @@
         """
         filtering_is_requested = bool(
             not all(element is None for element in [attributes, metrics, attr_elements])
         )
 
         if self._cross_tab:
             self._cross_tab_filter = {
-                'attributes': attributes, 'metrics': metrics, 'attr_elements': attr_elements
+                'attributes': attributes,
+                'metrics': metrics,
+                'attr_elements': attr_elements,
             }
         elif filtering_is_requested:
             self._filter._clear(
                 attributes=attributes, metrics=metrics, attr_elements=attr_elements
             )
             self._filter.operator = operator
             self._select_attribute_filter_conditionally(attributes)
@@ -509,22 +545,23 @@
 
     def _get_definition(self) -> None:
         """Get the definition of a report, including attributes and metrics.
 
         Implements GET /v2/reports/<report_id>.
         """
         response = reports_api.report_definition(
-            connection=self._connection,
-            report_id=self._id
+            connection=self._connection, report_id=self._id
         ).json()
 
         grid = response["definition"]["grid"]
         available_objects = response['definition']['availableObjects']
 
-        if version.parse(self._connection.iserver_version) >= version.parse("11.2.0100"):
+        if version.parse(self._connection.iserver_version) >= version.parse(
+            "11.2.0100"
+        ):
             self._subtotals = grid["subtotals"]
         self.name = response["name"]
         self._cross_tab = grid["crossTab"]
 
         # Check if report have custom groups or consolidations
         if available_objects['customGroups']:
             exception_handler(
@@ -540,34 +577,39 @@
         full_attributes = []
         for row in grid["rows"]:
             if row["type"] == "attribute":
                 full_attributes.append(row)
         for column in grid["columns"]:
             if column["type"] == "attribute":
                 full_attributes.append(column)
-        self._attributes = [{'name': attr['name'], 'id': attr['id']} for attr in full_attributes]
+        self._attributes = [
+            {'name': attr['name'], 'id': attr['id']} for attr in full_attributes
+        ]
 
         # Retrieve metrics from the report grid (only selected metrics)
         metrics_position = grid.get("metricsPosition")
         if metrics_position is None:
             self._metrics = []
         else:
-            full_metrics = grid[metrics_position["axis"]][metrics_position["index"]]["elements"]
-            self._metrics = [{'name': metr['name'], 'id': metr['id']} for metr in full_metrics]
+            full_metrics = grid[metrics_position["axis"]][metrics_position["index"]][
+                "elements"
+            ]
+            self._metrics = [
+                {'name': metr['name'], 'id': metr['id']} for metr in full_metrics
+            ]
 
         self.__definition_retrieved = True
 
     def __get_attr_elements(self, limit: int = 50000) -> list:
         """Get elements of report attributes synchronously.
 
         Implements GET /reports/<report_id>/attributes/<attribute_id>/elements.
         """
 
         def fetch_for_attribute(attribute):
-
             @fallback_on_timeout()
             def fetch_for_attribute_given_limit(limit):
                 response = reports_api.report_single_attribute_elements(
                     connection=self._connection,
                     report_id=self._id,
                     attribute_id=attribute['id'],
                     offset=0,
@@ -590,26 +632,26 @@
                     )
                     elements.extend(response.json())
 
                 # Return attribute data.
                 return {
                     "attribute_name": attribute['name'],
                     "attribute_id": attribute['id'],
-                    "elements": elements
+                    "elements": elements,
                 }
 
             return fetch_for_attribute_given_limit(limit)[0]
 
         attr_elements = []
         if self.attributes:
             pbar = tqdm(
                 self.attributes,
                 desc="Loading attribute elements",
                 leave=False,
-                disable=(not self._progress_bar)
+                disable=(not self._progress_bar),
             )
             attr_elements = [fetch_for_attribute(attribute) for attribute in pbar]
             pbar.close()
 
         return attr_elements
 
     def __get_attr_elements_async(self, limit: int = 50000) -> list:
@@ -617,23 +659,24 @@
 
         Implements GET /reports/<report_id>/attributes/<attribute_id>/elements.
         """
 
         attr_elements = []
         if self.attributes:
             threads = get_parallel_number(len(self.attributes))
-            with FuturesSessionWithRenewal(connection=self._connection,
-                                           max_workers=threads) as session:
+            with FuturesSessionWithRenewal(
+                connection=self._connection, max_workers=threads
+            ) as session:
                 # Fetch first chunk of attribute elements.
                 futures = self.__fetch_attribute_elements_chunks(session, limit)
                 pbar = tqdm(
                     futures,
                     desc="Loading attribute elements",
                     leave=False,
-                    disable=(not self._progress_bar)
+                    disable=(not self._progress_bar),
                 )
                 for i, future in enumerate(pbar):
                     attr = self.attributes[i]
                     response = future.result()
                     if not response.ok:
                         response_handler(
                             response, f"Error getting attribute {attr['name']} elements"
@@ -651,15 +694,15 @@
                         )
                         elements.extend(response.json())
                     # Append attribute data to the list of attributes.
                     attr_elements.append(
                         {
                             "attribute_name": attr['name'],
                             "attribute_id": attr['id'],
-                            "elements": elements
+                            "elements": elements,
                         }
                     )
                 pbar.close()
 
             return attr_elements
 
     def __fetch_attribute_elements_chunks(self, future_session, limit: int) -> list:
@@ -668,21 +711,24 @@
             reports_api.report_single_attribute_elements_coroutine(
                 future_session,
                 connection=self._connection,
                 report_id=self._id,
                 attribute_id=attribute['id'],
                 offset=0,
                 limit=limit,
-            ) for attribute in self.attributes
+            )
+            for attribute in self.attributes
         ]
 
     def list_properties(self):
         """List all properties of the object."""
 
-        attributes = {key: self.__dict__[key] for key in self.__dict__ if not key.startswith('_')}
+        attributes = {
+            key: self.__dict__[key] for key in self.__dict__ if not key.startswith('_')
+        }
         attributes = {
             **attributes,
             "id": self.id,
             "instance_id": self.instance_id,
             "type": self.type,
             "subtype": self.subtype,
             "ext_type": self.ext_type,
@@ -692,37 +738,43 @@
             "owner": self.owner,
             "view_media": self.view_media,
             "ancestors": self.ancestors,
             "certified_info": self.certified_info,
             "acg": self.acg,
             "acl": self.acl,
             "attributes": self.attributes,
-            "metrics": self.metrics
+            "metrics": self.metrics,
+        }
+        return {
+            key: attributes[key]
+            for key in sorted(attributes, key=sort_object_properties)
         }
-        return {key: attributes[key] for key in sorted(attributes, key=sort_object_properties)}
 
     def list_available_schedules(
-        self,
-        to_dictionary: bool = False
+        self, to_dictionary: bool = False
     ) -> list["Schedule"] | list[dict]:
         """Get a list of schedules available for the report.
 
         Args:
             to_dictionary (bool, optional): If True returns a list of
                 dictionaries, otherwise returns a list of Schedules.
                 False by default.
 
         Returns:
             List of Schedule objects or list of dictionaries.
         """
-        schedules_list_response = get_contents_schedule(
-            connection=self.connection,
-            project_id=self.connection.project_id,
-            body={'id': self.id, 'type': 'report'}
-        ).json().get('schedules')
+        schedules_list_response = (
+            get_contents_schedule(
+                connection=self.connection,
+                project_id=self.connection.project_id,
+                body={'id': self.id, 'type': 'report'},
+            )
+            .json()
+            .get('schedules')
+        )
         if to_dictionary:
             return schedules_list_response
         return [
             Schedule.from_dict(connection=self.connection, source=schedule_id)
             for schedule_id in schedules_list_response
         ]
 
@@ -742,30 +794,31 @@
     def attr_elements(self):
         if not self.__definition_retrieved:
             self._get_definition()
         if not self._attr_elements and self._id:
             if self._parallel is True:
                 # TODO: move the fallback inside the function to apply
                 # per-attribute, like with non-async version.
-                self._attr_elements = fallback_on_timeout()(self.__get_attr_elements_async
-                                                            )(50000)[0]
+                self._attr_elements = fallback_on_timeout()(
+                    self.__get_attr_elements_async
+                )(50000)[0]
             else:
                 self._attr_elements = self.__get_attr_elements()
             self._filter._populate_attr_elements(self._attr_elements)
         return self._attr_elements
 
     @property
     def _filter(self):
         if not self.__definition_retrieved:
             self._get_definition()
         if self.__filter is None:
             self.__filter = Filter(
                 attributes=self._attributes,
                 metrics=self._metrics,
-                attr_elements=self._attr_elements
+                attr_elements=self._attr_elements,
             )
         return self.__filter
 
     @property
     def selected_attributes(self):
         """Selected attributes for filtering."""
         return self._filter.attr_selected
```

### Comparing `mstrio-py-11.3.9.101/mstrio/server/cluster.py` & `mstrio-py-11.3.9.103/mstrio/server/cluster.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,20 +1,24 @@
-from enum import auto
 import getpass
 import logging
-from typing import Iterable, Optional, TYPE_CHECKING
+from enum import auto
+from typing import TYPE_CHECKING, Iterable, Optional
 
 import numpy as np
 import pandas as pd
 
 from mstrio import config
 from mstrio.api import administration, monitors, registrations
 from mstrio.connection import Connection
 from mstrio.utils.enum_helper import AutoName, AutoUpperName
-from mstrio.utils.helper import exception_handler, filter_list_of_dicts, validate_param_value
+from mstrio.utils.helper import (
+    exception_handler,
+    filter_list_of_dicts,
+    validate_param_value,
+)
 from mstrio.utils.version_helper import method_version_handler
 
 from .node import Node, Service, ServiceWithNode
 
 if TYPE_CHECKING:
     from pandas.io.formats.style import Styler
 
@@ -52,25 +56,26 @@
         self.connection = connection
 
     @method_version_handler('11.2.0000')
     def list_nodes(
         self,
         project: "Optional[str | Project]" = None,
         node: Optional[str | Node] = None,
-        to_dictionary: bool = False
+        to_dictionary: bool = False,
     ) -> list[Node | dict]:
         """Return a list of nodes and their properties within the cluster.
 
         Optionally filter by `project_id` or `node_name`.
 
         Args:
             project: Project ID or object
             node: Node name or object
         """
         from mstrio.server.project import Project
+
         project_id = project.id if isinstance(project, Project) else project
         node_name = node.name if isinstance(node, Node) else node
         response = monitors.get_node_info(self.connection, project_id, node_name)
         node_dicts = response.json()['nodes']
         if to_dictionary:
             return node_dicts
         else:
@@ -100,24 +105,34 @@
             except ValueError:
                 raise ValueError(
                     "When listing services it is possible to group them only by "
                     "`nodes` or `services`. See the GroupBy enum."
                 )
         if group_by == GroupBy.NODES:
             nodes = registrations.get_nodes(connection=self.connection).json()
-            return [{
-                'node': Node.from_dict(node['node']),
-                'services': [Service.from_dict(service) for service in node['services']]
-            } for node in nodes]
+            return [
+                {
+                    'node': Node.from_dict(node['node']),
+                    'services': [
+                        Service.from_dict(service) for service in node['services']
+                    ],
+                }
+                for node in nodes
+            ]
         else:  # GroupBy.SERVICES
             services = registrations.get_services(connection=self.connection).json()
-            return [{
-                'service': service['service'],
-                'nodes': [ServiceWithNode.from_dict(node) for node in service['nodes']]
-            } for service in services]
+            return [
+                {
+                    'service': service['service'],
+                    'nodes': [
+                        ServiceWithNode.from_dict(node) for node in service['nodes']
+                    ],
+                }
+                for service in services
+            ]
 
     def nodes_topology(self, styled=False) -> "pd.DataFrame | Styler":
         """Return cluster node topology as Pandas DataFrame or Styler object.
 
         DataFrame columns:
             - displayName -> it shows the name with which service is displayed
                 in Workstation
@@ -128,15 +143,17 @@
                 'Running' (green color), 'Stopped' (red color), 'Not Available
                 (service unavailable on the node)
 
         Returns:
             Pandas DataFrame or Styler object if styled is True.
         """
         nodes = self.list_services(group_by=GroupBy.NODES)
-        metadata = registrations.get_services_metadata(connection=self.connection).json()
+        metadata = registrations.get_services_metadata(
+            connection=self.connection
+        ).json()
         service_type = pd.DataFrame(metadata["serviceTypes"])[['displayName', 'name']]
 
         for node in nodes:
             node_name = node['node'].name
             if node['services']:
                 node_service = pd.DataFrame(
                     [service.to_dict() for service in node['services']]
@@ -180,18 +197,17 @@
         Returns:
             Pandas DataFrame or Styler object if styled is True.
         """
         services = self.list_services(group_by=GroupBy.SERVICES)
         services_topology = [
             {
                 "service": s['service'],
-                "nodes": [{
-                    "node": n.node, "status": n.status
-                } for n in s['nodes']]
-            } for s in services
+                "nodes": [{"node": n.node, "status": n.status} for n in s['nodes']],
+            }
+            for s in services
         ]
 
         tmp = []
         for s in services_topology:
             for n in s['nodes']:
                 n['service'] = s['service']
                 tmp.append(n)
@@ -249,23 +265,27 @@
     def check_dependency(self, service: str) -> list[str]:
         """Check all dependencies for the given service.
 
         Raises:
             ValueError: If incorrect service name is provided.
         """
         if not hasattr(self, '_metadata'):
-            self._metadata = registrations.get_services_metadata(connection=self.connection).json()
+            self._metadata = registrations.get_services_metadata(
+                connection=self.connection
+            ).json()
         service_id_map = {
             service['typeId']: service['name']
             for service in self._metadata['serviceTypes']
         }
         available_services = list(service_id_map.values())
 
         def get_dependencies_recursively(service_name: str):
-            service = filter_list_of_dicts(self._metadata['serviceTypes'], name=service_name)
+            service = filter_list_of_dicts(
+                self._metadata['serviceTypes'], name=service_name
+            )
             if service:
                 service = service[0]
                 dependencies_set = {
                     name
                     for id, name in service_id_map.items()
                     if id in service['dependsOn']
                 }
@@ -285,15 +305,15 @@
         return list(get_dependencies_recursively(service))
 
     def start(
         self,
         service: str,
         nodes: list[str],
         login: Optional[str] = None,
-        passwd: Optional[str] = None
+        passwd: Optional[str] = None,
     ):
         """Start up a service on selected nodes.
 
         Args:
             service: name of the service which will be started
             nodes: list of names of nodes on which service will be started
             login: login for SSH operation. If not provided, the user will be
@@ -307,15 +327,15 @@
 
     def stop(
         self,
         service: str,
         nodes: list[str],
         login: Optional[str] = None,
         passwd: Optional[str] = None,
-        force: bool = False
+        force: bool = False,
     ):
         """Stop a service on selected nodes. Provided service and node names
         are checked for correctness.
 
         Args:
             service: name of the service which will be started
             nodes: list of names of nodes on which service will be started
@@ -332,27 +352,27 @@
     def _control_service(
         self,
         action: ServiceAction,
         service: str,
         nodes: list[str],
         login: Optional[str] = None,
         passwd: Optional[str] = None,
-        force: bool = False
+        force: bool = False,
     ):
         # validate inputs
         self._check_nodes(nodes)
         service_list = self.list_services(group_by=GroupBy.SERVICES)
         self._check_service(service, service_list)
 
         # ask for confirmation when stopping MicroStrategy-Intelligence-Server
         if action == ServiceAction.STOP:
             if not force and service == 'MicroStrategy-Intelligence-Server':
                 msg = (
-                    "Stopping the Intelligence Server can affect all the users' sessions, "
-                    "including this current session."
+                    "Stopping the Intelligence Server can affect all the users' "
+                    "sessions, including this current session."
                 )
                 logger.info(msg)
                 if input("Are you sure you want to proceed? [Y/N]:") != 'Y':
                     return
         if action == ServiceAction.START:
             self._check_dependencies(service, service_list)
         # get credentials for operation on service
@@ -399,15 +419,15 @@
         return response.json()
 
     def update_node_settings(
         self,
         node: str | Node,
         load_balance_factor: int,
         initial_pool_size: int,
-        max_pool_size: int
+        max_pool_size: int,
     ) -> None:
         """Update I-Server configuration settings for a given server node
         within a cluster.
 
         Args:
             load_balance_factor: This setting becomes relevant in an environment
                 that has a MicroStrategy Intelligence Server cluster. By
@@ -423,44 +443,48 @@
         validate_param_value("initial_pool_size", initial_pool_size, int, 1024, 1)
         validate_param_value("max_pool_size", max_pool_size, int, 1024, 1)
 
         node_name = node.name if isinstance(node, Node) else node
         body = {
             "loadBalanceFactor": load_balance_factor,
             "initialPoolSize": initial_pool_size,
-            "maxPoolSize": max_pool_size
+            "maxPoolSize": max_pool_size,
         }
-        response = administration.update_iserver_node_settings(self.connection, body, node_name)
+        response = administration.update_iserver_node_settings(
+            self.connection, body, node_name
+        )
         if config.verbose and response.ok:
             logger.info(f'Intelligence Server configuration updated for {node_name}')
 
     def reset_node_settings(self, node: str | Node) -> None:
         """Remove I-Server configuration settings for given node within a
         cluster. Default values will be applied after execution of this method.
 
         Args:
             node: name of the node for which default settings will be applied.
         """
         node_name = node.name if isinstance(node, Node) else node
         administration.delete_iserver_node_settings(self.connection, node_name)
 
-    def list_projects(self, to_dictionary: bool = False, limit: Optional[int] = None,
-                      **filters) -> list["Project"]:
+    def list_projects(
+        self, to_dictionary: bool = False, limit: Optional[int] = None, **filters
+    ) -> list["Project"]:
         """Return list of project objects or if `to_dictionary=True`
         project dicts. Optionally filter the Projects by specifying the
         `filters` keyword arguments.
 
         Args:
             to_dictionary: If True returns list of project dicts
             limit: limit the number of elements returned. If `None`, all objects
                 are returned.
             **filters: Available filter parameters: ['name', 'id',
                 'description', 'date_created', 'date_modified', 'owner']
         """
         from mstrio.server.environment import Environment
+
         env = Environment(connection=self.connection)
         return env.list_projects(to_dictionary=to_dictionary, limit=limit, **filters)
 
     def load_project(
         self, project: "str | Project", on_nodes: Optional[str | list[str]] = None
     ) -> None:
         """Request to load the project onto the chosen cluster nodes. If
@@ -469,14 +493,15 @@
         Args:
             project: name or object of project which will be loaded
             on_nodes: name of node or nodes, if not passed, project will be
                 loaded on all of the nodes
         """
 
         from mstrio.server.project import Project
+
         project_name = project.name if isinstance(project, Project) else project
         project = Project._list_projects(self.connection, name=project_name)[0]
         project.load(on_nodes=on_nodes)
 
     def unload_project(
         self, project: "str | Project", on_nodes: Optional[str | list[str]] = None
     ) -> None:
@@ -488,132 +513,159 @@
 
         Args:
             project: name or object of project which will be unloaded
             on_nodes: name of node or nodes, if not passed, project will be
                 unloaded on all of the nodes
         """
         from mstrio.server.project import Project
+
         project_name = project.name if isinstance(project, Project) else project
         project = Project._list_projects(self.connection, name=project_name)[0]
         project.unload(on_nodes=on_nodes)
 
     def _show_start_stop_msg(
-        self, service_name: str, wrong: list[str], good: list[str], action: ServiceAction
+        self,
+        service_name: str,
+        wrong: list[str],
+        good: list[str],
+        action: ServiceAction,
     ):
         """Prepare message to show after action of stopping or starting a
         service with the information on which node the actions were good (done
         correctly) and on which were wrong (response status was not ok).
         """
         if len(wrong) > 0:
             action_msg = 'started' if action == ServiceAction.START else 'stopped'
             nodes_msg = ', '.join(wrong)
-            logger.warning(f'Service {service_name} was not {action_msg} for node(s) {nodes_msg}.')
+            logger.warning(
+                f'Service {service_name} was not {action_msg} for node(s) {nodes_msg}.'
+            )
         if len(good) > 0:
             action_msg = 'start' if action == ServiceAction.START else 'stop'
             nodes_msg = ','.join(good)
             logger.info(
-                f'Request to {action_msg} {service_name} was sent for node(s) {nodes_msg}.'
+                f'Request to {action_msg} {service_name} was sent for node(s) '
+                f'{nodes_msg}.'
             )
 
-    def _check_service(self, service_name: str, service_list: list[ServiceWithNode]) -> None:
+    def _check_service(
+        self, service_name: str, service_list: list[ServiceWithNode]
+    ) -> None:
         """Checks if the name of the given service is one of the names of
         existing services.
 
         Raises:
             ValueError: If name is incorrect.
         """
         valid_service_names = [service['service'] for service in service_list]
 
         if service_name not in valid_service_names:
             raise ValueError(
-                f"Service {service_name} is incorrect. Please choose one of: {valid_service_names}"
+                f"Service {service_name} is incorrect. Please choose one of: "
+                f"{valid_service_names}"
             )
 
-    def _check_dependencies(self, service_name: str, service_list: list[ServiceWithNode]):
+    def _check_dependencies(
+        self, service_name: str, service_list: list[ServiceWithNode]
+    ):
         """Check if service depends on other services.
 
         Warns if any one of the dependencies is not running.
         """
         dependencies = self.check_dependency(service_name)
         dependencies = [
-            service for service in dependencies
+            service
+            for service in dependencies
             if not Cluster._check_service_running(service_name, service_list)
         ]
 
         if dependencies:
             exception_handler(
-                f"Service {service_name} depends on services {dependencies} to run correctly.",
-                Warning
+                f"Service {service_name} depends on services {dependencies} to run "
+                "correctly.",
+                Warning,
             )
 
     def _check_nodes(self, node_names: Iterable[str]) -> None:
         """Checks if the names of the given nodes are within names of existing
         nodes. Checks if the node is running.
 
         Raises:
             ValueError: If name is incorrect.
         """
         all_nodes = self.list_nodes(to_dictionary=True)
         all_node_names = [node['name'] for node in all_nodes]
         active_nodes = [
-            node['name'] for node in filter(lambda node: node['status'] == 'running', all_nodes)
+            node['name']
+            for node in filter(lambda node: node['status'] == 'running', all_nodes)
         ]
 
         for node_name in node_names:
             if node_name not in all_node_names:
                 raise ValueError(
-                    f"Node '{node_name}' is incorrect. Please choose one of: {all_node_names}"
+                    f"Node '{node_name}' is incorrect. Please choose one of: "
+                    f"{all_node_names}"
                 )
             elif node_name not in active_nodes:
-                raise ValueError(f"Node '{node_name}' is stopped. Try starting it first.")
+                raise ValueError(
+                    f"Node '{node_name}' is stopped. Try starting it first."
+                )
             else:
                 continue
 
     @staticmethod
     def _check_service_running(
-        service_name: str, service_list: list[ServiceWithNode], node_name: Optional[str] = None
+        service_name: str,
+        service_list: list[ServiceWithNode],
+        node_name: Optional[str] = None,
     ) -> bool:
         """Return True if service is running on any node available.
 
         If `node_name` is provided, the service status will be given for
         the selected node.
         """
         nodes = [
-            service['nodes'] for service in service_list if service['service'] == service_name
+            service['nodes']
+            for service in service_list
+            if service['service'] == service_name
         ][0]
 
         if node_name:
             node = [node for node in nodes if node.node == node_name]
             if node.status == 'PASSING':
                 return True
             else:
                 return False
         else:
             return bool([True for node in nodes if node.status == 'PASSING'])
 
     @staticmethod
-    def _get_node_info(node_name: str, service_name: str,
-                       service_list: list[ServiceWithNode]) -> Optional[dict]:
+    def _get_node_info(
+        node_name: str, service_name: str, service_list: list[ServiceWithNode]
+    ) -> Optional[dict]:
         nodes = [
-            service['nodes'] for service in service_list if service['service'] == service_name
+            service['nodes']
+            for service in service_list
+            if service['service'] == service_name
         ][0]
         node = [node for node in nodes if node.node == node_name]
 
         if not node:
             exception_handler(
-                f"Service {service_name} is not available on {node_name}", exception_type=Warning
+                f"Service {service_name} is not available on {node_name}",
+                exception_type=Warning,
             )
             return None
         else:
             node = node[0]
 
         if node.service_control is False:
             exception_handler(
                 f"Service {service_name} cannot be controlled on {node_name}",
-                exception_type=Warning
+                exception_type=Warning,
             )
             return None
         else:
             return node.to_dict()
 
     @staticmethod
     def _show_color(val: str) -> str:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/server/environment.py` & `mstrio-py-11.3.9.103/mstrio/server/environment.py`

 * *Files 7% similar despite different names*

```diff
@@ -50,27 +50,29 @@
         object."""
         self.server_settings.update()
 
     def fetch_settings(self) -> None:
         """Fetch the current server settings from the environment."""
         self.server_settings.fetch()
 
-    def create_project(self, name: str, description: Optional[str] = None,
-                       force: bool = False) -> Optional["Project"]:
+    def create_project(
+        self, name: str, description: Optional[str] = None, force: bool = False
+    ) -> Optional["Project"]:
         """Create a new project on the environment.
 
         Args:
             name: Name of Project.
             description: Description of Application.
             force: If `True`, overrides the prompt.
         """
         return Project._create(self.connection, name, description, force)
 
-    def list_projects(self, to_dictionary: bool = False, limit: Optional[int] = None,
-                      **filters) -> Union[List["Project"], List[dict]]:
+    def list_projects(
+        self, to_dictionary: bool = False, limit: Optional[int] = None, **filters
+    ) -> Union[List["Project"], List[dict]]:
         """Return list of project objects or project dicts if
         `to_dictionary=True`. Optionally filter the Projects by specifying
         the `filters` keyword arguments.
 
         Args:
             to_dictionary: If True returns list of project dicts.
             limit: limit the number of elements returned. If `None`, all objects
@@ -81,16 +83,17 @@
         return Project._list_projects(
             connection=self.connection,
             to_dictionary=to_dictionary,
             limit=limit,
             **filters,
         )
 
-    def list_loaded_projects(self, to_dictionary: bool = False,
-                             **filters) -> Union[List["Project"], List[dict]]:
+    def list_loaded_projects(
+        self, to_dictionary: bool = False, **filters
+    ) -> Union[List["Project"], List[dict]]:
         """Return list of all loaded project objects or project dicts
         if `to_dictionary=True` that the user has access to. Optionally filter
         the Projects by specifying the `filters` keyword arguments.
 
         Args:
             to_dictionary: If True, returns list of project dicts
             **filters: Available filter parameters: ['acg', 'id', 'name',
@@ -100,15 +103,17 @@
         return Project._list_loaded_projects(
             connection=self.connection,
             to_dictionary=to_dictionary,
             **filters,
         )
 
     def list_nodes(
-        self, project: Optional[Union[str, "Project"]] = None, node_name: Optional[str] = None
+        self,
+        project: Optional[Union[str, "Project"]] = None,
+        node_name: Optional[str] = None,
     ) -> List[dict]:
         """Return a list of I-Server nodes and their properties. Optionally
         filter by `project` or `node_name`.
 
         Args:
             project: ID of project or Project object
             node_name: Name of node
@@ -145,15 +150,17 @@
             status = node['projects'][0]['status']
             loaded = True if status == 'loaded' else False
             if loaded:
                 break
         return loaded
 
     def compare_settings(
-        self, projects: Union[List[str], List["Project"]] = None, show_diff_only: bool = False
+        self,
+        projects: Union[List[str], List["Project"]] = None,
+        show_diff_only: bool = False,
     ) -> DataFrame:
         """Compare project' settings to the first project in the
         provided list.
 
         Args:
             projects (list of names or project objects, optional): List
                 of project objects or names to be compared. First element of
@@ -165,30 +172,32 @@
         Returns:
             Dataframe with values of selected project' settings.
         """
 
         def not_exist_warning(wrong_name):
             helper.exception_handler(
                 f"Project '{wrong_name}' does not exist and will be skipped.",
-                exception_type=Warning
+                exception_type=Warning,
             )
 
         if projects:
-            just_objects = [project for project in projects if isinstance(project, Project)]
+            just_objects = [
+                project for project in projects if isinstance(project, Project)
+            ]
         else:
             just_objects = []
         if len(just_objects) == len(projects):
             return compare_project_settings(projects, show_diff_only)
 
         all_projects = self.list_projects()
         if type(projects) == list:
             if len(projects) < 2:
                 helper.exception_handler(
                     "Provide more than one project object or name in list",
-                    exception_type=TypeError
+                    exception_type=TypeError,
                 )
 
             # extract project names from either project object or strings
             project_names = [
                 project.name if isinstance(project, Project) else str(project)
                 for project in projects
             ]
@@ -196,19 +205,21 @@
             all_project_names = [project.name for project in all_projects]
             [
                 not_exist_warning(a_name)
                 for a_name in project_names
                 if a_name not in all_project_names
             ]
 
-            projects = list(filter(lambda project: project.name in project_names, all_projects))
+            projects = list(
+                filter(lambda project: project.name in project_names, all_projects)
+            )
             projects = sorted(projects, key=lambda x: project_names.index(x.name))
 
         elif projects is None:
             projects = all_projects
         else:
             helper.exception_handler(
                 "The 'projects' parameter needs to be a list of len > 1 or None.",
-                exception_type=TypeError
+                exception_type=TypeError,
             )
 
         return compare_project_settings(projects, show_diff_only)
```

### Comparing `mstrio-py-11.3.9.101/mstrio/server/job_monitor.py` & `mstrio-py-11.3.9.103/mstrio/server/job_monitor.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,20 @@
 import logging
 from typing import List, Optional, TYPE_CHECKING, Union
 
 from packaging import version
 
 from mstrio import config
 from mstrio.api import monitors
-from mstrio.api.exceptions import MstrException, PartialSuccess, Success, VersionException
+from mstrio.api.exceptions import (
+    MstrException,
+    PartialSuccess,
+    Success,
+    VersionException,
+)
 from mstrio.connection import Connection
 from mstrio.server import Node, Project
 from mstrio.utils.entity import Entity, EntityBase
 from mstrio.utils.enum_helper import AutoName
 from mstrio.utils.helper import validate_param_value
 from mstrio.utils.monitors import all_nodes_async
 from mstrio.utils.time_helper import DatetimeFormats, map_str_to_datetime
@@ -165,15 +170,17 @@
     MEMORY_USAGE_DESC = '-memoryUsage'
     ELAPSED_TIME_ASC = '+elapsedTime'
     ELAPSED_TIME_DESC = '-elapsedTime'
 
 
 @method_version_handler('11.3.0200')
 def _set_api_wrappers(connection) -> dict:
-    if version.parse(connection.iserver_version) == version.parse(ISERVER_VERSION_11_3_2):
+    if version.parse(connection.iserver_version) == version.parse(
+        ISERVER_VERSION_11_3_2
+    ):
         return {
             (
                 'id',
                 'description',
                 'status',
                 'type',
                 'priority',
@@ -186,15 +193,15 @@
                 'total_tasks',
                 'completed_tasks',
                 'filter_name',
                 'template_name',
                 'sql',
                 'subscription_owner',
                 'subscription_recipient',
-                'destination'
+                'destination',
             ): monitors.get_job
         }
     else:
         return {
             (
                 'id',
                 'type',
@@ -219,15 +226,15 @@
                 'step_elapsed_time',
                 'filter_name',
                 'template_name',
                 'sql',
                 'subscription_owner',
                 'error_time',
                 'error_message',
-                'step_statistics'
+                'step_statistics',
             ): monitors.get_job_v2
         }
 
 
 @method_version_handler('11.3.0200')
 def list_jobs(
     connection: "Connection",
@@ -243,15 +250,15 @@
     subscription_type: Optional[Union[SubscriptionType, str]] = None,
     subscription_recipient: Optional[Union["User", str]] = None,
     memory_usage: Optional[str] = None,
     elapsed_time: Optional[str] = None,
     sort_by: Optional[Union[SortBy, str]] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> Union[List["Job"], List[dict]]:
     """List jobs objects or job dictionaires.
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`
         node(Node, str, optional): Node object or name, if not passed list jobs
             on all nodes
@@ -295,42 +302,50 @@
     Examples:
         >>> list_jobs_v1(connection, duration='gt:100')
 
     Returns:
         Union[List["Job"], List[dict]]: list of Job objects or dictionaries.
     """
     user = user.full_name if isinstance(user, Entity) else user
-    subscription_recipient = subscription_recipient.full_name if isinstance(
-        user, Entity
-    ) else subscription_recipient
+    subscription_recipient = (
+        subscription_recipient.full_name
+        if isinstance(user, Entity)
+        else subscription_recipient
+    )
     if project:
-        project = project if isinstance(project, Project) else Project(connection, name=project)
+        project = (
+            project
+            if isinstance(project, Project)
+            else Project(connection, name=project)
+        )
 
     # depending on version call either one or the other
-    if version.parse(connection.iserver_version) == version.parse(ISERVER_VERSION_11_3_2):
+    if version.parse(connection.iserver_version) == version.parse(
+        ISERVER_VERSION_11_3_2
+    ):
         filters = __prepare_v1_request(
             description,
             object_type,
             pu_name,
             subscription_type,
             subscription_recipient,
             memory_usage,
             elapsed_time,
-            filters
+            filters,
         )
         return list_jobs_v1(
             connection=connection,
             node=node,
             project=project,
             status=status,
             job_type=type,
             user=user,
             limit=limit,
             to_dictionary=to_dictionary,
-            **filters
+            **filters,
         )
     else:
         project_name = project.name if project else None
         node_name = node.name if isinstance(node, Node) else node
         msg = "Error fetching chunk of jobs."
         objects = all_nodes_async(
             connection,
@@ -349,15 +364,15 @@
             status=status,
             pu_name=pu_name,
             subscription_type=subscription_type,
             subscription_recipient=subscription_recipient,
             memory_usage=memory_usage,
             elapsed_time=elapsed_time,
             sort_by=sort_by,
-            fields=['jobs']
+            fields=['jobs'],
         )
 
     if to_dictionary:
         return objects
     else:
         return [Job.from_dict(source=obj, connection=connection) for obj in objects]
 
@@ -370,15 +385,15 @@
     status: Optional[Union[JobStatus, str]] = None,
     job_type: Optional[Union[JobType, str]] = None,
     user: Optional[Union["User", str]] = None,
     object_id: Optional[str] = None,
     sort_by: Optional[Union[SortBy, str]] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> Union[List["Job"], List[dict]]:
     """List job objects or job dictionaries. Optionally filter list.
     NOTE: list_jobs can return up to 1024 jobs per request.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             'connection.Connection()'
@@ -424,26 +439,27 @@
         limit=limit,
         node_name=node_name,
         project_id=project_id,
         status=status,
         job_type=job_type,
         user_full_name=user_full_name,
         object_id=object_id,
-        sort_by=sort_by
+        sort_by=sort_by,
     )
 
     if to_dictionary:
         return objects
     else:
         return [Job.from_dict(source=obj, connection=connection) for obj in objects]
 
 
 @method_version_handler('11.3.0200')
-def kill_jobs(connection: Connection,
-              jobs: List[Union["Job", str]]) -> Union[Success, PartialSuccess, MstrException]:
+def kill_jobs(
+    connection: Connection, jobs: List[Union["Job", str]]
+) -> Union[Success, PartialSuccess, MstrException]:
     """Kill existing jobs by Job objects or job ids.
 
     Args:
         connection(object): MicroStrategy connection object returned by
             'connection.Connection()'
         jobs: List of Job objects or job ids to kill
 
@@ -469,15 +485,15 @@
     project: Optional[Union[Project, str]] = None,
     pu_name: Optional[Union[PUName, str]] = None,
     subscription_type: Optional[Union[SubscriptionType, str]] = None,
     subscription_recipient: Optional[Union["User", str]] = None,
     memory_usage: Optional[str] = None,
     elapsed_time: Optional[str] = None,
     force: bool = False,
-    **filters
+    **filters,
 ) -> Union[Success, PartialSuccess, MstrException]:
     """Kill jobs filtered by passed fields
 
     Args:
         connection(object): MicroStrategy connection object returned by
             `connection.Connection()`
          node(Node, str, optional): Node object or name, if not passed kill jobs
@@ -528,15 +544,15 @@
         object_type,
         project,
         pu_name,
         subscription_type,
         subscription_recipient,
         memory_usage,
         elapsed_time,
-        filters
+        filters,
     )
     assert jobs, "No jobs to kill"
 
     jobs_ids = [job.id for job in jobs]
     if not force:
         print(f"Found jobs: {jobs}")
         user_input = input("Are you sure you want to kill those jobs?[Y/N]: ") or 'N'
@@ -548,19 +564,24 @@
     description: str,
     object_type: str,
     pu_name: str,
     subscription_type: str,
     subscription_recipient: str,
     memory_usage: str,
     elapsed_time: str,
-    filters: dict
+    filters: dict,
 ) -> dict:
     # raise VersionException if parameter not supported in v1
     unsupported_parameters = [
-        description, object_type, pu_name, subscription_type, subscription_recipient, memory_usage
+        description,
+        object_type,
+        pu_name,
+        subscription_type,
+        subscription_recipient,
+        memory_usage,
     ]
     params_str = (
         "description, object_type, pu_name, subscription_type, "
         "subscription_recipient, memory_usage"
     )
     if any(unsupported_parameters):
         msg = (
@@ -572,16 +593,19 @@
 
     if elapsed_time:
         filters['duration'] = elapsed_time
     return filters
 
 
 def __elapsed_filtering(elapsed: str) -> str:
-    if isinstance(elapsed, str) and len(elapsed) > 3 and (elapsed.startswith('gt:')
-                                                          or elapsed.startswith('lt:')):
+    if (
+        isinstance(elapsed, str)
+        and len(elapsed) > 3
+        and (elapsed.startswith('gt:') or elapsed.startswith('lt:'))
+    ):
         if elapsed.startswith('gt'):
             return f'>{elapsed[3:]}'
         elif elapsed.startswith('lt'):
             return f'<{elapsed[3:]}'
         else:
             return elapsed
     else:
@@ -666,15 +690,15 @@
             'step_elapsed_time',
             'filter_name',
             'template_name',
             'sql',
             'subscription_owner',
             'error_time',
             'error_message',
-            'step_statistics'
+            'step_statistics',
         ): monitors.get_job_v2
     }
     _REST_ATTR_MAP = {
         "job_id": None,  # delete job_id and only use id
         "job_type": "type",
         "user_full_name": "user",
         "total_task": "total_tasks",
@@ -706,51 +730,60 @@
         """Initialize variables given kwargs.
 
         Note: attributes not accepted by any implementation of this function
             in the inheritance chain will be disregarded.
         """
         kwargs = self._rest_to_python(kwargs)
         # create _AVAILABLE_ATTRIBUTES map
-        self._AVAILABLE_ATTRIBUTES.update({key: type(val) for key, val in kwargs.items()})
+        self._AVAILABLE_ATTRIBUTES.update(
+            {key: type(val) for key, val in kwargs.items()}
+        )
 
         self._connection = kwargs.get('connection')
         self._id = kwargs.get('id')
         self._description = kwargs.get('description')
         self._status = JobStatus(kwargs.get('status')) if kwargs.get('status') else None
         self._processing_unit_priority = kwargs.get('processing_unit_priority')
         self._creation_time = map_str_to_datetime(
             "creation_time", kwargs.get("creation_time"), self._FROM_DICT_MAP
         )
         self._elapsed_time = kwargs.get('elapsed_time')
         self._project_name = kwargs.get('project_name')
         self._object_id = kwargs.get('object_id')
-        self._object_type = ObjectType(kwargs.get('object_type')
-                                       ) if kwargs.get('object_type') else None
+        self._object_type = (
+            ObjectType(kwargs.get('object_type')) if kwargs.get('object_type') else None
+        )
         self._sql = kwargs.get('sql')
         self._subscription_owner = kwargs.get('subscription_owner')
         self._subscription_recipient = kwargs.get('subscription_recipient')
         self._client_machine = kwargs.get('client_machine')
         self._type = JobType(kwargs.get('type')) if kwargs.get('type') else None
         self._user = kwargs.get('user')
         self._total_tasks = kwargs.get('total_tasks')
         self._completed_tasks = kwargs.get('completed_tasks')
         self._parent_id = kwargs.get('parent_id')
         self._child_ids = kwargs.get('child_ids')
-        self._subscription_type = SubscriptionType(
-            kwargs.get('subscription_type')
-        ) if kwargs.get('subscription_type') else kwargs.get('subscription_type')
+        self._subscription_type = (
+            SubscriptionType(kwargs.get('subscription_type'))
+            if kwargs.get('subscription_type')
+            else kwargs.get('subscription_type')
+        )
         self._step_id = kwargs.get('step_id')
         self._pu_name = PUName(kwargs.get('pu_name')) if kwargs.get('pu_name') else None
         self._memory_usage = kwargs.get('memory_usage')
         self._step_elapsed_time = kwargs.get('step_elapsed_time')
         self._filter_name = kwargs.get('filter_name')
         self._template_name = kwargs.get('template_name')
-        self._error_time = map_str_to_datetime(
-            "error_time", kwargs.get("error_time"), self._FROM_DICT_MAP
-        ) if kwargs.get("error_time") else None
+        self._error_time = (
+            map_str_to_datetime(
+                "error_time", kwargs.get("error_time"), self._FROM_DICT_MAP
+            )
+            if kwargs.get("error_time")
+            else None
+        )
         self._error_message = kwargs.get('error_message')
         self._step_statistics = kwargs.get('step_statistics')
 
     def kill(self) -> bool:
         """Kill the job.
 
         Returns:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/server/node.py` & `mstrio-py-11.3.9.103/mstrio/server/node.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,40 +2,37 @@
 from typing import Optional
 
 from mstrio.utils.helper import Dictable
 
 
 @dataclass
 class Node(Dictable):
-
     name: Optional[str] = None
     address: Optional[str] = None
     service_control: Optional[bool] = None
 
     @classmethod
     def from_dict(cls, source: dict):
         if not source.get('name'):
             source['name'] = source['node']
         return super().from_dict(source)
 
 
 @dataclass
 class Service(Dictable):
-
     id: str
     service: str
     port: int
     status: str
     tags: Optional[dict] = None
     output: Optional[str] = None
 
 
 @dataclass
 class ServiceWithNode(Dictable):
-
     node: str
     address: str
     id: str
     service_control: bool
     port: int
     status: str
     service_address: str
```

### Comparing `mstrio-py-11.3.9.101/mstrio/server/project.py` & `mstrio-py-11.3.9.103/mstrio/server/project.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,22 +1,23 @@
-from enum import Enum, IntEnum
 import logging
 import time
-from typing import Optional, Union
+from enum import Enum, IntEnum
+from typing import Optional
 
 from pandas import DataFrame, Series
 from tqdm import tqdm
 
+import mstrio.utils.helper as helper
 from mstrio import config
 from mstrio.api import monitors, projects
 from mstrio.connection import Connection
 from mstrio.utils.entity import Entity, ObjectTypes
-import mstrio.utils.helper as helper
 from mstrio.utils.settings.base_settings import BaseSettings
 from mstrio.utils.version_helper import method_version_handler
+from mstrio.utils.vldb_mixin import ModelVldbMixin
 from mstrio.utils.wip import wip
 
 logger = logging.getLogger(__name__)
 
 
 class ProjectStatus(IntEnum):
     ACTIVE = 0
@@ -47,22 +48,25 @@
         queued jobs are canceled, and any newly submitted jobs are rejected.
     `PARTIAL` (Request Idle and Execution Idle for Warehouse jobs): all
         executing and queued jobs that do not submit SQL against the data
         warehouse are canceled, and any newly submitted jobs are rejected.
         Any currently executing and queued jobs that do not require SQL to
         be executed against the data warehouse are executed.
     """
+
     REQUEST = "request_idle"
     EXECUTION = "exec_idle"
     WAREHOUSEEXEC = "wh_exec_idle"
     FULL = "partial_idle"
     PARTIAL = "full_idle"
 
 
-def compare_project_settings(projects: list["Project"], show_diff_only: bool = False) -> DataFrame:
+def compare_project_settings(
+    projects: list["Project"], show_diff_only: bool = False
+) -> DataFrame:
     """Compares settings of project objects.
 
     Args:
         projects (List[Project]): List of project objects
             to compare.
         show_diff_only (bool, optional): Whether to display all settings
             or only different from first project in list.
@@ -91,15 +95,15 @@
                 f"There is no difference in settings between project '{base}' and "
                 f"remaining projects: '{project_names}'"
             )
             logger.info(msg)
     return df
 
 
-class Project(Entity):
+class Project(Entity, ModelVldbMixin):
     """Object representation of MicroStrategy Project (Project) object.
 
     Attributes:
         connection: A MicroStrategy connection object
         settings: Project settings object
         id: Project ID
         name: Project name
@@ -114,24 +118,34 @@
         version: Version ID
         owner: owner ID and name
         acg: Access rights (See EnumDSSXMLAccessRightFlags for possible values)
         acl: Object access control list
         status: Project
         ancestors: List of ancestor folders
     """
+
     _OBJECT_TYPE = ObjectTypes.PROJECT
     _API_GETTERS = {
-        **Entity._API_GETTERS, ('status', 'alias'): projects.get_project,
-        'nodes': monitors.get_node_info
+        **Entity._API_GETTERS,
+        ('status', 'alias'): projects.get_project,
+        'nodes': monitors.get_node_info,
     }
     _FROM_DICT_MAP = {**Entity._FROM_DICT_MAP, 'status': ProjectStatus}
     _STATUS_PATH = "/status"
+    _MODEL_VLDB_API = {
+        'GET_ADVANCED': projects.get_vldb_settings,
+        'PUT_ADVANCED': projects.update_vldb_settings,
+        'GET_APPLICABLE': projects.get_applicable_vldb_settings,
+    }
 
     def __init__(
-        self, connection: Connection, name: Optional[str] = None, id: Optional[str] = None
+        self,
+        connection: Connection,
+        name: Optional[str] = None,
+        id: Optional[str] = None,
     ) -> None:
         """Initialize Project object by passing `name` or `id`. When `id` is
         provided (not `None`), `name` is omitted.
 
         Args:
             connection: MicroStrategy connection object returned
                 by `connection.Connection()`
@@ -139,38 +153,38 @@
             id: Project ID
         """
 
         # initialize either by ID or Project Name
         if id is None and name is None:
             helper.exception_handler(
                 "Please specify either 'name' or 'id' parameter in the constructor.",
-                exception_type=ValueError
+                exception_type=ValueError,
             )
 
         if id is None:
             project_list = Project._list_project_ids(connection, name=name)
             if project_list:
                 id = project_list[0]
             else:
                 helper.exception_handler(
                     f"There is no project with the given name: '{name}'",
-                    exception_type=ValueError
+                    exception_type=ValueError,
                 )
 
         try:
             super().__init__(connection=connection, object_id=id, name=name)
         except helper.IServerError as e:
             if not self.is_loaded():
                 helper.exception_handler(
                     (
                         "Some projects are either unloaded or idled. Change "
                         "status using the 'load()' or 'resume()' method to use "
                         "all functionality."
                     ),
-                    exception_type=UserWarning
+                    exception_type=UserWarning,
                 )
             else:
                 raise e
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self._status = kwargs.get("status")
@@ -179,31 +193,39 @@
 
     @classmethod
     def _create(
         cls,
         connection: Connection,
         name: str,
         description: Optional[str] = None,
-        force: bool = False
+        force: bool = False,
     ) -> Optional["Project"]:
         user_input = 'N'
         if not force:
-            user_input = input(f"Are you sure you want to create new project '{name}'? [Y/N]: ")
+            user_input = input(
+                f"Are you sure you want to create new project '{name}'? [Y/N]: "
+            )
 
         if force or user_input == 'Y':
             # Create new project
-            with tqdm(desc=f"Please wait while Project '{name}' is being created.",
-                      bar_format='{desc}',
-                      leave=False,
-                      disable=config.verbose):
-                projects.create_project(connection, {"name": name, "description": description})
+            with tqdm(
+                desc=f"Please wait while Project '{name}' is being created.",
+                bar_format='{desc}',
+                leave=False,
+                disable=config.verbose,
+            ):
+                projects.create_project(
+                    connection, {"name": name, "description": description}
+                )
                 http_status, i_server_status = 500, 'ERR001'
                 while http_status == 500 and i_server_status == 'ERR001':
                     time.sleep(1)
-                    response = projects.get_project(connection, name, whitelist=[('ERR001', 500)])
+                    response = projects.get_project(
+                        connection, name, whitelist=[('ERR001', 500)]
+                    )
                     http_status = response.status_code
                     i_server_status = response.json().get('code')
                     id_ = response.json().get('id')
             if config.verbose:
                 logger.info(f"Project '{name}' successfully created.")
             return cls(connection, name=name, id=id_)
         else:
@@ -212,241 +234,261 @@
     @classmethod
     @method_version_handler('11.2.0000')
     def _list_projects(
         cls,
         connection: Connection,
         to_dictionary: bool = False,
         limit: Optional[int] = None,
-        **filters
-    ) -> Union[list["Project"], list[dict]]:
+        **filters,
+    ) -> list["Project"] | list[dict]:
         msg = "Error getting information for a set of Projects."
         objects = helper.fetch_objects_async(
             connection,
             monitors.get_projects,
             monitors.get_projects_async,
             dict_unpack_value='projects',
             limit=limit,
             chunk_size=1000,
             error_msg=msg,
-            filters=filters
+            filters=filters,
         )
         if to_dictionary:
             return objects
         else:
-            projects = [cls.from_dict(source=obj, connection=connection) for obj in objects]
-            projects_loaded = Project._list_loaded_projects(connection, to_dictionary=True)
+            projects = [
+                cls.from_dict(source=obj, connection=connection) for obj in objects
+            ]
+            projects_loaded = Project._list_loaded_projects(
+                connection, to_dictionary=True
+            )
             projects_loaded_ids = [project['id'] for project in projects_loaded]
-            unloaded = [project for project in projects if project.id not in projects_loaded_ids]
+            unloaded = [
+                project for project in projects if project.id not in projects_loaded_ids
+            ]
 
             if unloaded:
                 msg = (
-                    f"Projects {[project.name for project in unloaded]} are either unloaded or "
-                    "idled. Change status using the 'load()' or 'resume()' method to use all "
-                    "functionality."
+                    f"Projects {[project.name for project in unloaded]} are either "
+                    f"unloaded or idled. Change status using the 'load()' or 'resume()'"
+                    f" method to use all functionality."
                 )
                 helper.exception_handler(msg, exception_type=UserWarning)
             return projects
 
     @classmethod
-    def _list_project_ids(cls, connection: Connection, limit: Optional[int] = None,
-                          **filters) -> list[str]:
+    def _list_project_ids(
+        cls, connection: Connection, limit: Optional[int] = None, **filters
+    ) -> list[str]:
         project_dicts = Project._list_projects(
             connection=connection,
             to_dictionary=True,
             limit=limit,
             **dict(filters),
         )
         return [project['id'] for project in project_dicts]
 
     @classmethod
-    def _list_loaded_projects(cls, connection: Connection, to_dictionary: bool = False,
-                              **filters) -> Union[list["Project"], list[dict]]:
+    def _list_loaded_projects(
+        cls, connection: Connection, to_dictionary: bool = False, **filters
+    ) -> list["Project"] | list[dict]:
         response = projects.get_projects(connection, whitelist=[('ERR014', 403)])
         list_of_dicts = response.json() if response.ok else []
         list_of_dicts = helper.camel_to_snake(list_of_dicts)  # Convert keys
         raw_project = helper.filter_list_of_dicts(list_of_dicts, **filters)
 
         if to_dictionary:
             # return list of project names
             return raw_project
         else:
             # return list of Project objects
-            return [cls.from_dict(source=obj, connection=connection) for obj in raw_project]
+            return [
+                cls.from_dict(source=obj, connection=connection) for obj in raw_project
+            ]
 
     def alter(self, name: Optional[str] = None, description: Optional[str] = None):
         """Alter project name or/and description.
 
         Args:
             name: new name of the project.
             description: new description of the project.
         """
-        properties = helper.filter_params_for_func(self.alter, locals(), exclude=['self'])
+        properties = helper.filter_params_for_func(
+            self.alter, locals(), exclude=['self']
+        )
 
         self._alter_properties(**properties)
 
-    def __change_project_state(self, func, on_nodes: Union[str, list[str]] = None, **mode):
+    def __change_project_state(
+        self, func, on_nodes: Optional[str | list[str]] = None, **mode
+    ):
         if type(on_nodes) is list:
             for node in on_nodes:
                 func(node, **mode)
         elif type(on_nodes) is str:
             func(on_nodes, **mode)
         elif on_nodes is None:
             for node in self.nodes:
                 func(node.get('name'), **mode)  # type: ignore
         else:
             helper.exception_handler(
                 "'on_nodes' argument needs to be of type: [list[str], str, NoneType]",
-                exception_type=TypeError
+                exception_type=TypeError,
             )
 
     @method_version_handler('11.2.0000')
     def idle(
         self,
-        on_nodes: Optional[Union[str, list[str]]] = None,
-        mode: Union[IdleMode, str] = IdleMode.REQUEST
+        on_nodes: Optional[str | list[str]] = None,
+        mode: IdleMode | str = IdleMode.REQUEST,
     ) -> None:
         """Request to idle a specific cluster node. Idle project with mode
         options.
 
         Args:
             on_nodes: Name of node, if not passed, project will be idled on
                 all of the nodes.
             mode: One of: `IdleMode` values.
         """
 
         def idle_project(node: str, mode: IdleMode):
             body = {
                 "operationList": [
-                    {
-                        "op": "replace", "path": self._STATUS_PATH, "value": mode.value
-                    }
+                    {"op": "replace", "path": self._STATUS_PATH, "value": mode.value}
                 ]
             }
-            response = monitors.update_node_properties(self.connection, node, self.id, body)
+            response = monitors.update_node_properties(
+                self.connection, node, self.id, body
+            )
             if response.status_code == 202:
                 tmp = helper.filter_list_of_dicts(self.nodes, name=node)
                 tmp[0]['projects'] = [response.json()['project']]
                 self._nodes = tmp
                 if tmp[0]['projects'][0]['status'] != mode.value:
                     self.fetch('nodes')
                 if config.verbose:
                     logger.info(
-                        f"Project '{self.id}' changed status to '{mode}' on node '{node}'."
+                        f"Project '{self.id}' changed status to '{mode}' on node "
+                        f"'{node}'."
                     )
 
         if not isinstance(mode, IdleMode):
             # Previously `mode` was just a string with possible values
             # corresponding to the member names of the current IdleMode enum.
             # This attempts to convert it to avoid breaking backwards compat.
             if mode in IdleMode.__members__.values():
                 mode = IdleMode(mode)
             elif mode in IdleMode.__members__.keys():
                 mode = IdleMode[mode]
             else:
                 helper.exception_handler(
-                    "Unsupported mode, please provide a valid `IdleMode` value.", KeyError
+                    "Unsupported mode, please provide a valid `IdleMode` value.",
+                    KeyError,
                 )
 
         self.__change_project_state(func=idle_project, on_nodes=on_nodes, mode=mode)
 
     @method_version_handler('11.2.0000')
-    def resume(self, on_nodes: Optional[Union[str, list[str]]] = None) -> None:
+    def resume(self, on_nodes: Optional[str | list[str]] = None) -> None:
         """Request to resume the project on the chosen cluster nodes. If
         nodes are not specified, the project will be loaded on all nodes.
 
         Args:
             on_nodes: Name of node, if not passed, project will be resumed
                 on all of the nodes.
         """
 
         def resume_project(node):
             body = {
-                "operationList": [{
-                    "op": "replace", "path": self._STATUS_PATH, "value": "loaded"
-                }]
+                "operationList": [
+                    {"op": "replace", "path": self._STATUS_PATH, "value": "loaded"}
+                ]
             }
-            response = monitors.update_node_properties(self.connection, node, self.id, body)
+            response = monitors.update_node_properties(
+                self.connection, node, self.id, body
+            )
             if response.status_code == 202:
                 tmp = helper.filter_list_of_dicts(self.nodes, name=node)
                 tmp[0]['projects'] = [response.json()['project']]
                 self._nodes = tmp
                 if tmp[0]['projects'][0]['status'] != 'loaded':
                     self.fetch('nodes')
                 if config.verbose:
                     logger.info(f"Project '{self.id}' resumed on node '{node}'.")
 
         self.__change_project_state(func=resume_project, on_nodes=on_nodes)
 
     @method_version_handler('11.2.0000')
-    def load(self, on_nodes: Optional[Union[str, list[str]]] = None) -> None:
+    def load(self, on_nodes: Optional[str | list[str]] = None) -> None:
         """Request to load the project onto the chosen cluster nodes. If
         nodes are not specified, the project will be loaded on all nodes.
 
         Args:
             on_nodes: Name of node, if not passed, project will be loaded
                 on all of the nodes.
         """
 
         def load_project(node):
             body = {
-                "operationList": [{
-                    "op": "replace", "path": self._STATUS_PATH, "value": "loaded"
-                }]
+                "operationList": [
+                    {"op": "replace", "path": self._STATUS_PATH, "value": "loaded"}
+                ]
             }
-            response = monitors.update_node_properties(self.connection, node, self.id, body)
+            response = monitors.update_node_properties(
+                self.connection, node, self.id, body
+            )
             if response.status_code == 202:
                 tmp = helper.filter_list_of_dicts(self.nodes, name=node)
                 tmp[0]['projects'] = [response.json()['project']]
                 self._nodes = tmp
                 if tmp[0]['projects'][0]['status'] != 'loaded':
                     self.fetch('nodes')
                 if config.verbose:
                     logger.info(f"Project '{self.id}' loaded on node '{node}'.")
 
         self.__change_project_state(func=load_project, on_nodes=on_nodes)
 
     @method_version_handler('11.2.0000')
-    def unload(self, on_nodes: Optional[Union[str, list[str]]] = None) -> None:
+    def unload(self, on_nodes: Optional[str | list[str]] = None) -> None:
         """Request to unload the project from the chosen cluster nodes. If
         nodes are not specified, the project will be unloaded on all nodes.
         The unload action cannot be performed until all jobs and connections
         for project are completed. Once these processes have finished,
         pending project will be automatically unloaded.
 
         Args:
             on_nodes: Name of node, if not passed, project will be unloaded
                 on all of the nodes.
         """
 
         def unload_project(node):
             body = {
                 "operationList": [
-                    {
-                        "op": "replace", "path": self._STATUS_PATH, "value": "unloaded"
-                    }
+                    {"op": "replace", "path": self._STATUS_PATH, "value": "unloaded"}
                 ]
             }
             response = monitors.update_node_properties(
                 self.connection, node, self.id, body, whitelist=[('ERR001', 500)]
             )
             if response.status_code == 202:
                 tmp = helper.filter_list_of_dicts(self.nodes, name=node)
                 tmp[0]['projects'] = [response.json()['project']]
                 self._nodes = tmp
                 if tmp[0]['projects'][0]['status'] != 'unloaded':
                     self.fetch('nodes')
                 if config.verbose:
                     logger.info(f"Project '{self.id}' unloaded on node '{node}'.")
             if response.status_code == 500 and config.verbose:  # handle whitelisted
-                logger.warning(f"Project '{self.id}' already unloaded on node '{node}'.")
+                logger.warning(
+                    f"Project '{self.id}' already unloaded on node '{node}'."
+                )
 
         self.__change_project_state(func=unload_project, on_nodes=on_nodes)
 
     @method_version_handler('11.3.0000')
-    def register(self, on_nodes: Optional[Union[str, list]] = None) -> None:
+    def register(self, on_nodes: Optional[str | list] = None) -> None:
         """Register project on nodes.
 
         A registered project will load on node (server) startup.
 
         Args:
             on_nodes: Name of node, if not passed, project will be loaded
                 on all available nodes on startup.
@@ -455,15 +497,15 @@
             value = [node['name'] for node in self.nodes]
         else:
             on_nodes = on_nodes if isinstance(on_nodes, list) else [on_nodes]
             value = list(set(self.load_on_startup) | set(on_nodes))
         self._register(on_nodes=value)
 
     @method_version_handler('11.3.0000')
-    def unregister(self, on_nodes: Optional[Union[str, list]] = None) -> None:
+    def unregister(self, on_nodes: Optional[str | list] = None) -> None:
         """Unregister project on nodes.
 
         An unregistered project will not load on node (server) startup.
 
         Args:
             on_nodes (str or list, optional): Name of node, if not passed,
                 project will not be loaded on any nodes on startup.
@@ -501,26 +543,39 @@
 
     def is_loaded(self) -> bool:
         """Check if the project is loaded on any node (server)."""
         loaded = False
         self.fetch('nodes')
         if not isinstance(self.nodes, list):
             helper.exception_handler(
-                "Could not retrieve current project status.", exception_type=ConnectionError
+                "Could not retrieve current project status.",
+                exception_type=ConnectionError,
             )
         for node in self.nodes:
             projects = node.get('projects')
             if projects:
                 status = projects[0].get('status')
                 loaded = True if status == 'loaded' else False
                 if loaded:
                     break
         return loaded
 
-    def _register(self, on_nodes: Union[list]) -> None:
+    def get_data_engine_versions(self) -> dict:
+        """Fetch the currently available data engine versions for project."""
+
+        return projects.get_engine_settings(self.connection, self.id).json()['engine'][
+            'versions'
+        ]
+
+    def update_data_engine_version(self, new_version: int) -> None:
+        """Update data engine version for project."""
+
+        self.alter_vldb_settings(names_to_values={'AEVersion': new_version})
+
+    def _register(self, on_nodes: list) -> None:
         path = f"/projects/{self.id}/nodes"
         body = {"operationList": [{"op": "replace", "path": path, "value": on_nodes}]}
         projects.update_projects_on_startup(self.connection, body)
         if config.verbose:
             if on_nodes:
                 logger.info(f'Project will load on startup of: {on_nodes}')
             else:
@@ -538,15 +593,17 @@
 
         Settings can be listed by using `list_properties()` method.
         Settings can be modified directly by setting the values in the
         object.
         """
 
         if not hasattr(self, "_settings"):
-            super(Entity, self).__setattr__("_settings", ProjectSettings(self.connection, self.id))
+            super(Entity, self).__setattr__(
+                "_settings", ProjectSettings(self.connection, self.id)
+            )
         return self._settings
 
     @settings.setter
     def settings(self, settings: "ProjectSettings") -> None:
         super(Entity, self).__setattr__("_settings", settings)
 
     @property
@@ -595,28 +652,28 @@
         'reportCacheLifeTime': 'hour',
         'maxWarehouseJobExecTime': 'sec',
         'maxReportExecutionTime': 'sec',
         'maxScheduledReportExecutionTime': 'sec',
         'statisticsPurgeTimeout': 'sec',
         'maxPromptWaitingTime': 'sec',
         'maxRAMForReportRWDCacheIndex': '%',
-        'cubeIndexGrowthUpperBound': '%'
+        'cubeIndexGrowthUpperBound': '%',
     }
     _CACHING_SETTINGS_TO_ENABLE = (
         "enableReportServerCaching",
         "enableCachingForPromptedReportDocument",
         "enableCachingForNonPromptedReportDocument",
         "enableXmlCachingForReport",
     )
     _CACHING_SETTINGS_TO_DISABLE = _CACHING_SETTINGS_TO_ENABLE + (
         "recordPromptAnswersForCacheMonitoring",
         "enableDocumentOutputCachingInXml",
         "enableDocumentOutputCachingInHtml",
         "enableDocumentOutputCachingInPdf",
-        "enableDocumentOutputCachingInExcel"
+        "enableDocumentOutputCachingInExcel",
     )
 
     def __init__(self, connection: Connection, project_id: Optional[str] = None):
         """Initialize `ProjectSettings` object.
 
         Args:
             connection: MicroStrategy connection object returned by
@@ -645,15 +702,17 @@
         Settings object.
 
         Args:
             project_id: Project ID
         """
         self._check_params(project_id)
         set_dict = self._prepare_settings_push()
-        response = projects.update_project_settings(self._connection, self._project_id, set_dict)
+        response = projects.update_project_settings(
+            self._connection, self._project_id, set_dict
+        )
         if config.verbose:
             if response.status_code == 200:
                 logger.info('Project settings updated.')
             elif response.status_code == 207:
                 partial_succ = response.json()
                 logging.info(f'Project settings partially successful.\n{partial_succ}')
 
@@ -690,29 +749,35 @@
             helper.exception_handler(msg, Warning)
         return self._prepare_settings_fetch(settings)
 
     def _get_config(self):
         if not ProjectSettings._CONFIG:
             project_id = self._project_id
             if not project_id:
-                project_id = Project._list_loaded_projects(self._connection,
-                                                           to_dictionary=True)['id'][0]
-            response = projects.get_project_settings_config(self._connection, project_id)
+                project_id = Project._list_loaded_projects(
+                    self._connection, to_dictionary=True
+                )['id'][0]
+            response = projects.get_project_settings_config(
+                self._connection, project_id
+            )
             ProjectSettings._CONFIG = response.json()
             super()._get_config()
 
     def _check_params(self, project_id: Optional[str] = None):
         if project_id:
             super(BaseSettings, self).__setattr__('_project_id', project_id)
         if not self._connection or not self._project_id:
-            raise AttributeError("Please provide `connection` and `project_id` parameter")
+            raise AttributeError(
+                "Please provide `connection` and `project_id` parameter"
+            )
 
     @wip()
     def list_caching_properties(self) -> dict:
         """
         Fetch current project settings connected with caching from I-Server
         """
         self.fetch()
         return {
-            k: v for (k, v) in self.list_properties().items()
+            k: v
+            for (k, v) in self.list_properties().items()
             if any(word in k.lower() for word in ("cache", "caching"))
         }
```

### Comparing `mstrio-py-11.3.9.101/mstrio/server/server.py` & `mstrio-py-11.3.9.103/mstrio/server/server.py`

 * *Files identical despite different names*

### Comparing `mstrio-py-11.3.9.101/mstrio/types.py` & `mstrio-py-11.3.9.103/mstrio/types.py`

 * *Files 7% similar despite different names*

```diff
@@ -39,14 +39,15 @@
     DBTABLE = 53
     DOCUMENT_DEFINITION = 55
     DRILL_MAP = 56
     DBMS = 57
     SECURITY_FILTER = 58
     SHORTCUT = 67
     SHORTCUT_TARGET = 68
+    DRIVER = 84
     NONE = None
 
     def __new__(cls, value):
         member = object.__new__(cls)
         member._value_ = value
         return member
 
@@ -127,11 +128,10 @@
         member._value_ = value
         return member
 
     def __int__(self):
         return self.value
 
 
-TypeOrSubtype = Union[int,
-                      ObjectTypes,
-                      ObjectSubTypes,
-                      List[Union[int, ObjectTypes, ObjectSubTypes]]]
+TypeOrSubtype = Union[
+    int, ObjectTypes, ObjectSubTypes, List[Union[int, ObjectTypes, ObjectSubTypes]]
+]
```

### Comparing `mstrio-py-11.3.9.101/mstrio/users_and_groups/contact.py` & `mstrio-py-11.3.9.103/mstrio/users_and_groups/contact.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 # NOSONAR
+import logging
 from collections import defaultdict
 from enum import auto
-import logging
-from typing import Iterable, Optional, TYPE_CHECKING
+from typing import TYPE_CHECKING, Iterable, Optional
 
 from mstrio import config
 from mstrio.api import contacts
 from mstrio.users_and_groups.contact_group import ContactGroup
 from mstrio.users_and_groups.user import User
-from mstrio.utils.entity import auto_match_args_entity, DeleteMixin, EntityBase
+from mstrio.utils.entity import DeleteMixin, EntityBase, auto_match_args_entity
 from mstrio.utils.enum_helper import AutoName
 from mstrio.utils.helper import (
+    Dictable,
     camel_to_snake,
     delete_none_values,
-    Dictable,
     fetch_objects,
     get_args_from_func,
     get_default_args_from_func,
-    get_objects_id
+    get_objects_id,
 )
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
     from mstrio.distribution_services.device.device import Device
 
@@ -50,71 +50,83 @@
         is_default: specifies if address is default, optional,
             default value: False
         device: instance of Device or string (containing device's id),
             if device is a string, connection is required
         connection: instance of Connection, optional,
             is required if device is string
     """
+
     @staticmethod
     def __device_from_dict(source, connection):
         from mstrio.distribution_services.device.device import Device
+
         return Device.from_dict(source, connection)
 
-    _FROM_DICT_MAP = {'delivery_type': ContactDeliveryType, 'device': __device_from_dict}
+    _FROM_DICT_MAP = {
+        'delivery_type': ContactDeliveryType,
+        'device': __device_from_dict,
+    }
 
     def __init__(
         self,
         name: str,
         physical_address: str,
         delivery_type: ContactDeliveryType | str,
         device: 'Device | str',
         id: Optional[str] = None,
         is_default: bool = False,
-        connection: Optional['Connection'] = None
+        connection: Optional['Connection'] = None,
     ):
         self.id = id
         self.name = name
         self.physical_address = physical_address
         self.is_default = is_default
 
-        self.delivery_type = delivery_type if isinstance(delivery_type, ContactDeliveryType
-                                                         ) else ContactDeliveryType(delivery_type)
+        self.delivery_type = (
+            delivery_type
+            if isinstance(delivery_type, ContactDeliveryType)
+            else ContactDeliveryType(delivery_type)
+        )
 
         from mstrio.distribution_services.device.device import Device
+
         if isinstance(device, Device):
             self.device = device
         else:
             if not connection:
-                raise ValueError('Argument: connection is required if device is a string')
+                raise ValueError(
+                    'Argument: connection is required if device is a string'
+                )
 
             self.device = Device(connection, id=device)
 
     def __repr__(self) -> str:
         param_dict = auto_match_args_entity(
             self.__init__, self, exclude=['self'], include_defaults=False
         )
 
         params = [
             f"{param}={self.delivery_type}"
-            if param == 'delivery_type' else f'{param}={repr(value)}' for param,
-            value in param_dict.items()
+            if param == 'delivery_type'
+            else f'{param}={repr(value)}'
+            for param, value in param_dict.items()
         ]
         formatted_params = ', '.join(params)
 
         return f'ContactAddress({formatted_params})'
 
     def to_dict(self, camel_case=True) -> dict:
         result = {
             'name': self.name,
             'id': self.id,
             'physicalAddress': self.physical_address,
             'deliveryType': self.delivery_type.value,
             'deviceId': self.device.id,
             'deviceName': self.device.name,
-            'isDefault': self.is_default
+            'isDefault': self.is_default,
         }
 
         return result if camel_case else camel_to_snake(result)
 
     @classmethod
     def from_dict(cls, source, connection, to_snake_case=True) -> 'ContactAddress':
         source = source.copy()
@@ -125,28 +137,31 @@
         source['device'] = {'id': device_id, 'name': device_name}
 
         return super().from_dict(source, connection, to_snake_case)
 
 
 @method_version_handler('11.3.0100')
 def list_contacts(
-    connection: 'Connection', to_dictionary: bool = False, limit: Optional[int] = None, **filters
+    connection: 'Connection',
+    to_dictionary: bool = False,
+    limit: Optional[int] = None,
+    **filters,
 ) -> list['Contact'] | list[dict]:
     """Get all contacts as list of Contact objects or dictionaries.
 
     Optionally filter the contacts by specifying filters.
 
     Args:
         connection: MicroStrategy connection object
         to_dictionary: If True returns a list of contact dicts,
             otherwise returns a list of contact objects
         limit: limit the number of elements returned. If `None` (default), all
             objects are returned.
         **filters: Available filter parameters:
-            ['id', 'name', 'description', 'enabled']
+            ['id', 'name', 'description', 'enabled', 'linked_user']
     """
 
     return Contact._list_contacts(
         connection=connection, to_dictionary=to_dictionary, limit=limit, **filters
     )
 
 
@@ -162,62 +177,76 @@
         linked_user: user linked to contact, instance of User
         contact_addresses: list of contact's addresses,
             instances of ContactAddress
         memberships: list of Contact Groups that the contact belongs to
         connection: instance of Connection class, represents connection
                     to MicroStrategy Intelligence Server
     """
+
     _FROM_DICT_MAP = {
         **EntityBase._FROM_DICT_MAP,
         'linked_user': User.from_dict,
         'contact_addresses': [ContactAddress.from_dict],
         'memberships': [ContactGroup.from_dict],
     }
     _API_GETTERS = {
         (
             'id',
             'name',
             'description',
             'enabled',
             'linked_user',
             'memberships',
-            'contact_addresses'
+            'contact_addresses',
         ): contacts.get_contact
     }
     _API_DELETE = staticmethod(contacts.delete_contact)
     _API_PATCH = {
-        ('name', 'description', 'enabled', 'linked_user', 'contact_addresses',
-         'memberships'): (contacts.update_contact, 'put')
+        (
+            'name',
+            'description',
+            'enabled',
+            'linked_user',
+            'contact_addresses',
+            'memberships',
+        ): (contacts.update_contact, 'put')
     }
     _PATCH_PATH_TYPES = {
         'name': str,
         'description': str,
         'enabled': bool,
         'linked_user': dict,
         'contact_addresses': list,
-        'memberships': list
+        'memberships': list,
     }
 
     def __init__(
-        self, connection: 'Connection', id: Optional[str] = None, name: Optional[str] = None
+        self,
+        connection: 'Connection',
+        id: Optional[str] = None,
+        name: Optional[str] = None,
     ):
         """Initialize Contact object by passing id or name.
         When `id` is provided, name is omitted.
 
         Args:
             connection: MicroStrategy connection object
             id: ID of Contact
             name: name of Contact
         """
 
         if id is None and name is None:
-            raise ValueError("Please specify either 'id' or 'name' parameter in the constructor.")
+            raise ValueError(
+                "Please specify either 'id' or 'name' parameter in the constructor."
+            )
 
         if id is None:
-            result = Contact._list_contacts(connection=connection, name=name, to_dictionary=True)
+            result = Contact._list_contacts(
+                connection=connection, name=name, to_dictionary=True
+            )
 
             if result:
                 object_data = result[0]
                 object_data['connection'] = connection
                 self._init_variables(**object_data)
             else:
                 raise ValueError(f"There is no Contact named: '{name}'")
@@ -227,36 +256,45 @@
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
 
         self.description = kwargs.get('description')
         self.enabled = kwargs.get('enabled')
 
         linked_user = kwargs.get("linked_user")
-        self.linked_user = User.from_dict(linked_user, self.connection) if linked_user else None
+        self.linked_user = (
+            User.from_dict(linked_user, self.connection) if linked_user else None
+        )
 
         addresses = kwargs.get('contact_addresses')
-        self.contact_addresses = [
-            ContactAddress.from_dict(address, self.connection) for address in addresses
-        ] if addresses else None
+        self.contact_addresses = (
+            [
+                ContactAddress.from_dict(address, self.connection)
+                for address in addresses
+            ]
+            if addresses
+            else None
+        )
 
         memberships = kwargs.get('memberships')
-        self.memberships = [
-            ContactGroup.from_dict(m, self.connection) for m in memberships
-        ] if memberships else None
+        self.memberships = (
+            [ContactGroup.from_dict(m, self.connection) for m in memberships]
+            if memberships
+            else None
+        )
 
     @classmethod
     @method_version_handler('11.3.0200')
     def create(
         cls,
         connection: 'Connection',
         name: str,
         linked_user: 'User | str',
         contact_addresses: Iterable['ContactAddress | dict'],
         description: Optional[str] = None,
-        enabled: bool = True
+        enabled: bool = True,
     ) -> 'Contact':
         """Create a new contact.
 
         Args:
             connection: MicroStrategy connection object
                 returned by `connection.Connection()`
             name: contact name
@@ -267,39 +305,38 @@
         Returns:
             Contact object
         """
         body = {
             'name': name,
             'description': description,
             'enabled': enabled,
-            'linkedUser': {
-                'id': get_objects_id(linked_user, User)
-            },
+            'linkedUser': {'id': get_objects_id(linked_user, User)},
             'contactAddresses': [
                 address.to_dict() if isinstance(address, ContactAddress) else address
                 for address in contact_addresses
             ],
         }
         body = delete_none_values(body, recursion=True)
         response = contacts.create_contact(connection, body).json()
 
         if config.verbose:
             logger.info(
-                f"Successfully created contact named: '{name}' with ID: '{response['id']}'"
+                f"Successfully created contact named: '{name}' with ID: "
+                f"'{response['id']}'"
             )
 
         return cls.from_dict(source=response, connection=connection)
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
         enabled: Optional[bool] = None,
         linked_user: Optional['User | str'] = None,
-        contact_addresses: Optional[Iterable['ContactAddress | dict']] = None
+        contact_addresses: Optional[Iterable['ContactAddress | dict']] = None,
     ):
         """Update properties of a contact
 
         Args:
            name: name of a contact
            description: description of a contact
            enabled: specifies if a contact is enabled
@@ -307,15 +344,15 @@
            contact_addresses: list of contact addresses
         """
         linked_user = {'id': get_objects_id(linked_user, User)} if linked_user else None
 
         func = self.alter
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        defaults_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        defaults_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = defaultdict(dict)
 
         for property_key in defaults_dict:
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
 
@@ -323,15 +360,15 @@
 
     @classmethod
     def _list_contacts(
         cls,
         connection: 'Connection',
         to_dictionary: bool = False,
         limit: Optional[int] = None,
-        **filters
+        **filters,
     ) -> list['Contact'] | list[dict]:
         """Get all contacts as list of Contact objects or dictionaries.
 
         Optionally filter the contacts by specifying filters.
 
         Args:
             connection: MicroStrategy connection object
@@ -344,15 +381,15 @@
         """
 
         objects = fetch_objects(
             connection=connection,
             api=contacts.get_contacts,
             limit=limit,
             filters=filters,
-            dict_unpack_value='contacts'
+            dict_unpack_value='contacts',
         )
 
         if to_dictionary:
             return objects
 
         return [cls.from_dict(source=obj, connection=connection) for obj in objects]
```

### Comparing `mstrio-py-11.3.9.101/mstrio/users_and_groups/contact_group.py` & `mstrio-py-11.3.9.103/mstrio/users_and_groups/contact_group.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,15 +6,19 @@
 
 from mstrio import config
 from mstrio.api import contact_groups
 from mstrio.users_and_groups.user import User
 from mstrio.utils.entity import auto_match_args_entity, DeleteMixin, EntityBase
 from mstrio.utils.enum_helper import AutoName
 from mstrio.utils.helper import (
-    Dictable, fetch_objects_async, get_args_from_func, get_default_args_from_func, get_objects_id
+    Dictable,
+    fetch_objects_async,
+    get_args_from_func,
+    get_default_args_from_func,
+    get_objects_id,
 )
 from mstrio.utils.version_helper import class_version_handler, method_version_handler
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
     from mstrio.users_and_groups.contact import Contact
 
@@ -33,38 +37,39 @@
     Attributes:
         name: member's name
         type: type of a member, instance of ContactGroupMemberType
         id: id of member, optional
         description: member's description, optional
         enabled: specifies if a member is enabled
     """
+
     _FROM_DICT_MAP = {"type": ContactGroupMemberType}
 
     def __init__(
         self,
         name: str,
         type: Union[str, ContactGroupMemberType],
         id: Optional[str] = None,
         description: Optional[str] = None,
-        enabled: bool = True
+        enabled: bool = True,
     ):
         self.name = name
         self.type = ContactGroupMemberType(type) if isinstance(type, str) else type
         self.id = id
         self.description = description
         self.enabled = enabled
 
     def __repr__(self) -> str:
         param_dict = auto_match_args_entity(
             self.__init__, self, exclude=['self'], include_defaults=False
         )
 
         params = [
-            f"{param}={self.type}" if param == 'type' else f'{param}={repr(value)}' for param,
-            value in param_dict.items()
+            f"{param}={self.type}" if param == 'type' else f'{param}={repr(value)}'
+            for param, value in param_dict.items()
         ]
         formatted_params = ', '.join(params)
 
         return f'ContactGroupMember({formatted_params})'
 
     @classmethod
     def from_contact_or_contact_group(
@@ -81,34 +86,39 @@
         """
         from mstrio.users_and_groups.contact import Contact
 
         if isinstance(obj, Contact):
             return cls(id=obj.id, name=obj.name, type=ContactGroupMemberType.CONTACT)
 
         if isinstance(obj, ContactGroup):
-            return cls(id=obj.id, name=obj.name, type=ContactGroupMemberType.CONTACT_GROUP)
+            return cls(
+                id=obj.id, name=obj.name, type=ContactGroupMemberType.CONTACT_GROUP
+            )
 
 
 @method_version_handler('11.3.0200')
 def list_contact_groups(
-    connection: "Connection", to_dictionary: bool = False, limit: Optional[int] = None, **filters
+    connection: "Connection",
+    to_dictionary: bool = False,
+    limit: Optional[int] = None,
+    **filters,
 ) -> Union[List["ContactGroup"], List[dict]]:
     """Get all contact groups as list of ContactGroup objects or
     dictionaries.
 
     Optionally filter the contact groups by specifying filters.
 
     Args:
         connection(object): MicroStrategy connection object
         to_dictionary: If True returns a list of contact group dicts,
             otherwise returns a list of contact group objects
         limit: limit the number of elements returned. If `None` (default), all
             objects are returned.
         **filters: Available filter parameters: ['id', 'name', 'description',
-            enabled]
+            'enabled', 'linked_user']
     """
     return ContactGroup._list_contact_groups(
         connection=connection, to_dictionary=to_dictionary, limit=limit, **filters
     )
 
 
 @class_version_handler('11.3.0200')
@@ -123,51 +133,66 @@
         linked_user: user linked to contact group, instance of User
         members: list of contact group's members, instances of
             ContactGroupMember
         memberships: list of Contact Groups that the Contact Group belongs to
         connection: instance of Connection class, represents connection
                     to MicroStrategy Intelligence Server
     """
+
     _FROM_DICT_MAP = {
         **EntityBase._FROM_DICT_MAP,
         'linked_user': User.from_dict,
         'members': [ContactGroupMember.from_dict],
     }
     _API_GETTERS = {
-        ('id', 'name', 'description', 'enabled', 'linked_user', 'members',
-         'memberships'): contact_groups.get_contact_group
+        (
+            'id',
+            'name',
+            'description',
+            'enabled',
+            'linked_user',
+            'members',
+            'memberships',
+        ): contact_groups.get_contact_group
     }
     _API_DELETE = staticmethod(contact_groups.delete_contact_group)
     _API_PATCH = {
-        ('name', 'description', 'enabled', 'linked_user',
-         'members'): (contact_groups.update_contact_group, 'put')
+        ('name', 'description', 'enabled', 'linked_user', 'members'): (
+            contact_groups.update_contact_group,
+            'put',
+        )
     }
     _PATCH_PATH_TYPES = {
         'name': str,
         'description': str,
         'enabled': bool,
         'linked_user': dict,
         'members': list,
-        'memberships': list
+        'memberships': list,
     }
 
     def __init__(
-        self, connection: 'Connection', id: Optional[str] = None, name: Optional[str] = None
+        self,
+        connection: 'Connection',
+        id: Optional[str] = None,
+        name: Optional[str] = None,
     ):
         """Initialize Contact Group object by passing id or name.
         When `id` is provided, name is omitted.
 
         Args:
             connection: MicroStrategy connection object
             id: ID of Contact
             name: name of Contact Group
         """
 
         if id is None and name is None:
-            raise ValueError("Please specify either 'id' or 'name' parameter in the constructor.")
+            raise ValueError(
+                "Please specify either 'id' or 'name' parameter in the constructor."
+            )
 
         if id is None:
             result = ContactGroup._list_contact_groups(
                 connection=connection,
                 name=name,
                 to_dictionary=True,
             )
@@ -182,35 +207,41 @@
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
 
         self.description = kwargs.get('description')
         self.enabled = kwargs.get('enabled')
 
         linked_user = kwargs.get("linked_user")
-        self.linked_user = User.from_dict(linked_user, self.connection) if linked_user else None
+        self.linked_user = (
+            User.from_dict(linked_user, self.connection) if linked_user else None
+        )
 
         members = kwargs.get('members')
-        self.members = [
-            ContactGroupMember.from_dict(member) for member in members
-        ] if members else None
+        self.members = (
+            [ContactGroupMember.from_dict(member) for member in members]
+            if members
+            else None
+        )
 
         memberships = kwargs.get('memberships')
-        self._memberships = [
-            self.from_dict(m, self.connection) for m in memberships
-        ] if memberships else None
+        self._memberships = (
+            [self.from_dict(m, self.connection) for m in memberships]
+            if memberships
+            else None
+        )
 
     @classmethod
     def create(
         cls,
         connection: "Connection",
         name: str,
         linked_user: Union[str, User],
         members: List[Union[dict, ContactGroupMember]],
         description: Optional[str] = None,
-        enabled: bool = True
+        enabled: bool = True,
     ) -> 'ContactGroup':
         """Create a new contact group.
 
         Args:
             connection: MicroStrategy connection object
                 returned by `connection.Connection()`
             name: contact group name
@@ -218,24 +249,24 @@
             members: list of members
             description: description of contact
             enabled: specifies if contact should be enabled
 
         Returns:
             `ContactGroup` object
         """
-        members = [m.to_dict() if isinstance(m, ContactGroupMember) else m for m in members]
+        members = [
+            m.to_dict() if isinstance(m, ContactGroupMember) else m for m in members
+        ]
         linked_user = get_objects_id(linked_user, User)
         body = {
             'name': name,
             'description': description,
             'enabled': enabled,
-            'linkedUser': {
-                'id': linked_user
-            },
-            'members': members
+            'linkedUser': {'id': linked_user},
+            'members': members,
         }
         res = contact_groups.create_contact_group(connection, body).json()
         if config.verbose:
             logger.info(
                 f"Successfully created contact group named: '{res.get('name')}' "
                 f"with ID: '{res.get('id')}'"
             )
@@ -243,15 +274,15 @@
 
     def alter(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
         enabled: Optional[bool] = None,
         linked_user: Optional[Union['User', str]] = None,
-        members: Optional[Iterable[Union['ContactGroupMember', dict]]] = None
+        members: Optional[Iterable[Union['ContactGroupMember', dict]]] = None,
     ):
         """Update properties of a contact group
 
         Args:
             name: name of a contact
             description: description of a contact
             enabled: specifies if a contact is enabled
@@ -261,15 +292,15 @@
         """
 
         linked_user = {'id': get_objects_id(linked_user, User)} if linked_user else None
 
         func = self.alter
         args = get_args_from_func(func)
         defaults = get_default_args_from_func(func)
-        defaults_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        defaults_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
 
         properties = defaultdict(dict)
 
         for property_key in defaults_dict:
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
@@ -279,51 +310,57 @@
     @classmethod
     def _list_contact_groups(
         cls,
         connection: "Connection",
         to_dictionary: bool = False,
         limit: Optional[int] = None,
         offset: Optional[int] = None,
-        **filters
+        **filters,
     ) -> Union[List["ContactGroup"], List[dict]]:
         objects = fetch_objects_async(
             connection=connection,
             api=contact_groups.get_contact_groups,
             async_api=contact_groups.get_contact_groups_async,
             limit=limit,
             offset=offset,
             chunk_size=1000,
             filters=filters,
             dict_unpack_value='contactGroups',
         )
 
         if to_dictionary:
             return objects
-        return [ContactGroup.from_dict(source=obj, connection=connection) for obj in objects]
+        return [
+            ContactGroup.from_dict(source=obj, connection=connection) for obj in objects
+        ]
 
     def _set_object_attributes(self, **kwargs) -> None:
         super()._set_object_attributes(**kwargs)
         memberships = kwargs.get("memberships")
 
-        memberships_objs = [self.from_dict(m, self.connection)
-                            for m in memberships] if memberships else []
+        memberships_objs = (
+            [self.from_dict(m, self.connection) for m in memberships]
+            if memberships
+            else []
+        )
         setattr(self, '_memberships', memberships_objs)
 
     def add_members(
         self, members: Iterable[Union['ContactGroupMember', 'Contact', 'ContactGroup']]
     ):
         """Add member
 
         Args:
            members: list of members to add to contact group
         """
         members_ids = [member.id for member in self.members]
         new_members = [
             ContactGroupMember.from_contact_or_contact_group(obj)
-            if not isinstance(obj, ContactGroupMember) else obj
+            if not isinstance(obj, ContactGroupMember)
+            else obj
             for obj in members
             if obj.id not in members_ids
         ]
 
         self.alter(members=new_members + self.members)
 
     def remove_members(
@@ -331,14 +368,16 @@
     ):
         """Remove member
 
         Args:
            members: list of members to remove from contact group
         """
         ids_to_remove = [member.id for member in members]
-        new_member_list = [member for member in self.members if member.id not in ids_to_remove]
+        new_member_list = [
+            member for member in self.members if member.id not in ids_to_remove
+        ]
 
         self.alter(members=new_member_list)
 
     @property
     def memberships(self):
         return self._memberships
```

### Comparing `mstrio-py-11.3.9.101/mstrio/users_and_groups/user.py` & `mstrio-py-11.3.9.103/mstrio/users_and_groups/user.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-from datetime import datetime
-from enum import Enum, IntFlag
 import json
 import logging
-from typing import Optional, TYPE_CHECKING
+from datetime import datetime
+from enum import Enum, IntFlag
+from typing import TYPE_CHECKING, Optional
 
-from pandas import DataFrame, read_csv
 import pandas as pd
+from pandas import DataFrame, read_csv
 from requests.exceptions import HTTPError
 
 from mstrio import config
 from mstrio.access_and_security.privilege_mode import PrivilegeMode
 from mstrio.access_and_security.security_role import SecurityRole
 from mstrio.api import users
 from mstrio.connection import Connection
@@ -44,15 +44,15 @@
 
 def list_users(
     connection: Connection,
     name_begins: Optional[str] = None,
     abbreviation_begins: Optional[str] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> list["User"] | list[dict]:
     """Get list of user objects or user dicts. Optionally filter the users by
     specifying 'name_begins', 'abbreviation_begins' or other filters.
 
     Wildcards available for name_begins and abbreviation_begins:
         ? - any character
         * - 0 or more of any characters
@@ -152,15 +152,15 @@
             'password_modifiable',
             'require_new_password',
             'standard_auth',
             'memberships',
             'acg',
             'acl',
             'trust_id',
-            'initials'
+            'initials',
         ): users.get_user_info,
         'addresses': users.get_addresses,
         'security_roles': users.get_user_security_roles,
         'privileges': users.get_user_privileges,
     }
     _API_PATCH: dict = {
         (
@@ -177,28 +177,28 @@
             'standard_auth',
             'ldapdn',
             'trust_id',
             'initials',
             'privileges',
             'memberships',
             'addresses',
-            'security_roles'
+            'security_roles',
         ): (users.update_user_info, 'patch')
     }
     _FROM_DICT_MAP = {
         **Entity._FROM_DICT_MAP,
         'password_expiration_date': time_helper.DatetimeFormats.FULLDATETIME,
     }
 
     def __init__(
         self,
         connection: Connection,
         username: Optional[str] = None,
         name: Optional[str] = None,
-        id: Optional[str] = None
+        id: Optional[str] = None,
     ) -> None:
         """Initialize User object by passing username, name, or id.
         When `id` is provided (not `None`), `username` and `name` are omitted.
         When `id` is not provided (`None`) and `username` is provided (not
         `None`), `name` is omitted.
 
         Args:
@@ -206,37 +206,44 @@
                 `connection.Connection()`
             id: ID of User
             username: username of User
             name: name of User
         """
         if id is None and name is None and username is None:
             helper.exception_handler(
-                "Please specify either 'id', 'username' or 'name' parameter in the constructor."
+                "Please specify either 'id', 'username' or 'name' parameter in the "
+                "constructor."
             )
 
         if id is None:
-            users = User._get_user_ids(
-                connection=connection,
-                abbreviation_begins=username,
-                abbreviation=username,
-            ) if username is not None else User._get_user_ids(
-                connection=connection,
-                name_begins=name,
-                name=name,
+            users = (
+                User._get_user_ids(
+                    connection=connection,
+                    abbreviation_begins=username,
+                    abbreviation=username,
+                )
+                if username is not None
+                else User._get_user_ids(
+                    connection=connection,
+                    name_begins=name,
+                    name=name,
+                )
             )
 
             if users:
                 [id] = users
             else:
                 temp_name = name if name else username
                 helper.exception_handler(
                     f"There is no user: '{temp_name}'", exception_type=ValueError
                 )
 
-        super().__init__(connection=connection, object_id=id, username=username, name=name)
+        super().__init__(
+            connection=connection, object_id=id, username=username, name=name
+        )
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
         self.username = kwargs.get("username")
         self.full_name = kwargs.get("full_name")
         self.enabled = kwargs.get("enabled")
         self.password_modifiable = kwargs.get("password_modifiable")
@@ -264,15 +271,15 @@
         password_modifiable: bool = True,
         password_expiration_date: Optional[str | datetime] = None,
         require_new_password: bool = True,
         standard_auth: bool = True,
         ldapdn: Optional[str] = None,
         trust_id: Optional[str] = None,
         database_auth_login: Optional[str] = None,
-        memberships: Optional[list] = None
+        memberships: Optional[list] = None,
     ) -> "User":
         """Create a new user on the I-Server. Returns User object.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`
             username: username of user
@@ -291,42 +298,44 @@
             trust_id: Unique user ID provided by trusted authentication provider
             database_auth_login: Database Authentication Login
             memberships: specify User Group IDs which User will be member off.
         """
         password_expiration_date = time_helper.map_datetime_to_str(
             name='password_expiration_date',
             date=password_expiration_date,
-            string_to_date_map=cls._FROM_DICT_MAP
+            string_to_date_map=cls._FROM_DICT_MAP,
         )
         body = {
             "username": username,
             "fullName": full_name,
             "description": description,
             "password": password,
             "enabled": enabled,
             "passwordModifiable": password_modifiable,
             "passwordExpirationDate": password_expiration_date,
             "requireNewPassword": require_new_password,
             "standardAuth": standard_auth,
             "ldapdn": ldapdn,
             "trustId": trust_id,
             "databaseAuthLogin": database_auth_login,
-            "memberships": memberships
+            "memberships": memberships,
         }
         body = helper.delete_none_values(body, recursion=True)
         response = users.create_user(connection, body, username).json()
         if config.verbose:
             logger.info(
                 f"Successfully created user named: '{response.get('username')}' "
                 f"with ID: '{response.get('id')}'"
             )
         return cls.from_dict(source=response, connection=connection)
 
     @classmethod
-    def _create_users_from_csv(cls, connection: Connection, csv_file: str) -> list["User"]:
+    def _create_users_from_csv(
+        cls, connection: Connection, csv_file: str
+    ) -> list["User"]:
         func = cls.create
         args = helper.get_args_from_func(func)
         df = read_csv(csv_file, na_filter=False, usecols=lambda x: x in args)
         user_list = []
         all_param_value_dict = df.to_dict('records')
 
         for param_value_dict in all_param_value_dict:
@@ -344,41 +353,41 @@
     def _get_users(
         cls,
         connection: Connection,
         name_begins: Optional[str] = None,
         abbreviation_begins: Optional[str] = None,
         to_dictionary: bool = False,
         limit: Optional[int] = None,
-        **filters
+        **filters,
     ) -> list["User"] | list[dict]:
         msg = "Error getting information for a set of users."
         objects = helper.fetch_objects_async(
             connection,
             users.get_users_info,
             users.get_users_info_async,
             limit=limit,
             chunk_size=1000,
             error_msg=msg,
             name_begins=name_begins,
             abbreviation_begins=abbreviation_begins,
-            filters=filters
+            filters=filters,
         )
         if to_dictionary:
             return objects
         else:
             return [cls.from_dict(source=obj, connection=connection) for obj in objects]
 
     @classmethod
     def _get_user_ids(
         cls,
         connection: Connection,
         name_begins: Optional[str] = None,
         abbreviation_begins: Optional[str] = None,
         limit: Optional[int] = None,
-        **filters
+        **filters,
     ) -> list[str]:
         user_dicts = User._get_users(
             connection=connection,
             name_begins=name_begins,
             abbreviation_begins=abbreviation_begins,
             to_dictionary=True,
             limit=limit,
@@ -395,15 +404,15 @@
         enabled: Optional[bool] = None,
         password_modifiable: Optional[bool] = None,
         password_expiration_date: Optional[str] = None,
         standard_auth: Optional[bool] = None,
         require_new_password: Optional[bool] = None,
         ldapdn: Optional[str] = None,
         trust_id: Optional[str] = None,
-        database_auth_login: Optional[str] = None
+        database_auth_login: Optional[str] = None,
     ) -> None:
         """Alter user properties.
 
         Args:
             username: username of user
             full_name: user full name
             description: user description
@@ -419,59 +428,66 @@
             ldapdn: User's LDAP distinguished name
             trust_id: Unique user ID provided by trusted authentication provider
             database_auth_login: Database Authentication Login
         """
         func = self.alter
         args = helper.get_args_from_func(func)
         defaults = helper.get_default_args_from_func(func)
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
 
         self._alter_properties(**properties)
 
     def add_address(
-        self, name: Optional[str] = None, address: Optional[str] = None, default: bool = True
+        self,
+        name: Optional[str] = None,
+        address: Optional[str] = None,
+        default: bool = True,
     ) -> None:
         """Add new address to the user object.
 
         Args:
             name: User-specified name for the address
             address: The actual value of the address i.e. email address
                 associated with this address name/id
             default: Specifies whether this address is the default address
                 (change isDefault parameter). Default value is set to True.
         """
         helper.validate_param_value(
-            'address', address, str, regex=r"[^@]+@[^@]+\.[^@]+", valid_example="name@mail.com"
+            'address',
+            address,
+            str,
+            regex=r"[^@]+@[^@]+\.[^@]+",
+            valid_example="name@mail.com",
         )
         helper.validate_param_value('name', name, str)
         helper.validate_param_value('default', default, bool)
         body = {
             "name": name,
             "deliveryMode": "EMAIL",
             "device": "GENERIC_EMAIL",
             "value": address,
-            "default": default
+            "default": default,
         }
         response = users.create_address(self.connection, self.id, body)
         if response.ok:
             if config.verbose:
                 logger.info(f"Added address '{address}' for user '{self.name}'")
             setattr(self, "_addresses", response.json().get('addresses'))
 
     def update_address(
         self,
         id: str,
         name: Optional[str] = None,
         address: Optional[str] = None,
-        default: Optional[bool] = None
+        default: Optional[bool] = None,
     ) -> None:
         """Update existing address. The address ID has to be specified
         as the name is not unique.
 
         Args:
             id: ID of the address
             name: New user-specified name for the address
@@ -486,27 +502,30 @@
             body["name"] = name
         if address is not None:
             helper.validate_param_value(
                 'address',
                 address,
                 str,
                 regex=r"[^@]+@[^@]+\.[^@]+",
-                valid_example="name@mail.com"
+                valid_example="name@mail.com",
             )
             body["value"] = address
         if default is not None:
             helper.validate_param_value('default', default, bool)
         response = users.update_address(self.connection, self.id, id, body)
         if response.ok:
             if config.verbose:
                 logger.info(f"Updated address with ID '{id}' for user '{self.name}'")
             self.fetch("addresses")
 
     def remove_address(
-        self, name: Optional[str] = None, address: Optional[str] = None, id: Optional[str] = None
+        self,
+        name: Optional[str] = None,
+        address: Optional[str] = None,
+        id: Optional[str] = None,
     ) -> None:
         """Remove existing address from the user object. Specify either address
         ID or name. Warning, address names are not unique and can potentially
         remove multiple addresses.
 
         Args:
             name: User-specified name for the address
@@ -520,21 +539,27 @@
                 "Please specify either 'name' or 'id' parameter in the method."
             )
         if id is not None:
             addresses = helper.filter_list_of_dicts(initial_addresses, id=id)
             new_addresses = helper.filter_list_of_dicts(initial_addresses, id=f'!={id}')
         elif address is not None:
             addresses = helper.filter_list_of_dicts(initial_addresses, value=address)
-            new_addresses = helper.filter_list_of_dicts(initial_addresses, value=f'!={address}')
+            new_addresses = helper.filter_list_of_dicts(
+                initial_addresses, value=f'!={address}'
+            )
         elif name is not None:
             addresses = helper.filter_list_of_dicts(initial_addresses, name=name)
-            new_addresses = helper.filter_list_of_dicts(initial_addresses, name=f'!={name}')
+            new_addresses = helper.filter_list_of_dicts(
+                initial_addresses, name=f'!={name}'
+            )
 
         for addr in addresses:
-            response = users.delete_address(self.connection, id=self.id, address_id=addr['id'])
+            response = users.delete_address(
+                self.connection, id=self.id, address_id=addr['id']
+            )
             if response.ok:
                 if config.verbose:
                     logger.info(
                         f"Removed address '{addr['name']}' with id {addr['id']} "
                         f"from user '{self.name}'"
                     )
                 setattr(self, "_addresses", new_addresses)
@@ -543,75 +568,91 @@
         self, user_groups: "str | UserGroup | list[str | UserGroup]"
     ) -> None:
         """Adds this User to user groups specified in user_groups.
 
         Args:
             user_groups: list of `UserGroup` objects or IDs
         """
-        succeeded, failed = self._update_nested_properties(user_groups, "memberships", "add")
+        succeeded, failed = self._update_nested_properties(
+            user_groups, "memberships", "add"
+        )
         if succeeded and config.verbose:
             logger.info(f"Added user '{self.name}' to group(s): {succeeded}")
         elif failed and config.verbose:
             logger.info(f"User '{self.name}' is already a member of {failed}")
 
     def remove_from_user_groups(
         self, user_groups: "str | UserGroup | list[str | UserGroup]"
     ) -> None:
         """Removes this User from user groups specified in user_groups.
 
         Args:
             user_groups: list of `UserGroup` objects or IDs
         """
-        succeeded, failed = self._update_nested_properties(user_groups, "memberships", "remove")
+        succeeded, failed = self._update_nested_properties(
+            user_groups, "memberships", "remove"
+        )
         if succeeded and config.verbose:
             logger.info(f"Removed user '{self.name}' from group(s): {succeeded}")
         elif failed and config.verbose:
             logger.info(f"User '{self.name}' is not in {failed} group(s)")
 
     def remove_from_all_user_groups(self) -> None:
         """Removes this User from all user groups."""
         memberships = getattr(self, 'memberships')
         existing_ids = [obj.get('id') for obj in memberships]
         self.remove_from_user_groups(user_groups=existing_ids)
 
     def assign_security_role(
-        self, security_role: SecurityRole | str, project: Optional["Project | str"] = None
+        self,
+        security_role: SecurityRole | str,
+        project: Optional["Project | str"] = None,
     ) -> None:  # NOSONAR
         """Assigns a Security Role to the user for given project.
 
         Args:
             security_role: Security Role ID or object
             project: Project name or object
         """
 
-        security_role = security_role if isinstance(security_role, SecurityRole) else SecurityRole(
-            self.connection, id=str(security_role)
+        security_role = (
+            security_role
+            if isinstance(security_role, SecurityRole)
+            else SecurityRole(self.connection, id=str(security_role))
         )
 
         security_role.grant_to([self.id], project)
         if config.verbose:
-            logger.info(f"Assigned Security Role '{security_role.name}' to user: '{self.name}'")
+            logger.info(
+                f"Assigned Security Role '{security_role.name}' to user: '{self.name}'"
+            )
 
     def revoke_security_role(
-        self, security_role: SecurityRole | str, project: Optional["Project | str"] = None
+        self,
+        security_role: SecurityRole | str,
+        project: Optional["Project | str"] = None,
     ) -> None:  # NOSONAR
         """Removes a Security Role from the user for given project.
 
         Args:
             security_role: Security Role ID or object
             project: Project name or object
         """
 
-        security_role = security_role if isinstance(security_role, SecurityRole) else SecurityRole(
-            self.connection, id=str(security_role)
+        security_role = (
+            security_role
+            if isinstance(security_role, SecurityRole)
+            else SecurityRole(self.connection, id=str(security_role))
         )
 
         security_role.revoke_from([self.id], project)
         if config.verbose:
-            logger.info(f"Revoked Security Role '{security_role.name}' from user: '{self.name}'")
+            logger.info(
+                f"Revoked Security Role '{security_role.name}' from user: '{self.name}'"
+            )
 
     @method_version_handler('11.3.0200')
     def list_security_filters(
         self, projects: Optional[str | list[str]] = None, to_dictionary: bool = False
     ) -> dict:
         """Get the list of security filters for user. They can be filtered by
         the projects' ids.
@@ -625,122 +666,143 @@
         Returns:
             Dictionary with project names as keys and list with security
             filters as values. In case of no security filter for the given user
             in the particular project, then this project is not placed in
             the dictionary.
         """
         from mstrio.modeling.security_filter import SecurityFilter
+
         objects_ = users.get_security_filters(self.connection, self.id, projects).json()
         projects_ = objects_.get("projects")
 
         objects_ = {
             project_.get("name"): project_.get("securityFilters")
             for project_ in projects_
             if project_.get("securityFilters")
         }
 
-        self._security_filters = {
-            name:
-            [SecurityFilter.from_dict(sec_filter, self.connection) for sec_filter in sec_filters]
+        security_filters = {
+            name: [
+                SecurityFilter.from_dict(sec_filter, self.connection)
+                for sec_filter in sec_filters
+            ]
             for (name, sec_filters) in objects_.items()
         }
         if to_dictionary:
             return objects_
-        return self._security_filters
+        return security_filters
 
     def apply_security_filter(self, security_filter: "SecurityFilter | str") -> bool:
         """Apply a security filter to the user.
 
         Args:
             security_filter (string or object): identifier of security filter or
                 `SecurityFilter` object which will be applied to the user.
         Returns:
             True when applying was successful. False otherwise.
         """
         if isinstance(security_filter, str):
             from mstrio.modeling.security_filter import SecurityFilter
-            security_filter = SecurityFilter.from_dict({"id": security_filter}, self.connection)
+
+            security_filter = SecurityFilter.from_dict(
+                {"id": security_filter}, self.connection
+            )
         return security_filter.apply(self.id)
 
     def revoke_security_filter(self, security_filter: "SecurityFilter | str") -> bool:
         """Revoke a security filter from the user.
 
         Args:
             security_filter (string or object): identifier of security filter or
                 `SecurityFilter` object which will be revoked from the user.
 
         Returns:
             True when revoking was successful. False otherwise.
         """
         if isinstance(security_filter, str):
             from mstrio.modeling.security_filter import SecurityFilter
-            security_filter = SecurityFilter.from_dict({"id": security_filter}, self.connection)
+
+            security_filter = SecurityFilter.from_dict(
+                {"id": security_filter}, self.connection
+            )
         return security_filter.revoke(self.id)
 
     def grant_privilege(
         self, privilege: "str | list[str] | Privilege | list[Privilege]"
     ) -> None:
         """Grant privileges directly to the user.
 
         Args:
             privilege: list of privilege objects, ids or names
         """
         from mstrio.access_and_security.privilege import Privilege
+
         privileges = [
-            priv['id'] for priv in Privilege._validate_privileges(self.connection, privilege)
+            priv['id']
+            for priv in Privilege._validate_privileges(self.connection, privilege)
         ]
         existing_ids = [
-            privilege['privilege']['id'] for privilege in self.list_privileges(mode='GRANTED')
+            privilege['privilege']['id']
+            for privilege in self.list_privileges(mode='GRANTED')
         ]
-        succeeded, failed = self._update_nested_properties(privileges, "privileges", "add",
-                                                           existing_ids)
+        succeeded, failed = self._update_nested_properties(
+            privileges, "privileges", "add", existing_ids
+        )
 
         if succeeded:
-            self.fetch('privileges')  # fetch the object properties and set object attributes
+            self.fetch(
+                'privileges'
+            )  # fetch the object properties and set object attributes
             if config.verbose:
                 logger.info(f"Granted privilege(s) {succeeded} to '{self.name}'")
         if failed and config.verbose:
             logger.info(f"User '{self.name}' already has privilege(s) {failed}")
 
     def revoke_privilege(
         self, privilege: "str | list[str] | Privilege | list[Privilege]"
     ) -> None:
         """Revoke directly granted user privileges.
 
         Args:
             privilege: list of privilege objects, ids or names
         """
         from mstrio.access_and_security.privilege import Privilege
+
         privileges = {
             priv['id']
             for priv in Privilege._validate_privileges(self.connection, privilege)
         }
         existing_ids = [
-            privilege['privilege']['id'] for privilege in self.list_privileges(mode='ALL')
+            privilege['privilege']['id']
+            for privilege in self.list_privileges(mode='ALL')
         ]
         directly_granted = {
             privilege['privilege']['id']
             for privilege in self.list_privileges(mode='GRANTED')
         }
         to_revoke = list(privileges.intersection(directly_granted))
         not_directly_granted = list(
             (set(existing_ids) - directly_granted).intersection(privileges)
         )
 
         if not_directly_granted:
             msg = (
-                f"Privileges {sorted(not_directly_granted)} are inherited and will be omitted. "
-                "Only directly granted privileges can be revoked by this method."
+                f"Privileges {sorted(not_directly_granted)} are inherited and will be "
+                "omitted. Only directly granted privileges can be revoked by this "
+                "method."
             )
             helper.exception_handler(msg, exception_type=Warning)
 
-        succeeded, failed = self._update_nested_properties(to_revoke, "privileges", "remove",
-                                                           existing_ids)
+        succeeded, failed = self._update_nested_properties(
+            to_revoke, "privileges", "remove", existing_ids
+        )
         if succeeded:
-            self.fetch('privileges')  # fetch the object properties and set object attributes
+            self.fetch(
+                'privileges'
+            )  # fetch the object properties and set object attributes
             if config.verbose:
                 logger.info(f"Revoked privilege(s) {succeeded} from '{self.name}'")
         if failed and config.verbose:
             logger.warning(f"User '{self.name}' does not have privilege(s) {failed}")
 
     def revoke_all_privileges(self, force: bool = False) -> None:
         """Revoke directly granted user privileges.
@@ -748,26 +810,28 @@
         Args:
             force: If True, no additional prompt will be shown before revoking
                 all privileges from User.
         """
         user_input = 'N'
         if not force:
             user_input = input(
-                "Are you sure you want to revoke all privileges from user '{}'? [Y/N]: ".format(
-                    self.name
-                )
+                f"Are you sure you want to revoke all privileges from user "
+                f"'{self.name}'? [Y/N]: "
             )
         if force or user_input == 'Y':
             to_revoke = [
-                privilege['privilege']['id'] for privilege in self.list_privileges(mode='GRANTED')
+                privilege['privilege']['id']
+                for privilege in self.list_privileges(mode='GRANTED')
             ]
             if to_revoke:
                 self.revoke_privilege(privilege=to_revoke)
             else:
-                logger.info(f"User '{self.name}' does not have any directly granted privileges")
+                logger.info(
+                    f"User '{self.name}' does not have any directly granted privileges"
+                )
 
     def list_privileges(
         self, mode: PrivilegeMode | str = PrivilegeMode.ALL, to_dataframe: bool = False
     ) -> list:
         """List privileges for user.
 
         Args:
@@ -787,16 +851,16 @@
             return df
 
         if not isinstance(mode, PrivilegeMode):
             try:
                 mode = PrivilegeMode(mode)
             except ValueError:
                 msg = (
-                    "Wrong privilege mode has been passed, allowed modes are "
-                    "['ALL'/'INHERITED'/'GRANTED']. See: `privilege.PrivilegeMode` enum."
+                    "Wrong privilege mode has been passed, allowed modes are ['ALL'/"
+                    "'INHERITED'/'GRANTED']. See: `privilege.PrivilegeMode` enum."
                 )
                 helper.exception_handler(msg, ValueError)
 
         privileges = list()
         if mode == PrivilegeMode.ALL:
             privileges = self.privileges
         elif mode == PrivilegeMode.INHERITED:
@@ -834,27 +898,28 @@
             force: If True, no additional prompt will be shown before deleting
                 User.
         Returns:
             True for success. False otherwise.
         """
         return super().delete(force=force)
 
-    def _to_dataframe_as_columns(self, properties: Optional[list[str]] = None) -> pd.DataFrame:
+    def _to_dataframe_as_columns(
+        self, properties: Optional[list[str]] = None
+    ) -> pd.DataFrame:
         """Exports user object to dataframe, with properties as columns
 
         Args:
             properties (list, optional): list of properties to be exported
 
         Returns: dataframe
         """
         excluded_keys = ['connection']
         selected_keys = properties or (self.list_properties().keys() - excluded_keys)
 
         def convert(obj, inside=False):
-
             if isinstance(obj, IntFlag):
                 return obj.value
             if isinstance(obj, (str, int)):
                 return obj
             if isinstance(obj, Enum):
                 return obj.value
             if isinstance(obj, datetime):
@@ -863,30 +928,30 @@
             result = None
 
             if isinstance(obj, list):
                 result = [convert(el, inside=True) for el in obj]
             if isinstance(obj, Dictable):
                 result = dict(sorted(obj.to_dict().items()))
             if isinstance(obj, dict):
-                result = {key: convert(value, inside=True) for key, value in obj.items()}
+                result = {
+                    key: convert(value, inside=True) for key, value in obj.items()
+                }
 
             return result if inside else json.dumps(result)
 
         data = {
             key: convert(value)
             for key, value in self.list_properties().items()
             if key in selected_keys
         }
         return pd.DataFrame(data, index=[0])
 
     @classmethod
     def to_datafame_from_list(
-        cls,
-        objects: list['User'],
-        properties: Optional[list[str]] = None
+        cls, objects: list['User'], properties: Optional[list[str]] = None
     ) -> pd.DataFrame:
         """Exports list of user objects to dataframe.
         The properties that are lists, dictionaries, or objects of
         custom classes, are first converted to dictionary using `to_dict()`
         method, then serialized string as json.
 
         Args:
@@ -958,9 +1023,9 @@
     def privileges(self):
         self.fetch('privileges')
         return self._privileges
 
     @property
     def security_filters(self):
         if not self._security_filters:
-            self.list_security_filters()
+            self._security_filters = self.list_security_filters()
         return self._security_filters
```

### Comparing `mstrio-py-11.3.9.101/mstrio/users_and_groups/user_connections.py` & `mstrio-py-11.3.9.103/mstrio/users_and_groups/user_connections.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 import logging
-from typing import Any, Dict, List, Optional, TYPE_CHECKING, Union
+from typing import TYPE_CHECKING, Any, Optional
 
 from packaging import version
 
 from mstrio import config
 from mstrio.api import monitors
 from mstrio.connection import Connection
 from mstrio.server import Cluster
@@ -31,57 +31,63 @@
         """Initialize the `UserConnections` object.
 
         Args:
             connection: MicroStrategy connection object returned
                 by `connection.Connection()`
         """
         self.connection = connection
-        self.user_connections: List[Dict[str, Any]] = []
+        self.user_connections: list[dict[str, Any]] = []
 
     def fetch(self) -> None:
         """Populate the `UserConnections` object by retrieving all active user
         connections on the environment."""
         self.user_connections = self.list_connections()
 
-    def filter_connections(self, **filters) -> Union[List[Dict[str, Any]], None]:
+    def filter_connections(self, **filters) -> list[dict[str, Any]] | None:
         """Filter the user connections stored in the `UserConnections` object
         by specifying the `filters` keyword arguments.
 
         Args:
             **filters: Available filter parameters: ['id', 'parent_id',
                 'username', 'user_full_name', 'project_index', 'project_id',
                 'project_name', 'open_jobs_count', 'project_type',
                 'date_connection_created', 'duration', 'session_id', 'client',
                 'config_level']
         """
         filtered_connections = None
         if not self.user_connections:
             helper.exception_handler(
-                "Populate the `UserConnections` object with `UserConnections.fetch` first.",
-                Warning
+                "Populate the `UserConnections` object with `UserConnections.fetch` "
+                "first.",
+                Warning,
             )
         else:
-            filtered_connections = helper.filter_list_of_dicts(self.user_connections, **filters)
+            filtered_connections = helper.filter_list_of_dicts(
+                self.user_connections, **filters
+            )
         return filtered_connections
 
     def list_connections(
-        self, nodes: Union[str, List[str]] = None, limit: Optional[int] = None, **filters
-    ) -> List[Dict[str, Any]]:
+        self,
+        nodes: Optional[str | list[str]] = None,
+        limit: Optional[int] = None,
+        **filters,
+    ) -> list[dict[str, Any]]:
         """Get all active user connections. Optionally filter the connections
         by specifying the `filters` keyword arguments.
 
         Args:
             nodes: Node (server) names on which users will be disconnected.
             limit: limit the number of elements returned. If `None`, all objects
                 are returned.
             **filters: Available filter parameters: ['id', 'parent_id',
                 'username', 'user_full_name', 'project_index', 'project_id',
                 'project_name', 'open_jobs_count', 'project_type',
                 'date_connection_created', 'duration', 'session_id', 'client',
-                'config_level']
+                'config_level', 'application_type', 'last_action']
         """
         all_nodes = Cluster(self.connection).list_nodes(to_dictionary=True)
         all_connections = []
         if nodes is None:
             nodes = [node['name'] for node in all_nodes if node['status'] == 'running']
         else:
             nodes = nodes if isinstance(nodes, list) else [nodes]
@@ -94,27 +100,27 @@
                     monitors.get_user_connections,
                     monitors.get_user_connections_async,
                     dict_unpack_value="userConnections",
                     limit=limit,
                     chunk_size=1000,
                     error_msg=msg,
                     node_name=node,
-                    filters=filters
+                    filters=filters,
                 )
             )
         return all_connections
 
     def disconnect_users(
         self,
-        connection_ids: Union[str, List[str]] = None,
-        users: Optional[Union[List["User"], List[str]]] = None,
-        nodes: Union[str, List[str]] = None,
+        connection_ids: Optional[str | list[str]] = None,
+        users: Optional[list["User"] | list[str]] = None,
+        nodes: Optional[str | list[str]] = None,
         force: bool = False,
-        **filters
-    ) -> Union[List[dict], None]:
+        **filters,
+    ) -> list[dict] | None:
         """Disconnect user connections by passing in users (objects) or
         connection_ids. Optionally disconnect users by specifying the `filters`
         keyword arguments.
 
         Args:
             connection_ids: chosen ids that can be retrieved with
                 `list_connections()`
@@ -134,20 +140,27 @@
                 status code 207 is when some connections were disconnected
                 status code 403 without error code is when no connections were
                 disconnected
             - in case of error of nothing to disconnect it returns None
 
 
         """
-        from mstrio.users_and_groups.user import User  # import here to avoid circular imports
+        # import here to avoid circular imports
+        from mstrio.users_and_groups.user import User
 
-        if self.connection and not connection_ids and not users and not filters and not force:
+        if (
+            self.connection
+            and not connection_ids
+            and not users
+            and not filters
+            and not force
+        ):
             msg = (
-                "You need to pass connection_ids or users or specify filters. To disconnect "
-                "all connections use `disconnect_all_users()` method."
+                "You need to pass connection_ids or users or specify filters. To "
+                "disconnect all connections use `disconnect_all_users()` method."
             )
             helper.exception_handler(msg)
 
         if connection_ids:
             # disconnect specific user connections without fetching connections
             return self.__disconnect_by_connection_id(connection_ids)
         else:
@@ -160,85 +173,93 @@
                     if isinstance(user, User):
                         usernames.append(user.username)
                     elif isinstance(user, str):
                         usernames.append(user)
                     else:
                         helper.exception_handler(
                             "'user' param must be a list of User objects or usernames.",
-                            exception_type=TypeError
+                            exception_type=TypeError,
                         )
 
                 all_connections = list(
                     filter(lambda conn: conn['username'] in usernames, all_connections)
                 )
 
             if all_connections:
                 # extract connection ids and disconnect
                 connection_ids = [conn['id'] for conn in all_connections]
                 return self.__disconnect_by_connection_id(connection_ids)
             elif config.verbose:
                 logger.info('No active user connections.')
 
-    def disconnect_all_users(self, force: bool = False) -> Union[List[dict], None]:
+    def disconnect_all_users(self, force: bool = False) -> list[dict] | None:
         """Disconnect all user connections.
 
         Args:
             force: if True, no additional prompt will be shown before
                 disconnecting all users
 
         Returns:
             - list of statuses of disconnecting all connections with their ids
                and messages from the I-Server
             - in case of error it returns None
         """
         if not force:
             user_input = input(
-                "Are you sure you want to disconnect all users from the I-Server? [Y/N]: "
+                "Are you sure you want to disconnect all users from the I-Server? "
+                "[Y/N]: "
             )
             if user_input != "Y":
                 return None
             else:
                 force = True
 
         return self.disconnect_users(force=force)
 
     def __disconnect_by_connection_id(
-        self, connection_ids: Union[str, List[str]]
-    ) -> Union[List[dict], None]:
+        self, connection_ids: str | list[str]
+    ) -> list[dict] | None:
         """It disconnects connections which ids are provided in
         'connection_ids'. It prints information about executed operations.
         Returns list of statuses of for the given connection ids with the
         messages from the I-Server or `None` in case of an error.
         """
-        connection_ids = connection_ids if isinstance(connection_ids, list) else [connection_ids]
+        connection_ids = (
+            connection_ids if isinstance(connection_ids, list) else [connection_ids]
+        )
         server_version = helper.version_cut(self.connection.iserver_version)
 
         # use monitors.delete_user_connections
         # or monitors.delete_user_connection depending on the server version
         if version.parse(server_version) >= version.parse('11.3.1'):
-            res = monitors.delete_user_connections(connection=self.connection, ids=connection_ids)
-            if res.status_code in [200, 207] or (res.status_code == 403
-                                                 and not res.json().get('code', None)):
+            res = monitors.delete_user_connections(
+                connection=self.connection, ids=connection_ids
+            )
+            if res.status_code in [200, 207] or (
+                res.status_code == 403 and not res.json().get('code', None)
+            ):
                 return self._prepare_disconnect_by_id_message(
                     statuses=res.json()['deleteUserConnectionsStatus']
                 )
             else:
                 err_msg = f'Error disconnecting user sessions: {connection_ids}.'
-                return helper.response_handler(response=res, msg=err_msg, throw_error=False)
+                return helper.response_handler(
+                    response=res, msg=err_msg, throw_error=False
+                )
         else:
-            statuses: List[Dict[str, Union[str, int]]] = []
+            statuses: list[dict[str, str | int]] = []
             for connection_id in connection_ids:
                 response = monitors.delete_user_connection(
                     self.connection, connection_id, bulk=True
                 )
                 statuses.append({'id': connection_id, 'status': response.status_code})
             return self._prepare_disconnect_by_id_message(statuses=statuses)
 
     @staticmethod
-    def _prepare_disconnect_by_id_message(statuses: List[dict]) -> List[dict]:
+    def _prepare_disconnect_by_id_message(statuses: list[dict]) -> list[dict]:
         succeeded = []
         failed = []
 
         for s in statuses:
             status = s['status']
             id = s['id']
             if status >= 200 and status < 300:
@@ -246,16 +267,16 @@
             elif status >= 400:
                 # in most cases there will be status code 403
                 failed.append(id)
 
         if config.verbose:
             if succeeded:
                 logger.info(
-                    'User connections with ids below were successfully disconnected:\n\t'
-                    + ',\n\t'.join(succeeded)
+                    'User connections with ids below were successfully disconnected:'
+                    '\n\t' + ',\n\t'.join(succeeded)
                 )
             if failed:
                 logger.warning(
                     'User connections with ids below were not disconnected:\n\t'
                     + ',\n\t'.join(failed)
                 )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/users_and_groups/user_group.py` & `mstrio-py-11.3.9.103/mstrio/users_and_groups/user_group.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 import logging
-from typing import Optional, TYPE_CHECKING
+from typing import TYPE_CHECKING, Optional
 
 from pandas import DataFrame
 
 from mstrio import config
 from mstrio.access_and_security.privilege_mode import PrivilegeMode
 from mstrio.access_and_security.security_role import SecurityRole
 from mstrio.api import objects, usergroups
@@ -23,15 +23,15 @@
 
 
 def list_user_groups(
     connection: Connection,
     name_begins: Optional[str] = None,
     to_dictionary: bool = False,
     limit: Optional[int] = None,
-    **filters
+    **filters,
 ) -> list["UserGroup"]:
     """Get list of User Group objects or User Group dicts. Optionally filter
     the User Groups by specifying 'name_begins' or other filters.
 
     Optionally use `to_dictionary` or `to_dataframe` to choose output format.
     If `to_dictionary` is True, `to_dataframe` is omitted.
 
@@ -58,15 +58,15 @@
         >>>                  description='New group')
     """
     return UserGroup._get_user_groups(
         connection=connection,
         name_begins=name_begins,
         to_dictionary=to_dictionary,
         limit=limit,
-        **filters
+        **filters,
     )
 
 
 class UserGroup(Entity, DeleteMixin, TrusteeACLMixin):
     """Object representation of MicroStrategy User Group object.
 
     Attributes:
@@ -88,15 +88,19 @@
         owner: Owner name and ID
         ancestors: List of ancestor folders
         settings: Settings of User Group
         acg: Access rights (See EnumDSSXMLAccessRightFlags for possible values)
         acl: Object access control list
     """
 
-    _SUPPORTED_PATCH_OPERATIONS = {"add": "add", "remove": "remove", "change": "replace"}
+    _SUPPORTED_PATCH_OPERATIONS = {
+        "add": "add",
+        "remove": "remove",
+        "change": "replace",
+    }
     _OBJECT_TYPE = ObjectTypes.USERGROUP
     _API_GETTERS = {
         (
             'id',
             'name',
             'type',
             'subtype',
@@ -104,35 +108,44 @@
             'abbreviation',
             'date_created',
             'date_modified',
             'version',
             'owner',
             'ancestors',
             'acg',
-            'acl'
+            'acl',
         ): usergroups.get_user_group_info,
         'memberships': usergroups.get_memberships,
         'members': usergroups.get_members,
         'security_roles': usergroups.get_security_roles,
         'privileges': usergroups.get_privileges,
-        'settings': usergroups.get_settings
+        'settings': usergroups.get_settings,
     }
     _PATCH_PATH_TYPES = {
         "name": str,
         "description": str,
         "abbreviation": str,
     }
     _API_PATCH: dict = {
         ('abbreviation'): (objects.update_object, 'partial_put'),
-        ('name', 'description', 'memberships', 'security_roles', 'members',
-         'privileges'): (usergroups.update_user_group_info, 'patch')
+        (
+            'name',
+            'description',
+            'memberships',
+            'security_roles',
+            'members',
+            'privileges',
+        ): (usergroups.update_user_group_info, 'patch'),
     }
 
     def __init__(
-        self, connection: Connection, name: Optional[str] = None, id: Optional[str] = None
+        self,
+        connection: Connection,
+        name: Optional[str] = None,
+        id: Optional[str] = None,
     ) -> None:
         """Initialize UserGroup object by passing `name` or `id`. When `id` is
         provided (not `None`), `name` is omitted.
 
         Args:
             connection: MicroStrategy connection object returned
                 by `connection.Connection()`
@@ -149,15 +162,15 @@
                 connection=connection, name_begins=name, name=name
             )
             if user_groups:
                 id = user_groups[0]
             else:
                 helper.exception_handler(
                     f"There is no User Group with the given name: '{name}'",
-                    exception_type=ValueError
+                    exception_type=ValueError,
                 )
         super().__init__(connection=connection, object_id=id, name=name)
 
     def _init_variables(self, **kwargs) -> None:
         super()._init_variables(**kwargs)
 
         self._memberships = kwargs.get('memberships')
@@ -170,15 +183,15 @@
     @classmethod
     def create(
         cls,
         connection: Connection,
         name: str,
         description: Optional[str] = None,
         memberships: Optional[list[str]] = None,
-        members: Optional[list[str]] = None
+        members: Optional[list[str]] = None,
     ):
         """Create a new User Group on the I-Server. Returns `UserGroup` object.
 
         Args:
             connection: MicroStrategy connection object returned by
                 `connection.Connection()`
             name: Name of a newly created User Group
@@ -190,78 +203,79 @@
         """
         memberships = memberships or []
         members = members or []
         body = {
             "name": name,
             "description": description,
             "memberships": memberships,
-            "members": members
+            "members": members,
         }
         response = usergroups.create_user_group(connection, body)
         if response.ok:
             response = response.json()
             if config.verbose:
                 logger.info(
-                    f"Successfully created user group '{name}' with ID: '{response.get('id')}'"
+                    f"Successfully created user group '{name}' with ID: "
+                    f"'{response.get('id')}'"
                 )
             return cls.from_dict(source=response, connection=connection)
 
     @classmethod
     def _get_user_groups(
         cls,
         connection: Connection,
         name_begins: Optional[str] = None,
         to_dictionary: bool = False,
         limit: Optional[int] = None,
-        **filters
+        **filters,
     ) -> list["UserGroup"]:
         msg = "Error getting information for a set of User Groups."
         objects = helper.fetch_objects_async(
             connection,
             usergroups.get_info_all_user_groups,
             usergroups.get_info_all_user_groups_async,
             limit=limit,
             chunk_size=1000,
             error_msg=msg,
             name_begins=name_begins,
-            filters=filters
+            filters=filters,
         )
         if to_dictionary:
             return objects
         else:
             return [cls.from_dict(source=obj, connection=connection) for obj in objects]
 
     @classmethod
     def _get_user_group_ids(
         cls,
         connection: Connection,
         name_begins: Optional[str] = None,
         limit: Optional[int] = None,
-        **filters
+        **filters,
     ) -> list[str]:
         group_dicts = UserGroup._get_user_groups(
             connection=connection,
             name_begins=name_begins,
             to_dictionary=True,
             limit=limit,
-            **dict(filters)
+            **dict(filters),
         )
         return [group['id'] for group in group_dicts]
 
     def alter(self, name: Optional[str] = None, description: Optional[str] = None):
         """Alter User Group name or/and description.
 
         Args:
             name: New name of the User Group
             description: New description of the User Group
         """
         func = self.alter
         args = helper.get_args_from_func(func)
         defaults = helper.get_default_args_from_func(func)
-        default_dict = dict(zip(args[-len(defaults):], defaults)) if defaults else {}
+        default_dict = dict(zip(args[-len(defaults) :], defaults)) if defaults else {}
         local = locals()
         properties = {}
         for property_key in default_dict.keys():
             if local[property_key] is not None:
                 properties[property_key] = local[property_key]
 
         self._alter_properties(**properties)
@@ -317,118 +331,136 @@
         Args:
             groups: List of User Group objects or ids
         """
         succeeded, failed = self._update_nested_properties(groups, "memberships", "add")
         if succeeded and config.verbose:
             logger.info(f"Added group '{self.name}' to group(s): {succeeded}")
         if failed and config.verbose:
-            logger.warning(f"Group '{self.name}' is already a member of {failed} group(s)")
+            logger.warning(
+                f"Group '{self.name}' is already a member of {failed} group(s)"
+            )
 
     def remove_from_user_groups(
         self, groups: "str | UserGroup | list[str | UserGroup]"
     ) -> None:
         """Remove User Group from passed groups
 
         Args:
             groups: List of User Group objects or ids
         """
-        succeeded, failed = self._update_nested_properties(groups, 'memberships', "remove")
+        succeeded, failed = self._update_nested_properties(
+            groups, 'memberships', "remove"
+        )
         if succeeded and config.verbose:
             logger.info(f"Removed group '{self.name}' from group(s): {succeeded}")
         if failed and config.verbose:
             logger.warning(f"Group '{self.name}' is not a member of {failed} group(s)")
 
     def grant_privilege(
         self, privilege: "str | list[str] | Privilege | list[Privilege]"
     ) -> None:
         """Grant privileges directly to the User Group.
 
         Args:
             privilege: List of privilege objects, ids or names
         """
         from mstrio.access_and_security.privilege import Privilege
+
         privileges = [
-            priv['id'] for priv in Privilege._validate_privileges(self.connection, privilege)
+            priv['id']
+            for priv in Privilege._validate_privileges(self.connection, privilege)
         ]
         existing_ids = [
-            privilege['privilege']['id'] for privilege in self.list_privileges(mode='GRANTED')
+            privilege['privilege']['id']
+            for privilege in self.list_privileges(mode='GRANTED')
         ]
-        succeeded, failed = self._update_nested_properties(privileges, "privileges", "add",
-                                                           existing_ids)
+        succeeded, failed = self._update_nested_properties(
+            privileges, "privileges", "add", existing_ids
+        )
 
         if succeeded:
             self.fetch('privileges')  # fetch the object privileges
             if config.verbose:
                 logger.info(f"Granted privilege(s) {succeeded} to '{self.name}'")
         if failed and config.verbose:
-            logger.warning(f"User Group '{self.name}' already has privilege(s) {failed}")
+            logger.warning(
+                f"User Group '{self.name}' already has privilege(s) {failed}"
+            )
 
     def revoke_privilege(
         self, privilege: "str | list[str] | Privilege | list[Privilege]"
     ) -> None:
         """Revoke directly granted User Group privileges.
 
         Args:
             privilege: List of privilege objects, ids or names
         """
         from mstrio.access_and_security.privilege import Privilege
+
         privileges = {
             priv['id']
             for priv in Privilege._validate_privileges(self.connection, privilege)
         }
         existing_ids = [
-            privilege['privilege']['id'] for privilege in self.list_privileges(mode='ALL')
+            privilege['privilege']['id']
+            for privilege in self.list_privileges(mode='ALL')
         ]
         directly_granted = {
             privilege['privilege']['id']
             for privilege in self.list_privileges(mode='GRANTED')
         }
         to_revoke = list(privileges.intersection(directly_granted))
         not_directly_granted = list(
             (set(existing_ids) - directly_granted).intersection(privileges)
         )
 
         if not_directly_granted:
             msg = (
                 f"Privileges {sorted(not_directly_granted)} are inherited and will be "
-                "omitted. Only directly granted privileges can be revoked by this method."
+                "omitted. Only directly granted privileges can be revoked by this "
+                "method."
             )
             helper.exception_handler(msg, exception_type=Warning)
 
-        succeeded, failed = self._update_nested_properties(to_revoke, "privileges", "remove",
-                                                           existing_ids)
+        succeeded, failed = self._update_nested_properties(
+            to_revoke, "privileges", "remove", existing_ids
+        )
         if succeeded:
             self.fetch('privileges')  # fetch the object privileges
             if config.verbose:
                 logger.info(f"Revoked privilege(s) {succeeded} from '{self.name}'")
         if failed and config.verbose:
-            logger.warning(f"User group '{self.name}' does not have privilege(s) {failed}")
+            logger.warning(
+                f"User group '{self.name}' does not have privilege(s) {failed}"
+            )
 
     def revoke_all_privileges(self, force: bool = False) -> None:
         """Revoke directly granted group privileges.
 
         Args:
             force: If True, no additional prompt will be shown before revoking
                 all privileges from User Group
         """
         user_input = 'N'
         if not force:
             user_input = input(
-                "Are you sure you want to revoke all privileges from user group '{}'? [Y/N]: "
-                .format(self.name)
+                "Are you sure you want to revoke all privileges from user group "
+                f"'{self.name}'? [Y/N]: "
             )
         if force or user_input == 'Y':
             to_revoke = [
-                privilege['privilege']['id'] for privilege in self.list_privileges(mode='GRANTED')
+                privilege['privilege']['id']
+                for privilege in self.list_privileges(mode='GRANTED')
             ]
             if to_revoke:
                 self.revoke_privilege(privilege=to_revoke)
             else:
                 logger.info(
-                    f"User Group '{self.name}' does not have any directly granted privileges"
+                    f"User Group '{self.name}' does not have any directly granted "
+                    f"privileges"
                 )
 
     def list_privileges(
         self, mode: PrivilegeMode | str = PrivilegeMode.ALL, to_dataframe: bool = False
     ) -> list:
         """List privileges for user group.
 
@@ -450,15 +482,16 @@
 
         if not isinstance(mode, PrivilegeMode):
             try:
                 mode = PrivilegeMode(mode)
             except ValueError:
                 msg = (
                     "Wrong privilege mode has been passed, allowed modes are "
-                    "['ALL'/'INHERITED'/'GRANTED']. See: `privilege.PrivilegeMode` enum."
+                    "['ALL'/'INHERITED'/'GRANTED']. See: `privilege.PrivilegeMode` "
+                    "enum."
                 )
                 helper.exception_handler(msg, ValueError)
 
         privileges = list()
         if mode == PrivilegeMode.ALL:
             privileges = self.privileges
         elif mode == PrivilegeMode.INHERITED:
@@ -475,48 +508,61 @@
                     is_granted = source['direct'] or is_granted
                 if is_granted:
                     privileges.append(privilege)
 
         return to_df(privileges) if to_dataframe else privileges
 
     def assign_security_role(
-        self, security_role: SecurityRole | str, project: Optional["Project | str"] = None
+        self,
+        security_role: SecurityRole | str,
+        project: Optional["Project | str"] = None,
     ) -> None:  # NOSONAR
         """Assigns a Security Role to the User Group for given project.
 
         Args:
             security_role: Security Role ID or object
             project: Project name or object
         """
 
-        security_role = security_role if isinstance(security_role, SecurityRole) else SecurityRole(
-            self.connection, id=str(security_role)
+        security_role = (
+            security_role
+            if isinstance(security_role, SecurityRole)
+            else SecurityRole(self.connection, id=str(security_role))
         )
 
         security_role.grant_to([self.id], project)
         if config.verbose:
-            logger.info(f"Assigned Security Role '{security_role.name}' to group: '{self.name}'")
+            logger.info(
+                f"Assigned Security Role '{security_role.name}' to group: '{self.name}'"
+            )
 
     def revoke_security_role(
-        self, security_role: SecurityRole | str, project: Optional["Project | str"] = None
+        self,
+        security_role: SecurityRole | str,
+        project: Optional["Project | str"] = None,
     ) -> None:  # NOSONAR
         """Removes a Security Role from the User Group for given project.
 
         Args:
             security_role: Security Role ID or object
             project: Project name or object
         """
 
-        security_role = security_role if isinstance(security_role, SecurityRole) else SecurityRole(
-            self.connection, id=str(security_role)
+        security_role = (
+            security_role
+            if isinstance(security_role, SecurityRole)
+            else SecurityRole(self.connection, id=str(security_role))
         )
 
         security_role.revoke_from([self.id], project)
         if config.verbose:
-            logger.info(f"Revoked Security Role '{security_role.name}' from group: '{self.name}'")
+            logger.info(
+                f"Revoked Security Role '{security_role.name}' from group: "
+                f"'{self.name}'"
+            )
 
     @method_version_handler('11.3.0200')
     def list_security_filters(
         self, projects: Optional[str | list[str]] = None, to_dictionary: bool = False
     ) -> dict:
         """Get the list of security filters for user group. They can be filtered
         by the projects' ids.
@@ -530,26 +576,31 @@
         Returns:
             Dictionary with project names as keys and list with security
             filters as values. In case of no security filter for the given user
             group in the particular project, then this project is not placed in
             the dictionary.
         """
         from mstrio.modeling.security_filter import SecurityFilter
-        objects_ = usergroups.get_security_filters(self.connection, self.id, projects).json()
+
+        objects_ = usergroups.get_security_filters(
+            self.connection, self.id, projects
+        ).json()
         projects_ = objects_.get("projects")
 
         objects_ = {
             project_.get("name"): project_.get("securityFilters")
             for project_ in projects_
             if project_.get("securityFilters")
         }
 
         self._security_filters = {
-            name:
-            [SecurityFilter.from_dict(sec_filter, self.connection) for sec_filter in sec_filters]
+            name: [
+                SecurityFilter.from_dict(sec_filter, self.connection)
+                for sec_filter in sec_filters
+            ]
             for (name, sec_filters) in objects_.items()
         }
         if to_dictionary:
             return objects_
         return self._security_filters
 
     def apply_security_filter(self, security_filter: "SecurityFilter | str"):
@@ -559,15 +610,18 @@
             security_filter (string or object): identifier of security filter or
                 `SecurityFilter` object which will be applied to the user group.
         Returns:
             True when applying was successful. False otherwise.
         """
         if isinstance(security_filter, str):
             from mstrio.modeling.security_filter import SecurityFilter
-            security_filter = SecurityFilter.from_dict({"id": security_filter}, self.connection)
+
+            security_filter = SecurityFilter.from_dict(
+                {"id": security_filter}, self.connection
+            )
         return security_filter.apply(self.id)
 
     def revoke_security_filter(self, security_filter: "SecurityFilter | str"):
         """Revoke a security filter from the user group.
 
         Args:
             security_filter (string or object): identifier of security filter or
@@ -575,15 +629,18 @@
                 group.
 
         Returns:
             True when revoking was successful. False otherwise.
         """
         if isinstance(security_filter, str):
             from mstrio.modeling.security_filter import SecurityFilter
-            security_filter = SecurityFilter.from_dict({"id": security_filter}, self.connection)
+
+            security_filter = SecurityFilter.from_dict(
+                {"id": security_filter}, self.connection
+            )
         return security_filter.revoke(self.id)
 
     def get_settings(self) -> dict:
         """Get the User Group settings from the I-Server."""
         res = self._API_GETTERS.get('settings')(
             self.connection, self.id, include_access=True
         )  # type: ignore
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/acl.py` & `mstrio-py-11.3.9.103/mstrio/utils/acl.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,26 +1,36 @@
+import logging
 from enum import Enum, IntFlag
-from typing import Any, Optional, TYPE_CHECKING, TypeVar
+from typing import TYPE_CHECKING, Any, Optional, TypeVar
 
 import pandas as pd
 
+from mstrio import config
 from mstrio.api import objects
 from mstrio.connection import Connection
 from mstrio.types import ObjectTypes
-from mstrio.utils.helper import Dictable, exception_handler, filter_obj_list, IServerError
+from mstrio.utils.helper import (
+    Dictable,
+    IServerError,
+    exception_handler,
+    filter_obj_list,
+)
 
 if TYPE_CHECKING:
     from mstrio.server import Project
     from mstrio.users_and_groups import UserOrGroup
     from mstrio.utils.entity import Entity
 
+logger = logging.getLogger(__name__)
+
 
 class Rights(IntFlag):
-    """"Enumeration constants used to specify the access granted attribute of
-    the DSS objects. """
+    """ "Enumeration constants used to specify the access granted attribute of
+    the DSS objects."""
+
     EXECUTE = 0b10000000
     USE = 0b01000000
     CONTROL = 0b00100000
     DELETE = 0b00010000
     WRITE = 0b00001000
     READ = 0b00000100
     USE_EXECUTE = 0b00000010  # This constant is deprecated
@@ -31,24 +41,26 @@
 class Permissions(Enum):
     """Enumeration constants used to specify combination of Rights values
     similar to workstation Security Access.
 
     TODO: This has to be string-based to discern between 'Denied All'
     and 'Full Control', which have the same mask.
     """
+
     DENIED_ALL = 'Denied All'
     DEFAULT_ALL = 'Default All'
     CONSUME = 'Consume'
     VIEW = 'View'
     MODIFY = 'Modify'
     FULL_CONTROL = 'Full Control'
 
 
 class AggregatedRights(IntFlag):
     """Enumeration constants used to specify combination of Rights values."""
+
     NONE = 0b00000000
     CONSUME = 0b01000101
     VIEW = 0b11000101
     MODIFY = 0b11011101
     ALL = 0b11111111
 
 
@@ -61,29 +73,28 @@
     Permissions.CONSUME: AggregatedRights.CONSUME,
 }
 
 T = TypeVar("T")
 
 
 class ACE(Dictable):
-
     _FROM_DICT_MAP = {
         'rights': Rights,
     }
 
     def __init__(
         self,
         deny: bool,
         entry_type: int,
         rights: Rights | int,
         trustee_id: str,
         trustee_name: str,
         trustee_type: int,
         trustee_subtype: int,
-        inheritable: bool
+        inheritable: bool,
     ):
         """Set ACL object.
 
         Args:
             deny: Specifies whether access is denied
             entry_type: Access control entry type (1 for object access).
                 Possible values can be found in EnumDSSXMLAccessEntryType
@@ -92,18 +103,20 @@
             trustee_name: User name of the designated trustee
             trustee_type: Type of the designated trustee
             trustee_subtype: Sub-type of the designated trustee
             inheritable: Specifies whether access control is inherited
         """
 
         self.rights = rights if isinstance(rights, Rights) else Rights(rights)
-        if self.rights not in range(256) and self.rights not in range(536_870_912, 536_871_167):
+        if self.rights not in range(256) and self.rights not in range(
+            536_870_912, 536_871_167
+        ):
             msg = (
-                "Wrong `rights` value, please provide value in range 0-255 or combination of "
-                "Rights enums"
+                "Wrong `rights` value, please provide value in range 0-255 or "
+                "combination of Rights enums"
             )
             exception_handler(msg)
         self.deny = deny
         self.entry_type = entry_type
         self.trustee_id = trustee_id
         self.trustee_name = trustee_name
         self.trustee_type = trustee_type
@@ -116,25 +129,23 @@
         for attr in self.__dict__:
             if getattr(self, attr) != getattr(other, attr):
                 return False
         return True
 
     @classmethod
     def from_dict(cls, source: dict[str, Any], connection: Connection):
-
         def translate_names(name: str):
             if name == "type":
                 return "entry_type"
             return name
 
         modified_source = {translate_names(key): val for key, val in source.items()}
         return super().from_dict(modified_source, connection)
 
     def to_dict(self, camel_case=True):
-
         def translate_names(name: str):
             if name == "entry_type" or name == "entryType":
                 return "type"
             return name
 
         result_dict = super().to_dict(camel_case=camel_case)
         return {translate_names(key): val for key, val in result_dict.items()}
@@ -142,15 +153,15 @@
     def _get_request_body(self, op):
         result_dict = {
             "op": op,
             "trustee": self.trustee_id,
             "rights": self.rights.value,
             "type": self.entry_type,
             "denied": self.deny,
-            "inheritable": self.inheritable
+            "inheritable": self.inheritable,
         }
         return result_dict
 
 
 class ACLMixin:
     """ACLMixin class adds Access Control List (ACL) management for supporting
     objects.
@@ -161,16 +172,17 @@
     particular object. For example, a user may have permissions to view and
     execute a report , but cannot modify the report definition or delete the
     report.
 
     NOTE: Must be mixedin with Entity or its subclasses.
     """
 
-    def list_acl(self, to_dataframe: bool = False, to_dictionary: bool = False,
-                 **filters) -> pd.DataFrame | list[dict | ACE]:
+    def list_acl(
+        self, to_dataframe: bool = False, to_dictionary: bool = False, **filters
+    ) -> pd.DataFrame | list[dict | ACE]:
         """Get Access Control List (ACL) for this object. Optionally filter
         ACLs by specifying filters.
 
         Args:
             to_dataframe(bool, optional): if True, return datasets as
                 pandas DataFrame
             to_dictionary(bool, optional): if True, return datasets as dicts
@@ -191,15 +203,15 @@
 
     def acl_add(
         self: "Entity",
         rights: int | Rights | AggregatedRights,
         trustees: "list[UserOrGroup] | UserOrGroup",
         denied: bool = False,
         inheritable: Optional[bool] = None,
-        propagate_to_children: Optional[bool] = None
+        propagate_to_children: Optional[bool] = None,
     ) -> None:
         """Add Access Control Element (ACE) to the object ACL.
 
         Note:
             Argument `propagate_to_children` is used only for objects with
             type `ObjectTypes.FOLDER`.
 
@@ -222,24 +234,24 @@
         """
         self._update_acl(
             op="ADD",
             rights=rights,
             trustees=trustees,
             denied=denied,
             inheritable=inheritable,
-            propagate_to_children=propagate_to_children
+            propagate_to_children=propagate_to_children,
         )
 
     def acl_remove(
         self: "Entity",
         rights: int | Rights | AggregatedRights,
         trustees: "list[UserOrGroup] | UserOrGroup",
         denied: bool = False,
         inheritable: Optional[bool] = None,
-        propagate_to_children: Optional[bool] = None
+        propagate_to_children: Optional[bool] = None,
     ) -> None:
         """Remove Access Control Element (ACE) from the object ACL.
 
         Note:
             Argument `propagate_to_children` is used only for objects with
             type `ObjectTypes.FOLDER`.
 
@@ -262,24 +274,24 @@
         """
         self._update_acl(
             op="REMOVE",
             rights=rights,
             trustees=trustees,
             denied=denied,
             inheritable=inheritable,
-            propagate_to_children=propagate_to_children
+            propagate_to_children=propagate_to_children,
         )
 
     def acl_alter(
         self: "Entity",
         rights: int | Rights | AggregatedRights,
         trustees: "list[UserOrGroup] | UserOrGroup",
         denied: bool = False,
         inheritable: Optional[bool] = None,
-        propagate_to_children: Optional[bool] = None
+        propagate_to_children: Optional[bool] = None,
     ) -> None:
         """Alter an existing Access Control Element (ACE) of the object ACL.
 
         Note:
             Argument `propagate_to_children` is used only for objects with
             type `ObjectTypes.FOLDER`.
 
@@ -302,15 +314,15 @@
         """
         self._update_acl(
             op="REPLACE",
             rights=rights,
             trustees=trustees,
             denied=denied,
             inheritable=inheritable,
-            propagate_to_children=propagate_to_children
+            propagate_to_children=propagate_to_children,
         )
 
     def _update_acl(
         self: "Entity",
         op: str,
         rights: int | Rights | AggregatedRights,
         trustees: "list[UserOrGroup] | UserOrGroup",
@@ -343,15 +355,15 @@
             object_type=self._OBJECT_TYPE,
             ids=self.id,
             op=op,
             rights=rights,
             trustees=trustees,
             denied=denied,
             inheritable=inheritable,
-            propagate_to_children=propagate_to_children
+            propagate_to_children=propagate_to_children,
         )
 
         self._set_object_attributes(**response)
 
 
 class TrusteeACLMixin:
     """TrusteeACLMixin class adds ACL management for Trustee classes.
@@ -361,15 +373,15 @@
 
     def set_permission(
         self,
         permission: Permissions | str,
         to_objects: str | list[str],
         object_type: "ObjectTypes | int",
         project: "Optional[Project | str]" = None,
-        propagate_to_children: Optional[bool] = None
+        propagate_to_children: Optional[bool] = None,
     ) -> None:
         """Set permission to perform actions on given object(s).
 
         Function is used to set permission of the trustee to perform given
         actions on the provided objects. Within one execution of the function
         permission will be set in the same manner for each of the provided
         objects. The only available values of permission are: 'View', 'Modify',
@@ -402,68 +414,73 @@
                     "See: Permissions enum."
                 )
                 exception_handler(msg)
         right_value = AGGREGATED_RIGHTS_MAP[permission].value
         denied = permission is Permissions.DENIED_ALL
 
         # those 2 tries are for clearing current rights (set to default values)
-        try:
-            modify_rights(
-                connection=self.connection,
-                object_type=object_type,
-                trustees=self.id,
-                op='REMOVE',
-                rights=AggregatedRights.ALL.value,
-                ids=to_objects,
-                denied=(not denied),
-                propagate_to_children=propagate_to_children,
-                project=project
-            )
-        except IServerError:
-            pass
-        try:
-            modify_rights(
-                connection=self.connection,
-                object_type=object_type,
-                trustees=self.id,
-                op='REMOVE',
-                rights=AggregatedRights.ALL.value,
-                ids=to_objects,
-                denied=denied,
-                propagate_to_children=propagate_to_children,
-                project=project
-            )
-        except IServerError:
-            pass
+        for is_denied in True, False:
+            try:
+                current_permission = (
+                    Permissions.DENIED_ALL if is_denied else Permissions.FULL_CONTROL
+                ).value
+                if config.verbose:
+                    logger.info(
+                        f"Attempting to remove default permission: {current_permission}"
+                    )
+                modify_rights(
+                    connection=self.connection,
+                    object_type=object_type,
+                    trustees=self.id,
+                    op='REMOVE',
+                    rights=AggregatedRights.ALL.value,
+                    ids=to_objects,
+                    denied=is_denied,
+                    propagate_to_children=propagate_to_children,
+                    project=project,
+                )
+                if config.verbose:
+                    logger.info(
+                        f"Successfully removed permission: {current_permission}"
+                    )
+            except IServerError:
+                pass
 
         if permission != Permissions.DEFAULT_ALL:
-            modify_rights(
-                connection=self.connection,
-                object_type=object_type,
-                trustees=self.id,
-                op='ADD',
-                rights=right_value,
-                ids=to_objects,
-                denied=denied,
-                propagate_to_children=propagate_to_children,
-                project=project
-            )
+            try:
+                if config.verbose:
+                    logger.info(f"Attempting to add permission: {permission.value}")
+                modify_rights(
+                    connection=self.connection,
+                    object_type=object_type,
+                    trustees=self.id,
+                    op='ADD',
+                    rights=right_value,
+                    ids=to_objects,
+                    denied=denied,
+                    propagate_to_children=propagate_to_children,
+                    project=project,
+                )
+                if config.verbose:
+                    logger.info(f"Successfully added permission: {permission.value}")
+            except IServerError:
+                pass
 
     def set_custom_permissions(
         self,
         to_objects: str | list[str],
         object_type: "ObjectTypes | int",
         project: "Optional[Project | str]" = None,
         execute: Optional[str] = None,
         use: Optional[str] = None,
         control: Optional[str] = None,
         delete: Optional[str] = None,
         write: Optional[str] = None,
         read: Optional[str] = None,
-        browse: Optional[str] = None
+        browse: Optional[str] = None,
     ) -> None:
         """Set custom permissions to perform actions on given object(s).
 
         Function is used to set rights of the trustee to perform given actions
         on the provided objects. Within one execution of the function rights
         will be set in the same manner for each of the provided objects.
         None of the rights is necessary, but if provided then only possible
@@ -502,29 +519,28 @@
             trustee_id: str,
             right: Rights | list[Rights],
             to_objects: list[str],
             object_type: "ObjectTypes | int",
             denied: bool,
             default: bool = False,
             propagate_to_children: Optional[bool] = None,
-            project: "Optional[Project | str]" = None
+            project: "Optional[Project | str]" = None,
         ) -> None:
-
             right_value = _get_custom_right_value(right)
             try:
                 modify_rights(
                     connection=connection,
                     trustees=trustee_id,
                     op='REMOVE',
                     rights=right_value,
                     ids=to_objects,
                     object_type=object_type,
                     project=project,
                     denied=(not denied),
-                    propagate_to_children=propagate_to_children
+                    propagate_to_children=propagate_to_children,
                 )
             except IServerError:
                 pass
 
             op = 'REMOVE' if default else 'ADD'
             try:
                 modify_rights(
@@ -532,66 +548,68 @@
                     trustees=trustee_id,
                     op=op,
                     rights=right_value,
                     ids=to_objects,
                     object_type=object_type,
                     project=project,
                     denied=denied,
-                    propagate_to_children=propagate_to_children
+                    propagate_to_children=propagate_to_children,
                 )
             except IServerError:
                 pass
 
         rights_dict = {
             Rights.EXECUTE: execute,
             Rights.USE: use,
             Rights.CONTROL: control,
             Rights.DELETE: delete,
             Rights.WRITE: write,
             Rights.READ: read,
-            Rights.BROWSE: browse
+            Rights.BROWSE: browse,
         }
         if not set(rights_dict.values()).issubset({'grant', 'deny', 'default', None}):
             msg = (
                 "Invalid value of the right. Available values are 'grant', 'deny', "
                 "'default' or None."
             )
             raise ValueError(msg)
 
         grant_list = [right for right, value in rights_dict.items() if value == 'grant']
         deny_list = [right for right, value in rights_dict.items() if value == 'deny']
-        default_list = [right for right, value in rights_dict.items() if value == 'default']
+        default_list = [
+            right for right, value in rights_dict.items() if value == 'default'
+        ]
 
         modify_custom_rights(
             connection=self.connection,
             trustee_id=self.id,
             right=grant_list,
             to_objects=to_objects,
             object_type=object_type,
             denied=False,
-            project=project
+            project=project,
         )
         modify_custom_rights(
             connection=self.connection,
             trustee_id=self.id,
             right=deny_list,
             to_objects=to_objects,
             object_type=object_type,
             denied=True,
-            project=project
+            project=project,
         )
         modify_custom_rights(
             connection=self.connection,
             trustee_id=self.id,
             right=default_list,
             to_objects=to_objects,
             object_type=object_type,
             denied=True,
             project=project,
-            default=True
+            default=True,
         )
 
 
 def modify_rights(
     connection,
     object_type: "ObjectTypes | int",
     ids: list[str] | str,
@@ -642,27 +660,29 @@
     if not isinstance(ids, list):
         ids = [ids]
     if not isinstance(trustees, list):
         trustees = [trustees]
     if not isinstance(object_type, ObjectTypes):
         object_type = ObjectTypes(object_type)
 
-    trustees = [trustee if isinstance(trustee, str) else trustee.id for trustee in trustees]
+    trustees = [
+        trustee if isinstance(trustee, str) else trustee.id for trustee in trustees
+    ]
     project = project.id if project and not isinstance(project, str) else project
     if op not in ["ADD", "REMOVE", "REPLACE"]:
         raise ValueError("Wrong ACL operator passed. Please use ADD, REMOVE or REPLACE")
 
     for id in ids:
         for trustee in trustees:
             if inheritable is None and object_type is ObjectTypes.FOLDER:
                 response = objects.get_object_info(
                     connection=connection,
                     id=id,
                     object_type=object_type.value,
-                    project_id=project
+                    project_id=project,
                 ).json()
                 tmp = [
                     ace['inheritable']
                     for ace in response.get('acl', [])
                     if ace['trusteeId'] == trustee and ace['deny'] == denied
                 ]
                 inheritable = False if not tmp else tmp[0]
@@ -673,29 +693,29 @@
                         rights=rights,
                         trustee_id=trustee,
                         deny=denied,
                         inheritable=inheritable,
                         trustee_name=None,
                         trustee_type=None,
                         trustee_subtype=None,
-                        entry_type=1
+                        entry_type=1,
                     )._get_request_body(op=op)
                 ]
             }
 
             if propagate_to_children and object_type is ObjectTypes.FOLDER:
                 body["propagateACLToChildren"] = propagate_to_children
                 body["propagationBehavior"] = "overwrite_recursive"
 
             response = objects.update_object(
                 connection=connection,
                 id=id,
                 body=body,
                 object_type=object_type.value,
-                project_id=project
+                project_id=project,
             )
         if len(ids) == 1 and response.ok:
             return response.json()
 
 
 def _parse_acl_rights_bin_to_dict(rights_bin: int) -> dict[Rights, bool]:
     return {right: rights_bin & right.value != 0 for right in Rights}
@@ -715,13 +735,13 @@
         right = [right]
     for r in right:
         if not isinstance(r, Rights):
             try:
                 r = Rights[r.upper()]
             except ValueError:
                 msg = (
-                    f"Invalid custom `right` value: {r}. Available values are: EXECUTE, USE, "
-                    "CONTROL, DELETE, WRITE, READ, BROWSE. See: the Rights enum."
+                    f"Invalid custom `right` value: {r}. Available values are: EXECUTE,"
+                    f" USE, CONTROL, DELETE, WRITE, READ, BROWSE. See: the Rights enum."
                 )
                 raise ValueError(msg)
         right_value |= r.value
     return right_value
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/api_helpers.py` & `mstrio-py-11.3.9.103/mstrio/utils/api_helpers.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,36 +1,46 @@
 from concurrent.futures import as_completed
 from contextlib import contextmanager
 from functools import wraps
 from json import dumps
-from typing import List, Optional
+from typing import TYPE_CHECKING, Optional
 
-from mstrio.api.changesets import commit_changeset_changes, create_changeset, delete_changeset
-from mstrio.connection import Connection
+from mstrio.api.changesets import (
+    commit_changeset_changes,
+    create_changeset,
+    delete_changeset,
+)
 from mstrio.utils.helper import (
-    auto_match_args, delete_none_values, get_parallel_number, response_handler
+    auto_match_args,
+    delete_none_values,
+    get_parallel_number,
+    response_handler,
 )
 from mstrio.utils.sessions import FuturesSessionWithRenewal
 
+if TYPE_CHECKING:
+    from mstrio.connection import Connection
 
-def unpack_information(func):
 
+def unpack_information(func):
     @wraps(func)
     def unpack_information_inner(*args, **kwargs):
         if kwargs.get('body'):
             info = {
                 "information": {
                     "objectId": kwargs['body'].pop('id', None),
                     "subType": kwargs['body'].pop('subType', None),
                     "name": kwargs['body'].pop('name', None),
                     "isEmbedded": kwargs['body'].pop('isEmbedded', None),
                     "description": kwargs['body'].pop('description', None),
                     "dateCreated": kwargs['body'].pop('dateCreated', None),
                     "dateModified": kwargs['body'].pop('dateModified', None),
-                    "destinationFolderId": kwargs['body'].pop('destinationFolderId', None),
+                    "destinationFolderId": kwargs['body'].pop(
+                        'destinationFolderId', None
+                    ),
                     "versionId": kwargs['body'].pop('versionId', None),
                     "path": kwargs['body'].pop('path', None),
                     "primaryLocale": kwargs['body'].pop('primaryLocale', None),
                 }
             }
             info = delete_none_values(info, recursion=True)
             if info['information']:
@@ -40,15 +50,18 @@
         response_json = resp.json()
 
         if response_json.get('information'):
             response_json.update(response_json.pop('information'))
             response_json['id'] = response_json.pop('objectId', None)
         if response_json.get('tables'):
             response_json = unpack_tables(response_json)
-        if isinstance(response_json, dict) and response_json.get('subType') == 'logical_table':
+        if (
+            isinstance(response_json, dict)
+            and response_json.get('subType') == 'logical_table'
+        ):
             response_json = unpack_table(response_json)
         resp.encoding, resp._content = 'utf-8', dumps(response_json).encode('utf-8')
         return resp
 
     return unpack_information_inner
 
 
@@ -70,17 +83,17 @@
 
     return copy
 
 
 def unpack_tables(response_json):
     copy = response_json.get('tables').copy()
     for table in copy:
-        PHYSICAL_TABLE_FIELD_SET = table.get('physicalTable') and len(
-            table.keys()
-        ) == 1  # if retrieved with tables.get_tables(...,fields='physicalTable')
+        PHYSICAL_TABLE_FIELD_SET = (
+            table.get('physicalTable') and len(table.keys()) == 1
+        )  # if retrieved with tables.get_tables(...,fields='physicalTable')
         if PHYSICAL_TABLE_FIELD_SET:
             table.update(table.pop('physicalTable'))
         if table.get('information'):
             table.update(table.pop('information'))
             table['id'] = table.pop('objectId', None)
     return copy
 
@@ -94,19 +107,19 @@
         commit_changeset_changes(connection=connection, id=changeset_id)
     finally:
         delete_changeset(connection=connection, id=changeset_id)
 
 
 def async_get(
     async_wrapper: callable,
-    connection: Connection,
-    ids: List[str],
+    connection: 'Connection',
+    ids: list[str],
     error_msg: Optional[str] = None,
-    **kwargs
-) -> List[dict]:
+    **kwargs,
+) -> list[dict]:
     """Asynchronously get results of single object GET requests. GET requests
     requires to have future session param to be used with this function. Threads
     number is set automatically.
 
     Args:
         async_wrapper: callable async REST API wrapper function
         connection: Connection object
@@ -120,21 +133,25 @@
     Examples:
         >>> async_get(tables.get_table_async, connection, ['112233','223344'])
     """
     project_id = kwargs.get('project_id') or connection.project_id
     kwargs['project_id'] = project_id
     threads = get_parallel_number(len(ids))
     all_objects = []
-    with FuturesSessionWithRenewal(connection=connection, max_workers=threads) as session:
+    with FuturesSessionWithRenewal(
+        connection=connection, max_workers=threads
+    ) as session:
         # Extract parameters of the api wrapper and set them using kwargs
         param_value_dict = auto_match_args(
             async_wrapper, kwargs, exclude=['connection', 'session', 'error_msg', 'id']
         )
         futures = [
-            async_wrapper(session=session, connection=connection, id=id, **param_value_dict)
+            async_wrapper(
+                session=session, connection=connection, id=id, **param_value_dict
+            )
             for id in ids
         ]
         for f in as_completed(futures):
             response = f.result()
             if not response.ok:
                 response_handler(response, error_msg, throw_error=False)
             all_objects.append(response.json())
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/cache.py` & `mstrio-py-11.3.9.103/mstrio/utils/cache.py`

 * *Files 4% similar despite different names*

```diff
@@ -21,15 +21,17 @@
 
 
 class Cache:
     """
     Base class for managing cache.
     """
 
-    def __init__(self, connection: Connection, cache_id: str, cache_dict: Optional[dict] = None):
+    def __init__(
+        self, connection: Connection, cache_id: str, cache_dict: Optional[dict] = None
+    ):
         """Initialize the Cache object.
 
         Args:
             connection (Connection): MicroStrategy connection object returned by
                 `connection.Connection()`.
             cache_id (string): cache id
             cache_dict (dict, optional): dictionary with properties of cache
@@ -43,15 +45,17 @@
 
         self._init_variables(**cache_dict)
 
     def _init_variables(self, **kwargs) -> None:
         """Initialize variables given cache_dict."""
         kwargs = camel_to_snake(kwargs)
         self._project_name = kwargs.get('project_name')
-        self._source = CacheSource.from_dict(source) if (source := kwargs.get('source')) else None
+        self._source = (
+            CacheSource.from_dict(source) if (source := kwargs.get('source')) else None
+        )
         self._last_update_time = kwargs.get('last_update_time')
         self._last_hit_time = kwargs.get('last_hit_time')
         self._hit_count = kwargs.get('hit_count')
         self._size = kwargs.get('size')
         self._creator_name = kwargs.get('creator_name') or kwargs.get('creator')
         self._creation_time = kwargs.get('creation_time')
 
@@ -103,15 +107,14 @@
     @property
     def creation_time(self):
         return self._creation_time
 
 
 @dataclass
 class CacheSource(Dictable):
-
     class Type(AutoName):
         REPORT = auto()
         DOCUMENT = auto()
         DOSSIER = auto()
         DOCDOSSIER = auto()
         CUBE = auto()
 
@@ -120,15 +123,17 @@
     }
 
     id: str
     name: str
     type: Type
 
     def __repr__(self):
-        return f"CacheSource(id='{self.id}, name='{self.name}, type='{self.type.value}')"
+        return (
+            f"CacheSource(id='{self.id}, name='{self.name}, type='{self.type.value}')"
+        )
 
 
 class ContentCacheMixin:
     """ContentCacheMixin class adds ContentCache management for supporting cache
 
     Objects currently supported are ContentCache for documents, dossiers and
     reports.
@@ -153,15 +158,15 @@
     @staticmethod
     def __alter_status(
         connection: "Connection",
         op: str,
         cache_ids: list[str],
         value: Optional[bool] = None,
         status: Optional[str] = None,
-        nodes: Optional[list[str]] = None
+        nodes: Optional[list[str]] = None,
     ) -> Response:
         """Engine for altering ContentCache status
 
         Args:
             connection (object): MicroStrategy connection object returned
                 by `connection.Connection()`
             op (str): Replace or Remove operation to be performed
@@ -179,28 +184,31 @@
 
         if not nodes:
             nodes = ContentCacheMixin.fetch_nodes(connection, connection.project_id)
         body = {'operationList': []}
         logger_message = {
             'replace/loaded/True': 'load',
             'replace/loaded/False': 'unload',
-            'remove/None/None': 'delete'
+            'remove/None/None': 'delete',
         }.get(f'{op}/{status}/{value}')
 
         for cache_id in cache_ids:
             content_cache = ContentCache(connection, cache_id)
             if not content_cache.combined_id and config.verbose:
                 logger.info(f'Could not {logger_message} cache {cache_id}')
                 continue
             body['operationList'].append(
                 {
                     'op': op,
-                    'path': f'/contentCaches/{content_cache.combined_id}/status/{status}'
-                    if status else f'/contentCaches/{content_cache.combined_id}',
-                    'value': value
+                    'path': (
+                        f'/contentCaches/{content_cache.combined_id}/status/{status}'
+                    )
+                    if status
+                    else f'/contentCaches/{content_cache.combined_id}',
+                    'value': value,
                 }
             )
         if body['operationList']:
             return monitors.update_contents_caches(connection, nodes, body)
         elif config.verbose:
             logger.info(NO_CACHE_LOG)
 
@@ -212,15 +220,19 @@
             connection (Connection): MicroStrategy connection object returned
             by 'connection.Connection()'
             cache_ids (list[str]): list of cache ids to be loaded
 
         Returns:
             Response object."""
         res = ContentCacheMixin.__alter_status(
-            connection=connection, op='replace', cache_ids=cache_ids, value=True, status='loaded'
+            connection=connection,
+            op='replace',
+            cache_ids=cache_ids,
+            value=True,
+            status='loaded',
         )
         if config.verbose and res:
             logger.info('Successfully loaded content caches')
         return res
 
     @staticmethod
     def unload_caches(connection: "Connection", cache_ids: list[str]) -> Response:
@@ -230,15 +242,19 @@
             connection (Connection): MicroStrategy connection object returned
             by 'connection.Connection()'
             cache_ids (list[str]): list of cache ids to be unloaded
 
         Returns:
             Response object."""
         res = ContentCacheMixin.__alter_status(
-            connection=connection, op='replace', cache_ids=cache_ids, value=False, status='loaded'
+            connection=connection,
+            op='replace',
+            cache_ids=cache_ids,
+            value=False,
+            status='loaded',
         )
         if config.verbose and res:
             logger.info('Successfully unloaded content caches')
         return res
 
     @staticmethod
     def delete_caches(
@@ -253,18 +269,21 @@
             force (bool, optional): If True, then no additional prompt will be
                 shown before deleting objects.
 
         Returns:
             Response object."""
         user_input = 'N'
         if not force:
-            user_input = input(
-                'Are you sure you want to delete all content caches with '
-                'provided IDs? [Y/N]: '
-            ) or 'N'
+            user_input = (
+                input(
+                    'Are you sure you want to delete all content caches with '
+                    'provided IDs? [Y/N]: '
+                )
+                or 'N'
+            )
         if force or user_input == 'Y':
             res = ContentCacheMixin.__alter_status(
                 connection=connection, op='remove', cache_ids=cache_ids
             )
             if config.verbose and res:
                 logger.info('Successfully deleted content caches')
             return res
@@ -346,43 +365,46 @@
             project_id=project_id,
             node=nodes,
             limit=None,
             status=status,
             content_type=content_type,
             size=size,
             owner=owner,
-            filters={}
+            filters={},
         )
         caches = [list(cache.items())[0] for cache in caches['content_caches']]
         if limit:
             caches = caches[:limit]
 
         caches = [{**cache[1], 'combined_id': cache[0]} for cache in caches]
 
         # apply filtering
-        filtered_caches = (
-            lambda str_arg, arg: [cache for cache in caches if cache.get(str_arg, '') == arg]
-        )
+        def filtered_caches(str_arg, arg):
+            return [cache for cache in caches if cache.get(str_arg, '') == arg]
+
         if id:
             caches = filtered_caches('id', id)
         if db_connection_id:
             caches = filtered_caches('databaseConnectionId', db_connection_id)
         if db_login_id:
             caches = filtered_caches('databaseLoginId', db_login_id)
         if wh_tables:
             caches = filtered_caches('warehouseTablesUsed', wh_tables)
         if security_filter_id:
             caches = filtered_caches('securityFilterId', security_filter_id)
         if unloaded:
-            caches = [cache for cache in caches if not cache.get('status').get('loaded')]
+            caches = [
+                cache for cache in caches if not cache.get('status').get('loaded')
+            ]
 
         if to_dictionary:
             return caches
         else:
             from mstrio.project_objects import ContentCache
+
             return ContentCache.from_dict(connection, caches)
 
     @classmethod
     def load_all_caches(
         cls,
         connection: "Connection",
         **filters,
@@ -452,16 +474,19 @@
                 `connection.Connection()`
             force (bool, optional): If True, then no additional prompt will be
                 shown before deleting objects.
             **filters: Available filter parameters: ['db_connection_id',
                 'db_login_id', 'owner', 'status', 'size', 'wh_tables',
                 'security_filter_id']
         """
-        cache_ids = [cache.id for cache in cls.list_caches(connection, **filters)
-                     if cache.status.ready]
+        cache_ids = [
+            cache.id
+            for cache in cls.list_caches(connection, **filters)
+            if cache.status.ready
+        ]
         if cache_ids:
             cls.delete_caches(
                 connection=connection,
                 cache_ids=cache_ids,
                 force=force,
             )
         elif config.verbose:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/certified_info.py` & `mstrio-py-11.3.9.103/mstrio/utils/certified_info.py`

 * *Files 1% similar despite different names*

```diff
@@ -22,20 +22,22 @@
     """
 
     def __init__(
         self,
         connection: Connection,
         certified: bool,
         date_certified: Optional[str] = None,
-        certifier: Optional[dict] = None
+        certifier: Optional[dict] = None,
     ):
         self._connection = connection
         self._certified = certified
         self._date_certified = date_certified
-        self._certifier = User.from_dict(certifier, self._connection) if certifier else None
+        self._certifier = (
+            User.from_dict(certifier, self._connection) if certifier else None
+        )
 
     def __str__(self):
         if not self.certified:
             return 'Object is not certified.'
         return f"Object certified on {self.date_certified} by {self._certifier}"
 
     def __repr__(self):
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/datasources.py` & `mstrio-py-11.3.9.103/mstrio/utils/datasources.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,63 +1,78 @@
 import json
 
 
 def alter_conn_resp(response):
     response_json = response.json()
     response_json = alter_conn_json(response_json)
-    response.encoding, response._content = 'utf-8', json.dumps(response_json).encode('utf-8')
+    response.encoding, response._content = 'utf-8', json.dumps(response_json).encode(
+        'utf-8'
+    )
     return response
 
 
 def alter_conn_list_resp(response):
     response_json = response.json()
     for conn in response_json["connections"]:
         alter_conn_json(conn)
-    response.encoding, response._content = 'utf-8', json.dumps(response_json).encode('utf-8')
+    response.encoding, response._content = 'utf-8', json.dumps(response_json).encode(
+        'utf-8'
+    )
     return response
 
 
 def alter_conn_json(response_json):
     response_json['datasource_login'] = response_json["database"]["login"]
     response_json['database_type'] = response_json["database"]["type"]
     response_json['database_version'] = response_json["database"]["version"]
     del response_json["database"]
     return response_json
 
 
 def alter_instance_resp(response):
     response_json = response.json()
     response_json = alter_instance_json(response_json)
-    response.encoding, response._content = 'utf-8', json.dumps(response_json).encode('utf-8')
+    response.encoding, response._content = 'utf-8', json.dumps(response_json).encode(
+        'utf-8'
+    )
     return response
 
 
 def alter_instance_list_resp(response):
     response_json = response.json()
     for ds in response_json["datasources"]:
         alter_instance_json(ds)
-    response.encoding, response._content = 'utf-8', json.dumps(response_json).encode('utf-8')
+    response.encoding, response._content = 'utf-8', json.dumps(response_json).encode(
+        'utf-8'
+    )
     return response
 
 
 def alter_instance_json(response_json):
     response_json['datasource_connection'] = response_json["database"].get("connection")
     response_json['database_type'] = response_json["database"].get("type")
     response_json['database_version'] = response_json["database"].get("version")
-    response_json['primary_datasource'] = response_json["database"].get("primaryDatasource")
-    response_json['data_mart_datasource'] = response_json["database"].get("dataMartDatasource")
+    response_json['primary_datasource'] = response_json["database"].get(
+        "primaryDatasource"
+    )
+    response_json['data_mart_datasource'] = response_json["database"].get(
+        "dataMartDatasource"
+    )
     del response_json["database"]
     return response_json
 
 
 def alter_patch_req_body(op_dict, initial_path, altered_path):
     if op_dict["path"] == initial_path:
         op_dict["path"] = altered_path
-        op_dict["value"] = op_dict["value"] if isinstance(op_dict["value"],
-                                                          str) else op_dict["value"].get("id")
+        op_dict["value"] = (
+            op_dict["value"]
+            if isinstance(op_dict["value"], str)
+            else op_dict["value"].get("id")
+        )
     return op_dict
 
 
 def get_objects_id(obj, obj_class):
     if isinstance(obj, str):
         return obj
     elif isinstance(obj, obj_class):
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/dependence_mixin.py` & `mstrio-py-11.3.9.103/mstrio/utils/dependence_mixin.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,17 @@
 from typing import Optional, TYPE_CHECKING, Union
 
 from mstrio.utils.exceptions import NotSupportedError
 from mstrio.types import ObjectTypes
 
 if TYPE_CHECKING:
     from mstrio.object_management.search_enums import (
-        SearchDomain, SearchPattern, SearchResultsFormat
+        SearchDomain,
+        SearchPattern,
+        SearchResultsFormat,
     )
     from mstrio.server import Project
     from mstrio.types import TypeOrSubtype
     from mstrio.utils.entity import Entity
 
 
 class DependenceMixin:
@@ -96,15 +98,15 @@
             object_types=object_types,
             uses_recursive=uses_recursive,
             root=root,
             limit=limit,
             offset=offset,
             results_format=results_format,
             to_dictionary=to_dictionary,
-            **filters
+            **filters,
         )
 
     def list_dependencies(
         self: 'Entity',
         project: Optional[Union['Project', str]] = None,
         name: Optional[str] = None,
         pattern: Union['SearchPattern', int] = 4,
@@ -182,9 +184,9 @@
             used_by_recursive=used_by_recursive,
             name=name,
             object_types=object_types,
             root=root,
             limit=limit,
             offset=offset,
             to_dictionary=to_dictionary,
-            **filters
+            **filters,
         )
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/dict_filter.py` & `mstrio-py-11.3.9.103/mstrio/utils/dict_filter.py`

 * *Files 5% similar despite different names*

```diff
@@ -26,15 +26,18 @@
 ENTITY_COMPARE = 'entity'
 
 
 def check_valid_param(dict_object: Dict[KT, VT], params: Iterable) -> None:
     """Check if filter parameters can be used with given dict."""
     # all keys from dict that are supported for filtering
     allowed = list(
-        filter(lambda el: not isinstance(dict_object[el], (list, tuple, set)), dict_object.keys())
+        filter(
+            lambda el: not isinstance(dict_object[el], (list, tuple, set)),
+            dict_object.keys(),
+        )
     )
 
     # check filter param is in the allowed
     for param in params:
         if param not in allowed:
             raise KeyError(
                 f"The filter parameter '{param}' is not valid. "
@@ -57,15 +60,15 @@
         filter_value = expression
     elif isinstance(expression, str):
         # extract the operation from the expression if it exists
         if expression and expression[0] in [SMALLER, LARGER, NOT, EQUAL]:
             op = expression[0]
             if expression[0] in [SMALLER, LARGER, NOT] and expression[1] == EQUAL:
                 op += expression[1]
-        filter_value = expression[len(op):] if op is not None else expression
+        filter_value = expression[len(op) :] if op is not None else expression
 
         if filter_value.lower() == 'true':  # Support string bool values
             filter_value = True
             op = IS
         elif filter_value.lower() == 'false':
             filter_value = False
             op = IS
@@ -111,15 +114,17 @@
             return filter_value
         elif isinstance(filter_value, value_type) and op != IN:
             return filter_value
         elif not isinstance(filter_value, value_type):
             # check if all other types are not equal to value_type and cast
             if op in (DICT_COMPARE, IS):
                 # do not cast to bool or to dict
-                raise TypeError(f"'{param}' needs to be compatible with type {value_type}.")
+                raise TypeError(
+                    f"'{param}' needs to be compatible with type {value_type}."
+                )
 
             try:
                 # cast filter_value to dict element type
                 if op == IN:
                     return [value_type(val) for val in filter_value]
 
                 else:
@@ -152,15 +157,20 @@
         elif op == LARGER_EQUAL:
             return value >= filter_value
         elif op == SMALLER_EQUAL:
             return value <= filter_value
         elif op == IN:
             return value in filter_value
         elif op == DICT_COMPARE:
-            return all((value[k] == v if k in value else False for k, v in filter_value.items()))
+            return all(
+                (
+                    value[k] == v if k in value else False
+                    for k, v in filter_value.items()
+                )
+            )
 
     return my_filter
 
 
 def filter_list_of_dicts(
     list_of_dicts: List[Dict[KT, VT]], **filters: Dict[str, SupportedExpression]
 ) -> List[Dict[KT, VT]]:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/encoder.py` & `mstrio-py-11.3.9.103/mstrio/utils/encoder.py`

 * *Files 2% similar despite different names*

```diff
@@ -46,12 +46,13 @@
         else:
             self.__orientation = self.__table_type_orient_map[dataset_type]
 
     @property
     def encode(self):
         """Encode data in base 64."""
         self.__b64_data = b64encode(
-            self.__data_frame.to_json(orient=self.__orientation,
-                                      date_format='iso').encode('utf-8')
+            self.__data_frame.to_json(
+                orient=self.__orientation, date_format='iso'
+            ).encode('utf-8')
         ).decode('utf-8')
         # return base 64 encoded data to calling environment
         return self.__b64_data
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/entity.py` & `mstrio-py-11.3.9.103/mstrio/utils/entity.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,29 +1,40 @@
 import csv
 from enum import Enum
 import inspect
 import logging
 from os.path import join as joinpath
 from pprint import pprint
 from sys import version_info
-from typing import Any, Callable, Dict, List, Optional, Tuple, TYPE_CHECKING, TypeVar, Union
+from typing import (
+    Any,
+    Callable,
+    Optional,
+    TYPE_CHECKING,
+    TypeVar,
+)
 
 from pandas import DataFrame
-from stringcase import snakecase
+import humps
 
 from mstrio import config
 from mstrio.api import objects
 from mstrio.api.exceptions import VersionException
 from mstrio.connection import Connection
 from mstrio.types import ExtendedType, ObjectSubTypes, ObjectTypes
 from mstrio.utils import helper
 from mstrio.utils.acl import ACE, ACLMixin, Rights
 from mstrio.utils.dependence_mixin import DependenceMixin
 from mstrio.utils.exceptions import NotSupportedError
-from mstrio.utils.time_helper import bulk_str_to_datetime, DatetimeFormats, map_str_to_datetime
+from mstrio.utils.helper import rename_dict_keys
+from mstrio.utils.time_helper import (
+    bulk_str_to_datetime,
+    DatetimeFormats,
+    map_str_to_datetime,
+)
 
 if TYPE_CHECKING:
     from mstrio.object_management import Folder
     from mstrio.server import Project
 
 logger = logging.getLogger(__name__)
 
@@ -49,39 +60,39 @@
         override `_init_variables` method to implement this mapping such as:
          ```
             kwargs = self._rest_to_python(kwargs)
             self._AVAILABLE_ATTRIBUTES.update({key: type(val) for key, val
                 in kwargs.items()})
             # init logic follows
         ```
-    _API_GETTERS (Dict[Union[str, tuple], Callable]): A dictionary whose keys
+    _API_GETTERS (dict[str | tuple, Callable]): A dictionary whose keys
         are either a name of an attribute (as a string) or names of attributes
         (as a tuple), and values are the REST API wrapper functions used to
         fetch related data from a server. For example:
         {'id': objects.get_object_info} or
         {('id', 'name', 'description): objects.get_object_info}
-    _FROM_DICT_MAP (Dict[str, Callable]): A dictionary whose keys are
+    _FROM_DICT_MAP (dict[str, Callable]): A dictionary whose keys are
         attribute's name and values are the attribute's type. This mapping is
         required to determine a proper composite form in which a value will be
         stored (such as an Enum, list of Enums etc.). Therefore, only attributes
         with composite and not primitive data types should be included here.
-    _AVAILABLE_ATTRIBUTES (Dict[str, type]): A dictionary which keys are
+    _AVAILABLE_ATTRIBUTES (dict[str, type]): A dictionary which keys are
         object's attribute names as strings, and which values are types of
         attributes value. It is used for validating attribute's type during the
         process of properties update. This dictionary is created from keyword
         arguments passed to an object's constructor.
-    _API_PATCH (Dict[Tuple[str], Tuple[Union[Callable, str]]]): A dictionary
+    _API_PATCH (dict[tuple[str], tuple[Callable | str]]): A dictionary
         whose keys are tuples with an object's attribute names as strings, and
         values are tuples with two elements: first element is a REST API wrapper
         function used to update the object's properties, and the second element
         is a definition (as a string) how this update should be performed. For
         example:
         {('name', 'description', 'abbreviation'):
             (objects.update_object, 'partial_put')}
-    _PATCH_PATH_TYPES (Dict[str, type]): A dictionary whose keys are names of
+    _PATCH_PATH_TYPES (dict[str, type]): A dictionary whose keys are names of
         object's attributes and values are attribute types. Used to
         validate correctness of a new value during the process of properties
         update. For example: {'id': str, 'enabled': bool}
     _API_DELETE(Callable): A function which is used to delete an object from the
         server. Defaults to staticmethod(objects.delete_object).
 
 
@@ -117,41 +128,46 @@
             version IDs mismatch, MSTR Object Manager determines that objects
             'Exists Differently'.
         owner (User): The object's owner information.
         icon_path (str): A path to a location where the object's icon is stored.
         view_media (int): The enumeration constant used to represent the default
             mode of a RSD or a dossier, and available modes of a RSD or a
             dossier.
-        ancestors (List[Dict]): A list of the object's ancestor folders.
+        ancestors (list[dict]): A list of the object's ancestor folders.
         certified_info (CertifiedInfo): The object's certification status,
             time of certification, and information about the certifier
             (currently only for document and report)
         acg (Rights): The enumeration constant used to specify the access
             granted attribute of the object.
-        acl (List[ACE]): A list of permissions on the object so that users, or
+        acl (list[ACE]): A list of permissions on the object so that users, or
             user groups have control over individual objects in the system.
             Those permissions decide whether or not a user can perform a
             particular class of operations on a particular object. For example,
             a user may have permissions to view and execute a report , but
             cannot modify the report definition or delete the report.
         hidden (bool): Determines whether the object is hidden on a server.
         project_id (str): The ID of a project in which the object resides.
-        comments (List[str]): Custom user's comments related to the object
+        comments (list[str]): Custom user's comments related to the object
         target_info (dict): ?
     """
-    _OBJECT_TYPE: ObjectTypes = ObjectTypes.NONE  # MSTR object type defined in ObjectTypes
-    _OBJECT_SUBTYPES: list[ObjectSubTypes] | None = None  # None means subtype won't be verified.
-    _REST_ATTR_MAP: Dict[str, str] = {}
-    _API_GETTERS: Dict[Union[str, tuple], Callable] = {}
-    _FROM_DICT_MAP: Dict[str, Callable] = {
+
+    _OBJECT_TYPE: ObjectTypes = (
+        ObjectTypes.NONE
+    )  # MSTR object type defined in ObjectTypes
+    _OBJECT_SUBTYPES: list[
+        ObjectSubTypes
+    ] | None = None  # None means subtype won't be verified.
+    _REST_ATTR_MAP: dict[str, str] = {}
+    _API_GETTERS: dict[str | tuple, Callable] = {}
+    _FROM_DICT_MAP: dict[str, Callable] = {
         'type': ObjectTypes
     }  # map attributes to Enums and Composites
-    _AVAILABLE_ATTRIBUTES: Dict[str, type] = {}  # fetched on runtime from all Getters
-    _API_PATCH: Dict[Tuple[str], Tuple[Union[Callable, str]]] = {}
-    _PATCH_PATH_TYPES: Dict[str, type] = {}  # used in update_properties method
+    _AVAILABLE_ATTRIBUTES: dict[str, type] = {}  # fetched on runtime from all Getters
+    _API_PATCH: dict[tuple[str], tuple[Callable | str]] = {}
+    _PATCH_PATH_TYPES: dict[str, type] = {}  # used in update_properties method
     _API_DELETE: Callable = staticmethod(objects.delete_object)
 
     def __init__(self, connection: Connection, object_id: str, **kwargs) -> None:
         self._init_variables(connection=connection, id=object_id, **kwargs)
         if config.fetch_on_init and self._find_func("id") is not None:
             self.fetch("id")
         if config.verbose:
@@ -168,19 +184,23 @@
         properly update object's properties on a server.
 
         Note: attributes not accepted by any implementation of this function
             in the inheritance chain will be disregarded.
         """
         kwargs = self._rest_to_python(kwargs)
         # create _AVAILABLE_ATTRIBUTES map
-        self._AVAILABLE_ATTRIBUTES.update({key: type(val) for key, val in kwargs.items()})
+        self._AVAILABLE_ATTRIBUTES.update(
+            {key: type(val) for key, val in kwargs.items()}
+        )
         self._connection = kwargs.get("connection")
         self._id = kwargs.get("id")
-        self._type = self._OBJECT_TYPE if 'type' in self._FROM_DICT_MAP else kwargs.get(
-            "type", self._OBJECT_TYPE
+        self._type = (
+            self._OBJECT_TYPE
+            if 'type' in self._FROM_DICT_MAP
+            else kwargs.get("type", self._OBJECT_TYPE)
         )
         self.name = kwargs.get("name")
         self._altered_properties = dict()
 
     def fetch(self, attr: Optional[str] = None) -> None:  # NOSONAR
         """Fetch the latest object's state from the I-Server.
 
@@ -192,34 +212,43 @@
             it will use all getters specified in `_API_GETTERS` dictionary.
             Defaults to None.
         Raises:
             ValueError: If `attr` cannot be fetched.
         """
         functions = self._API_GETTERS  # by default fetch all endpoints
 
-        if attr is not None:  # if attr is specified fetch endpoint matched to the attribute name
+        if (
+            attr is not None
+        ):  # if attr is specified fetch endpoint matched to the attribute name
             function = self._find_func(attr)
             if not function:
-                raise ValueError(f"The attribute `{attr}` cannot be fetched for this object")
+                raise ValueError(
+                    f"The attribute `{attr}` cannot be fetched for this object"
+                )
             else:
-                functions = {attr: func for attr, func in functions.items() if func == function}
+                functions = {
+                    attr: func for attr, func in functions.items() if func == function
+                }
 
         for key, func in functions.items():  # call respective API getters
             param_value_dict = auto_match_args_entity(func, self)
 
             response = func(**param_value_dict)
-            if response.ok:
-                json = response.json()
+
+            if response:
+                json = (
+                    response if isinstance(response, (dict, list)) else response.json()
+                )
+
                 if self._OBJECT_SUBTYPES and (subtype := json['subtype']):
                     self._check_object_subtype(subtype)
                 if type(json) == dict:
                     object_dict = {
                         key if isinstance(key, str) and len(json) == 1 else k: v
-                        for k,
-                        v in json.items()
+                        for k, v in json.items()
                     }
                     self._set_object_attributes(**object_dict)
                 elif type(json) == list:
                     self._set_object_attributes(**{key: json})
 
             # keep track of fetched attributes
             self._add_to_fetched(key)
@@ -251,19 +280,19 @@
 
         Returns:
             True if subtype is supported by class.
             False if subtype is not supported.
         """
         return subtype in [item.value for item in cls._OBJECT_SUBTYPES]
 
-    def _add_to_fetched(self, keys: Union[str, tuple]) -> None:
+    def _add_to_fetched(self, keys: str | tuple) -> None:
         """Adds name/-s of attribute/-s to the `_fetched_attributes` set.
 
         Args:
-            keys (Union[str, tuple]): Name, or tuple with names of attributes.
+            keys (str | tuple): Name, or tuple with names of attributes.
         """
         if isinstance(keys, str):
             keys = [keys]
         for key in keys:
             key = key[1:] if key.startswith("_") else key
             self._fetched_attributes.add(key)
 
@@ -305,21 +334,16 @@
 
         Args:
             response (dict): A dictionary representing an HTTP response.
 
         Returns:
             dict: A dictionary with field names converted to Python API names.
         """
-        """"""
-        for rest_name, python_name in cls._REST_ATTR_MAP.items():
-            if rest_name in response:
-                old = response.pop(rest_name)
-                if python_name:
-                    response[python_name] = old
-        return response
+
+        return rename_dict_keys(response, cls._REST_ATTR_MAP)
 
     @classmethod
     def _python_to_rest(cls, request_body: dict) -> dict:
         """Map Python API field names to REST API field names as specified in
         cls._REST_ATTR_MAP.
 
         Args:
@@ -353,37 +377,41 @@
             elif isinstance(self._FROM_DICT_MAP[key], type(Enum)):
                 val = self._FROM_DICT_MAP[key](val)
             elif isinstance(self._FROM_DICT_MAP[key], list) and val is not None:
                 if isinstance(self._FROM_DICT_MAP[key][0], type(Enum)):
                     val = [self._FROM_DICT_MAP[key][0](v) for v in val]
                 else:
                     val = [
-                        self._FROM_DICT_MAP[key][0](source=v, connection=self.connection)
+                        self._FROM_DICT_MAP[key][0](
+                            source=v, connection=self.connection
+                        )
                         for v in val
                     ]
             elif val == {}:
                 return None
             else:
                 val = self._FROM_DICT_MAP[key](source=val, connection=self.connection)
 
         return val
 
     def _set_object_attributes(self, **kwargs) -> None:
         """Set object's attributes programmatically by providing keyword args.
         Support ENUMs and creating composites. This function inspects whether
         the attribute was set as a property, and if yes it stores the attribute
-        with '_' prefix """
+        with '_' prefix"""
 
         object_info = helper.camel_to_snake(kwargs, whitelist=self._KEEP_CAMEL_CASE)
         object_info = self._rest_to_python(object_info)
 
         # determine which attributes should be private
         properties = {
             elem[0]
-            for elem in inspect.getmembers(self.__class__, lambda x: isinstance(x, property))
+            for elem in inspect.getmembers(
+                self.__class__, lambda x: isinstance(x, property)
+            )
         }
 
         for key, val in object_info.items():  # type: ignore
             # update _AVAILABLE_ATTRIBUTES map
             self._AVAILABLE_ATTRIBUTES.update({key: type(val)})
 
             # if self is a composite, create component instance
@@ -400,58 +428,65 @@
         the object to a dictionary.
 
         Returns:
             dict: A dictionary which keys are object's attribute names, and
                 which values are object's attribute values.
         """
         if hasattr(self, "_API_GETTERS"):  # fetch attributes not loaded on init
-            attr = [
-                attr for attr in self._API_GETTERS.keys() if isinstance(attr, str)  # type: ignore
-            ]
+            attr = [attr for attr in self._API_GETTERS.keys() if isinstance(attr, str)]
             for a in attr:
                 try:
                     getattr(self, a)
                 except VersionException:
                     pass
 
-        properties = inspect.getmembers(self.__class__, lambda x: isinstance(x, property))
+        properties = inspect.getmembers(
+            self.__class__, lambda x: isinstance(x, property)
+        )
         properties = {elem[0]: elem[1].fget(self) for elem in properties}
-        attributes = {key: val for key, val in vars(self).items() if not key.startswith('_')}
+        attributes = {
+            key: val for key, val in vars(self).items() if not key.startswith('_')
+        }
         attributes = {**properties, **attributes}
 
         return {
             key: attributes[key]
             for key in sorted(attributes, key=helper.sort_object_properties)
         }
 
     def to_dataframe(self) -> DataFrame:
         """Converts all properties of the object to a dataframe.
 
         Returns:
             DataFrame: A `DataFrame` object containing object properties.
         """
-        return DataFrame.from_dict(self.list_properties(), orient='index', columns=['value'])
+        return DataFrame.from_dict(
+            self.list_properties(), orient='index', columns=['value']
+        )
 
     def print(self) -> None:
         """Pretty Print all properties of the object."""
         if version_info.major >= 3 and version_info.minor >= 8:
             pprint(self.list_properties(), sort_dicts=False)  # type: ignore
         else:
             pprint(self.list_properties())
 
     @classmethod
     def from_dict(
-        cls: T, source: Dict[str, Any], connection: Connection, to_snake_case: bool = True
+        cls: T,
+        source: dict[str, Any],
+        connection: Connection,
+        to_snake_case: bool = True,
     ) -> T:
         """Overrides `Dictable.from_dict()` to instantiate an object from
             a dictionary without calling any additional getters.
 
         Args:
             cls (T): Class (type) of an object that should be created.
-            source (Dict[str, Any]): a dictionary from which an object will be
+            source (dict[str, Any]): a dictionary from which an object will be
                 constructed.
             connection (Connection): A MicroStrategy Connection object.
             to_snake_case (bool, optional): Set to True if attribute names
             should be converted from camel case to snake case. Defaults to True.
 
         Returns:
             T: An object of type T.
@@ -507,35 +542,42 @@
         if isinstance(other, str):
             return self.id == other or self.name == other
         elif isinstance(other, type(self)):
             return self.id == other.id
         elif isinstance(other, dict):
             # check all items in other dict equal entity object attributes
             return all(
-                (getattr(self, k) == v if hasattr(self, k) else False for k, v in other.items())
+                (
+                    getattr(self, k) == v if hasattr(self, k) else False
+                    for k, v in other.items()
+                )
             )
         else:
             return NotImplemented  # don't attempt to compare against unrelated types
 
     @classmethod
     def to_csv(  # NOSONAR
-            cls: T, objects: Union[T, List[T]], name: str, path: Optional[str] = None,
-            properties: Optional[List[str]] = None) -> None:
+        cls: T,
+        objects: T | list[T],
+        name: str,
+        path: Optional[str] = None,
+        properties: Optional[list[str]] = None,
+    ) -> None:
         """Exports MSTR objects to a csv file.
 
         Optionally, saves only the object properties specified in the properties
         parameter.
 
         Args:
-            objects (Union[T, List[T]]): List of objects of the same type that
+            objects (T | list[T]): List of objects of the same type that
             will be exported.
             name (str): The name of the csv file ending with '.csv'
             path (Optional[str], optional): A path to the directory where the
                 file will be saved. Defaults to None.
-            properties (Optional[List[str]], optional): A list of object's
+            properties (Optional[list[str]], optional): A list of object's
                 attribute names that should be included in the exported file.
                 Defaults to None.
 
         Raises:
             TypeError: If `objects` is not of type `T` or list of type `T`
             objects.
         """
@@ -554,15 +596,15 @@
             if not isinstance(obj, cls):
                 helper.exception_handler(
                     (
                         f"Object '{obj}' of type '{type(obj)}' is not supported."
                         f"Objects should be of type {cls.__name__} or "
                         f"list of {cls.__name__}."
                     ),
-                    exception_type=TypeError
+                    exception_type=TypeError,
                 )
             if properties:
                 list_of_objects.append({key: getattr(obj, key) for key in properties})
             else:
                 list_of_objects.append(obj.list_properties())
 
         with open(file, 'w') as f:
@@ -598,15 +640,15 @@
                 attribute names (in camel case) and values.
 
         Returns:
             dict: A dictionary used as a PUT request body.
         """
         body = {}
         for name, value in camel_properties.items():
-            snake_case_name = snakecase(name)
+            snake_case_name = humps.decamelize(name)
             if snake_case_name in attrs:
                 value = self._unpack_objects(name, value, camel_case=True)
                 body[name] = self._validate_type(snake_case_name, value)
         return body
 
     def __put_body(self, attrs: tuple, properties: dict) -> dict:
         """Prepares the 'put' update request's body.
@@ -640,27 +682,29 @@
 
         Returns:
             dict: A dictionary used as a PATCH request body.
         """
 
         body = {"operationList": []}
         for name, value in camel_properties.items():
-            snake_case_name = snakecase(name)
+            snake_case_name = humps.decamelize(name)
             if snake_case_name in attrs:
                 value = self._unpack_objects(name, value, camel_case=True)
                 body['operationList'].append(
                     {
                         "op": op,
                         "path": f"/{name}",
-                        "value": self._validate_type(snake_case_name, value)
+                        "value": self._validate_type(snake_case_name, value),
                     }
                 )
         return body
 
-    def _send_proper_patch_request(self, properties: dict, op: str = 'replace') -> List[bool]:
+    def _send_proper_patch_request(
+        self, properties: dict, op: str = 'replace'
+    ) -> list[bool]:
         """Internal method to update objects with the specified patch wrapper.
         Used for adding and removing objects from nested properties of an
         object like memberships. Automatically converts `properties` keys from
         a snake case to a camel case. The update's type is specified in the
         `self._API_PATCH` dictionary and be described as follows:
         - 'patch' : Used when the REST API provides a PATCH endpoint to update
             the object.
@@ -682,100 +726,111 @@
 
         Raises:
             NotSupportedError: If there is no information in `self._API_PATCH`
                 dictionary about the update's type ('partial_put', 'put' or
                 'patch').
         """
         changed = []
-        camel_properties = helper.snake_to_camel(properties, whitelist=self._KEEP_CAMEL_CASE)
+        camel_properties = helper.snake_to_camel(
+            properties, whitelist=self._KEEP_CAMEL_CASE
+        )
         for attrs, (func, func_type) in self._API_PATCH.items():
             if func_type == 'partial_put':
                 translated_properties = self._python_to_rest(camel_properties)
                 body = self.__partial_put_body(attrs, translated_properties)
             elif func_type == 'put':  # Update using the generic update_object()
                 body = self.__put_body(attrs, properties)
                 body = self._python_to_rest(body)
             elif func_type == 'patch':
                 translated_properties = self._python_to_rest(camel_properties)
                 body = self.__patch_body(attrs, translated_properties, op)
             else:
-                msg = f"{func} function is not supported by `_send_proper_patch_request`"
+                msg = (
+                    f"{func} function is not supported by `_send_proper_patch_request`"
+                )
                 raise NotSupportedError(msg)
 
             if not body:
                 continue
             # send patch request from the specified update wrapper
             param_value_dict = auto_match_args_entity(func, self, exclude=["body"])
             param_value_dict['body'] = body
             response = func(**param_value_dict)
 
-            if response.ok:
+            if response:
                 changed.append(True)
-                response = response.json()
-                if type(response) == dict:
-                    self._set_object_attributes(**response)
+
+                json = (
+                    response if isinstance(response, (dict, list)) else response.json()
+                )
+                if type(json) == dict:
+                    self._set_object_attributes(**json)
             else:
                 changed.append(False)
         return changed
 
     def _alter_properties(self, **properties) -> None:
         """Generic alter method that has to be implemented in child classes
         where arguments will be specified. If a **properties dictionary is empty
         the method will not dispatch any request. If there is at least one entry
         in **properties, an update will be performed according to the update
         type specified in `_API_PATCH` dictionary. A message with update status
         is printed both on failure and success."""
         if not properties:
             if config.verbose:
-                logger.info(f"No changes specified for {type(self).__name__} '{self.name}'.")
+                logger.info(
+                    f"No changes specified for {type(self).__name__} '{self.name}'."
+                )
             return None
 
         changed = self._send_proper_patch_request(properties)
 
         if config.verbose and all(changed):
             msg = (
                 f"{type(self).__name__} '{self.name}' has been modified on the server. "
-                f"Your changes are saved locally."
+                "Your changes are saved locally."
             )
             logger.info(msg)
 
     def _update_nested_properties(
         self,
-        objects: Union[Any, List[Any]],
+        objects: Any | list[Any],
         path: str,
         op: str,
-        existing_ids: Optional[List[str]] = None
-    ) -> Tuple[str, str]:
+        existing_ids: Optional[list[str]] = None,
+    ) -> tuple[str, str]:
         """Internal method to update objects with the specified patch wrapper.
         Used for adding and removing objects from nested properties of an
         object like memberships.
 
         Args:
-            objects (Union[Any, List[Any]]): An id, object or list of objects
+            objects (Any | list[Any]): An id, object or list of objects
                 or/ and object ids on which nested properties should be updated.
             path (str): The name of an attribute that nests other objects.
             op (str): An operation type. Non-ignored values are 'add' or
                 'remove'.
-            existing_ids (Optional[List[str]], optional): IDs of objects which
+            existing_ids (Optional[list[str]], optional): IDs of objects which
                 are already nested in `path` attribute. Defaults to None.
 
         Returns:
-            Tuple[List[str]]: A tuple whose first element is a list of IDs of
+            tuple[list[str]]: A tuple whose first element is a list of IDs of
                 successful operations, and second element is a list of IDs of
                 failed operations.
         """
         from mstrio.access_and_security.privilege import Privilege
 
         # check whether existing_ids are supplied
         if existing_ids is None:
             existing_ids = [obj.get('id') for obj in getattr(self, path)]
 
         # create list of objects from strings/objects/lists
         objects_list = objects if isinstance(objects, list) else [objects]
-        object_map = {obj.id: obj.name for obj in objects_list if isinstance(obj, Entity)}
+        object_map = {
+            obj.id: obj.name for obj in objects_list if isinstance(obj, Entity)
+        }
 
         object_ids_list = [
             obj.id if isinstance(obj, (EntityBase, Privilege)) else str(obj)
             for obj in objects_list
         ]
 
         # check if objects can be manipulated by comparing to existing values
@@ -788,15 +843,17 @@
                 list(filter(lambda x: x in existing_ids, object_ids_list))
             )
         if filtered_object_ids:
             properties = {path: filtered_object_ids}
             self._send_proper_patch_request(properties, op)
 
         failed = list(sorted(set(object_ids_list) - set(filtered_object_ids)))
-        failed_formatted = [object_map.get(object_id, object_id) for object_id in failed]
+        failed_formatted = [
+            object_map.get(object_id, object_id) for object_id in failed
+        ]
         succeeded_formatted = [
             object_map.get(object_id, object_id) for object_id in filtered_object_ids
         ]
         return (succeeded_formatted, failed_formatted)
 
     def _validate_type(self, name: str, value: T) -> T:
         """Uses information specified in `self._AVAILABLE_ATTRIBUTES` and
@@ -813,15 +870,17 @@
         Returns:
             T: Unchanged `value` parameter.
         """
         type_map = {**self._AVAILABLE_ATTRIBUTES, **self._PATCH_PATH_TYPES}
         value_type = type_map.get(name, 'Not Found')
 
         if value_type != 'Not Found' and type(value) != value_type:
-            raise TypeError(f"'{name}' has incorrect type. Expected type: '{value_type}'")
+            raise TypeError(
+                f"'{name}' has incorrect type. Expected type: '{value_type}'"
+            )
         return value
 
     def __setattr__(self, name: str, value: Any) -> None:
         """Overloads the __setattr__ method to validate if this attribute can
         be set for current object. If type of `value` or its literal differs
         from the one that is currently stored, the change will be tracked in a
         dictionary `self._altered_properties` which is later used to update
@@ -849,29 +908,31 @@
             # if value not equal to None then treat as fetched
             if value is not None:
                 self._add_to_fetched(name)
         super().__setattr__(name, value)
 
     def __getattribute__(self, name: str) -> Any:
         """On first fetch, it creates a set `_fetched_attributes` used to track
-            attributes that were already fetched from the server. Additionally,
-            it checks if there is an API getter in a `_API_GETTERS` dictionary
-            that corresponds to the attribute's name. If there is and the object
-            has an id and it has not been fetched yet it will fetch the value
-            from the server. If not, it will return the value straight away. """
+        attributes that were already fetched from the server. Additionally,
+        it checks if there is an API getter in a `_API_GETTERS` dictionary
+        that corresponds to the attribute's name. If there is and the object
+        has an id and it has not been fetched yet it will fetch the value
+        from the server. If not, it will return the value straight away."""
         val = super().__getattribute__(name)
 
         if name in ["_fetched_attributes", "_find_func"]:
             return val
         if not hasattr(self, "_fetched_attributes"):
             self._fetched_attributes = set()
         if hasattr(self, "_fetched_attributes") and hasattr(self, "_find_func"):
             _name = name[1:] if name.startswith("_") else name
             was_fetched = _name in self._fetched_attributes
-            can_fetch = self._find_func(_name) is not None and "id" in self._fetched_attributes
+            can_fetch = (
+                self._find_func(_name) is not None and "id" in self._fetched_attributes
+            )
             if can_fetch and not was_fetched:
                 self.fetch(_name)  # fetch the relevant object data
             val = super().__getattribute__(name)
 
         return val
 
     def _set_dates(self, **kwargs):
@@ -889,20 +950,20 @@
     def connection(self) -> Connection:
         """An object representation of MicroStrategy connection specific to the
         object."""
         return self._connection
 
     @property
     def id(self) -> str:
-        """The object's id. """
+        """The object's id."""
         return self._id
 
     @property
     def type(self) -> ObjectTypes:
-        """The object's type. """
+        """The object's type."""
         return self._type
 
 
 class Entity(EntityBase, ACLMixin, DependenceMixin):
     """Base class representation of the MSTR object.
 
     Provides methods to fetch, update, and view the object. To implement
@@ -927,15 +988,15 @@
         certified_info: Certification status, time of certification, and
             information about the certifier (currently only for document and
             report)
         acg: Access rights (See EnumDSSXMLAccessRightFlags for possible values)
         acl: Object access control list
     """
 
-    _API_GETTERS: Dict[Union[str, tuple], Callable] = {
+    _API_GETTERS: dict[str | tuple, Callable] = {
         (
             'id',
             'name',
             'description',
             'abbreviation',
             'type',
             'subtype',
@@ -949,15 +1010,15 @@
             'ancestors',
             'certified_info',
             'acg',
             'acl',
             'comments',
             'project_id',
             'hidden',
-            'target_info'
+            'target_info',
         ): objects.get_object_info
     }
     _API_PATCH: dict = {
         ('name', 'description', 'abbreviation'): (objects.update_object, 'partial_put')
     }
     _PATCH_PATH_TYPES = {"name": str, "description": str, "abbreviation": str}
     _FROM_DICT_MAP = {
@@ -969,44 +1030,54 @@
         'acg': Rights,
     }
 
     def _init_variables(self, **kwargs) -> None:
         """Initialize variables given kwargs."""
         from mstrio.users_and_groups.user import User
         from mstrio.utils.certified_info import CertifiedInfo
+
         super()._init_variables(**kwargs)
         self._date_created = map_str_to_datetime(
             "date_created", kwargs.get("date_created"), self._FROM_DICT_MAP
         )
         self._date_modified = map_str_to_datetime(
             "date_modified", kwargs.get("date_modified"), self._FROM_DICT_MAP
         )
         self.description = kwargs.get("description")
         self.abbreviation = kwargs.get("abbreviation")
         self._subtype = kwargs.get("subtype")
-        self._ext_type = ExtendedType(kwargs["ext_type"]) if kwargs.get("ext_type") else None
+        self._ext_type = (
+            ExtendedType(kwargs["ext_type"]) if kwargs.get("ext_type") else None
+        )
         self._version = kwargs.get("version")
-        self._owner = User.from_dict(
-            kwargs.get("owner"),
-            self.connection,
-        ) if kwargs.get("owner") else None
+        self._owner = (
+            User.from_dict(
+                kwargs.get("owner"),
+                self.connection,
+            )
+            if kwargs.get("owner")
+            else None
+        )
         self._icon_path = kwargs.get("icon_path")
         self._view_media = kwargs.get("view_media")
         self._ancestors = kwargs.get("ancestors")
-        self._certified_info = CertifiedInfo.from_dict(
-            kwargs.get("certified_info"), self.connection
-        ) if kwargs.get("certified_info") else None
+        self._certified_info = (
+            CertifiedInfo.from_dict(kwargs.get("certified_info"), self.connection)
+            if kwargs.get("certified_info")
+            else None
+        )
         self._hidden = kwargs.get("hidden")
         self._project_id = kwargs.get("project_id")
         self._comments = kwargs.get("comments")
         self._target_info = kwargs.get("target_info")
         self._acg = Rights(kwargs.get("acg")) if kwargs.get("acg") else None
         self._acl = (
-            [ACE.from_dict(ac, self._connection)
-             for ac in kwargs.get("acl")] if kwargs.get("acl") else None
+            [ACE.from_dict(ac, self._connection) for ac in kwargs.get("acl")]
+            if kwargs.get("acl")
+            else None
         )
 
     @property
     def subtype(self) -> ObjectSubTypes:
         return self._subtype
 
     @property
@@ -1034,39 +1105,39 @@
         return self._icon_path
 
     @property
     def view_media(self) -> int:
         return self._view_media
 
     @property
-    def ancestors(self) -> List[Dict]:
+    def ancestors(self) -> list[dict]:
         return self._ancestors
 
     @property
     def certified_info(self):
         return self._certified_info
 
     @property
     def acg(self) -> Rights:
         return self._acg
 
     @property
-    def acl(self) -> List[ACE]:
+    def acl(self) -> list[ACE]:
         return self._acl
 
     @property
     def hidden(self) -> bool:
         return self._hidden
 
     @property
     def project_id(self) -> str:
         return self._project_id
 
     @property
-    def comments(self) -> List[str]:
+    def comments(self) -> list[str]:
         return self._comments
 
     @property
     def target_info(self) -> dict:
         return self._target_info
 
 
@@ -1077,15 +1148,15 @@
     Entity or its subclasses.
     """
 
     def create_copy(
         self: Entity,
         name: Optional[str] = None,
         folder_id: Optional[str] = None,
-        project: Optional[Union["Project", str]] = None
+        project: Optional['Project | str'] = None,
     ) -> Any:
         """Create a copy of the object on the I-Server.
 
         Args:
             name: New name of the object. If None, a default name is generated,
                 such as 'Old Name (1)'
             folder_id: ID of the destination folder. If None, the object is
@@ -1097,31 +1168,32 @@
         Returns:
                 New python object holding the copied object.
         """
         if self._OBJECT_TYPE.value in [32]:
             raise NotSupportedError("Copying of object with type 32 is not supported.")
 
         from mstrio.server.project import Project
+
         response = objects.copy_object(
             self.connection,
             id=self.id,
             name=name,
             folder_id=folder_id,
             object_type=self._OBJECT_TYPE.value,
-            project_id=project.id if isinstance(project, Project) else project
+            project_id=project.id if isinstance(project, Project) else project,
         )
         return self.from_dict(source=response.json(), connection=self.connection)
 
 
 class MoveMixin:
     """MoveMixin class adds moving objects functionality.
     Must be mixedin with Entity or its subclasses.
     """
 
-    def move(self: Entity, folder: Union["Folder", str]):
+    def move(self: Entity, folder: 'Folder | str'):
         """Move the object to a folder on the I-Server.
 
         Args:
             folder: Destination folder, specified either by id
                 or the Folder object.
         """
         from mstrio.object_management.folder import Folder
@@ -1129,47 +1201,53 @@
         folder = folder.id if isinstance(folder, Folder) else folder
         self._alter_properties(folder_id=folder)
 
     def _find_object_with_name(
         self,
         connection: Connection,
         name: Optional[str] = None,
-        listing_function: callable = None
-    ) -> Dict:
+        listing_function: callable = None,
+    ) -> dict:
         """Find objects with given name if no id is given.
 
         Args:
             connection: A MicroStrategy connection object
             name: name of the object. Defaults to None.
             object_type: type of an object that is searched.
             listing_function: function called to list all the objects
                 with given name
 
         Returns:
-            Dict: object properties in a dictionary.
+            dict: object properties in a dictionary.
 
         Raises:
             ValueError: if both `id` and `name` are not provided,
                 if there is more than 1 object with the given `name` or
                 if object with the given `name` doesn't exist.
         """
         if name is None:
-            raise ValueError("Please specify either 'name' or 'id' parameter in the constructor.")
+            raise ValueError(
+                "Please specify either 'name' or 'id' parameter in the constructor."
+            )
         objects = listing_function(connection=connection, name=name)
         if objects:
             number_of_objects = len(objects)
             if 1 < number_of_objects <= 5:
-                error_string = f"There are {number_of_objects} {self.__class__.__name__} objects"\
+                error_string = (
+                    f"There are {number_of_objects} {self.__class__.__name__} objects"
                     " with this name. Please initialize with id.\n"
+                )
                 for object in objects:
                     error_string += 'Folder path: '
                     for d in object.ancestors:
                         error_string += d['name'] + '/'
-                    error_string += f' {self.__class__.__name__} id: {object.id} - '\
+                    error_string += (
+                        f' {self.__class__.__name__} id: {object.id} - '
                         f'{self.__class__.__name__} name: {object.name}\n'
+                    )
                 raise ValueError(error_string)
             if number_of_objects > 5:
                 raise ValueError(
                     f"There are {number_of_objects} {self.__class__.__name__}"
                     " objects with this name. Please initialize with id."
                 )
             return objects[0].to_dict()
@@ -1221,34 +1299,39 @@
 
 
 class CertifyMixin:
     """CertifyMixin class adds certifying and decertifying functionality.
     Must be mixedin with Entity or its subclasses.
     """
 
-    def _toggle_certification(self: Entity, certify: bool = True, success_msg: str = None) -> bool:
+    def _toggle_certification(
+        self: Entity, certify: bool = True, success_msg: str = None
+    ) -> bool:
         object_name = self.__class__.__name__
         expected_result = 'certified' if certify else 'decertified'
 
         self.fetch()
         if certify == self.certified_info.certified:
-            logger.warning(f"The {object_name} with ID: '{self._id}' is already {expected_result}")
+            logger.warning(
+                f"The {object_name} with ID: '{self._id}' is already {expected_result}"
+            )
             return True
 
         response = objects.toggle_certification(
             connection=self._connection,
             id=self._id,
             object_type=self._OBJECT_TYPE.value,
-            certify=certify
+            certify=certify,
         )
         if response.ok and config.verbose:
             self._set_object_attributes(**response.json())
+            id_ = self._id
             msg = (
                 success_msg
-                or f"The {object_name} with ID: '{self._id}' has been {expected_result}."
+                or f"The {object_name} with ID: '{id_}' has been {expected_result}."
             )
             logger.info(msg)
         return response.ok
 
     def certify(self: Entity) -> bool:
         """Certify object.
         Args:
@@ -1268,49 +1351,63 @@
 
 class VldbMixin:
     """VLDBMixin class adds vldb management for supporting objects.
 
     Objects currently supporting VLDB settings are dataset, document, dossier.
     Must be mixedin with Entity or its subclasses.
     """
+
     _parameter_error = "Please specify the project parameter."
 
     def list_vldb_settings(self: Entity, project: Optional[str] = None) -> list:
         """List VLDB settings."""
-        connection = self.connection if hasattr(self, 'connection') else self._connection
+        connection = (
+            self.connection if hasattr(self, 'connection') else self._connection
+        )
         if not project and not connection.project_id:
             raise ValueError(self._parameter_error)
 
-        response = objects.get_vldb_settings(connection, self.id, self._OBJECT_TYPE.value, project)
+        response = objects.get_vldb_settings(
+            connection, self.id, self._OBJECT_TYPE.value, project
+        )
         return response.json()
 
     def alter_vldb_settings(
         self: Entity,
         property_set_name: str,
         name: str,
         value: dict,
-        project: Optional[str] = None
+        project: Optional[str] = None,
     ) -> None:
         """Alter VLDB settings for a given property set."""
 
-        connection = self.connection if hasattr(self, 'connection') else self._connection
+        connection = (
+            self.connection if hasattr(self, 'connection') else self._connection
+        )
         if not project and not connection.project_id:
             raise ValueError(self._parameter_error)
 
         body = [{"name": name, "value": value}]
         response = objects.set_vldb_settings(
-            connection, self.id, self._OBJECT_TYPE.value, property_set_name, body, project
+            connection,
+            self.id,
+            self._OBJECT_TYPE.value,
+            property_set_name,
+            body,
+            project,
         )
         if config.verbose and response.ok:
             logger.info('VLDB settings altered.')
 
     def reset_vldb_settings(self: Entity, project: Optional[str] = None) -> None:
         """Reset VLDB settings to default values."""
 
-        connection = self.connection if hasattr(self, 'connection') else self._connection
+        connection = (
+            self.connection if hasattr(self, 'connection') else self._connection
+        )
         if not project and not connection.project_id:
             raise ValueError(self._parameter_error)
 
         response = objects.delete_vldb_settings(
             connection, self.id, self._OBJECT_TYPE.value, project
         )
         if config.verbose and response.ok:
@@ -1331,14 +1428,17 @@
         exclude: set `exclude` parameter to exclude specific param-value pairs
         include_defaults: if `False` then values which have the same value as
             default will not be included in the result
     Raises:
         KeyError: could not match all required arguments
     """
     # convert names starting with '_'
-    obj_dict = {key[1:] if key.startswith("_") else key: val for key, val in obj.__dict__.items()}
+    obj_dict = {
+        key[1:] if key.startswith("_") else key: val
+        for key, val in obj.__dict__.items()
+    }
     kwargs = helper.auto_match_args(func, obj_dict, exclude, include_defaults)
 
     if "object_type" in kwargs:
         kwargs.update({"object_type": obj._OBJECT_TYPE.value})
 
     return kwargs
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/enum_helper.py` & `mstrio-py-11.3.9.103/mstrio/utils/enum_helper.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,58 +1,66 @@
 from enum import Enum
 from itertools import chain
-from typing import Tuple, Union
+from typing import Type
 
 
 class AutoName(Enum):
-
     def _generate_next_value_(self, start, count, last_values):
         return self.lower()
 
     @classmethod
     def has_value(cls, value):
         return value in set(item.value for item in cls)
 
 
 class AutoUpperName(Enum):
-
     def _generate_next_value_(self, start, count, last_values):
         return self
 
 
-def __get_enum_helper(obj, enum: Union[Enum, Tuple[Enum]] = Enum,
-                      get_value: bool = False) -> Union[str, Enum, None]:
+class AutoCapitalizedName(Enum):
+    def _generate_next_value_(self, start, count, last_values):
+        return self.capitalize()
+
+
+def __get_enum_helper(
+    obj, enum: Type[Enum] = Enum, get_value: bool = False
+) -> str | Type[Enum] | None:
     """Helper function for `get_enum` and `get_enum_val`."""
     if obj is None:
         return obj
-    elif isinstance(obj, Enum) and isinstance(obj, enum):
+
+    if isinstance(obj, Enum) and isinstance(obj, enum):
         obj = obj.value if get_value else obj
     elif isinstance(obj, (str, int)):
         validate_enum_value(obj, enum)
         obj = obj if get_value else enum(obj)
     else:
         raise TypeError(f"Incorrect type. Value should be of type: {enum}.")
 
     return obj
 
 
-def get_enum(obj, enum: Union[Enum, Tuple[Enum]] = Enum) -> Union[Enum, None]:
+def get_enum(obj, enum: Type[Enum] = Enum) -> Type[Enum] | None:
     """Safely get enum from enum or str."""
     return __get_enum_helper(obj, enum)
 
 
-def get_enum_val(obj, enum: Union[Enum, Tuple[Enum]] = Enum) -> Union[str, None]:
+def get_enum_val(obj, enum: Type[Enum] = Enum) -> str | None:
     """Safely extract value from enum or str."""
     return __get_enum_helper(obj, enum, True)
 
 
 def validate_enum_value(obj, enum):
     """Validate provided value. If not correct,
     error message with possible options will be displayed.
     """
     from mstrio.utils.helper import exception_handler
-    possible_values = [[e.value
-                        for e in item]
-                       for item in enum] if isinstance(enum, tuple) else [e.value for e in enum]
+
+    possible_values = (
+        [[e.value for e in item] for item in enum]
+        if isinstance(enum, tuple)
+        else [e.value for e in enum]
+    )
     err_msg = f"Incorrect enum value '{obj}'. Possible values are {possible_values}"
     if obj not in list(chain(possible_values)):
         exception_handler(err_msg, exception_type=ValueError)
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/error_handlers.py` & `mstrio-py-11.3.9.103/mstrio/utils/error_handlers.py`

 * *Files 3% similar despite different names*

```diff
@@ -44,19 +44,20 @@
         with the appropriate values if they appear in the function arguments
     """
 
     def __init__(self, err_msg: str):
         self._err_msg = err_msg
 
     def __call__(self, func: Callable[[Any], Any]):
-
         @wraps(func)
         def inner(*args, **kwargs):
             response = func(*args, **kwargs)
-            error_msg = kwargs.get("error_msg") if kwargs.get("error_msg") else self._err_msg
+            error_msg = (
+                kwargs.get("error_msg") if kwargs.get("error_msg") else self._err_msg
+            )
             if not response.ok:
                 handler_kwargs = self._get_resp_handler_kwargs(kwargs)
                 error_msg = self._replace_with_values(error_msg, func, *args, **kwargs)
                 response_handler(response, error_msg, **handler_kwargs)
             return response
 
         return inner
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/filter.py` & `mstrio-py-11.3.9.103/mstrio/utils/filter.py`

 * *Files 4% similar despite different names*

```diff
@@ -9,31 +9,30 @@
 
     def __init__(
         self,
         attributes: list,
         metrics: list,
         attr_elements: Optional[list] = None,
         row_count_metrics: Optional[list] = None,
-        operator: str = 'In'
+        operator: str = 'In',
     ):
-
         self.attributes = {}
         for a in attributes:
             self.attributes[a["id"]] = {"name": a["name"]}
 
         self.metrics = {}
         for m in metrics:
             self.metrics[m["id"]] = {"name": m["name"]}
 
         self.attr_elems = {}
         if attr_elements is not None:
             self._populate_attr_elements(attr_elements)
-        self.row_count_metrics = [] if row_count_metrics is None else [
-            i['id'] for i in row_count_metrics
-        ]
+        self.row_count_metrics = (
+            [] if row_count_metrics is None else [i['id'] for i in row_count_metrics]
+        )
         self.attr_selected = []
         self.metr_selected = []
         self.attr_elem_selected = []
         self.operator = operator
 
         # select all metrics and all attributes
         self._select([metric_id['id'] for metric_id in metrics])
@@ -72,15 +71,16 @@
         else:
             attribute_id = element_id.split(':')[0]
             if self.__invalid(attribute_id):
                 raise ValueError(self.err_msg_invalid.format(element_id))
 
             if self.__duplicated(element_id):
                 helper.exception_handler(
-                    msg=self.err_msg_duplicated.format(element_id), exception_type=Warning
+                    msg=self.err_msg_duplicated.format(element_id),
+                    exception_type=Warning,
                 )
             else:
                 self.attr_elems[element_id] = {}
                 self.attr_elems[element_id]["name"] = element_id
                 self.attr_elems[element_id]["attribute_id"] = attribute_id
                 self.attr_elem_selected.append(element_id)
 
@@ -117,15 +117,14 @@
                 ro["attributes"].append({"id": i})
 
         ro["metrics"] = [{"id": i} for i in self.metr_selected]
 
         return ro
 
     def _view_filter(self):
-
         if not self.attr_elem_selected:
             return None
 
         else:
             # build {attribute_id:[element_id, element_id_n]} lookup dict
             lkp = {}
             for s in self.attr_elem_selected:
@@ -156,15 +155,16 @@
 
         return fb
 
     def _populate_attr_elements(self, attr_elements):
         for att in attr_elements:
             for el in att["elements"]:
                 self.attr_elems[el["id"]] = {
-                    "name": att["attribute_name"], "attribute_id": att["attribute_id"]
+                    "name": att["attribute_name"],
+                    "attribute_id": att["attribute_id"],
                 }
 
     def __type(self, object_id):
         """Look up and return object type from available objects."""
 
         if object_id in self.attributes.keys():
             return "attribute"
@@ -177,20 +177,25 @@
 
     def __invalid(self, object_id):
         """Check if requested object_id is a valid object id."""
         object_is_attr_el = ':' in object_id
         if object_is_attr_el:
             return object_id.split(':')[0] not in self.attributes.keys()
         else:
-            valid_object_ids = list(self.metrics.keys()
-                                    ) + list(self.attributes.keys()) + self.row_count_metrics
+            valid_object_ids = (
+                list(self.metrics.keys())
+                + list(self.attributes.keys())
+                + self.row_count_metrics
+            )
             return object_id not in valid_object_ids
 
     def __duplicated(self, object_id):
         """Check if requested object_id is already selected."""
         attr_selected = [elem[0] for elem in self.attr_selected]
-        all_selected_objects = attr_selected + self.metr_selected + self.attr_elem_selected
+        all_selected_objects = (
+            attr_selected + self.metr_selected + self.attr_elem_selected
+        )
 
         if object_id in all_selected_objects:
             return True
         else:
             return False
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/formjson.py` & `mstrio-py-11.3.9.103/mstrio/utils/formjson.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,41 +8,39 @@
     elif datatype == 'bool':
         return "BOOL"
     elif datatype == 'datetime64[ns]':
         return 'DATETIME'
 
 
 def formjson(df, table_name, as_metrics=None, as_attributes=None):
-
     def _form_column_headers(_col_names, _col_types):
         return [{'name': n, 'dataType': t} for n, t in zip(_col_names, _col_types)]
 
     def _form_attribute_list(_attributes):
         return [
             {
                 'name': n,
                 'attributeForms': [
                     {
-                        'category': 'ID', 'expressions': [{
-                            'formula': table_name + "." + n
-                        }]
+                        'category': 'ID',
+                        'expressions': [{'formula': table_name + "." + n}],
                     }
-                ]
-            } for n in _attributes
+                ],
+            }
+            for n in _attributes
         ]
 
     def _form_metric_list(_metrics):
         return [
             {
                 'name': n,
                 'dataType': 'number',
-                'expressions': [{
-                    'formula': table_name + "." + n
-                }]
-            } for n in _metrics
+                'expressions': [{'formula': table_name + "." + n}],
+            }
+            for n in _metrics
         ]
 
     col_names = list(df.columns)
     col_types = list(map(_map_data_type, list(df.dtypes.values)))
 
     # Adjust attributes/metrics mapping if new mappings were provided in
     # as_metrics and as_attributes
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/helper.py` & `mstrio-py-11.3.9.103/mstrio/utils/helper.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,44 +1,54 @@
-from datetime import datetime
-from enum import Enum
-from functools import reduce, wraps
 import inspect
-from json.decoder import JSONDecodeError
 import logging
 import os
 import re
-from typing import Any, Callable, Dict, List, Optional, Tuple, TYPE_CHECKING, TypeVar, Union
+import time
 import warnings
+from datetime import datetime
+from enum import Enum
+from functools import reduce, wraps
+from json.decoder import JSONDecodeError
+from typing import TYPE_CHECKING, Any, Callable, Optional, TypeVar
 
+import humps
 import pandas as pd
-import stringcase
 
 from mstrio import __version__ as mstrio_version
 from mstrio import config
-from mstrio.api.exceptions import MstrTimeoutError, PromptedContentError, VersionException
+from mstrio.api.exceptions import (
+    MstrTimeoutError,
+    PromptedContentError,
+    VersionException,
+)
 from mstrio.types import ObjectSubTypes
 from mstrio.utils.dict_filter import filter_list_of_dicts
 from mstrio.utils.enum_helper import get_enum_val
 from mstrio.utils.sessions import FuturesSessionWithRenewal
-from mstrio.utils.time_helper import DatetimeFormats, map_datetime_to_str, map_str_to_datetime
+from mstrio.utils.time_helper import (
+    DatetimeFormats,
+    map_datetime_to_str,
+    map_str_to_datetime,
+)
 
 if TYPE_CHECKING:
     from mstrio.connection import Connection
     from mstrio.project_objects.datasets import OlapCube, SuperCube
+    from mstrio.server import Project
     from mstrio.types import ObjectTypes
 
 logger = logging.getLogger(__name__)
 
 
 def deprecation_warning(
     deprecated: str,
     new: str,
     version: str,
     module: bool = True,
-    change_compatible_immediately=True
+    change_compatible_immediately=True,
 ):
     """This function is used to provide a user with a warning, that a given
     functionality is now deprecated, and won't be supported from a given
     version.
 
     Args:
         deprecated (str): name of a functionality that is deprecated
@@ -50,36 +60,36 @@
         change_compatible_immediately (bool, optional): Whether the new
         functionality can be used immediately. Defaults to True.
     """
 
     module = " module" if module else ""
     if change_compatible_immediately:
         msg = (
-            f"{deprecated}{module} is deprecated and will not be supported starting from mstrio-py"
-            f" {version}. Please use {new} instead."
+            f"{deprecated}{module} is deprecated and will not be supported starting "
+            f"from mstrio-py {version}. Please use {new} instead."
         )
     else:
         msg = (
-            f"From version {version} {deprecated}{module} will be removed and replaced with "
-            f"{new}"
+            f"From version {version} {deprecated}{module} will be removed and replaced "
+            f"with {new}"
         )
     warnings.warn(DeprecationWarning(msg))
 
 
 def url_check(url):
     """Checks the validity of the url required in the connection object and
     returns a validated url."""
     regex = r'^https?://.+$'
     match = re.search(regex, url)
     api_index = url.find('/api')
 
     if match is None:
         msg = (
-            "Please check the validity of the base_url parameter. Typically of the form "
-            "'https://<<MSTR Domain>>/MicroStrategyLibrary/'"
+            "Please check the validity of the base_url parameter. Typically of the "
+            "form 'https://<<MSTR Domain>>/MicroStrategyLibrary/'"
         )
         raise ValueError(msg)
     if api_index != -1:
         url = url[:api_index]
     if url.endswith('/'):
         url = url[:-1]
 
@@ -96,56 +106,57 @@
     return list(signature.parameters.keys())
 
 
 def get_default_args_from_func(func: Callable[[Any], Any]):
     signature = inspect.signature(func)
     return {
         k: v.default
-        for k,
-        v in signature.parameters.items()
+        for k, v in signature.parameters.items()
         if v.default is not inspect.Parameter.empty
     }
 
 
 def camel_to_snake(
-    response: Union[dict, list],
+    response: dict | list,
     whitelist: list[str] = None,
-) -> Union[dict, List[dict]]:
+) -> dict | list[dict]:
     """Converts dictionary keys from camelCase to snake_case.
-       It works recursively for dicts in dicts."""
+    It works recursively for dicts in dicts."""
 
     whitelist = whitelist or []
 
     def convert_dict(source):
         return {
-            stringcase.snakecase(key):
-            value if not isinstance(value, dict) or key in whitelist else convert_dict(value)
+            humps.decamelize(key): value
+            if not isinstance(value, dict) or key in whitelist
+            else convert_dict(value)
             for key, value in source.items()
         }
 
     if type(response) == list:
         return [convert_dict(source) for source in response if type(source) == dict]
     elif type(response) == dict:
         return convert_dict(response)
     else:
         raise ValueError("Not supported data type for camel_to_snake conversion")
 
 
 def snake_to_camel(
-    response: Union[dict, list],
+    response: dict | list,
     whitelist: list[str] = None,
-) -> Union[dict, List[dict]]:
+) -> dict | list[dict]:
     """Converts dictionary keys from snake_case to camelCase.
-       It works recursively for dicts in dicts."""
+    It works recursively for dicts in dicts."""
     whitelist = whitelist or []
 
     def convert_dict(source):
         return {
-            stringcase.camelcase(key):
-            value if not isinstance(value, dict) or key in whitelist else convert_dict(value)
+            humps.camelize(key): value
+            if not isinstance(value, dict) or key in whitelist
+            else convert_dict(value)
             for key, value in source.items()
         }
 
     if type(response) == list:
         return [convert_dict(source) for source in response if type(source) == dict]
     elif type(response) == dict:
         return convert_dict(response)
@@ -162,24 +173,27 @@
     """Generic error message handler.
 
     Args:
         msg (str): Message to print in the Exception or Warning
         exception_type (Exception): Instance of Exception or Warning class
         stack_lvl (int, optional): controls how deep the stacktrace will be
     """
-    if not isinstance(exception_type, type) or not issubclass(exception_type, Exception):
+    if not isinstance(exception_type, type) or not issubclass(
+        exception_type, Exception
+    ):
         raise ValueError("exception_type has to be a subclass of Exception class")
-    elif (issubclass(exception_type, Exception) and not issubclass(exception_type, Warning)):
+    elif issubclass(exception_type, Exception) and not issubclass(
+        exception_type, Warning
+    ):
         raise exception_type(msg)
     elif issubclass(exception_type, Warning):
         warnings.warn(msg, exception_type, stacklevel=stack_lvl)
 
 
 class IServerError(IOError):
-
     def __init__(self, message, http_code):
         super().__init__(message)
         self.http_code = http_code
 
 
 def response_handler(response, msg, throw_error=True, verbose=True, whitelist=None):
     """Generic error message handler for transactions against I-Server.
@@ -211,24 +225,29 @@
         server_code = res.get('code')
         server_msg = res.get('message')
         ticket_id = res.get('ticketId')
         iserver_code = res.get('iServerCode')
         is_whitelisted = (server_code, response.status_code) in whitelist
 
         if not is_whitelisted:
-            if ((server_code == 'ERR004' and response.status_code == 404
-                 and server_msg == 'HTTP 404 Not Found')
-                    or (server_code == 'ERR001' and response.status_code == 405
-                        and server_msg == 'HTTP 405 Method Not Allowed')):
+            if (
+                server_code == 'ERR004'
+                and response.status_code == 404
+                and server_msg == 'HTTP 404 Not Found'
+            ) or (
+                server_code == 'ERR001'
+                and response.status_code == 405
+                and server_msg == 'HTTP 405 Method Not Allowed'
+            ):
                 msg = (
-                    "This REST API functionality is not yet supported on this version of "
-                    f"the I-Server: {version_cut(config.iserver_version)}. Please upgrade "
-                    "the I-Server version or downgrade the mstrio-py package (current "
-                    f"version: {version_cut(mstrio_version)}) in order for the versions to "
-                    "match."
+                    "This REST API functionality is not yet supported on this version "
+                    f"of the I-Server: {version_cut(config.iserver_version)}. Please "
+                    "upgrade the I-Server version or downgrade the mstrio-py package "
+                    f"(current version: {version_cut(mstrio_version)}) in order for "
+                    "the versions to match."
                 )
                 exception_handler(msg, exception_type=VersionException)
             elif iserver_code == -2147206497:  # MSI_REQUEST_TIMEOUT on server-side
                 raise MstrTimeoutError(res)
             elif iserver_code == -2147468903:
                 raise PromptedContentError(
                     'Prompted content subscription creation is not supported.'
@@ -237,27 +256,30 @@
                 logger.error(
                     f'{msg}\n'
                     f'I-Server Error {server_code}, {server_msg}\n'
                     f'Ticket ID: {ticket_id}'
                 )
             if throw_error:
                 raise IServerError(
-                    message=f"{server_msg}; code: '{server_code}', ticket_id: '{ticket_id}'",
-                    http_code=response.status_code
+                    message=(
+                        f"{server_msg}; code: '{server_code}', ticket_id: '{ticket_id}'"
+                    ),
+                    http_code=response.status_code,
                 )
     except JSONDecodeError:
         logger.debug(f"Response body: {response.text}")
 
         if verbose:
             logger.error(
-                f'{msg}\n'
-                f'Could not decode the response from the I-Server. Please check if I-Server is '
-                f'running correctly'
+                f"{msg}\n"
+                f"Could not decode the response from the I-Server. Please check if "
+                f"I-Server is running correctly"
             )
-            response.raise_for_status()  # raise error if I-Server response cannot be decoded
+            # raise error if I-Server response cannot be decoded
+            response.raise_for_status()
 
 
 def fallback_on_timeout(min_limit: int = 50):
     """Return a decorator, which decorates a function with one argument,
     `limit`, to retry with half as big limit if it encounters a timeout error.
 
     Do note that the wrapped function will return a (result, working_limit)
@@ -269,23 +291,23 @@
     """
 
     def decorate(func: Callable[[int], Any]):
         """Replaces `fot_wrapper`'s __name__, __doc__ and __module__ with those
         of `func`."""
 
         @wraps(func)
-        def fot_wrapper(limit: int) -> Tuple[Any, int]:
+        def fot_wrapper(limit: int) -> tuple[Any, int]:
             try:
                 return func(limit), limit
             except MstrTimeoutError as err:
                 new_limit = limit // 2
                 if new_limit >= min_limit:
                     logger.warning(
-                        f'Timout hit when executing {func.__name__} with limit {limit}, '
-                        f'retrying with limit {new_limit}'
+                        f"Timeout hit when executing {func.__name__} with limit "
+                        f"{limit}, retrying with limit {new_limit}"
                     )
                     return fot_wrapper(new_limit)
                 else:
                     raise err
 
         return fot_wrapper
 
@@ -293,24 +315,24 @@
 
 
 def get_parallel_number(total_chunks):
     """Returns the optimal number of threads to be used for downloading
     cubes/reports in parallel."""
 
     threads = min(8, os.cpu_count() + 4)
-    if (total_chunks > 0):
+    if total_chunks > 0:
         threads = min(total_chunks, threads)
 
     return threads
 
 
 def _prepare_objects(
-    objects: Union[dict, List[dict]],
+    objects: dict | list[dict],
     filters: Optional[dict] = None,
-    dict_unpack_value: Optional[str] = None
+    dict_unpack_value: Optional[str] = None,
 ):
     if type(objects) is dict and dict_unpack_value:
         objects = objects[dict_unpack_value]
     objects = camel_to_snake(objects)
     if filters:
         objects = filter_list_of_dicts(objects, **filters)  # type: ignore
     return objects
@@ -321,15 +343,15 @@
     api: Callable,
     async_api: Callable,
     limit: Optional[int],
     chunk_size: int,
     filters: dict,
     error_msg: Optional[str] = None,
     dict_unpack_value: Optional[str] = None,
-    **kwargs
+    **kwargs,
 ) -> list:
     """Get all objects asynchronously. Optionally filter the objects using
     `filters` parameter. Works only for endpoints with `limit` and `offset`
     query parameter (pagination).
 
     Args:
         connection: MicroStrategy REST API connection object
@@ -358,40 +380,49 @@
         if arg not in ['connection', 'limit', 'offset', 'error_msg']
     }
     response = api(
         connection=connection,
         offset=offset,
         limit=chunk_size,
         error_msg=error_msg,
-        **param_value_dict
+        **param_value_dict,
     )
     objects = _prepare_objects(response.json(), filters, dict_unpack_value)
     all_objects.extend(objects)
     current_count = offset + chunk_size
     total_objects = int(response.headers.get('x-mstr-total-count'))
     total_objects = min(limit, total_objects) if limit else total_objects
 
     if total_objects > current_count:
         it_total = int(total_objects / chunk_size) + (total_objects % chunk_size != 0)
         threads = get_parallel_number(it_total)
-        with FuturesSessionWithRenewal(connection=connection, max_workers=threads) as session:
+        with FuturesSessionWithRenewal(
+            connection=connection, max_workers=threads
+        ) as session:
             # Extract parameters of the api wrapper and set them using kwargs
             param_value_dict = auto_match_args(
                 api,
                 kwargs,
-                exclude=['connection', 'limit', 'offset', 'future_session', 'error_msg']
+                exclude=[
+                    'connection',
+                    'limit',
+                    'offset',
+                    'future_session',
+                    'error_msg',
+                ],
             )
             futures = [
                 async_api(
                     future_session=session,
                     connection=connection,
                     offset=offset,
                     limit=chunk_size,
-                    **param_value_dict
-                ) for offset in range(current_count, total_objects, chunk_size)
+                    **param_value_dict,
+                )
+                for offset in range(current_count, total_objects, chunk_size)
             ]
 
         for f in futures:
             response = f.result()
             if not response.ok:
                 response_handler(response, error_msg, throw_error=False)
             objects = _prepare_objects(response.json(), filters, dict_unpack_value)
@@ -402,15 +433,15 @@
 def fetch_objects(
     connection: "Connection",
     api: Callable,
     limit: Optional[int],
     filters: dict,
     error_msg: Optional[str] = None,
     dict_unpack_value: Optional[str] = None,
-    **kwargs
+    **kwargs,
 ) -> list:
     """Fetch and prepare objects. Optionally filter the objects by using the
     filters parameter. This function only supports endpoints without pagination.
 
     Args:
         connection: MicroStrategy REST API connection object
         api: GET API wrapper function that will return list of objects in bulk
@@ -453,15 +484,15 @@
     return preffered_order.get(source, 50)
 
 
 def auto_match_args(
     func: Callable,
     param_dict: dict,
     exclude: Optional[list] = None,
-    include_defaults: bool = True
+    include_defaults: bool = True,
 ) -> dict:
     """Automatically match dict data to function arguments.
 
     Handles default parameters. Extracts value from Enums. Returns matched
     arguments as dict.
 
     Note: don't use it for alter purposes as, changing parameter value
@@ -482,16 +513,24 @@
     default_dict = get_default_args_from_func(func)
 
     param_value_dict = {}
     for arg in args:
         if arg in exclude:
             continue
         else:
-            val = param_dict.get(arg) if param_dict.get(arg) is not None else default_dict.get(arg)
-            if not include_defaults and arg in default_dict and val == default_dict[arg]:
+            val = (
+                param_dict.get(arg)
+                if param_dict.get(arg) is not None
+                else default_dict.get(arg)
+            )
+            if (
+                not include_defaults
+                and arg in default_dict
+                and val == default_dict[arg]
+            ):
                 continue
 
             if isinstance(val, Enum):
                 val = val.value
         param_value_dict.update({arg: val})
 
     return param_value_dict
@@ -524,15 +563,15 @@
     param_name,
     data_type,
     max_val,
     min_val,
     regex,
     valid_example,
     inv_val,
-    special_values=None
+    special_values=None,
 ):
     special_values = special_values or []
     if value in special_values:
         return True
 
     if max_val is not None and value > max_val:
         msg = f"'{param_name}' has to be less than or equal to {max_val}"
@@ -543,16 +582,19 @@
         exception_handler(msg, inv_val)
         return False
     elif regex is not None and not re.match(regex, value):
         pattern = valid_example or regex
         msg = f"'{param_name}' has to match pattern '{pattern}'"
         exception_handler(msg, inv_val)
         return False
-    elif (all(cond is None for cond in [max_val, min_val, regex]) and special_values
-          and str not in data_type):
+    elif (
+        all(cond is None for cond in [max_val, min_val, regex])
+        and special_values
+        and str not in data_type
+    ):
         msg = f"'{param_name}' has to be one of {special_values}"
         exception_handler(msg, inv_val)
         return False
     return True
 
 
 def validate_param_value(
@@ -560,28 +602,30 @@
     param_val,
     data_type,
     max_val=None,
     min_val=None,
     special_values=None,
     regex=None,
     exception=True,
-    valid_example=None
+    valid_example=None,
 ) -> bool:
     """Validate param data type and optionally max, min special values.
 
     Raise:
         TypeError
         ValueError
     """
     special_values = special_values or []
     inv_type = TypeError if exception else Warning
     inv_val = ValueError if exception else Warning
     data_type = data_type if isinstance(data_type, list) else [data_type]
 
-    if any(map(lambda x: x == param_val and isinstance(x, type(param_val)), special_values)):
+    if any(
+        map(lambda x: x == param_val and isinstance(x, type(param_val)), special_values)
+    ):
         return True
 
     if type(param_val) not in data_type:
         msg = f"'{param_name}' needs to be of type {data_type}"
         exception_handler(msg, inv_type)
         return False
     if type(param_val) == list:
@@ -592,35 +636,36 @@
                     param_name,
                     data_type,
                     max_val,
                     min_val,
                     regex,
                     valid_example,
                     inv_val,
-                    special_values
-                ) for value in param_val
+                    special_values,
+                )
+                for value in param_val
             ]
         )
 
     return __validate_single_param_value(
         param_val,
         param_name,
         data_type,
         max_val,
         min_val,
         regex,
         valid_example,
         inv_val,
-        special_values
+        special_values,
     )
 
 
-def extract_all_dict_values(list_of_dicts: List[Dict]) -> List[Any]:
+def extract_all_dict_values(list_of_dicts: list[dict]) -> list[Any]:
     """Extract list of dicts values into list."""
-    all_options: List = []
+    all_options = []
     for option in list_of_dicts:
         all_options.extend(option.values())
     return all_options
 
 
 def delete_none_values(
     source: dict, *, whitelist_attributes: Optional[list] = None, recursion: bool
@@ -657,16 +702,16 @@
 
 
 def list_folders(
     connection,
     name: Optional[str] = None,
     to_dataframe: bool = False,
     limit: Optional[int] = None,
-    **filters
-) -> Union[List[dict], pd.DataFrame]:
+    **filters,
+) -> list[dict] | pd.DataFrame:
     """List folders.
 
     Args:
         connection: MicroStrategy connection object returned by
             `connection.Connection()`.
         name (string, optional): exact name of a folder to filter results.
             If `None`, all folders will be retrieved.
@@ -688,27 +733,27 @@
 
     msg = "Error while creating an instance for searching objects"
     res_e = objects.create_search_objects_instance(
         connection=connection,
         name=name,
         pattern=DSS_XML_SEARCH_TYPE_EXACTLY,
         object_type=FOLDER_TYPE,
-        error_msg=msg
+        error_msg=msg,
     )
     search_id = res_e.json()['id']
     msg = "Error while retrieving folders from the environment."
     fldrs = fetch_objects_async(
         connection,
         api=objects.get_objects,
         async_api=objects.get_objects_async,
         limit=limit,
         chunk_size=1000,
         error_msg=msg,
         filters=filters,
-        search_id=search_id
+        search_id=search_id,
     )
 
     if to_dataframe:
         return pd.DataFrame(fldrs)
     else:
         return fldrs
 
@@ -745,27 +790,29 @@
               name exists when providing `parent_name`
     """
     from mstrio.api import folders
 
     if parent_id is None and parent_name is None:
         exception_handler("Please specify either 'parent_name' or 'parent_id'.")
     if parent_name is not None and parent_id is not None:
-        exception_handler("Please specify either 'parent_name' or 'parent_id' but not both.")
+        exception_handler(
+            "Please specify either 'parent_name' or 'parent_id' but not both."
+        )
     if parent_id is None:
         fldrs = list_folders(connection=connection, name=parent_name)
         if len(fldrs) != 1:
             msg = f"Parent folder with name '{parent_name}' was either not found "
             msg += "or multiple folders with the same name exists."
             exception_handler(msg)
         parent_id = fldrs[0]['id']
     return folders.create_folder(
         connection=connection,
         name=folder_name,
         parent_id=parent_id,
-        description=folder_description
+        description=folder_description,
     )
 
 
 def delete_folder(
     connection, id: Optional[str] = None, name: Optional[str] = None, error_msg=None
 ):
     """Delete a folder.
@@ -786,17 +833,22 @@
             - both `name` and `id` are specified
             - folder was not found or multiple folders with the same name
               exists when providing `name`
     """
     from mstrio.api import objects
 
     if id is None and name is None:
-        exception_handler("Please specify either 'name' or 'id' of the folder to be deleted.")
+        exception_handler(
+            "Please specify either 'name' or 'id' of the folder to be deleted."
+        )
     if name is not None and id is not None:
-        msg = "Please specify either 'name' or 'id' of the folder to be deleted but not both."
+        msg = (
+            "Please specify either 'name' or 'id' of the folder to be deleted "
+            "but not both."
+        )
         exception_handler(msg)
     if id is None:
         fldrs = list_folders(connection=connection, name=name)
         if len(fldrs) != 1:
             msg = f"Folder with name '{name}' was either not found "
             msg += "or multiple folders with the same name exists."
             exception_handler(msg)
@@ -805,24 +857,28 @@
     return objects.delete_object(
         connection=connection, id=id, object_type=FOLDER_TYPE, error_msg=error_msg
     )
 
 
 def merge_id_and_type(
     object_id: str,
-    object_type: Union["ObjectTypes", "ObjectSubTypes", int],
-    error_msg: Optional[str] = None
+    object_type: 'ObjectTypes | ObjectSubTypes | int',
+    error_msg: Optional[str] = None,
 ) -> str:
     if not object_id or not object_type:
         exception_handler(
-            msg=error_msg or "Please provide both `id` and `type`.", exception_type=AttributeError
+            msg=error_msg or "Please provide both `id` and `type`.",
+            exception_type=AttributeError,
         )
     object_id = get_objects_id(object_id, type(object_id))
-    object_type = get_enum_val(object_type, type(object_type)
-                               ) if isinstance(object_type, Enum) else object_type
+    object_type = (
+        get_enum_val(object_type, type(object_type))
+        if isinstance(object_type, Enum)
+        else object_type
+    )
     return f'{object_id};{object_type}'
 
 
 def rsetattr(obj, attr, val):
     """Recursive setattr. This can only modify last attr in the chain.
     For example rsetattr(obj, 'attr1.attr2.attr3', new_value) won't work
     if attr2 doesn't exist.
@@ -861,15 +917,17 @@
 
     def _getattr(obj, attr):
         return getattr(obj, attr, *default)
 
     return reduce(_getattr, [obj] + attr.split('.'))
 
 
-def filter_params_for_func(func: Callable, params: dict, exclude: Optional[list] = None) -> dict:
+def filter_params_for_func(
+    func: Callable, params: dict, exclude: Optional[list] = None
+) -> dict:
     """Filter dict of parameters and return only those that are parameters
     of a `func`.
     Mainly used in `EntityBase.alter()`, before calling
     `EntityBase._alter_properties()` as shown in `Example`.
 
     Args:
         func: a function that the params are going to be fit for
@@ -895,39 +953,46 @@
             properties.update({arg: defaults_dict.get(arg)})
     return properties
 
 
 T = TypeVar("T")
 
 
-def filter_obj_list(obj_list: List[T], **filters: Dict[str, Any]) -> List[T]:
-    """Filter a list of objects by providing one or more key-value pair filters.
+def filter_obj_list(obj_list: list[T], **filters: dict[str, Any]) -> list[T]:
     """
-    return [obj for obj in obj_list if all(getattr(obj, f) == v for f, v in filters.items())]
+    Filter a list of objects by providing one or more key-value pair filters.
+    """
+    return [
+        obj for obj in obj_list if all(getattr(obj, f) == v for f, v in filters.items())
+    ]
 
 
-def choose_cube(connection: "Connection", cube_dict: dict) -> Union["OlapCube", "SuperCube", None]:
+def choose_cube(
+    connection: 'Connection', cube_dict: dict
+) -> 'OlapCube | SuperCube | None':
     """Return correct cube object based on dictionary with cube's info.
 
-        Note: In case of wrong subtype, `None` is returned.
+    Note: In case of wrong subtype, `None` is returned.
     """
     cube_subtype = cube_dict['subtype']
     if cube_subtype == ObjectSubTypes.OLAP_CUBE.value:
         from mstrio.project_objects.datasets.olap_cube import OlapCube
+
         return OlapCube.from_dict(cube_dict, connection)
     elif cube_subtype == ObjectSubTypes.SUPER_CUBE.value:
         from mstrio.project_objects.datasets.super_cube import SuperCube
+
         return SuperCube.from_dict(cube_dict, connection)
 
 
 def get_valid_project_id(
     connection: "Connection",
     project_id: Optional[str] = None,
     project_name: Optional[str] = None,
-    with_fallback: bool = False
+    with_fallback: bool = False,
 ):
     """Check if the project name exists and return the project ID.
 
     Args:
         connection(object): MicroStrategy connection object
         project_id: Project ID
         project_name: Project name
@@ -935,17 +1000,21 @@
         object if `project_id` is not specified and the project failed to be
         found based on `project_name`
     """
     from mstrio.server import Project
 
     # Search for a project by its name if id was not specified, but name was
     if not project_id:
-        project_loaded_list = Project._list_loaded_projects(
-            connection, to_dictionary=True, name=project_name
-        ) if project_name else []
+        project_loaded_list = (
+            Project._list_loaded_projects(
+                connection, to_dictionary=True, name=project_name
+            )
+            if project_name
+            else []
+        )
         if project_loaded_list:
             project_id = project_loaded_list[0]['id']
         else:
             if project_name:
                 msg = (
                     f"There is no project with the given name: '{project_name}'"
                     f" or the project is not loaded."
@@ -954,26 +1023,28 @@
                 msg = "`project_id` and `project_name` were not provided. "
             if with_fallback:
                 logger.info(msg + "Project from `connection` object is used instead.")
                 project_id = fallback_to_conn_project_id(connection)
             else:
                 exception_handler(
                     msg + "Please specify valid `project_id` or `project_name`",
-                    exception_type=ValueError
+                    exception_type=ValueError,
                 )
 
     return project_id
 
 
 def fallback_to_conn_project_id(connection: "Connection") -> Optional[str]:
     try:
         connection._validate_project_selected()
         return connection.project_id
     except AttributeError:
-        exception_handler(msg="Project could not be determined.", exception_type=ValueError)
+        exception_handler(
+            msg="Project could not be determined.", exception_type=ValueError
+        )
 
 
 def get_valid_project_name(connection: "Connection", project_id: str):
     """Returns project name of given project based on its ID.
 
     Args:
         connection(object): MicroStrategy connection object
@@ -989,18 +1060,19 @@
     return project_name
 
 
 class Dictable:
     """The fundamental class in mstrio-py package. Includes support for
     converting an object to a dictionary, and creating an object from a
     dictionary."""
-    _FROM_DICT_MAP: Dict[str, Callable] = {}  # map attributes to Enums and components
+
+    _FROM_DICT_MAP: dict[str, Callable] = {}  # map attributes to Enums and components
     # list of attribute name, which are allowed to have none values
     # in dict returned by .to_dict()
-    _ALLOW_NONE_ATTRIBUTES: List[str] = []
+    _ALLOW_NONE_ATTRIBUTES: list[str] = []
     _KEEP_CAMEL_CASE: list[str] = []
 
     @classmethod
     def _unpack_objects(cls, key, val, camel_case=True):
         """Unpack Enums, Dictable obj, list of Enums"""
         if isinstance(val, datetime):
             return map_datetime_to_str(key, val, cls._FROM_DICT_MAP)
@@ -1010,31 +1082,34 @@
             return val.to_dict(camel_case)
         elif isinstance(val, list):
             return [cls._unpack_objects(key, v, camel_case) for v in val]
         return val
 
     @classmethod
     def _dict_to_obj(cls, connection, val, key):
-
         def constructor():
             if isinstance(cls._FROM_DICT_MAP[key], DatetimeFormats):
                 return map_str_to_datetime(key, val, cls._FROM_DICT_MAP)
             elif isinstance(cls._FROM_DICT_MAP[key], type(Enum)):
                 return cls._FROM_DICT_MAP[key](val)
             elif isinstance(cls._FROM_DICT_MAP[key], type(Dictable)):
                 return cls._FROM_DICT_MAP[key].from_dict(val)
             elif isinstance(cls._FROM_DICT_MAP[key], list):
                 if isinstance(cls._FROM_DICT_MAP[key][0], list):
                     # for: List[List[handling_cls]]
                     handling_cls = cls._FROM_DICT_MAP[key][0][0]
                     return [[handling_cls.from_dict(item) for item in v] for v in val]
-                elif (all(isinstance(v, type(Enum)) for v in cls._FROM_DICT_MAP[key])
-                      and val is not None):
+                elif (
+                    all(isinstance(v, type(Enum)) for v in cls._FROM_DICT_MAP[key])
+                    and val is not None
+                ):
                     return [cls._FROM_DICT_MAP[key][0](v) for v in val]
-                elif all([isinstance(v, type(Dictable)) for v in cls._FROM_DICT_MAP[key]]):
+                elif all(
+                    [isinstance(v, type(Dictable)) for v in cls._FROM_DICT_MAP[key]]
+                ):
                     return [cls._FROM_DICT_MAP[key][0].from_dict(v) for v in val]
                 elif callable(cls._FROM_DICT_MAP[key][0]):
                     return [cls._FROM_DICT_MAP[key][0](v, connection) for v in val]
             else:
                 return cls._FROM_DICT_MAP[key](val, connection)
 
         return val if key not in cls._FROM_DICT_MAP else constructor()
@@ -1052,45 +1127,54 @@
 
         Returns:
             dict: A dictionary representation of object's attributes and values.
                 By default, the dictionary keys are in camel case.
         """
 
         hidden_keys = [
-            '_fetched_attributes', '_altered_properties', '_connection', 'connection', '_type'
+            '_fetched_attributes',
+            '_altered_properties',
+            '_connection',
+            'connection',
+            '_type',
         ]
         cleaned_dict = self.__dict__.copy()
         properties = {
             elem[0]
-            for elem in inspect.getmembers(self.__class__, lambda x: isinstance(x, property))
+            for elem in inspect.getmembers(
+                self.__class__, lambda x: isinstance(x, property)
+            )
         }
         for prop in properties:
             to_be_deleted = '_' + prop
             cleaned_dict[prop] = cleaned_dict.pop(to_be_deleted, None)
         result = {
             key: self._unpack_objects(key, val, camel_case)
-            for key,
-            val in cleaned_dict.items()
+            for key, val in cleaned_dict.items()
             if key not in hidden_keys
         }
 
         result = delete_none_values(
-            result,
-            whitelist_attributes=self._ALLOW_NONE_ATTRIBUTES,
-            recursion=False
+            result, whitelist_attributes=self._ALLOW_NONE_ATTRIBUTES, recursion=False
+        )
+        result = {
+            key: result[key] for key in sorted(result, key=sort_object_properties)
+        }
+        return (
+            snake_to_camel(result, whitelist=self._KEEP_CAMEL_CASE)
+            if camel_case
+            else result
         )
-        result = {key: result[key] for key in sorted(result, key=sort_object_properties)}
-        return snake_to_camel(result, whitelist=self._KEEP_CAMEL_CASE) if camel_case else result
 
     @classmethod
     def from_dict(
         cls: T,
-        source: Dict[str, Any],
+        source: dict[str, Any],
         connection: Optional["Connection"] = None,
-        to_snake_case: bool = True
+        to_snake_case: bool = True,
     ) -> T:
         """Creates an object from a dictionary. The dictionary's keys in camel
         case are changed to object's attribute names (by default in snake case)
         and dict values are composed to their proper data types such as Enums,
         list of Enums etc. as specified in _FROM_DICT_MAP.
 
         Args:
@@ -1113,27 +1197,26 @@
         )
 
         if connection is not None:
             object_source["connection"] = connection
 
         args = {
             key: cls._dict_to_obj(connection, val, key)
-            for key,
-            val in object_source.items()
+            for key, val in object_source.items()
             if key in cls.__init__.__code__.co_varnames
         }
         obj = cls(**args)  # type: ignore
         return obj
 
     @classmethod
     def bulk_from_dict(
         cls: T,
         source_list: list[dict[str, Any]],
         connection: Optional["Connection"] = None,
-        to_snake_case: bool = True
+        to_snake_case: bool = True,
     ) -> list[T]:
         """Creates multiple objects from a list of dictionaries. For each
         dictionary provided the keys in camel case are changed to object's
         attribute names (by default in snake case) and dict values are composed
         to their proper data types such as Enums, list of Enums etc. as
         specified in the object's _FROM_DICT_MAP.
 
@@ -1147,20 +1230,23 @@
                 should be converted from camel case to snake case. Defaults to
                 True.
 
         Returns:
             T: A list of objects of type T.
         """
         return [
-            cls.from_dict(source=source, connection=connection, to_snake_case=to_snake_case)
+            cls.from_dict(
+                source=source, connection=connection, to_snake_case=to_snake_case
+            )
             for source in source_list
         ]
 
     def __repr__(self) -> str:
         from mstrio.utils.entity import auto_match_args_entity
+
         param_dict = auto_match_args_entity(
             self.__init__,
             self,
             exclude=['self'],
             include_defaults=False,
         )
         formatted_params = ', '.join(
@@ -1169,15 +1255,82 @@
         return f'{self.__class__.__name__}({formatted_params})'
 
 
 def is_dossier(view_media: int):
     """Documents and dossiers have the same type and subtype when returned
     from search api. They can be distinguished only by view_media value.
     """
-    return view_media & 4160749568 == 1879048192 or view_media & 4160749568 == 1610612736
+    return (
+        view_media & 4160749568 == 1879048192 or view_media & 4160749568 == 1610612736
+    )
 
 
 def is_document(view_media: int):
     """Documents and dossiers have the same type and subtype when returned
     from search api. They can be distinguished only by view_media value.
     """
     return not is_dossier(view_media)
+
+
+def rename_dict_keys(source: dict, mapping: dict) -> dict:
+    """Rename dict keys according to mapping.
+
+    Args:
+        source (dict): An original dictionary, which keys are to be renamed.
+        mapping (dict): A dictionary containing mapping of keys.
+
+    Returns:
+        dict: A dictionary with keys renamed.
+    """
+    for rest_name, python_name in mapping.items():
+        if rest_name in source:
+            old = source.pop(rest_name)
+            if python_name:
+                source[python_name] = old
+    return source
+
+
+def verify_project_status(
+    project: 'Project', correct_statuses: list[str] | str, node: Optional[str] = None
+) -> bool:
+    """Veriy if provided status is correct for given project.
+
+    Args:
+        project (Project): Project for which statuses will be verified.
+        correct_statuses (list[str], str): A list of correct statuses
+            or just one status.
+        node (str, optional): Node name on which status should be verified,
+            represented as name of first node if not provided.
+
+    Returns:
+        bool: True if status is correct and False otherwise.
+    """
+
+    def get_status(project: 'Project', node: Optional[str] = None) -> str:
+        node_name = project.nodes[0]['name'] if not node else node
+        nodes_filtered = [node for node in project.nodes if node['name'] == node_name]
+
+        if not nodes_filtered:
+            raise ValueError(
+                f"Node {node} not found. Available nodes "
+                f"{[node['name'] for node in project.nodes]}"
+            )
+
+        projects_filtered = [
+            proj
+            for node in nodes_filtered
+            for proj in node['projects']
+            if proj['id'] == project.id
+        ]
+
+        return projects_filtered[0]['status']
+
+    status = get_status(project=project, node=node)
+    iteration = 0
+
+    while status not in correct_statuses and iteration < 20:
+        time.sleep(1)
+        project.fetch('nodes')
+        status = get_status(project=project, node=node)
+        iteration += 1
+
+    return status in correct_statuses
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/model.py` & `mstrio-py-11.3.9.103/mstrio/utils/model.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 import pandas as pd
 import datetime as dt
+from collections import defaultdict
 
 
 class Model:
     """Internal utility for generating the definition of multi-table and
     single-table datasets.
 
     Create the definition of a super cube containing one or more tables. The
@@ -17,19 +18,32 @@
     _KEY_TABLE_NAME = 'table_name'
     _KEY_DATA_FRAME = 'data_frame'
     _KEY_AS_ATTR = 'to_attribute'
     _KEY_AS_METR = 'to_metric'
     _KEY_UPDATE_POL = 'update_policy'
     _KEY_TABLES = [_KEY_TABLE_NAME, _KEY_DATA_FRAME, _KEY_AS_ATTR, _KEY_AS_METR]
 
-    __MAX_DESC_LEN = 250
+    _MAX_DESC_LEN = 250
 
-    _INVALID_CHARS = ['\\', '"', '[', ']']  # check for invalid characters in column names
-
-    def __init__(self, tables, name, description=None, folder_id=None, ignore_special_chars=False):
+    _INVALID_CHARS = [
+        '\\',
+        '"',
+        '[',
+        ']',
+    ]  # check for invalid characters in column names
+
+    def __init__(
+        self,
+        tables,
+        name,
+        description=None,
+        folder_id=None,
+        ignore_special_chars=False,
+        attr_forms_mapping=None,
+    ):
         """Initializes Model with tables, a name, and an optional description.
 
         Args:
             tables (list of dicts): List of one or more dictionaries with keys
                 `table_name`, `data_frame`, and optionally `as_attribute` and
                 `as_metric`. Note that `as_attribute` and `as_metric` should be
                 used when the default Python data type (e.g. `int`) should be
@@ -38,269 +52,283 @@
             description (str, optional): Description of the data set. Must be
                 less than or equal to 250 characters.
             folder_id (str, optional): ID of the shared folder that the super
                 cube should be created within. If `None`, defaults to the user's
                 My Reports folder.
         """
 
-        self.__ignore_special_chars = ignore_special_chars
+        self._ignore_special_chars = ignore_special_chars
 
         # check integrity of tables list
-        self.__check_table_list(tables=tables)
+        self._check_table_list(tables=tables)
 
         # check super cube name params
-        self.__name = name
-        self.__check_param_str(self.__name, msg="SuperCube name should be a string.")
-        self.__check_param_len(
-            self.__name,
-            msg=f"SuperCube name should be <= {self.__MAX_DESC_LEN} characters.",
-            max_length=self.__MAX_DESC_LEN
+        self._name = name
+        self._check_param_str(self._name, msg="SuperCube name should be a string.")
+        self._check_param_len(
+            self._name,
+            msg=f"SuperCube name should be <= {self._MAX_DESC_LEN} characters.",
+            max_length=self._MAX_DESC_LEN,
         )
-        self.__check_param_inv_chars(
-            self.__name,
+        self._check_param_inv_chars(
+            self._name,
             msg="SuperCube name cannot contain '{}', '{}', '{}', '{}'.".format(
                 *self._INVALID_CHARS
             ),
-            invalid_chars=self._INVALID_CHARS
+            invalid_chars=self._INVALID_CHARS,
         )
 
         # check super cube description params
         if description is None:
-            self.__description = ""
+            self._description = ""
         else:
-            self.__description = description
-            self.__check_param_str(
-                self.__description, msg="SuperCube description should be a string."
+            self._description = description
+            self._check_param_str(
+                self._description, msg="SuperCube description should be a string."
             )
-            self.__check_param_len(
-                self.__description,
-                msg="SuperCube description should be <= {} characters.".format(
-                    self.__MAX_DESC_LEN
+            self._check_param_len(
+                self._description,
+                msg=(
+                    f"SuperCube description should be <= {self._MAX_DESC_LEN}"
+                    " characters."
                 ),
-                max_length=self.__MAX_DESC_LEN
+                max_length=self._MAX_DESC_LEN,
             )
 
         # check folder_id param
-        if folder_id is None:
-            self._folder_id = ""
-        else:
-            self._folder_id = folder_id
+        self._folder_id = folder_id or ''
 
         # init lists to accumulate table, attr, metric definitions and model
-        self.__tables = []
-        self.__attributes = []
-        self.__metrics = []
-        self.__model = None
+        self._tables = []
+        self._attributes = []
+        self._metrics = []
+        self._model = None
 
+        forms_mapping = attr_forms_mapping or []
         # build the model
-        self.__build(tables=tables)
+        self._build(tables=tables, forms_mapping=forms_mapping)
 
     def get_model(self):
         """Return the model object."""
-        return self.__model
+        return self._model
 
-    def __build(self, tables):
+    def _build(self, tables, forms_mapping):
         """Generates the data model by mapping attributes and metrics from list
         of tables."""
 
+        table2columns_used = self._add_user_defined_attribute_forms(forms_mapping)
+
         # Map tables one by one
         for table in tables:
-            self.__map_table(table)
+            mapped_columns = table2columns_used[table['table_name']]
+            self._map_table(table, mapped_columns)
 
         # set model object
-        self.__model = {
-            "name": self.__name,
-            "description": self.__description,
-            "folderId": self._folder_id,
-            "tables": self.__tables,
-            "metrics": self.__metrics,
-            "attributes": self.__attributes
+        self._model = {
+            'name': self._name,
+            'description': self._description,
+            'folderId': self._folder_id,
+            'tables': self._tables,
+            'metrics': self._metrics,
+            'attributes': self._attributes,
         }
 
-    def __map_table(self, table):
+    def _add_user_defined_attribute_forms(self, forms_mapping):
+        table2columns_used = defaultdict(set)
+
+        for attr in forms_mapping:
+            self._attributes.append(attr.to_dict())
+            for form in attr.forms:
+                for expr in form.expressions:
+                    table2columns_used[expr.table].add(expr.column)
+
+        return table2columns_used
+
+    def _map_table(self, table, skip_columns):
+        df = table[self._KEY_DATA_FRAME]
+
         # map column names and column types
-        _col_names = self.__get_col_names(table[self._KEY_DATA_FRAME])
-        _col_types = self.__get_col_types(table[self._KEY_DATA_FRAME])
+        col_names = self._get_col_names(df)
+        col_types = self._get_col_types(df)
+        table_name = table[self._KEY_TABLE_NAME]
 
         # map tables
-        self.__add_table(
-            name=table[self._KEY_TABLE_NAME], col_names=_col_names, col_types=_col_types
-        )
+        self._add_table(name=table_name, col_names=col_names, col_types=col_types)
 
         # map attributes and metrics
-        for _name, _type in zip(_col_names, _col_types):
-
-            if self.__is_metric(_type):
-                if self._KEY_AS_ATTR in table.keys() and _name in table[self._KEY_AS_ATTR]:
-                    self.__add_attribute(_name, table[self._KEY_TABLE_NAME])
-                else:
-                    self.__add_metric(_name, table[self._KEY_TABLE_NAME])
-
+        for name, column_type in zip(col_names, col_types):
+            if name in skip_columns:
+                continue
+
+            if name in table.get(self._KEY_AS_ATTR, []):
+                self._add_attribute(name, table_name)
+            elif name in table.get(self._KEY_AS_METR, []) or self._is_metric(
+                column_type
+            ):
+                self._add_metric(name, table_name)
             else:
-                if self._KEY_AS_METR in table.keys() and _name in table[self._KEY_AS_METR]:
-                    self.__add_metric(_name, table[self._KEY_TABLE_NAME])
-                else:
-                    self.__add_attribute(_name, table[self._KEY_TABLE_NAME])
+                self._add_attribute(name, table_name)
 
-    def __get_col_types(self, table):
+    def _get_col_types(self, table):
         """Map column types from each column in the list of table."""
         list_dtypes_values = list(table.dtypes.values)
+
         for i in range(len(table.columns)):
-            if list_dtypes_values[i] == 'object' and isinstance(table.columns[i][0], dt.time):
+            if list_dtypes_values[i] == 'object' and isinstance(
+                table.columns[i][0], dt.time
+            ):
                 list_dtypes_values[i] = 'time'
-        return list(map(self.__map_data_type, list_dtypes_values))
 
-    def __add_metric(self, name, table_name):
+        return [self._map_data_type(datatype) for datatype in list_dtypes_values]
+
+    def _add_metric(self, name, table_name):
         """Add a metric to a metric list instance."""
-        self.__metrics.append(
+        self._metrics.append(
             {
-                'name': name, 'expressions': [{
-                    'tableName': table_name, 'columnName': name
-                }]
+                'name': name,
+                'expressions': [{'tableName': table_name, 'columnName': name}],
             }
         )
 
-    def __add_attribute(self, name, table_name):
+    def _add_attribute(self, name, table_name):
         """Add an attribute to an attribute list instance."""
-        self.__attributes.append(
+        self._attributes.append(
             {
                 'name': name,
                 'attributeForms': [
                     {
                         'category': 'ID',
-                        'expressions': [{
-                            'tableName': table_name, 'columnName': name
-                        }]
+                        'expressions': [{'tableName': table_name, 'columnName': name}],
                     }
-                ]
+                ],
             }
         )
 
-    def __add_table(self, name, col_names, col_types):
+    def _add_table(self, name, col_names, col_types):
         """Add a table to a table list instance."""
-        self.__tables.append(
+        self._tables.append(
             {
                 'name': name,
                 'columnHeaders': [
-                    {
-                        'name': name, 'dataType': typ
-                    } for name, typ in zip(col_names, col_types)
-                ]
+                    {'name': name, 'dataType': typ}
+                    for name, typ in zip(col_names, col_types)
+                ],
             }
         )
 
-    def __check_table_list(self, tables):
+    def _check_table_list(self, tables):
         """Check integrity of table list parameter."""
 
         # tables must be a list
         if not isinstance(tables, list):
             raise TypeError("Elements of tables must be a list of dicts.")
 
         # tables cannot be length 0
         if len(tables) == 0:
             raise ValueError("No tables have been added to the super cube.")
 
         # check integrity of each table passed to tables
         for table in tables:
-            self.__check_table(table)
+            self._check_table(table)
 
-    def __check_table(self, table):
+    def _check_table(self, table):
         """Check integrity of table parameter."""
 
         # force all list elements to be a dict with specific names
-        msg = "Each table must be a dictionary with keys: '{}', '{}', '{},' and '{}'.".format(
-            *self._KEY_TABLES
-        )
+        table_keys_list = "', '".join(self._KEY_TABLES)
+        msg = f"Each table must be a dictionary with keys: '{table_keys_list}'."
+
         if not isinstance(table, dict):
             raise TypeError(msg)
 
-        if not all(k in table.keys() for k in (self._KEY_TABLE_NAME, self._KEY_DATA_FRAME)):
+        if not all(k in table for k in (self._KEY_TABLE_NAME, self._KEY_DATA_FRAME)):
             raise ValueError(msg)
 
         # check that the value of the data frame key is a pandas data frame
         if not isinstance(table[self._KEY_DATA_FRAME], pd.DataFrame):
-            msg = "Pandas DataFrame must be passed as the value in the '{}' key.".format(
-                self._KEY_DATA_FRAME
+            msg = (
+                "Pandas DataFrame must be passed as the value in the "
+                f"'{self._KEY_DATA_FRAME}' key."
             )
             raise TypeError(msg)
 
         # check for presence of invalid characters in data frame column names
-        if not self.__ignore_special_chars and any(
-            [col for col in table[self._KEY_DATA_FRAME].columns
-             for inv in self._INVALID_CHARS if inv in col]):
-            msg = "Column names cannot contain '{}', '{}', '{}', '{}'".format(*self._INVALID_CHARS)
+        if not self._ignore_special_chars and any(
+            [
+                col
+                for col in table[self._KEY_DATA_FRAME].columns
+                for inv in self._INVALID_CHARS
+                if inv in col
+            ]
+        ):
+            msg = "Column names cannot contain '{}', '{}', '{}', '{}'".format(
+                *self._INVALID_CHARS
+            )
             raise ValueError(msg)
 
     @staticmethod
-    def __get_col_names(table):
+    def _get_col_names(table):
         """Returns column names from a table as a list."""
         return list(table.columns)
 
     @staticmethod
-    def __map_data_type(datatype):
+    def _map_data_type(datatype):
         """Maps a Python data type to a MicroStrategy data type."""
-        if datatype == 'object':
-            return "STRING"
-        elif datatype == 'int32':
-            return "INTEGER"
-        elif datatype == 'int64':
-            return "BIGINTEGER"
-        elif datatype in ['float64', 'float32']:
-            return "DOUBLE"
-        elif datatype == 'bool':
-            return "BOOLEAN"
-        elif datatype == 'datetime64[ns]':
-            return 'DATETIME'
-        elif datatype == 'time':
-            return 'TIME'
+        return {
+            'object': 'STRING',
+            'int32': 'INTEGER',
+            'int64': 'BIGINTEGER',
+            'float32': 'DOUBLE',
+            'float64': 'DOUBLE',
+            'bool': 'BOOLEAN',
+            'datetime64[ns]': 'DATETIME',
+            'time': 'TIME',
+        }.get(str(datatype))
 
     @staticmethod
-    def __check_param_len(param, msg, max_length):
+    def _check_param_len(param, msg, max_length):
         if len(param) > max_length:
             raise ValueError(msg)
-        else:
-            return True
+
+        return True
 
     @staticmethod
-    def __check_param_str(param, msg):
+    def _check_param_str(param, msg):
         if not isinstance(param, str):
             raise TypeError(msg)
-        else:
-            return True
+
+        return True
 
     @staticmethod
-    def __check_param_inv_chars(param, msg, invalid_chars):
-        if any([inv for inv in invalid_chars if inv in param]):
+    def _check_param_inv_chars(param, msg, invalid_chars):
+        if any(inv for inv in invalid_chars if inv in param):
             raise ValueError(msg)
 
     @staticmethod
-    def __is_metric(datatype):
+    def _is_metric(datatype):
         """Helper function for determining if the requested datatype is (by
         default) a metric or attribute."""
-        if datatype in ["DOUBLE", "INTEGER", "BIGINTEGER", "BIGDECIMAL"]:
-            return True
-        else:
-            return False
+        return datatype in ['DOUBLE', 'INTEGER', 'BIGINTEGER', 'BIGDECIMAL']
 
     @property
     def name(self):
-        return self.__name
+        return self._name
 
     @property
     def description(self):
-        return self.__description
+        return self._description
 
     @property
     def folder_id(self):
         return self._folder_id
 
     @property
     def tables(self):
-        return self.__tables
+        return self._tables
 
     @property
     def attributes(self):
-        return self.__attributes
+        return self._attributes
 
     @property
     def metrics(self):
-        return self.__metrics
+        return self._metrics
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/monitors.py` & `mstrio-py-11.3.9.103/mstrio/utils/monitors.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,18 +9,17 @@
 def all_nodes_async(
     connection,
     async_api: Callable,
     filters: dict,
     error_msg: str,
     unpack_value: Optional[str] = None,
     limit: Optional[int] = None,
-    **kwargs
+    **kwargs,
 ):
-    """Return list of objects fetched async using wrappers in monitors.py
-    """
+    """Return list of objects fetched async using wrappers in monitors.py"""
 
     node = kwargs.get('node_name')
     if not node:
         nodes_response = monitors.get_node_info(connection).json()
         all_nodes = nodes_response['nodes']
         node_names = [node['name'] for node in all_nodes if node['status'] == 'running']
     else:
@@ -32,20 +31,31 @@
         error_msg = kwargs.get('error_msg')
 
     with FuturesSessionWithRenewal(connection=connection, max_workers=8) as session:
         # Extract parameters of the api wrapper and set them using kwargs
         param_value_dict = auto_match_args(
             async_api,
             kwargs,
-            exclude=['connection', 'limit', 'offset', 'future_session', 'error_msg', 'node_name']
+            exclude=[
+                'connection',
+                'limit',
+                'offset',
+                'future_session',
+                'error_msg',
+                'node_name',
+            ],
         )
         futures = [
             async_api(
-                future_session=session, connection=connection, node_name=n, **param_value_dict
-            ) for n in node_names
+                future_session=session,
+                connection=connection,
+                node_name=n,
+                **param_value_dict,
+            )
+            for n in node_names
         ]
         objects = []
         for f in futures:
             response = f.result()
             if not response.ok:
                 response_handler(response, error_msg, throw_error=False)
             else:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/object_mapping.py` & `mstrio-py-11.3.9.103/mstrio/utils/object_mapping.py`

 * *Files 8% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 from mstrio.modeling.filter import Filter  # noqa: F401
 from mstrio.modeling.metric import Metric  # noqa: F401
 from mstrio.modeling.schema import (  # noqa: F401
     Attribute,
     Fact,
     LogicalTable,
     Transformation,
-    UserHierarchy
+    UserHierarchy,
 )
 from mstrio.modeling.security_filter import SecurityFilter  # noqa: F401
 from mstrio.object_management.folder import Folder  # noqa: F401
 from mstrio.object_management.object import Object
 from mstrio.object_management.search_operations import SearchObject  # noqa: F401
 from mstrio.object_management.shortcut import Shortcut  # noqa: F401
 from mstrio.project_objects import Document, Report  # noqa: F401
@@ -60,50 +60,51 @@
     UserGroup = ObjectSubTypes.USER_GROUP  # noqa: F811
 
 
 def __str_to_class(classname):
     return getattr(sys.modules[__name__], classname)
 
 
-def map_to_object(object_type: int | ObjectTypes, subtype: Optional[int | ObjectSubTypes] = None):
+def map_to_object(
+    object_type: int | ObjectTypes, subtype: Optional[int | ObjectSubTypes] = None
+):
     if not isinstance(object_type, ObjectTypes):
         try:
             object_type = ObjectTypes(object_type)
         except ValueError:
             object_type = None
     if not isinstance(subtype, ObjectSubTypes):
         try:
             subtype = ObjectSubTypes(subtype)
         except ValueError:
             subtype = None
 
-    if ((object_type == ObjectTypes.REPORT_DEFINITION
-         and subtype in (ObjectSubTypes.OLAP_CUBE, ObjectSubTypes.SUPER_CUBE))
-            or (object_type == ObjectTypes.USER
-                and subtype in (ObjectSubTypes.USER, ObjectSubTypes.USER_GROUP))):
+    if (
+        object_type == ObjectTypes.REPORT_DEFINITION
+        and subtype in (ObjectSubTypes.OLAP_CUBE, ObjectSubTypes.SUPER_CUBE)
+    ) or (
+        object_type == ObjectTypes.USER
+        and subtype in (ObjectSubTypes.USER, ObjectSubTypes.USER_GROUP)
+    ):
         return __str_to_class(SubTypeObjectMapping(subtype).name)
     elif object_type in [v.value for v in TypeObjectMapping]:
         return __str_to_class(TypeObjectMapping(object_type).name)
     else:
         return Object
 
 
 def map_object(connection: "Connection", obj: dict):
     """Map a dict that represents an object to an instance of the corresponding
-        mstrio class.
+    mstrio class.
     """
 
-    return map_to_object(
-        obj.get('type'),
-        obj.get('subtype')
-    ).from_dict(source=obj, connection=connection)
+    return map_to_object(obj.get('type'), obj.get('subtype')).from_dict(
+        source=obj, connection=connection
+    )
 
 
 def map_objects_list(connection: "Connection", objects_list: list):
     """Map a list of dict that represent objects to instances of
-        the corresponding mstrio classes.
+    the corresponding mstrio classes.
     """
 
-    return [
-        map_object(connection, obj)
-        for obj in objects_list
-    ]
+    return [map_object(connection, obj) for obj in objects_list]
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/parser.py` & `mstrio-py-11.3.9.103/mstrio/utils/parser.py`

 * *Files 4% similar despite different names*

```diff
@@ -11,62 +11,71 @@
     structure."""
 
     AF_COL_SEP = "@"  # attribute form column label separator; commonly "@"
     chunk_size = None
     total_rows = None
 
     def __init__(self, response, parse_cube=True):
-
         self.parse_cube = parse_cube
         # row-level metric data
         self._metric_values_raw = []
 
         # extract column headers and names
         self._metric_col_names = self.__extract_metric_col_names(response=response)
 
         # attribute objects
         # extract attribute names
         self._attribute_names = self.__extract_attribute_names(response=response)
 
         # extract attribute form names
-        self._attribute_elem_form_names = self.__extract_attribute_form_names(response=response)
+        self._attribute_elem_form_names = self.__extract_attribute_form_names(
+            response=response
+        )
 
-        # parse attribute column names including attribute form names into final column names  # noqa
+        # parse attribute column names including attribute form names
+        # into final column names
         self._attribute_col_names = self.__get_attribute_col_names()
 
         self.__extract_paging_info(response)
 
         # attribute data
-        self._mapped_attributes = np.zeros((0, len(self._attribute_col_names)), dtype=object)
+        self._mapped_attributes = np.zeros(
+            (0, len(self._attribute_col_names)), dtype=object
+        )
 
     def parse(self, response):
         """
         Args:
             response: JSON-formatted content of API response.
         """
         if self.total_rows > 0:
-            # extract attribute values into numpy 2D array if attributes exist in the response  # noqa
+            # extract attribute values into numpy 2D array if attributes exist
+            # in the response
             if self._attribute_names:
                 self._mapped_attributes = np.vstack(
                     (self._mapped_attributes, self.__map_attributes(response=response))
                 )
 
             # extract metric values if metrics exist in the response
             if self._metric_col_names:
-                self._metric_values_raw.extend(self.__extract_metric_values(response=response))
+                self._metric_values_raw.extend(
+                    self.__extract_metric_values(response=response)
+                )
 
     def __to_dataframe(self):
-
-        # create attribute data frame, then re-map integer array with corresponding attribute element values  # noqa
+        # create attribute data frame, then re-map integer array with
+        # corresponding attribute element values
         attribute_df = pd.DataFrame(
             data=self._mapped_attributes, columns=self._attribute_col_names
         )
 
         # create metric values data frame
-        metric_df = pd.DataFrame(data=self._metric_values_raw, columns=self._metric_col_names)
+        metric_df = pd.DataFrame(
+            data=self._metric_values_raw, columns=self._metric_col_names
+        )
 
         return pd.concat([attribute_df, metric_df], axis=1)
 
     def __map_attributes(self, response):
         label_map = self.__create_attribute_element_map(response=response)
         row_index = self.__extract_attribute_element_row_index(response=response)
         row_index_array = np.array(row_index)
@@ -84,15 +93,17 @@
 
         The index of the list corresponds to attribute element row index from
         the grid headers. The map is used to map the integer-based grid
         header values to the real attribute element labels."""
 
         # extract attribute form and attribute elements labels
         rows = response["definition"]["grid"]["rows"]
-        form_values_rows = [[el['formValues'] for el in row['elements']] for row in rows]
+        form_values_rows = [
+            [el['formValues'] for el in row['elements']] for row in rows
+        ]
 
         def replicate_form_values(form_values):
             """Replicate attribute element values for total, count, etc. to fill
             the lists to correct size. I-Server only sends them once per
             attribute"""
             if self.parse_cube:
                 return
@@ -109,73 +120,92 @@
             nested lists into a list of list where one element corresponds to an
             attribute column"""
             final_list = []
             try:
                 for attr in form_values:
                     row = len(attr[0])
                     col = len(attr)
-                    final_list.extend(np.array(attr).reshape(col, row).transpose().tolist())
+                    final_list.extend(
+                        np.array(attr).reshape(col, row).transpose().tolist()
+                    )
                 return final_list
             except IndexError:
                 msg = (
-                    "Missing attribute elements, please check if attribute elements IDs are "
-                    "valid and if they exist in report."
+                    "Missing attribute elements, please check if attribute elements IDs"
+                    " are valid and if they exist in report."
                 )
                 exception_handler(msg, IndexError)
 
         replicate_form_values(form_values_rows)
         ae_index_map = separate(form_values_rows)
 
         return ae_index_map
 
     def __extract_attribute_element_row_index(self, response):
         # extracts the attribute element row index from the headers
         return [
             list(
                 chain.from_iterable(
-                    [[r for _ in f] for r, f in zip(row, self._attribute_elem_form_names)]
+                    [
+                        [r for _ in f]
+                        for r, f in zip(row, self._attribute_elem_form_names)
+                    ]
                 )
-            ) for row in response["data"]["headers"]["rows"]
+            )
+            for row in response["data"]["headers"]["rows"]
         ]
 
     def __extract_paging_info(self, response):
         # extract paging info
         self.chunk_size = response["data"]["paging"]["limit"]
         self.total_rows = response["data"]["paging"]["total"]
 
     @staticmethod
     def __extract_metric_values(response):
         return response["data"]["metricValues"]["raw"]
 
     @staticmethod
     def __extract_metric_col_names(response):
         if response["definition"]["grid"]["columns"]:
-            return [i['name'] for i in response["definition"]["grid"]["columns"][-1]["elements"]]
+            return [
+                i['name']
+                for i in response["definition"]["grid"]["columns"][-1]["elements"]
+            ]
         else:
             return []
 
     @staticmethod
     def __extract_attribute_form_names(response):
         # extract attribute form names
-        return [[e["name"] for e in i["forms"]] for i in response["definition"]["grid"]["rows"]]
+        return [
+            [form["name"] for form in attribute["forms"]]
+            for attribute in response["definition"]["grid"]["rows"]
+        ]
 
     @staticmethod
     def __extract_attribute_names(response):
-        return [i["name"] for i in response["definition"]["grid"]["rows"]]
+        return [
+            attribute["name"] for attribute in response["definition"]["grid"]["rows"]
+        ]
 
     def __get_attribute_col_names(self):
         # extract and format attribute form column labels
         col_names = []
         for attr, forms in zip(self._attribute_names, self._attribute_elem_form_names):
             if len(forms) == 1:
-                # if only one form, do not display the attribute form type in the column headers  # noqa
+                # if only one form, do not display the attribute form type
+                # in the column headers
                 col_names.append(attr)
             else:
-                # otherwise concatenate the attribute name, separator, and form type  # noqa
+                # otherwise concatenate the attribute name, separator,
+                # and form type
                 for form in forms:
                     col_names.append(attr + self.AF_COL_SEP + form)
 
         return col_names
 
+    def has_multiform_attributes(self):
+        return any(len(item) > 1 for item in self._attribute_elem_form_names)
+
     @property
     def dataframe(self):
         return self.__to_dataframe()
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/progress_bar_mixin.py` & `mstrio-py-11.3.9.103/mstrio/utils/progress_bar_mixin.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,15 +10,15 @@
         self,
         desc: str,
         total: Union[int, float],
         unit: Optional[str] = None,
         initial: Union[int, float] = 0,
         bar_format: Optional[str] = None,
         leave: bool = True,
-        **kwargs
+        **kwargs,
     ):
         """Create and display progress bar. Needs to be closed with
         `close_progress_bar`, when updates no longer needed.
 
         Args:
             desc : str, optional
                 Prefix for the progressbar.
@@ -43,33 +43,35 @@
                 postfix, unit_divisor, remaining, remaining_s, eta.
                 Note that a trailing ": " is automatically removed after {desc}
                 if the latter is empty.
             initial : int or float, optional
                 The initial counter value. Useful when restarting a progress
                 bar [default: 0]. If using float, consider specifying {n:.3f} or
                 similar in bar_format, or specifying unit_scale.
-            """
+        """
         self._progress_bar = tqdm(
             total=total,
             desc=desc,
             unit=unit,
             bar_format=bar_format,
             initial=initial,
             leave=leave,
-            **kwargs
+            **kwargs,
         )
 
     def _close_progress_bar(self):
         """Close progress bar when no longer needed. Blocks updates with
         `update_progress_bar_if_needed`."""
         self._progress_bar.close()
         self._progress_bar = None
 
     def _update_progress_bar_if_needed(
-        self, new_description: Optional[str] = None, update_increment: Union[int, float] = 1
+        self,
+        new_description: Optional[str] = None,
+        update_increment: Union[int, float] = 1,
     ):
         """Updates the state of the progress bar.
         Use it after `display_progress_bar`.
         Args:
             new_description(str): New description of the progress bar
             update_increment: value used when updating progress bar"""
         if self._progress_bar is not None:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/resources/locales.py` & `mstrio-py-11.3.9.103/mstrio/utils/resources/locales.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,103 +1,103 @@
 def get_locales():
     return [
         {
             "id": "000008044F95EF3956E52781700C1E7A",
             "name": "Chinese (Simplified)",
-            "abbreviation": "zh-CN"
+            "abbreviation": "zh-CN",
         },
         {
             "id": "000004044F95EF3956E52781700C1E7A",
             "name": "Chinese (Traditional)",
-            "abbreviation": "zh-TW"
+            "abbreviation": "zh-TW",
         },
         {
             "id": "000004064F95EF3956E52781700C1E7A",
             "name": "Danish (Denmark)",
-            "abbreviation": "da-DK"
+            "abbreviation": "da-DK",
         },
         {
             "id": "000004134F95EF3956E52781700C1E7A",
             "name": "Dutch (Netherlands)",
-            "abbreviation": "nl-NL"
+            "abbreviation": "nl-NL",
         },
         {
             "id": "000008094F95EF3956E52781700C1E7A",
             "name": "English (United Kingdom)",
-            "abbreviation": "en-UK"
+            "abbreviation": "en-UK",
         },
         {
             "id": "000004094F95EF3956E52781700C1E7A",
             "name": "English (United States)",
-            "abbreviation": "en-US"
+            "abbreviation": "en-US",
         },
         {
             "id": "0000080C4F95EF3956E52781700C1E7A",
             "name": "French (Belgium)",
-            "abbreviation": "fr-BE"
+            "abbreviation": "fr-BE",
         },
         {
             "id": "0000040C4F95EF3956E52781700C1E7A",
             "name": "French (France)",
-            "abbreviation": "fr-FR"
+            "abbreviation": "fr-FR",
         },
         {
             "id": "0000100C4F95EF3956E52781700C1E7A",
             "name": "French (Switzerland)",
-            "abbreviation": "fr-CH"
+            "abbreviation": "fr-CH",
         },
         {
             "id": "000004074F95EF3956E52781700C1E7A",
             "name": "German (Germany)",
-            "abbreviation": "de-DE"
+            "abbreviation": "de-DE",
         },
         {
             "id": "000008074F95EF3956E52781700C1E7A",
             "name": "German (Switzerland)",
-            "abbreviation": "de-CH"
+            "abbreviation": "de-CH",
         },
         {
             "id": "000004104F95EF3956E52781700C1E7A",
             "name": "Italian (Italy)",
-            "abbreviation": "it-IT"
+            "abbreviation": "it-IT",
         },
         {
             "id": "000008104F95EF3956E52781700C1E7A",
             "name": "Italian (Switzerland)",
-            "abbreviation": "it-CH"
+            "abbreviation": "it-CH",
         },
         {
             "id": "000004114F95EF3956E52781700C1E7A",
             "name": "Japanese",
-            "abbreviation": "ja-JP"
+            "abbreviation": "ja-JP",
         },
         {
             "id": "000004124F95EF3956E52781700C1E7A",
             "name": "Korean",
-            "abbreviation": "ko-KR"
+            "abbreviation": "ko-KR",
         },
         {
             "id": "000004154F95EF3956E52781700C1E7A",
             "name": "Polish",
-            "abbreviation": "pl-PL"
+            "abbreviation": "pl-PL",
         },
         {
             "id": "000004164F95EF3956E52781700C1E7A",
             "name": "Portuguese (Brazil)",
-            "abbreviation": "pt-PT"
+            "abbreviation": "pt-PT",
         },
         {
             "id": "000004194F95EF3956E52781700C1E7A",
             "name": "Russian",
-            "abbreviation": "ru-RU"
+            "abbreviation": "ru-RU",
         },
         {
             "id": "00000C0A4F95EF3956E52781700C1E7A",
             "name": "Spanish (Spain)",
-            "abbreviation": "es-ES"
+            "abbreviation": "es-ES",
         },
         {
             "id": "0000041D4F95EF3956E52781700C1E7A",
             "name": "Swedish (Sweden)",
-            "abbreviation": "sv-SE"
-        }
+            "abbreviation": "sv-SE",
+        },
     ]
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/sessions.py` & `mstrio-py-11.3.9.103/mstrio/utils/sessions.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,42 +1,41 @@
 import functools
 import logging
 
 from requests_futures.sessions import FuturesSession
 
 
 class FuturesSessionWithRenewal(FuturesSession):
-
     def __init__(self, *, connection, **kwargs):
         super().__init__(session=connection._session, **kwargs)
         self.connection = connection
 
     def request(self, *args, **kwargs):
         if self.connection._is_session_expired():
             self.connection._renew_or_reconnect()
 
         return super().request(*args, **kwargs)
 
 
 def renew_session(func):
-
     @functools.wraps(func)
     def wrapper(self, *args, **kwargs):
-        if not kwargs.pop('skip_expiration_check', False) and self._is_session_expired():
+        if (
+            not kwargs.pop('skip_expiration_check', False)
+            and self._is_session_expired()
+        ):
             self._renew_or_reconnect()
 
         return func(self, *args, **kwargs)
 
     return wrapper
 
 
 def log_request(logger):
-
     def decorator(func):
-
         @functools.wraps(func)
         def wrapper(self, url, *args, **kwargs):
             if logger.isEnabledFor(logging.DEBUG):
                 logger.debug("method = %s url = '%s'", func.__name__.upper(), url)
                 logger.debug("headers = %s", self._session.headers)
                 logger.debug("headers additional = %s", kwargs.get('headers'))
                 logger.debug("body = %s", kwargs.get('json'))
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/settings/base_settings.py` & `mstrio-py-11.3.9.103/mstrio/utils/settings/base_settings.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,20 @@
 from pandas import DataFrame, Series
 
 from mstrio import config
 import mstrio.utils.helper as helper
 
 from .setting_types import DeprecatedSetting, SettingValue, SettingValueFactory
 from .settings_helper import convert_settings_to_byte, convert_settings_to_mega_byte
-from .settings_io import CSVSettingsIO, JSONSettingsIO, PickleSettingsIO, SettingsSerializerFactory
+from .settings_io import (
+    CSVSettingsIO,
+    JSONSettingsIO,
+    PickleSettingsIO,
+    SettingsSerializerFactory,
+)
 
 logger = logging.getLogger(__name__)
 
 
 class BaseSettings(metaclass=ABCMeta):
     """Base class for fetching and updating Project or Server Settings. The
     settings object can be optionally initialized with `connection` and `id`,
@@ -26,14 +31,15 @@
     `import_from()` method. Settings attributes can be modified manually.
     Lastly, the settings object can be validated and applied to a given object
     (Project, Server) using the `update()` method.
 
     Attributes:
         settings: settings
     """
+
     _CONFIG: Dict = {}
     # !NOTE define in child classes
     _TYPE: Union[str, None] = None
     _READ_ONLY: List[str] = []
     _CONVERSION_MAP: Dict[str, str] = {}
 
     def alter(self, **settings):
@@ -65,15 +71,17 @@
         """Fetch the settings config to be used in this Settings class."""
         for setting, cfg in self._CONFIG.items():
             setting_type = cfg.get('type')
             if setting_type is None:
                 self._READ_ONLY.append(setting)
             cfg.update({'name': setting})
 
-    def compare_with_files(self, files: List[str], show_diff_only: bool = False) -> DataFrame:
+    def compare_with_files(
+        self, files: List[str], show_diff_only: bool = False
+    ) -> DataFrame:
         """Compare the current project settings to settings in file/files
         Args:
             files (str): List of paths to the settings files. Supported settings
                 files are JSON, CSV, Pickle. Ex: "/file.csv"
             show_diff_only(bool, optional): Whether to display all settings or
                 only different from first project in list.
         Returns:
@@ -91,15 +99,16 @@
             index = Series([True] * len(current['setting']))
             for proj_name in files:
                 compare = current[base].eq(current[proj_name])
                 index = compare & index
             current = current[~index]
             if current.empty and config.verbose:
                 logger.info(
-                    'There is no difference between current settings and settings from files.'
+                    'There is no difference between current settings and settings '
+                    'from files.'
                 )
         return current
 
     def to_csv(self, name: str) -> None:
         """Export the current project settings to the csv file.
 
         Args:
@@ -132,15 +141,15 @@
         serializer = SettingsSerializerFactory().get_serializer(file)
         settings_dict = serializer.from_file(file, self)
 
         # Try to validate settings by fetching settings from I-Server
         self._validate_settings(settings_dict)
 
         # If no Exception was raised, assign the settings to the object
-        for (setting, value) in settings_dict.items():
+        for setting, value in settings_dict.items():
             setattr(self, setting, value)
         if config.verbose:
             logger.info(f"Settings imported from '{file}'")
 
     def list_properties(self, show_names: bool = True) -> dict:
         """Return settings and their values as dictionary.
 
@@ -160,15 +169,17 @@
                 for key in sorted(self.__dict__)
                 if not key.startswith('_')
             }
 
     def to_dataframe(self) -> DataFrame:
         """Return a `DataFrame` object containing settings and their values."""
 
-        df = DataFrame.from_dict(self.list_properties(), orient='index', columns=['value'])
+        df = DataFrame.from_dict(
+            self.list_properties(), orient='index', columns=['value']
+        )
         df.reset_index(inplace=True)
         df.rename({'index': 'setting'}, axis=1, inplace=True)
         return df
 
     @property
     def info(self) -> None:
         if version_info.major >= 3 and version_info.minor >= 7:
@@ -179,23 +190,20 @@
     @property
     def setting_types(self) -> DataFrame:
         df = DataFrame.from_dict(self._CONFIG, orient='index')
         df.drop(
             ['name', 'read_only', 'reboot_rule', 'deprecated'],
             axis='columns',
             inplace=True,
-            errors='ignore'
+            errors='ignore',
         )
         return df
 
     def _validate_settings(
-        self,
-        settings: Optional[dict] = None,
-        bad_setting=Warning,
-        bulk_error=True
+        self, settings: Optional[dict] = None, bad_setting=Warning, bulk_error=True
     ) -> None:
         """Validate setting-value pairs and raise AttributeError or TypeError
         if invalid. If `bad_setting` or `bad_type` is of type Exception, then
         Exception is raised as soon as the first invalid pair is found. If they
         are of type Warning the validation will continue and not raise error.
 
         Raises:
@@ -218,29 +226,29 @@
                     if not valid:
                         bad_settings_keys.append((setting, value))
         if bulk_error and bad_settings_keys:
             helper.exception_handler(
                 "Invalid settings: {}".format(
                     [item[0] + ': ' + str(item[1]) for item in bad_settings_keys]
                 ),
-                exception_type=ValueError
+                exception_type=ValueError,
             )
 
     def _prepare_settings_push(self) -> dict:
-
         def to_rest_format(settings: dict) -> dict:
-            return {k: {'value': v} for k, v in settings.items() if k not in self._READ_ONLY}
+            return {
+                k: {'value': v} for k, v in settings.items() if k not in self._READ_ONLY
+            }
 
         settings = self.list_properties(show_names=False)
         settings = convert_settings_to_byte(settings, self._CONVERSION_MAP)
         settings = to_rest_format(settings)
         return settings
 
     def _prepare_settings_fetch(self, settings: dict) -> dict:
-
         def from_rest_format(settings: dict) -> dict:
             return {k: v['value'] for k, v in settings.items()}
 
         settings = from_rest_format(settings)
         settings = convert_settings_to_mega_byte(settings, self._CONVERSION_MAP)
         return settings
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/settings/setting_types.py` & `mstrio-py-11.3.9.103/mstrio/utils/settings/setting_types.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,25 +1,24 @@
 import warnings
 
 import mstrio.utils.helper as helper
 
 
-class SettingValueFactory():
-
+class SettingValueFactory:
     def get_setting(self, config: dict) -> "SettingValue":
         setting_value_types = {
             'number': NumberSetting,
             'string': StringSetting,
             'enum': EnumSetting,
             'boolean': BoolSetting,
             'time': TimeSetting,
             'email': EmailSetting,
             'object': ObjectSetting,
             'mstr_object': MstrObjectSetting,
-            None: DeprecatedSetting
+            None: DeprecatedSetting,
         }
         setting_type = config.get('type')
         return setting_value_types[setting_type](config)
 
 
 class SettingValue:
     """Base Settings Value class.
@@ -63,14 +62,15 @@
     @property
     def info(self):
         return self.__dict__
 
 
 class EnumSetting(SettingValue):
     """Representation of an Enum setting type."""
+
     # initially empty options that require additional action
     # to be available (e.g. creating a TimeZone object)
     _DYNAMICALLY_ADDED_OPTIONS = {'defaultTimezone': str}
 
     def __init__(self, config: dict):
         super().__init__(config)
         config_name = config.get('name')
@@ -121,40 +121,47 @@
         return helper.validate_param_value(
             self.name,
             value,
             self.type,
             self.max_value,
             self.min_value,
             options,
-            exception=exception
+            exception=exception,
         )
 
 
 class StringSetting(SettingValue):
     """Representation of a String setting type."""
 
     def __init__(self, config: dict):
         super().__init__(config)
         self.type = list if self.multi_select else str
 
     def _validate_value(self, value, exception=True):
-        return helper.validate_param_value(self.name, value, self.type, exception=exception)
+        return helper.validate_param_value(
+            self.name, value, self.type, exception=exception
+        )
 
 
 class TimeSetting(SettingValue):
     """Representation of a Time setting type."""
 
     def __init__(self, config: dict):
         super().__init__(config)
         self.type = list if self.multi_select else str
 
     def _validate_value(self, value, exception=True):
         regex = r"^[1-2][0-9](:[0-5][0-9]){1,2}$"
         return helper.validate_param_value(
-            self.name, value, str, regex=regex, exception=exception, valid_example='23:45'
+            self.name,
+            value,
+            str,
+            regex=regex,
+            exception=exception,
+            valid_example='23:45',
         )
 
 
 class EmailSetting(SettingValue):
     """Representation of a Email setting type."""
 
     def __init__(self, config: dict):
@@ -166,15 +173,15 @@
         return helper.validate_param_value(
             self.name,
             value,
             self.type,
             special_values=[''],
             regex=regex,
             exception=exception,
-            valid_example='name@mail.com'
+            valid_example='name@mail.com',
         )
 
 
 class ObjectSetting(SettingValue):
     """Representation of an Object setting type."""
 
     def __init__(self, config: dict):
@@ -197,15 +204,17 @@
 
     def __init__(self, config: dict):
         self.value = None
         self.name = config.get('name')
         self.description = config.get('description')
 
     def _validate_value(self, value):
-        msg = f"Setting '{self.name}' with value '{value}' is deprecated and is read-only"
+        msg = (
+            f"Setting '{self.name}' with value '{value}' is deprecated and is read-only"
+        )
         warnings.warn(msg, DeprecationWarning)
         return True
 
     def __repr__(self):
         return str(self._get_value())
 
     def _get_value(self):
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/settings/settings_helper.py` & `mstrio-py-11.3.9.103/mstrio/utils/settings/settings_helper.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,21 @@
 def convert_settings_to_byte(settings: dict, mapping: dict) -> dict:
-
     def convert(setting, value):
         unit = mapping.get(setting)
         if unit is not None:
             if unit == 'B':
                 return value * (1024**2)
             elif unit == 'KB':
                 return value * 1024
         return value
 
     return {setting: convert(setting, value) for setting, value in settings.items()}
 
 
 def convert_settings_to_mega_byte(settings: dict, mapping: dict) -> dict:
-
     def convert(setting, value):
         unit = mapping.get(setting)
         if unit is not None:
             if unit == 'B':
                 return value // (1024**2)
             elif unit == 'KB':
                 return value // 1024
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/settings/settings_io.py` & `mstrio-py-11.3.9.103/mstrio/utils/settings/settings_io.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,25 +16,25 @@
     from mstrio.utils.settings.base_settings import BaseSettings
 
 logger = logging.getLogger(__name__)
 
 EXPORTED_MSG = "Settings exported to"
 
 
-class SettingsSerializerFactory():
-
+class SettingsSerializerFactory:
     def get_serializer(self, file):
         file_type = None
         for extension in ['.json', '.csv', '.p', '.pkl', '.pickle']:
             if extension in file[-7:].lower():
                 file_type = extension[1:]
 
         if file_type is None:
             raise ValueError(
-                "This file type is not supported. Supported file types are .json, .csv, .pickle"
+                "This file type is not supported. Supported file types are .json, .csv,"
+                " .pickle"
             )
         elif file_type == 'json':
             return JSONSettingsIO()
         elif file_type == 'csv':
             return CSVSettingsIO()
         elif file_type in ['pkl', 'pickle', 'p']:
             return PickleSettingsIO()
@@ -55,21 +55,24 @@
 
     @classmethod
     def validate_file_name(cls, file):
         if not isinstance(cls.FILE_NAME, (str, tuple)):
             raise ValueError("FILE_NAME not defined")
         elif not file.endswith(cls.FILE_NAME):
             msg = (
-                f'The file extension is different than {cls.FILE_NAME}, please note that using'
-                ' a different extension might disrupt opening the file correctly.'
+                f"The file extension is different than {cls.FILE_NAME}, please note "
+                f"that using a different extension might disrupt opening the file "
+                f"correctly."
             )
             helper.exception_handler(msg, exception_type=Warning)
 
     @classmethod
-    def check_type(cls, settings_type: Union[str, None], settings_obj: "BaseSettings") -> None:
+    def check_type(
+        cls, settings_type: Union[str, None], settings_obj: "BaseSettings"
+    ) -> None:
         if settings_type is None:
             return None
         elif settings_type != settings_obj._TYPE:
             raise TypeError('Unsupported settings.')
 
     @classmethod
     def check_version(
@@ -108,21 +111,22 @@
         settings_dict = settings_obj.list_properties(show_names=False)
 
         with open(file, 'wb') as f:
             # save version and type
             settings_dict.update(
                 __version__=cls.get_version(settings_obj), __page__=settings_obj._TYPE
             )
-            pickle.dump(settings_dict, f, protocol=4)  # pickle protocol added in python 3.4
+            pickle.dump(
+                settings_dict, f, protocol=4
+            )  # pickle protocol added in python 3.4
         if config.verbose:
             logger.info(f"{EXPORTED_MSG} '{file}'")
 
     @classmethod
     def from_file(cls, file: str, settings_obj: "BaseSettings") -> dict:
-
         with open(file, 'rb') as f:
             settings_dict = pickle.load(f)
 
             # check versioning and type
             version = settings_dict.pop("__version__", None)
             settings_type = settings_dict.pop('__page__', None)
             cls.check_type(settings_type, settings_obj)
@@ -153,15 +157,14 @@
             )
             json.dump(settings_dict, f, indent=4)
         if config.verbose:
             logger.info(f"{EXPORTED_MSG} '{file}'")
 
     @classmethod
     def from_file(cls, file: str, settings_obj: "BaseSettings") -> dict:
-
         with open(file) as f:
             settings_dict = json.load(f)
 
             # check versioning and type
             version = settings_dict.pop("__version__", None)
             settings_type = settings_dict.pop('__page__', None)
             cls.check_type(settings_type, settings_obj)
@@ -186,26 +189,30 @@
         # newline = '' to disable universal newlines translation
         # It should always be safe to specify newline='', since the csv module
         # does its own (universal) newline handling.
         # https://docs.python.org/3/library/csv.html#examples
         with open(file, 'w', newline='') as f:
             # Add lines for workstation compatibility
             version = cls.get_version(settings_obj)
-            f.write(f"#__page__,{settings_obj._TYPE}\n#__version__,{version}\nName, Value\n")
+            f.write(
+                f"#__page__,{settings_obj._TYPE}\n#__version__,{version}\nName, Value\n"
+            )
             w = csv.DictWriter(f, fieldnames=['Name', 'Value'], quoting=csv.QUOTE_ALL)
 
             settings_dict = settings_obj.list_properties(show_names=False)
-            rows = [{'Name': setting, 'Value': value} for setting, value in settings_dict.items()]
+            rows = [
+                {'Name': setting, 'Value': value}
+                for setting, value in settings_dict.items()
+            ]
             w.writerows(rows)
             if config.verbose:
                 logger.info(f"{EXPORTED_MSG} '{file}'")
 
     @classmethod
     def from_file(cls, file: str, settings_obj: "BaseSettings") -> dict:
-
         with open(file) as f:
             settings_dict = dict(csv.reader(f, quoting=csv.QUOTE_ALL))
             return cls.process_csv_settings(settings_dict, settings_obj)
 
     @classmethod
     def process_csv_settings(cls, settings: dict, settings_obj: "BaseSettings") -> dict:
         """Helper function to extract settings from csv settings files."""
@@ -237,15 +244,17 @@
             processed_settings = convert_settings_to_mega_byte(
                 processed_settings, settings_obj._CONVERSION_MAP
             )
 
         return processed_settings
 
     @classmethod
-    def check_type(cls, settings_type: Union[str, None], settings_obj: "BaseSettings") -> None:
+    def check_type(
+        cls, settings_type: Union[str, None], settings_obj: "BaseSettings"
+    ) -> None:
         if settings_type is None:
             raise ValueError('CSV settings are missing `#__page__` header')
         elif settings_type != settings_obj._TYPE:
             raise TypeError('Unsupported settings.')
 
     @classmethod
     def check_version(cls, version: Union[int, None], settings_type: str) -> None:
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/time_helper.py` & `mstrio-py-11.3.9.103/mstrio/utils/time_helper.py`

 * *Files 3% similar despite different names*

```diff
@@ -39,28 +39,32 @@
     initial_date = date
 
     # save localization of date (if any) for later parsing
     if date[-1] == 'Z':
         date = date[:-1]
     plus_index = date.find('+')
     percent_z_index = format_str.find('%z')
-    localization = '' if plus_index == -1 or percent_z_index == -1 else date[plus_index:]
+    localization = (
+        '' if plus_index == -1 or percent_z_index == -1 else date[plus_index:]
+    )
     date = date[:plus_index] if plus_index != -1 else date
 
     # fill time with zeros to match the format with maximum number of details
     t_index = date.find('T')
     if t_index == -1:  # there is no time in the date
         date += 'T00:00:00.000'
         t_index = date.find('T')  # calculate again as this value was changed
     elif t_index + 3 == len(date):  # T00
         date += ':00:00.000'
     elif t_index + 6 == len(date):  # T00:00
         date += ':00.000'
     elif t_index + 9 == len(date):  # T00:00:00
         date += '.000'
+    elif t_index + 13 < len(date):
+        date = date[: t_index + 13]
 
     # cut `date` to match the provided format
     dot_index = date.find('.')
 
     if _without_loc(format_str) == _without_loc(DatetimeFormats.YMDHMSmS.value):
         # when `format_str` is equal to value of `DatetimeFormats.YMDHMSms`
         # then `date` is properly prepared and doesn't need any more changes
@@ -68,17 +72,18 @@
     elif _without_loc(format_str) == _without_loc(DatetimeFormats.YMDHMS.value):
         date = date[:dot_index]
     elif _without_loc(format_str) == _without_loc(DatetimeFormats.YMD.value):
         date = date[:t_index]
         localization = ''  # don't add localization if format is without time
     else:
         from mstrio.utils.helper import exception_handler
+
         msg = (
-            f"For given format of date ({format_str}) adapting date to such format is not"
-            "provided."
+            f"For given format of date ({format_str}) adapting date to such format "
+            f"is not provided."
         )
         exception_handler(msg, Warning)
         return (initial_date, format_str)
 
     # add localization prepared before if needed
     date += localization
 
@@ -141,27 +146,35 @@
         key: value
         for (key, value) in string_to_date_map.items()
         if isinstance(value, DatetimeFormats)
     }
 
 
 def _solve_prefix_and_convert_date(
-    func, name: str, date: str, string_to_date_map: dict, only_datetimefomat: bool = True
+    func,
+    name: str,
+    date: str,
+    string_to_date_map: dict,
+    only_datetimefomat: bool = True,
 ):
     if only_datetimefomat:
         string_to_date_map = _get_only_datetimeformat_map(string_to_date_map)
     if f'_{name}' in string_to_date_map:
-        date_format = string_to_date_map[f'_{name}'].value if isinstance(
-            string_to_date_map[f'_{name}'], DatetimeFormats
-        ) else string_to_date_map[f'_{name}']
+        date_format = (
+            string_to_date_map[f'_{name}'].value
+            if isinstance(string_to_date_map[f'_{name}'], DatetimeFormats)
+            else string_to_date_map[f'_{name}']
+        )
         return func(date, date_format)
     elif name in string_to_date_map:
-        date_format = string_to_date_map[name].value if isinstance(
-            string_to_date_map[name], DatetimeFormats
-        ) else string_to_date_map[name]
+        date_format = (
+            string_to_date_map[name].value
+            if isinstance(string_to_date_map[name], DatetimeFormats)
+            else string_to_date_map[name]
+        )
         return func(date, date_format)
     return date
 
 
 def map_str_to_datetime(
     name: str, date: str, string_to_date_map: dict, only_datetimefomat: bool = True
 ) -> datetime:
@@ -191,26 +204,30 @@
 def bulk_str_to_datetime(
     source: dict, string_to_date_map: dict, only_datetimefomat: bool = True
 ) -> dict:
     """Change all dates from `source` found in `string_to_date_map`
     to datetime format. If parameter is not found in `string_to_date_map`,
     it is returned without changes."""
     for key, val in source.items():
-        source[key] = map_str_to_datetime(key, val, string_to_date_map, only_datetimefomat)
+        source[key] = map_str_to_datetime(
+            key, val, string_to_date_map, only_datetimefomat
+        )
     return source
 
 
 def bulk_datetime_to_str(
     source: dict, string_to_date_map: dict, only_datetimefomat: bool = True
 ) -> dict:
     """Change all dates from `source` found in `string_to_date_map`
     to string format. If parameter is not found in `string_to_date_map`,
     it is returned without changes."""
     for key, val in source.items():
-        source[key] = map_datetime_to_str(key, val, string_to_date_map, only_datetimefomat)
+        source[key] = map_datetime_to_str(
+            key, val, string_to_date_map, only_datetimefomat
+        )
     return source
 
 
 def override_datetime_format(
     original_format: str, expected_format: str, fields: tuple, to_unpack=None
 ):
     """A decorator designed to override the datetime format
@@ -222,27 +239,27 @@
         expected_format: the format you want to convert to
         fields: fields of the object - e.g. dateModified, dateCreated
         to_unpack: when response returns a list of objects
             probably they need to be unpacked
     """
 
     def decorator_datetime(func):
-
         @wraps(func)
         def wrapped(*args, **kwargs):
             response = func(*args, **kwargs)
             response_json = response.json()
             try:
                 iterable = response_json[to_unpack] if to_unpack else [response_json]
             except KeyError:
                 iterable = []
             for obj in iterable:
                 for field in fields:
                     datetime_obj = str_to_datetime(obj[field], original_format)
                     obj[field] = datetime_to_str(datetime_obj, expected_format)
-            response.encoding, response._content = 'utf-8', json.dumps(response_json).encode(
-                'utf-8')
+            response.encoding, response._content = 'utf-8', json.dumps(
+                response_json
+            ).encode('utf-8')
             return response
 
         return wrapped
 
     return decorator_datetime
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/version_helper.py` & `mstrio-py-11.3.9.103/mstrio/utils/version_helper.py`

 * *Files 1% similar despite different names*

```diff
@@ -23,16 +23,15 @@
         def inner(*args, **kwargs):
             if conn := kwargs.get('connection'):
                 connection_obj = conn
             elif conn := [arg for arg in args if isinstance(arg, Connection)]:
                 connection_obj = conn[0]
             elif cls:
                 raise TypeError(
-                    f"{function.__name__}() "
-                    "missing required argument: 'connection'"
+                    f"{function.__name__}() " "missing required argument: 'connection'"
                 )
             else:
                 connection_obj = getattr(args[0], 'connection', None) or getattr(
                     args[0], '_connection', None
                 )
 
             if version_parser(connection_obj.iserver_version) < version_parser(version):
```

### Comparing `mstrio-py-11.3.9.101/mstrio/utils/wip.py` & `mstrio-py-11.3.9.103/mstrio/utils/wip.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,16 +8,17 @@
 
 from packaging.version import Version
 
 from .exceptions import NotSupportedError
 from .. import __version__, config
 
 logger = logging.getLogger(__name__)
-logging.basicConfig(level=logging.INFO, format='%(message)s', stream=sys.stderr)  # NOSONAR
-
+logging.basicConfig(  # NOSONAR
+    level=logging.INFO, format='%(message)s', stream=sys.stderr
+)
 current_version = Version(__version__)
 
 
 class WipLevels(Enum):
     SILENT = auto()
     PREVIEW = auto()
     INFO = auto()
@@ -31,15 +32,17 @@
 
 message_templates = {
     WipLevels.PREVIEW: (
         "In a current version, {}is available as "
         "a Functionality Preview. It is subject to change until it is released "
         "as Generally Available."
     ),
-    WipLevels.INFO: "This {}functionality is a work-in-progress. It may change in future updates.",
+    WipLevels.INFO: (
+        "This {}functionality is a work-in-progress. It may change in future updates."
+    ),
     WipLevels.WARNING: (
         "This {}functionality is a work-in-progress. Use it only if you understand"
         " the underlying code. It may change in future updates."
     ),
     WipLevels.ERROR: (
         "This {}functionality is a work-in-progress. It has been deemed unsafe to use"
         " and is currently blocked."
@@ -64,15 +67,15 @@
     else:
         return message_templates[WipLevels.INFO]
 
 
 def _construct_message(
     name: Optional[str] = None,
     target_release: Optional[Union[Version, str]] = None,
-    level: WipLevels = WipLevels.WARNING
+    level: WipLevels = WipLevels.WARNING,
 ):
     template = _get_message_template(level)
     if name is None:
         message = template.format("")
     else:
         message = template.format(f"({name}) ")
     if target_release is not None:
@@ -80,15 +83,15 @@
     return message
 
 
 def _emit(
     name: Optional[str] = None,
     target_release: Optional[Union[Version, str]] = None,
     level: WipLevels = WipLevels.WARNING,
-    message: Optional[str] = None
+    message: Optional[str] = None,
 ):
     if level == WipLevels.SILENT or not config.wip_warnings_enabled:
         return None
 
     if message is None:
         message = _construct_message(name, target_release, level)
 
@@ -103,15 +106,15 @@
 
 
 def wip(
     target_release: Optional[Union[Version, str]] = None,
     level: WipLevels = WipLevels.WARNING,
     message: Optional[str] = None,
     prefix_doc: Union[bool, str] = True,
-    mark_attr: bool = True
+    mark_attr: bool = True,
 ):
     """Work-In-Progress wrapper
 
     Note:
         This is a decorator generator, which accepts arguments and returns the
         actual decorator, so even when not providing arguments and letting it
         choose the defaults it should be used like `@wip()`, not plain `@wip`.
@@ -140,15 +143,14 @@
                 "WIP wrapper called with target_release equal to"
                 " or lower than current release."
             )
     if level not in WipLevels:
         _wiplevel_error(level)
 
     def wrap_func(f):
-
         @functools.wraps(f)
         def wrapped(*args, **kwargs):
             _emit(wrapped.__name__, target_release, level, message)
             return f(*args, **kwargs)
 
         if mark_attr:
             wrapped._wip = True  # This makes it trivial to programmatically check.
@@ -171,15 +173,15 @@
 
 def module_wip(
     module_globals: dict,
     target_release: Optional[Union[Version, str]] = None,
     level: WipLevels = WipLevels.WARNING,
     message: Optional[str] = None,
     prefix_doc: Union[bool, str] = True,
-    mark_attr: bool = True
+    mark_attr: bool = True,
 ):
     """Emit the WIP warning/error/info when the module is loaded."""
     if mark_attr:
         module_globals["_wip"] = True
     if prefix_doc:
         if not module_globals["__doc__"]:
             module_globals["__doc__"] = ""
```

### Comparing `mstrio-py-11.3.9.101/mstrio_py.egg-info/PKG-INFO` & `mstrio-py-11.3.9.103/mstrio_py.egg-info/PKG-INFO`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mstrio-py
-Version: 11.3.9.101
+Version: 11.3.9.103
 Summary: Python interface for the MicroStrategy REST API
 Home-page: https://github.com/MicroStrategy/mstrio-py
 Author: MicroStrategy
 Author-email: pkowal@microstrategy.com
 License: Apache License 2.0
 Project-URL: Bug Tracker, https://github.com/MicroStrategy/mstrio-py/issues
 Project-URL: Documentation, http://www2.microstrategy.com/producthelp/Current/mstrio-py/
@@ -79,25 +79,27 @@
 
 - Import and filter data from a **OlapCube**, **SuperCube** or **Report** into a Pandas DataFrame (see [code_snippets][code_snippet_import])
 - Export data into MicroStrategy by creating or updating **SuperCube** (see [code_snippets][code_snippet_export])
 
 Since version **11.3.0.1**, **mstrio-py** includes also administration modules:
 
 - **Project** management module (see [code_snippets][code_snippet_project])
+with **VLDB settings** management (see [code_snippets][code_snippet_vldb])
 - **Server** management module (see [code_snippets][code_snippet_server])
 - **User** and **User Group** management modules (see [code_snippets][code_snippet_user])
 - **Schedules** management module (see [code_snippets][code_snippet_schedules])
 - **Subscription** management modules including **Email Subscription**,  **Cache Update Subscription**, **File Subscription**, **FTP Subscription** and **History List Subscription** (see [code_snippets][code_snippet_subs])
 - **User Library** module (see [code_snippets][code_snippet_library])
 - **User Connections** management module
 - **Privilege** and **Security Role** management modules (see [code_snippets][code_snippet_privilege])
 - **Cube Cache** management modules (see [code_snippets][code_snippet_cache])
 - **Intelligent Cube** management modules (see [code_snippets][code_snippet_olap])
 - **Security filter** module (see [code_snippets][code_snippet_security_filter])
 - **Datasources and Connection Mapping** subpackage for database management (see [code_snippets][code_snippet_datasource])
+with **VLDB settings** management (see [code_snippets][code_snippet_vldb])
 - **Job Monitor** module for job monitoring (see [code_snippets][code_snippet_job_monitor])
 - **Object management** module (see [code_snippets][code_snippet_object_mgmt])
 - **Contact** module (see [code_snippets][code_snippet_contact])
 - **Contact Group** module (see [code_snippets][code_snippet_contact_group])
 - **Device** module (see [code_snippets][code_snippet_device])
 - **Transmitter** module (see [code_snippets][code_snippet_transmitter])
 - **Event** module (see [code_snippets][code_snippet_events])
@@ -111,14 +113,17 @@
 - **Filter** module (see [code_snippets][code_snippet_filter])
 - **Transformation** module (see [code_snippets][code_snippet_transformation])
 - **Metric** module (see [code_snippets][code_snippet_metrics])
 - **Document** module (see [code_snippets][code_snippet_document])
 - **Dossier** module (see [code_snippets][code_snippet_dossier])
 - **Content Cache** module (see [code_snippets][code_snippet_content_cache])
 - **Dynamic Recipient List** module (see [code_snippets][code_snippet_dynamic_recipient_list])
+- **Driver** module (see [code_snippets][code_snippet_datasource])
+- **Gateway** module (see [code_snippets][code_snippet_datasource])
+
 
 <a id="documentation" name="documentation"></a>
 # Documentation
 
 Detailed information about **mstrio-py** package can be found in [**official documentation**][mstrio_py_doc].
 
 <a id="usage-remarks" name="usage-remarks"></a>
@@ -204,15 +209,15 @@
 jupyter nbextension install connector-jupyter --py --sys-prefix
 jupyter nbextension enable connector-jupyter --py --sys-prefix
 ```
 
 <a id="versioning--changelog" name="versioning--changelog"></a>
 # Versioning & Changelog
 
-Current version: **11.3.9.101** (3 March 2023). Check out [**Changelog**][release_notes] to see what's new.
+Current version: **11.3.9.103** (5 May 2023). Check out [**Changelog**][release_notes] to see what's new.
 
 mstrio-py is constantly developed to support newest MicroStrategy REST APIs. Functionalities may be added to mstrio on monthly basis. It is **recommended** to always install the newest version of mstrio-py, as it will be most stable and still maintain backwards compatibility with various MicroStrategy installations, dating back to 11.1.4.
 
 Features that will be added to the package but require APIs not supported by your environment (I-Server), will raise `VersionException`.
 
 mstrio-py can be used for both, **data-science** related activities and for **administrative tasks**. Former requires at least MicroStrategy 2019 Update 4 (11.1.4), latter works with 11.2.1 and higher.
 
@@ -295,7 +300,8 @@
 [code_snippet_privilege]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/security_roles_and_privileges.py
 [code_snippet_transformation]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/transformation.py
 [code_snippet_metrics]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/metrics.py
 [code_snippet_content_cache]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/content_cache.py
 [code_snippet_document]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/document.py
 [code_snippet_dossier]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/dossier.py
 [code_snippet_dynamic_recipient_list]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/dynamic_recipient_list.py
+[code_snippet_vldb]: https://github.com/MicroStrategy/mstrio-py/blob/master/code_snippets/vldb.py
```

### Comparing `mstrio-py-11.3.9.101/mstrio_py.egg-info/SOURCES.txt` & `mstrio-py-11.3.9.103/mstrio_py.egg-info/SOURCES.txt`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 LICENSE
 MANIFEST.in
 NEWS.md
 README.md
 requirements.txt
 setup.cfg
 setup.py
+version.txt
 code_snippets/attributes.py
 code_snippets/connect.py
 code_snippets/contact_group_mgmt.py
 code_snippets/contacts.py
 code_snippets/content_cache.py
 code_snippets/create_super_cube.py
 code_snippets/cube_cache.py
@@ -37,14 +38,15 @@
 code_snippets/table_mgmt.py
 code_snippets/transformation.py
 code_snippets/transmitter_mgmt.py
 code_snippets/user_hierarchy_mgmt.py
 code_snippets/user_library.py
 code_snippets/user_mgmt.py
 code_snippets/variables.json
+code_snippets/vldb.py
 connector-jupyter/.gitignore
 connector-jupyter/__init__.py
 connector-jupyter/package-lock.json
 connector-jupyter/package.json
 connector-jupyter/production/jupyter-config/nbconfig/notebook.d/mstr_jupyter.json
 connector-jupyter/production/mstr_jupyter/static/.eslintrc.js
 connector-jupyter/production/mstr_jupyter/static/MicroStrategy.yaml
@@ -101,19 +103,21 @@
 mstrio/api/contact_groups.py
 mstrio/api/contacts.py
 mstrio/api/cubes.py
 mstrio/api/datasets.py
 mstrio/api/datasources.py
 mstrio/api/devices.py
 mstrio/api/documents.py
+mstrio/api/drivers.py
 mstrio/api/events.py
 mstrio/api/exceptions.py
 mstrio/api/facts.py
 mstrio/api/filters.py
 mstrio/api/folders.py
+mstrio/api/gateways.py
 mstrio/api/hierarchies.py
 mstrio/api/hooks.py
 mstrio/api/incremental_refresh_reports.py
 mstrio/api/library.py
 mstrio/api/metrics.py
 mstrio/api/migration.py
 mstrio/api/misc.py
@@ -136,14 +140,17 @@
 mstrio/datasources/__init__.py
 mstrio/datasources/database_connections.py
 mstrio/datasources/datasource_connection.py
 mstrio/datasources/datasource_instance.py
 mstrio/datasources/datasource_login.py
 mstrio/datasources/datasource_map.py
 mstrio/datasources/dbms.py
+mstrio/datasources/driver.py
+mstrio/datasources/gateway.py
+mstrio/datasources/helpers.py
 mstrio/distribution_services/__init__.py
 mstrio/distribution_services/event.py
 mstrio/distribution_services/device/__init__.py
 mstrio/distribution_services/device/device.py
 mstrio/distribution_services/device/device_properties.py
 mstrio/distribution_services/schedule/__init__.py
 mstrio/distribution_services/schedule/schedule.py
@@ -253,17 +260,22 @@
 mstrio/utils/monitors.py
 mstrio/utils/object_mapping.py
 mstrio/utils/parser.py
 mstrio/utils/progress_bar_mixin.py
 mstrio/utils/sessions.py
 mstrio/utils/time_helper.py
 mstrio/utils/version_helper.py
+mstrio/utils/vldb_mixin.py
 mstrio/utils/wip.py
 mstrio/utils/resources/__init__.py
 mstrio/utils/resources/locales.py
+mstrio/utils/response_processors/__init__.py
+mstrio/utils/response_processors/drivers.py
+mstrio/utils/response_processors/gateways.py
+mstrio/utils/response_processors/objects.py
 mstrio/utils/settings/__init__.py
 mstrio/utils/settings/base_settings.py
 mstrio/utils/settings/setting_types.py
 mstrio/utils/settings/settings_helper.py
 mstrio/utils/settings/settings_io.py
 mstrio_py.egg-info/PKG-INFO
 mstrio_py.egg-info/SOURCES.txt
```

### Comparing `mstrio-py-11.3.9.101/requirements.txt` & `mstrio-py-11.3.9.103/requirements.txt`

 * *Files 11% similar despite different names*

```diff
@@ -1,117 +1,120 @@
 anyio==3.6.2
 appnope==0.1.3
 argon2-cffi==21.3.0
 argon2-cffi-bindings==21.2.0
 asttokens==2.2.1
 attrs==22.2.0
 backcall==0.2.0
-beautifulsoup4==4.11.1
-bleach==5.0.1
+beautifulsoup4==4.11.2
+black==23.1.0
+bleach==6.0.0
+build==0.10.0
 certifi==2022.12.7
 cffi==1.15.1
 cfgv==3.3.1
 charset-normalizer==3.0.1
 comm==0.1.2
-coverage==7.0.5
-debugpy==1.6.5
+coverage==7.1.0
+debugpy==1.6.6
 decorator==5.1.1
 defusedxml==0.7.1
 distlib==0.3.6
-entrypoints==0.4
 exceptiongroup==1.1.0
 executing==1.2.0
 fastjsonschema==2.16.2
 filelock==3.9.0
 flake8==6.0.0
+flake8-black==0.3.6
 flaky==3.7.0
-identify==2.5.13
+pyhumps==3.8.0
+identify==2.5.18
 idna==3.4
 iniconfig==2.0.0
-ipykernel==6.20.2
-ipython==8.8.0
+ipykernel==6.21.2
+ipython==8.10.0
 ipython-genutils==0.2.0
 ipywidgets==8.0.4
-isort==5.11.4
+isort==5.12.0
 jedi==0.18.2
 Jinja2==3.1.2
 jsonschema==4.17.3
 jupyter-contrib-core==0.4.2
 jupyter-contrib-nbextensions==0.5.1
 jupyter-events==0.6.3
 jupyter-highlight-selected-word==0.2.0
 jupyter-latex-envs==1.4.6
 jupyter-nbextensions-configurator==0.6.1
-jupyter_client==7.4.9
-jupyter_core==5.1.3
-jupyter_server==2.1.0
+jupyter_client==8.0.3
+jupyter_core==5.2.0
+jupyter_server==2.3.0
 jupyter_server_terminals==0.4.4
 jupyterlab-pygments==0.2.2
 jupyterlab-widgets==3.0.5
 lxml==4.9.2
 MarkupSafe==2.1.2
 matplotlib-inline==0.1.6
 mccabe==0.7.0
-mistune==2.0.4
-mypy==0.991
-mypy-extensions==0.4.3
-nbclassic==0.4.8
+mistune==2.0.5
+mypy==1.0.0
+mypy-extensions==1.0.0
+nbclassic==0.5.1
 nbclient==0.7.2
-nbconvert==7.2.8
+nbconvert==7.2.9
 nbformat==5.7.3
 nest-asyncio==1.5.6
 nodeenv==1.7.0
 nose==1.3.7
 notebook==6.5.2
 notebook_shim==0.2.2
-numpy==1.24.1
-packaging==21.3
+numpy==1.24.2
+packaging==22.0
 pandas==1.5.3
 pandocfilters==1.5.0
 parso==0.8.3
 pexpect==4.8.0
 pickleshare==0.7.5
-platformdirs==2.6.2
+platformdirs==3.0.0
 pluggy==1.0.0
-pre-commit==2.21.0
-prometheus-client==0.15.0
+pre-commit==3.0.4
+prometheus-client==0.16.0
 prompt-toolkit==3.0.36
 psutil==5.9.4
 ptyprocess==0.7.0
 pure-eval==0.2.2
 pycodestyle==2.10.0
 pycparser==2.21
 pyflakes==3.0.1
 Pygments==2.14.0
 pyparsing==3.0.9
 pyrsistent==0.19.3
 pytest==7.2.1
 pytest-cov==4.0.0
 python-dateutil==2.8.2
 python-decouple==3.7
-python-json-logger==2.0.4
+python-json-logger==2.0.6
 pytz==2022.7.1
 PyYAML==6.0
 pyzmq==25.0.0
 requests==2.28.2
 requests-futures==1.0.0
 Send2Trash==1.8.0
 setuptools==65.5.1
 six==1.16.0
 sniffio==1.3.0
-soupsieve==2.3.2.post1
+soupsieve==2.4
 stack-data==0.6.2
 stringcase==1.2.0
 terminado==0.17.1
 tinycss2==1.2.1
 tomli==2.0.1
 tornado==6.2
 tqdm==4.64.1
-traitlets==5.8.1
-typing_extensions==4.4.0
+traitlets==5.9.0
+typing_extensions==4.5.0
 urllib3==1.26.14
-virtualenv==20.17.1
+virtualenv==20.19.0
 wcwidth==0.2.6
 webencodings==0.5.1
-websocket-client==1.4.2
+websocket-client==1.5.1
 widgetsnbextension==4.0.5
 yapf==0.32.0
```

### Comparing `mstrio-py-11.3.9.101/setup.py` & `mstrio-py-11.3.9.103/setup.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,30 +1,35 @@
 import os
 
 import pkg_resources
 from setuptools import find_packages, setup
 from setuptools.extern.packaging import version as packaging_version
 
-from mstrio import (__author__, __author_email__, __description__, __license__, __title__,
-                    __version__)
+from mstrio import (
+    __author__,
+    __author_email__,
+    __description__,
+    __license__,
+    __title__,
+    __version__,
+)
 
 MANIFEST_FILE = 'MANIFEST.in'
 
 if 'version.txt' in os.listdir():
     with open('version.txt') as f:
         dist_version = f.read().strip()
 else:
     dist_version = __version__  # define the default version
 
 # Patch Version class to preserve original version string
 pkg_resources.safe_version = lambda v: v
 
 
 class NoNormalizeVersion(packaging_version.Version):
-
     def __init__(self, version):
         self._orig_version = version
         super().__init__(version)
 
     def __str__(self):
         return self._orig_version
 
@@ -40,47 +45,50 @@
 
 packaging_version.Version = NoNormalizeVersion
 with open('README.md') as f:
     long_description = f.read()
 
 
 peer_force_version = [  # peer dependency (dep of dep)
-                        # but we need to force version for SEC
-                        # backend only (front peers are
-                        # handled in code ~20 lines below)
+    # but we need to force version for SEC
+    # backend only (front peers are
+    # handled in code ~20 lines below)
     'urllib3>=1.26.0',  # ver 1.25.x is incompatible
-    'Jinja2>=3, <4',    # UI related, but also dev-dep of `pandas` but required for testing
+    'Jinja2>=3, <4',  # UI related, but also dev-dep of pandas but required for testing
     'certifi>=2022.12.7',  # SEC safe version
 ]
 
+# Update test_packages in PyExec integration tests if this list of requirements
+# is updated (new package is added or one of them is removed)
+# https://github.com/mstr-kiai/PyExec/blob/m2021/tests/integration/test_pyexec.py#L195
 requirements = [
     'requests>=2.27, <2.29',
     'requests-futures>=1.0.0, <1.1',
     'pandas>=1.1.5, <1.6',
     'numpy>=1.24, <1.25',
     'tqdm>=4.41, <4.70',
-    'packaging>=21.3, <22',
-    'stringcase>=1.2, <1.3'
+    'packaging>=22.0, <23.0',
+    'stringcase>=1.2, <1.3',
+    'pyhumps>=3.8',
 ] + peer_force_version
 
 # Add dependencies for connector-jupyter if connector-jupyter folder is added
 if find_in_file('graft connector-jupyter', MANIFEST_FILE):
     requirements += [
         # direct dependencies
         'jupyter-contrib-nbextensions>=0.5.1, <0.6',
         'ipywidgets>=8.0.2, <9',
-
         # peer, UI related, force version for SEC
         'notebook>=6.4.12',
         'jupyter_core>=4.11.2',
         'lxml>=4.9.1',
-        'ipython>=8.4.0, <9',
+        'ipython>=8.10.0, <9',
         'nbconvert>=7, <8',
         'mistune>=2.0.4',
-        'setuptools>=65.5.1'
+        'setuptools>=65.5.1',
     ]
 
 setup(
     name=__title__,
     python_requires='>=3.10',
     version=dist_version,
     license=__license__,
@@ -95,16 +103,28 @@
         'Documentation': 'http://www2.microstrategy.com/producthelp/Current/mstrio-py/',
         'Source Code': 'https://github.com/MicroStrategy/mstrio-py',
         'Quick Manual': 'https://www2.microstrategy.com/producthelp/current/MSTR-for-Jupyter/Content/mstr_for_jupyter.htm',  # noqa
     },
     install_requires=requirements,
     extras_require={
         'dev': [
-            'flake8', 'mypy', 'yapf', 'nose', 'coverage', 'pytest', 'pytest-cov', 'isort',
-            'pre-commit', 'flaky', 'python-decouple'
+            'flake8',
+            'mypy',
+            'yapf',
+            'nose',
+            'coverage',
+            'pytest',
+            'pytest-cov',
+            'isort',
+            'pre-commit',
+            'flaky',
+            'python-decouple',
+            'black',
+            'flake8-black',
+            'build',
         ],  # noqa
     },
     packages=find_packages(),
     include_package_data=True,
     classifiers=[
         'Natural Language :: English',
         'Operating System :: OS Independent',
```

### Comparing `mstrio-py-11.3.9.101/workflows/add_email_to_new_users.py` & `mstrio-py-11.3.9.103/workflows/add_email_to_new_users.py`

 * *Files 4% similar despite different names*

```diff
@@ -5,15 +5,17 @@
 
 from typing import List
 
 from mstrio.connection import Connection, get_connection
 from mstrio.users_and_groups import list_users, User
 
 
-def add_email_to_new_users(connection: "Connection", domain="microstrategy.com") -> List["User"]:
+def add_email_to_new_users(
+    connection: "Connection", domain="microstrategy.com"
+) -> List["User"]:
     """Add email address with a form `{username}@microstrategy.com`
     to every user which is enabled but doesn't have an email address.
     For each successfully added email address a message will be printed.
 
     Args:
         connection: MicroStrategy connection object returned by
             `connection.Connection()`
```

### Comparing `mstrio-py-11.3.9.101/workflows/delete_addresses_from_departed_users.py` & `mstrio-py-11.3.9.103/workflows/delete_addresses_from_departed_users.py`

 * *Files 11% similar despite different names*

```diff
@@ -25,15 +25,17 @@
         # remove all email addresses from the given user
         if user_.addresses:
             for address in user_.addresses:
                 user_.remove_address(id=address['id'])
 
                 removed_addresses.append(
                     {
-                        'user_id': user_.id, 'username': user_.username, 'address': address
+                        'user_id': user_.id,
+                        'username': user_.username,
+                        'address': address,
                     }
                 )
     return removed_addresses
 
 
 # connect to environment without providing user credentials
 # variable `workstationData` is stored within Workstation
```

### Comparing `mstrio-py-11.3.9.101/workflows/delete_inactive_cube_caches.py` & `mstrio-py-11.3.9.103/workflows/delete_inactive_cube_caches.py`

 * *Files 1% similar despite different names*

```diff
@@ -33,16 +33,18 @@
     """
     connection._validate_project_selected()
     caches = list_cube_caches(connection, nodes)
     # delete caches which fulfill requirements to be treated as inactive
     deleted_caches = []
     for cache in caches:
         today = datetime.now(timezone.utc)
-        if (cache.hit_count == 0
-                and (today - _get_datetime(cache.last_update_time)).days > days_diff):
+        if (
+            cache.hit_count == 0
+            and (today - _get_datetime(cache.last_update_time)).days > days_diff
+        ):
             cache.delete(force=True)
             deleted_caches.append(cache)
 
     return deleted_caches
 
 
 # connect to environment without providing user credentials
```

### Comparing `mstrio-py-11.3.9.101/workflows/delete_subscriptions_of_departed_users.py` & `mstrio-py-11.3.9.103/workflows/delete_subscriptions_of_departed_users.py`

 * *Files 5% similar despite different names*

```diff
@@ -33,15 +33,16 @@
             msg += f" in project {project_['name']} with ID: {project_['id']}"
             # call of the function below returns True if all passed
             # subscriptions were deleted
             if sub_manager.delete(subscriptions=subs, force=True):
                 print("All " + msg + " were deleted.", flush=True)
             else:
                 print(
-                    "Not all " + msg + " were deleted or there was no subscriptions.", flush=True
+                    "Not all " + msg + " were deleted or there was no subscriptions.",
+                    flush=True,
                 )
 
 
 # connect to environment without providing user credentials
 # variable `workstationData` is stored within Workstation
 conn = get_connection(workstationData, 'MicroStrategy Tutorial')
```

### Comparing `mstrio-py-11.3.9.101/workflows/get_all_columns_in_table.py` & `mstrio-py-11.3.9.103/workflows/get_all_columns_in_table.py`

 * *Files 4% similar despite different names*

```diff
@@ -35,24 +35,29 @@
 
     def unpack(table_res):
         columns_list_dict = table_res['physicalTable']['columns']
         return [
             SchemaObjectReference(
                 col['information']['subType'],
                 col['information']['objectId'],
-                col['information']['name']
-            ) for col in columns_list_dict
+                col['information']['name'],
+            )
+            for col in columns_list_dict
         ]
 
     if table:
         table_id = table if isinstance(table, str) else table.object_id
-        table_res = tables.get_table(connection, table_id, project_id=connection.project_id).json()
+        table_res = tables.get_table(
+            connection, table_id, project_id=connection.project_id
+        ).json()
         return {table_res['information']['name']: unpack(table_res)}
     else:
-        table_res = tables.get_tables(connection, project_id=connection.project_id).json()
+        table_res = tables.get_tables(
+            connection, project_id=connection.project_id
+        ).json()
         ids = [tab['information']['objectId'] for tab in table_res['tables']]
         tables_async = async_get(tables.get_table_async, connection, ids)
         return {table['information']['name']: unpack(table) for table in tables_async}
 
 
 # connect to environment without providing user credentials
 # variable `workstationData` is stored within Workstation
```

### Comparing `mstrio-py-11.3.9.101/workflows/list_active_user_privileges.py` & `mstrio-py-11.3.9.103/workflows/list_active_user_privileges.py`

 * *Files 5% similar despite different names*

```diff
@@ -23,15 +23,18 @@
         }
     """
     all_users = list_users(connection=connection)
     active_users = [u for u in all_users if u.enabled]
     privileges_list = []
     for usr in active_users:
         p = {
-            'id': usr.id, 'name': usr.name, 'username': usr.username, 'privileges': usr.privileges
+            'id': usr.id,
+            'name': usr.name,
+            'username': usr.username,
+            'privileges': usr.privileges,
         }
         print(f"{p['name']} ({p['username']}) ", flush=True)
         for prvlg in p['privileges']:
             print("\t" + prvlg['privilege']['name'], flush=True)
         privileges_list.append(p)
     return privileges_list
```

### Comparing `mstrio-py-11.3.9.101/workflows/list_empty_user_groups.py` & `mstrio-py-11.3.9.103/workflows/list_empty_user_groups.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,17 @@
     """List empty user groups.
 
     Args:
         connection: MicroStrategy connection object returned by
             `connection.Connection()`
     """
     all_user_groups = list_user_groups(connection=connection)
-    return [user_group_ for user_group_ in all_user_groups if not user_group_.list_members()]
+    return [
+        user_group_ for user_group_ in all_user_groups if not user_group_.list_members()
+    ]
 
 
 # connect to environment without providing user credentials
 # variable `workstationData` is stored within Workstation
 conn = get_connection(workstationData, 'MicroStrategy Tutorial')
 
 # get empty user groups
```

### Comparing `mstrio-py-11.3.9.101/workflows/list_security_roles_per_user.py` & `mstrio-py-11.3.9.103/workflows/list_security_roles_per_user.py`

 * *Files 5% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 from mstrio.users_and_groups import User, UserGroup
 
 
 def list_security_roles_per_user(
     connection: "Connection",
     user_group_name: str = None,
     user_group_id: str = None,
-    include_user_groups: bool = False
+    include_user_groups: bool = False,
 ) -> List[dict]:
     """List security roles for every user in a user group.
     It is possible to provide either name or id of user group.
 
     Args:
         connection: MicroStrategy connection object returned by
             `connection.Connection()`
@@ -32,15 +32,17 @@
             'id' - id of object
             'name' - name of object
             'username' - username of user (for user group it is None)
             'security_roles' - list of security roles which object has
         }
     """
 
-    user_group_ = UserGroup(connection=connection, name=user_group_name, id=user_group_id)
+    user_group_ = UserGroup(
+        connection=connection, name=user_group_name, id=user_group_id
+    )
     all_security_roles = []
     for member in user_group_.list_members():
         if not member.get('fullName', None):
             if not include_user_groups:
                 continue
             member_type = 'user_group'
             tmp_ug = UserGroup(connection=connection, id=member['id'])
@@ -50,15 +52,15 @@
             tmp_u = User(connection=connection, id=member['id'])
             security_roles = tmp_u.security_roles
         m = {
             'type': member_type,
             'id': member['id'],
             'name': member['name'],
             'username': member.get('username', None),
-            'security_roles': security_roles
+            'security_roles': security_roles,
         }
         print('Security roles:', flush=True)
         for project_ in m['security_roles']:
             print("\tProject: " + project_['name'], flush=True)
             for sec_role in project_['securityRoles']:
                 print("\t\t" + sec_role['name'], flush=True)
         all_security_roles.append(m)
```

